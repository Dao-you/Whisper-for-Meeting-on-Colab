{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPVNdNTz+oKSM+L/WyGH3V3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1564fadc93cb47258fb24d74c5214e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37a4b92fa712448881d3cdae1804721e",
              "IPY_MODEL_616e9b69038643d5b8a486e06b0d9eb7",
              "IPY_MODEL_12c41eb6345743c2b13e7c154339e4a5"
            ],
            "layout": "IPY_MODEL_50a445d112cc421ab44d2b9bbae61dd5"
          }
        },
        "37a4b92fa712448881d3cdae1804721e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1945236303394653b4d948a71249655a",
            "placeholder": "​",
            "style": "IPY_MODEL_579c1d04c4294f02863c8935c689fdbd",
            "value": "preprocessor_config.json: 100%"
          }
        },
        "616e9b69038643d5b8a486e06b0d9eb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5afc8f51b1b43f2bad1ee9fa11106b2",
            "max": 340,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_06f32deb89054f1f81662dd32bf48d48",
            "value": 340
          }
        },
        "12c41eb6345743c2b13e7c154339e4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ecf9e19c5a4414eac74b9d989bdc6b6",
            "placeholder": "​",
            "style": "IPY_MODEL_e6d70e1c30a4452986e634a0e0a4b7c0",
            "value": " 340/340 [00:00&lt;00:00, 16.1kB/s]"
          }
        },
        "50a445d112cc421ab44d2b9bbae61dd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1945236303394653b4d948a71249655a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "579c1d04c4294f02863c8935c689fdbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5afc8f51b1b43f2bad1ee9fa11106b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06f32deb89054f1f81662dd32bf48d48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7ecf9e19c5a4414eac74b9d989bdc6b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6d70e1c30a4452986e634a0e0a4b7c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1704c3adb542403daa6c5fcd88b68573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c1ada565d1f34cdba81621fe31a9fda6",
              "IPY_MODEL_6ccb5d7166ff403b8b4c90641c94b0f1",
              "IPY_MODEL_68f9c9c396144256a527c46809331f29"
            ],
            "layout": "IPY_MODEL_302c4bf146584c05a87025656cbe64ae"
          }
        },
        "c1ada565d1f34cdba81621fe31a9fda6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92682e36a9cb450b95fb3283f47be2ae",
            "placeholder": "​",
            "style": "IPY_MODEL_681a9c16a72d407ba1bbf71b84513359",
            "value": "vocabulary.json: "
          }
        },
        "6ccb5d7166ff403b8b4c90641c94b0f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4acfbe4811554b12a1b708dac3dc0a0f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1985a6be6599498889e1c2627a5805de",
            "value": 1
          }
        },
        "68f9c9c396144256a527c46809331f29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96c9d86c400f4f4188f40cf540505732",
            "placeholder": "​",
            "style": "IPY_MODEL_4a1d8834277c4b008c01532ce94821fb",
            "value": " 1.07M/? [00:00&lt;00:00, 20.5MB/s]"
          }
        },
        "302c4bf146584c05a87025656cbe64ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92682e36a9cb450b95fb3283f47be2ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "681a9c16a72d407ba1bbf71b84513359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4acfbe4811554b12a1b708dac3dc0a0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1985a6be6599498889e1c2627a5805de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96c9d86c400f4f4188f40cf540505732": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a1d8834277c4b008c01532ce94821fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ca4fe1da6cd14b1daca42e73924209b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf52035b8aa14d008967415bae3fc2ab",
              "IPY_MODEL_2478eba1b77a473d8942305898273e0c",
              "IPY_MODEL_3e9c540784034a2aaf795c4621370f03"
            ],
            "layout": "IPY_MODEL_3bff6412e2a346b688285581dbd55fb9"
          }
        },
        "bf52035b8aa14d008967415bae3fc2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c6f787cc32149d7a773e40f6795bd5f",
            "placeholder": "​",
            "style": "IPY_MODEL_a0298322cea84cf09462d83f881466d1",
            "value": "tokenizer.json: "
          }
        },
        "2478eba1b77a473d8942305898273e0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb0efe9d451741d9abdcf0300cafaf19",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1f7b3d10e4ca4c4088dc191d3e14a2b0",
            "value": 1
          }
        },
        "3e9c540784034a2aaf795c4621370f03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fb61bc2b84a4cb4a0a71290569891eb",
            "placeholder": "​",
            "style": "IPY_MODEL_d5ee299dace344db8e2bbc838006f87e",
            "value": " 2.48M/? [00:00&lt;00:00, 32.9MB/s]"
          }
        },
        "3bff6412e2a346b688285581dbd55fb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c6f787cc32149d7a773e40f6795bd5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0298322cea84cf09462d83f881466d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb0efe9d451741d9abdcf0300cafaf19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "1f7b3d10e4ca4c4088dc191d3e14a2b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fb61bc2b84a4cb4a0a71290569891eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5ee299dace344db8e2bbc838006f87e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "198e13ae302845f4b087e5f5229d98a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_406ce394133a43f884b51eb82d9b3d28",
              "IPY_MODEL_ba20062b8f3943f7857202ef085ab2af",
              "IPY_MODEL_7d929da5ad104f868e2d31d8e38f79a0"
            ],
            "layout": "IPY_MODEL_0ec622a496b74200aaaebeb4932273b5"
          }
        },
        "406ce394133a43f884b51eb82d9b3d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_850bcb0854e64a79b47cf8e6bb82a39f",
            "placeholder": "​",
            "style": "IPY_MODEL_d668a267c4cf4ed2aa57475a62c22f5c",
            "value": "model.bin: 100%"
          }
        },
        "ba20062b8f3943f7857202ef085ab2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a2a795fc3964570b34ba7f1ac295b55",
            "max": 3087284237,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_798fdac0fe8149a88d9024156a462f7a",
            "value": 3087284237
          }
        },
        "7d929da5ad104f868e2d31d8e38f79a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ece5871ea32141ee97e73348a85bf9db",
            "placeholder": "​",
            "style": "IPY_MODEL_7d854b340ad64a6ea95b09d506c89032",
            "value": " 3.09G/3.09G [00:55&lt;00:00, 88.0MB/s]"
          }
        },
        "0ec622a496b74200aaaebeb4932273b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "850bcb0854e64a79b47cf8e6bb82a39f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d668a267c4cf4ed2aa57475a62c22f5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a2a795fc3964570b34ba7f1ac295b55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "798fdac0fe8149a88d9024156a462f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ece5871ea32141ee97e73348a85bf9db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d854b340ad64a6ea95b09d506c89032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d7b2a8d77258494f8457cb9dce734f24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3694133570964ce39a66238bcc3a57af",
              "IPY_MODEL_65da845ed9074aa5af0cb66efa14aed4",
              "IPY_MODEL_00ab2f80a1e84958be2377176ad31353"
            ],
            "layout": "IPY_MODEL_951a27ac40fd4e8e9b5111c513bd557d"
          }
        },
        "3694133570964ce39a66238bcc3a57af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d492c41a8060471783027613374a9d4e",
            "placeholder": "​",
            "style": "IPY_MODEL_7609d0567151435d93e7a7a683f8cd33",
            "value": "config.json: "
          }
        },
        "65da845ed9074aa5af0cb66efa14aed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f99295ff35ae40ec8055bb9478823c4c",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e20eafa7fd6e467cb16828efcb20557b",
            "value": 1
          }
        },
        "00ab2f80a1e84958be2377176ad31353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d185afb010e74650bf89081d9fc10b26",
            "placeholder": "​",
            "style": "IPY_MODEL_0396995662e240d4bf368f3f67e3ead5",
            "value": " 2.39k/? [00:00&lt;00:00, 217kB/s]"
          }
        },
        "951a27ac40fd4e8e9b5111c513bd557d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d492c41a8060471783027613374a9d4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7609d0567151435d93e7a7a683f8cd33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f99295ff35ae40ec8055bb9478823c4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "e20eafa7fd6e467cb16828efcb20557b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d185afb010e74650bf89081d9fc10b26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0396995662e240d4bf368f3f67e3ead5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03679313e38c4c0ba18e9bfec031beba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_86f0a340d9254bd98be02af00112c19f",
              "IPY_MODEL_d05dad97913d4ab0a00d51704d23a6d1",
              "IPY_MODEL_77ae3eaa29544dcc8ddf2f67a35b4abf"
            ],
            "layout": "IPY_MODEL_73f871f1f1aa44db8a91f029d07eab01"
          }
        },
        "86f0a340d9254bd98be02af00112c19f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcbb711d8ea94e37975b83adf501d464",
            "placeholder": "​",
            "style": "IPY_MODEL_be00a9ad739f49e79e6522d33101d9e4",
            "value": "Fetching 1 files: 100%"
          }
        },
        "d05dad97913d4ab0a00d51704d23a6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2137ee94b63b4450b4e569a351f03161",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d33cd7cfde5145e192df1fd8496a9ac1",
            "value": 1
          }
        },
        "77ae3eaa29544dcc8ddf2f67a35b4abf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_221840795acc49b48bad748bb55e5e6f",
            "placeholder": "​",
            "style": "IPY_MODEL_a03672df0ec24fd681888898c238ffad",
            "value": " 1/1 [08:03&lt;00:00, 483.27s/it]"
          }
        },
        "73f871f1f1aa44db8a91f029d07eab01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcbb711d8ea94e37975b83adf501d464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be00a9ad739f49e79e6522d33101d9e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2137ee94b63b4450b4e569a351f03161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d33cd7cfde5145e192df1fd8496a9ac1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "221840795acc49b48bad748bb55e5e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a03672df0ec24fd681888898c238ffad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ece8f8cf5e204ef888b582888b6630a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_457c30be1bd240978e1a004c7f7f742d",
              "IPY_MODEL_3dd11ad8896844a3914282ad5d214656",
              "IPY_MODEL_6f6e1fd3552348d49062340242d4eb46"
            ],
            "layout": "IPY_MODEL_c8e14e9335744935a418efa2ac291580"
          }
        },
        "457c30be1bd240978e1a004c7f7f742d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db7dd6f122b34438987d7ef5174209a1",
            "placeholder": "​",
            "style": "IPY_MODEL_f013a30d92af467a932c4193990aec19",
            "value": "gpt-oss-20b-Q4_K_M.gguf: 100%"
          }
        },
        "3dd11ad8896844a3914282ad5d214656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_104ab3e9ba2d43858671872d8bc2ebcc",
            "max": 11624759488,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e27acefe56ee4fd0bbe64fbdd9fcb289",
            "value": 11624759488
          }
        },
        "6f6e1fd3552348d49062340242d4eb46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ddb3c5fcf6c465f88bfdbd08c06085a",
            "placeholder": "​",
            "style": "IPY_MODEL_c9b2f4f98f0c456cbad4b8a23e21471e",
            "value": " 11.6G/11.6G [08:02&lt;00:00, 24.2MB/s]"
          }
        },
        "c8e14e9335744935a418efa2ac291580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db7dd6f122b34438987d7ef5174209a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f013a30d92af467a932c4193990aec19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "104ab3e9ba2d43858671872d8bc2ebcc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e27acefe56ee4fd0bbe64fbdd9fcb289": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ddb3c5fcf6c465f88bfdbd08c06085a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b2f4f98f0c456cbad4b8a23e21471e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f145246fe0c4ec39d57b620556528d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ba1445af6a04d6993a5b8f699ab54dd",
              "IPY_MODEL_44936da86ad04f09897756c1814e13d9",
              "IPY_MODEL_210cb9c5190048ed92c46ac847cc1059"
            ],
            "layout": "IPY_MODEL_7879a598aeb94f08945a3f00bc694d94"
          }
        },
        "6ba1445af6a04d6993a5b8f699ab54dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac2bca7bb35b452e90bfcd1dab7f6744",
            "placeholder": "​",
            "style": "IPY_MODEL_3e9487be9bb445fe914ff92254d86869",
            "value": "Fetching 1 files: 100%"
          }
        },
        "44936da86ad04f09897756c1814e13d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_912464d86c4346f79558f43da65ac8ba",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6c15def5dd1414381faad3a71324c44",
            "value": 1
          }
        },
        "210cb9c5190048ed92c46ac847cc1059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e8b014908464d69aa5357dd0c5caf0c",
            "placeholder": "​",
            "style": "IPY_MODEL_a5cd0f452523415686f4dc25bdfb6a2a",
            "value": " 1/1 [00:00&lt;00:00, 72.22it/s]"
          }
        },
        "7879a598aeb94f08945a3f00bc694d94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac2bca7bb35b452e90bfcd1dab7f6744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e9487be9bb445fe914ff92254d86869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "912464d86c4346f79558f43da65ac8ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6c15def5dd1414381faad3a71324c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e8b014908464d69aa5357dd0c5caf0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5cd0f452523415686f4dc25bdfb6a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "da0d61306b9240d5b25a4d5e122d34c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c165005ad8a04e0586cbf4e10938ad89",
              "IPY_MODEL_f010932a6b3040f985e1080dada2b1dc",
              "IPY_MODEL_cc8e0587711f45ed9f77050e6afc8542"
            ],
            "layout": "IPY_MODEL_eacc7017b0ab442eb15490167801c498"
          }
        },
        "c165005ad8a04e0586cbf4e10938ad89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a3feeee7e2149dbb6cf1c3052a02570",
            "placeholder": "​",
            "style": "IPY_MODEL_bb49827449354984b5a8ddc299525ade",
            "value": "Fetching 1 files: 100%"
          }
        },
        "f010932a6b3040f985e1080dada2b1dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be1c2c68245a49ee96a6665f3deb5232",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b763cfafc4b147e096d3da07a8ab1de7",
            "value": 1
          }
        },
        "cc8e0587711f45ed9f77050e6afc8542": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01deb4c750ca4f6c94e14864acec0b8e",
            "placeholder": "​",
            "style": "IPY_MODEL_f32ee0c8c032431eaa2a844d79ea8424",
            "value": " 1/1 [00:00&lt;00:00, 94.64it/s]"
          }
        },
        "eacc7017b0ab442eb15490167801c498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a3feeee7e2149dbb6cf1c3052a02570": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb49827449354984b5a8ddc299525ade": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be1c2c68245a49ee96a6665f3deb5232": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b763cfafc4b147e096d3da07a8ab1de7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "01deb4c750ca4f6c94e14864acec0b8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f32ee0c8c032431eaa2a844d79ea8424": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01d270dbeee74c69807db8c6edc37af3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18fc30067529421b8958a7a099df429f",
              "IPY_MODEL_c5abda77104f4809bb0c047a4493d814",
              "IPY_MODEL_73e40fb1b2b14f8f96f0ecd1a3be7bb0"
            ],
            "layout": "IPY_MODEL_7bc67d206d9c4f7b9e0f2889ef07762c"
          }
        },
        "18fc30067529421b8958a7a099df429f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7336b7e7dc3c4c7f98673f72a997c7ce",
            "placeholder": "​",
            "style": "IPY_MODEL_5966fe6e47cd40cdab4a1e0b5c306c66",
            "value": "Fetching 1 files: 100%"
          }
        },
        "c5abda77104f4809bb0c047a4493d814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd46c9ad25474b688f257c4c23320b50",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a01b2b0d65ee4e408c943c89d05031e0",
            "value": 1
          }
        },
        "73e40fb1b2b14f8f96f0ecd1a3be7bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94f3a1ee69c2439d944ae1c6f51b0a79",
            "placeholder": "​",
            "style": "IPY_MODEL_a80fe84c33a042c7b6419a58ab2f9b5e",
            "value": " 1/1 [00:00&lt;00:00, 64.52it/s]"
          }
        },
        "7bc67d206d9c4f7b9e0f2889ef07762c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7336b7e7dc3c4c7f98673f72a997c7ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5966fe6e47cd40cdab4a1e0b5c306c66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cd46c9ad25474b688f257c4c23320b50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a01b2b0d65ee4e408c943c89d05031e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94f3a1ee69c2439d944ae1c6f51b0a79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a80fe84c33a042c7b6419a58ab2f9b5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2522ae85bd99479a95953834e70aa67d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_60d250c7936a42fc8a22eaf8e1554412",
              "IPY_MODEL_908b949fc9df47cca76fdf38b7265f3a",
              "IPY_MODEL_8f320e06792d4826980b9102f129b5d5"
            ],
            "layout": "IPY_MODEL_cc8daa865afb45d5b2e091fe5399baa3"
          }
        },
        "60d250c7936a42fc8a22eaf8e1554412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_683d373a753e4812861b0d55886fdf78",
            "placeholder": "​",
            "style": "IPY_MODEL_e2f3b6838bbf4c57a130874e3b0faeb0",
            "value": "Fetching 1 files: 100%"
          }
        },
        "908b949fc9df47cca76fdf38b7265f3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_103313f38c444e3a864dab25bb327e9f",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a05bfdec839349a8b72e4e41e78060a3",
            "value": 1
          }
        },
        "8f320e06792d4826980b9102f129b5d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f7248dc94704d50a054e704d67b7e54",
            "placeholder": "​",
            "style": "IPY_MODEL_be36a527b6eb41cfaa37bfea98ad38c5",
            "value": " 1/1 [00:00&lt;00:00, 62.96it/s]"
          }
        },
        "cc8daa865afb45d5b2e091fe5399baa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "683d373a753e4812861b0d55886fdf78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2f3b6838bbf4c57a130874e3b0faeb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "103313f38c444e3a864dab25bb327e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a05bfdec839349a8b72e4e41e78060a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f7248dc94704d50a054e704d67b7e54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be36a527b6eb41cfaa37bfea98ad38c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae82c25f33084774bf7b06bde73c997d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_565ede674ed94d62bf3b47bc94773039",
              "IPY_MODEL_aea8e34970264fef85549630f4360e4c",
              "IPY_MODEL_2bba020ca5d44ad4be4a39cbf92375c6"
            ],
            "layout": "IPY_MODEL_dcb3c4d76cbd4142bb4865f591f4768f"
          }
        },
        "565ede674ed94d62bf3b47bc94773039": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c075ecfb7324b42af680edb704258dc",
            "placeholder": "​",
            "style": "IPY_MODEL_905870b83d344d3a9dfc1d32de45ecd0",
            "value": "Fetching 1 files: 100%"
          }
        },
        "aea8e34970264fef85549630f4360e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_699da63442f24116b809006f7c43000b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3c0d0dee82a4660a818d83780a64ef1",
            "value": 1
          }
        },
        "2bba020ca5d44ad4be4a39cbf92375c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e136d17ce8b34967afa139602ac837b1",
            "placeholder": "​",
            "style": "IPY_MODEL_9bf0b980ce274095a1ad49df83670c06",
            "value": " 1/1 [00:00&lt;00:00, 86.89it/s]"
          }
        },
        "dcb3c4d76cbd4142bb4865f591f4768f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c075ecfb7324b42af680edb704258dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "905870b83d344d3a9dfc1d32de45ecd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "699da63442f24116b809006f7c43000b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3c0d0dee82a4660a818d83780a64ef1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e136d17ce8b34967afa139602ac837b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9bf0b980ce274095a1ad49df83670c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dao-you/Whisper-for-Meeting-on-Colab/blob/main/Whisper_for_Meeting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYlqmtJfD3Sd"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Whisper Automatic Subtitle Generation: GPU Transcription + CPU Denoising + OpenCC Post-processing (Traditional/Simplified Conversion)\n",
        "# - Transcription: faster-whisper (CUDA, compute: int8_float16→float16→int8)\n",
        "# - Denoising: ffmpeg afftdn (CPU)\n",
        "# - Progress: Real-time printing of \"current sentence + video total length percentage\"\n",
        "# - Network source download and output: MyDrive/whisper; Files in Drive: Output to the same folder\n",
        "# - Prompts \"Delete runtime and restart\" if download is blocked or abnormal\n",
        "# =========================================================\n",
        "\n",
        "# Restrict multithreading (more stable)\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# [1/8] Mount Google Drive\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "except:\n",
        "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "import sys, gc, shutil, datetime, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\"/content/gdrive/MyDrive\")\n",
        "WHISPER_DIR = ROOT / \"whisper\"\n",
        "WHISPER_DIR.mkdir(exist_ok=True, parents=True)\n",
        "os.chdir(ROOT)\n",
        "print(f\"→ 當前工作目錄：{os.getcwd()}\")\n",
        "\n",
        "# [2/8] User Form Parameters\n",
        "#@title Whisper / Faster-Whisper（GPU 轉錄 + CPU 降噪 + OpenCC）\n",
        "#@markdown # 輸入雲端硬碟檔案（相對於 MyDrive）或影片網址（YouTube/HTTP）\n",
        "filename = \"whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\"  #@param {type:\"string\"}\n",
        "#@markdown ✔ 網路來源是否另存到 MyDrive/whisper\n",
        "save_video_to_google_drive = True  #@param {type:\"boolean\"}\n",
        "#@markdown # 模型（GPU 可用 large-v3；若 VRAM 吃緊可降 medium）\n",
        "model_size = \"large-v3\"  #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\"]\n",
        "#@markdown # 語言（不翻譯，只轉錄）\n",
        "language = \"自動偵測\"  #@param [\"自動偵測\", \"中文\", \"英文\"]\n",
        "#@markdown # 降噪方法（CPU）\n",
        "denoise_method = \"afftdn (建議)\"  #@param [\"afftdn (建議)\", \"none\"]\n",
        "#@markdown # 文字正規化：OpenCC 轉換（套用在輸出 SRT/TXT）\n",
        "text_postprocess = \"臺灣繁體中文（預設）\"  #@param [\"臺灣繁體中文（預設）\",\"香港繁體中文\",\"大陸簡體中文\",\"關閉\"]\n",
        "#@markdown （選填）YouTube cookies 檔（相對 MyDrive；Netscape 格式，如 `cookies/youtube.txt`）\n",
        "youtube_cookies_txt_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "language_code_map = {\"自動偵測\": None, \"中文\":\"zh\", \"英文\":\"en\"}\n",
        "language_code = language_code_map[language]\n",
        "\n",
        "# Developer Options (Do not put in Markdown form)\n",
        "# These options allow fine-tuning parameters without affecting normal operation.\n",
        "DEBUG_MODE = False # Set to True for more detailed logging\n",
        "\n",
        "# --- Transcription Parameters ---\n",
        "TRANSCRIPTION_BEAM_SIZE_PRIMARY = 3\n",
        "TRANSCRIPTION_CHUNK_LENGTH_PRIMARY = 20\n",
        "TRANSCRIPTION_BEAM_SIZE_FALLBACK = 1 # Used if primary fails\n",
        "TRANSCRIPTION_CHUNK_LENGTH_FALLBACK = 15 # Used if primary fails\n",
        "\n",
        "# --- Denoising Parameters ---\n",
        "DENOISE_NOISE_FLOOR_DB = -25\n",
        "\n",
        "# --- Filtering Parameters ---\n",
        "FILTER_MIN_DURATION_SHORT = 1.5 # Minimum duration for short segments\n",
        "FILTER_AVG_LOGPROB_THRESHOLD = -1.0 # Avg log probability threshold for short segments\n",
        "FILTER_MIN_DURATION_SPEECH_PROB = 2.0 # Minimum duration for speech probability filtering\n",
        "FILTER_NO_SPEECH_PROB_THRESHOLD = 0.6 # No speech probability threshold\n",
        "\n",
        "# [3/8] Install Dependencies\n",
        "if DEBUG_MODE: print(\"[Install] faster-whisper / yt-dlp / soundfile / opencc ...\")\n",
        "!pip -q install -U faster-whisper yt-dlp soundfile opencc-python-reimplemented > /dev/null\n",
        "\n",
        "import soundfile as sf\n",
        "from faster_whisper import WhisperModel\n",
        "from opencc import OpenCC\n",
        "\n",
        "# ---------- Utility Functions ----------\n",
        "def suggest_runtime_reset():\n",
        "    print(\"\\n🧹 建議動作（Colab）\")\n",
        "    print(\"1) 依序：『執行階段 Runtime』 → 『刪除執行階段/還原出廠設定 Factory reset runtime』\")\n",
        "    print(\"2) 重新執行本 Notebook（從掛載雲端硬碟那格開始）\\n\", flush=True)\n",
        "\n",
        "def run_cmd(cmd:list, check=True):\n",
        "    if DEBUG_MODE: print(\"  $\", \" \".join(cmd))\n",
        "    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"命令失敗：{' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "def is_youtube_url(s:str)->bool:\n",
        "    return isinstance(s, str) and (\"youtu.be\" in s or \"youtube.com\" in s)\n",
        "def is_http_url(s:str)->bool:\n",
        "    return isinstance(s, str) and s.lower().startswith(\"http\")\n",
        "def to_abs_mydrive(p:str)->Path:\n",
        "    return (Path(p) if p.startswith(\"/\") else (ROOT / p)).resolve()\n",
        "def fmt_ts_srt(t:float)->str:\n",
        "    h = int(t//3600); m = int((t%3600)//60); s = t - h*3600 - m*60\n",
        "    return f\"{h:02d}:{m:02d}:{int(s):02d},{int(round((s-int(s))*1000)):03d}\"\n",
        "def verify_wav_ok(path: Path)->bool:\n",
        "    try:\n",
        "        info = sf.info(str(path))\n",
        "        return info.samplerate > 0 and info.channels in (1, 2)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# OpenCC converter setup\n",
        "def build_opencc_pipeline(choice:str):\n",
        "    if choice.startswith(\"臺灣\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2tw')]\n",
        "    if choice.startswith(\"香港\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2hk')]\n",
        "    if choice.startswith(\"大陸\"):\n",
        "        return [OpenCC('t2s')]\n",
        "    return []  # Disable\n",
        "\n",
        "def apply_opencc(text:str, pipeline)->str:\n",
        "    for cc in pipeline:\n",
        "        text = cc.convert(text)\n",
        "    return text\n",
        "\n",
        "def ytdl(yturl:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    cmd = [\"yt-dlp\", \"-f\", \"mp4\", \"-o\", str(tmp / \"%(title)s.%(ext)s\")]\n",
        "    if youtube_cookies_txt_path.strip():\n",
        "        cookies_abs = to_abs_mydrive(youtube_cookies_txt_path.strip())\n",
        "        if cookies_abs.exists():\n",
        "            cmd += [\"--cookies\", str(cookies_abs)]\n",
        "        else:\n",
        "            if DEBUG_MODE: print(f\"⚠️ 找不到 cookies 檔：{cookies_abs}（改為不帶 cookies）\")\n",
        "    cmd.append(yturl)\n",
        "    if DEBUG_MODE: print(\"[Download] Getting YouTube video ...\")\n",
        "    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        if \"Sign in to confirm\" in (p.stdout or \"\"):\n",
        "            print(\"\\n❗YouTube 要求登入/驗證，請提供 cookies 或先自行下載到雲端硬碟。\")\n",
        "        print(\"🔄 若多次失敗，請刪除執行階段並重啟後重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise RuntimeError(\"yt-dlp 下載失敗\")\n",
        "    files = list(tmp.glob(\"*\"))\n",
        "    if not files:\n",
        "        print(\"🔄 下載為空，建議刪除執行階段再重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise FileNotFoundError(\"YouTube 下載失敗：/tmp/dl 為空\")\n",
        "    f = files[0]\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(f, WHISPER_DIR / f.name)\n",
        "    return f\n",
        "\n",
        "def http_dl(url:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting HTTP(S) video ...\")\n",
        "    run_cmd([\"curl\", \"-L\", \"-o\", str(out), url])\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(out, WHISPER_DIR / out.name)\n",
        "    return out\n",
        "\n",
        "# Extract audio: ffmpeg -> 16k/mono WAV\n",
        "def ffmpeg_extract_wav(in_path:Path, out_wav:Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-vn\",\"-ac\",\"1\",\"-ar\",str(sr),\"-f\",\"wav\",str(out_wav)]\n",
        "    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout);\n",
        "        raise RuntimeError(\"ffmpeg 轉 WAV 失敗\")\n",
        "\n",
        "# CPU Denoising: ffmpeg afftdn\n",
        "def ffmpeg_afftdn(in_wav: Path, out_wav: Path, noise_floor_db=DENOISE_NOISE_FLOOR_DB):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-af\",f\"afftdn=nf={noise_floor_db}\",\n",
        "           \"-ac\",\"1\",\"-ar\",\"16000\",\"-f\",\"wav\",str(out_wav)]\n",
        "    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout);\n",
        "        raise RuntimeError(\"ffmpeg afftdn 失敗\")\n",
        "\n",
        "# Safeguard: Repack WAV header if format is strange\n",
        "def ffmpeg_repack_wav(in_wav: Path, out_wav: Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-acodec\",\"pcm_s16le\",\"-ac\",\"1\",\"-ar\",str(sr),str(out_wav)]\n",
        "    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout);\n",
        "        raise RuntimeError(\"ffmpeg 重包 WAV 失敗\")\n",
        "\n",
        "# [4/8] Parse Source\n",
        "if DEBUG_MODE: print(\"[4/8] Parsing input source ...\")\n",
        "try:\n",
        "    if is_youtube_url(filename):\n",
        "        src_path = ytdl(filename); out_base_dir = WHISPER_DIR\n",
        "    elif is_http_url(filename):\n",
        "        src_path = http_dl(filename); out_base_dir = WHISPER_DIR\n",
        "    else:\n",
        "        src_path = to_abs_mydrive(filename)\n",
        "        if not src_path.exists(): raise FileNotFoundError(f\"找不到檔案：{src_path}\")\n",
        "        out_base_dir = src_path.parent\n",
        "except Exception as e:\n",
        "    print(f\"\\n⛔ 來源解析/下載失敗：{e}\")\n",
        "    print(\"🔄 請刪除執行階段並重新啟動後重跑。\"); suggest_runtime_reset(); raise\n",
        "\n",
        "print(f\"→ 來源檔：{src_path}\")\n",
        "print(f\"→ 輸出資料夾：{out_base_dir}\")\n",
        "\n",
        "# [5/8] Extract Audio & CPU Denoising\n",
        "AUDIO_16K = Path(\"/tmp/audio_16k.wav\")\n",
        "if DEBUG_MODE: print(\"[5/8] Extracting audio (ffmpeg → 16k/mono WAV) ...\")\n",
        "ffmpeg_extract_wav(src_path, AUDIO_16K, sr=16000)\n",
        "\n",
        "if denoise_method.startswith(\"afftdn\"):\n",
        "    if DEBUG_MODE: print(\"[5.5/8] Denoising (ffmpeg afftdn, CPU) ...\")\n",
        "    DENOISED = Path(\"/tmp/audio_16k_denoised.wav\")\n",
        "    ffmpeg_afftdn(AUDIO_16K, DENOISED, noise_floor_db=DENOISE_NOISE_FLOOR_DB)\n",
        "    denoised_audio = DENOISED if verify_wav_ok(DENOISED) else AUDIO_16K\n",
        "else:\n",
        "    denoised_audio = AUDIO_16K\n",
        "\n",
        "if not verify_wav_ok(denoised_audio):\n",
        "    if DEBUG_MODE: print(\"  - 音訊格式異常；嘗試重包 WAV ...\")\n",
        "    FIXED = Path(\"/tmp/audio_16k_fixed.wav\")\n",
        "    ffmpeg_repack_wav(denoised_audio, FIXED, sr=16000)\n",
        "    denoised_audio = FIXED\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ 最終輸入音訊：{denoised_audio}\")\n",
        "\n",
        "# [6/8] Load faster-whisper (GPU enforced)\n",
        "if DEBUG_MODE: print(\"[6/8] Loading faster-whisper model (GPU) ...\")\n",
        "device = \"cuda\"  # Enforce GPU\n",
        "model = None; last_err = None\n",
        "for ctype in [\"int8_float16\", \"float16\", \"int8\"]:\n",
        "    try:\n",
        "        if DEBUG_MODE: print(f\"  - Trying compute_type={ctype}\")\n",
        "        model = WhisperModel(model_size, device=device, compute_type=ctype)\n",
        "        if DEBUG_MODE: print(\"  - Model loaded successfully\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        last_err = e; if DEBUG_MODE: print(f\"  - Load failed: {e}\")\n",
        "if model is None:\n",
        "    print(\"\\n⛔ GPU 模型載入失敗。請確認『變更執行階段類型』選了 GPU（T4/A100），或刪除執行階段後重試。\")\n",
        "    suggest_runtime_reset()\n",
        "    raise RuntimeError(f\"無法載入模型：{last_err}\")\n",
        "\n",
        "gc.collect()  # Clean up before transcription (safety)\n",
        "\n",
        "# [7/8] Transcribe (GPU; real-time progress per segment)\n",
        "if DEBUG_MODE: print(f\"[7/8] Starting transcription (GPU: beam={TRANSCRIPTION_BEAM_SIZE_PRIMARY} / chunk={TRANSCRIPTION_CHUNK_LENGTH_PRIMARY}s / no VAD) ...\")\n",
        "\n",
        "def transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY):\n",
        "    return model.transcribe(\n",
        "        str(denoised_audio),\n",
        "        task=\"transcribe\",\n",
        "        language=language_code,\n",
        "        temperature=0.0,\n",
        "        condition_on_previous_text=False,\n",
        "        compression_ratio_threshold=2.4,\n",
        "        log_prob_threshold=-1.0,\n",
        "        no_speech_threshold=0.6,\n",
        "        beam_size=_beam,\n",
        "        chunk_length=_chunk,\n",
        "        vad_filter=False,\n",
        "        word_timestamps=False\n",
        "    )\n",
        "\n",
        "try:\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY)\n",
        "except Exception as e:\n",
        "    if DEBUG_MODE: print(f\"  - First transcription failed: {e}\\n    → Trying more conservative (beam={TRANSCRIPTION_BEAM_SIZE_FALLBACK}, chunk={TRANSCRIPTION_CHUNK_LENGTH_FALLBACK}) ...\")\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_FALLBACK, _chunk=TRANSCRIPTION_CHUNK_LENGTH_FALLBACK)\n",
        "\n",
        "# Display percentage based on total video duration\n",
        "duration = float(getattr(info, \"duration\", 0.0) or 0.0)\n",
        "if duration <= 0: duration = 1.0\n",
        "\n",
        "segments = []\n",
        "filtered = []\n",
        "\n",
        "if DEBUG_MODE:\n",
        "    print(f\"  - Detected language: {getattr(info,'language','未知')} (p={getattr(info,'language_probability',0):.2f})\")\n",
        "    print(f\"  - Audio length: {duration:.2f}s\")\n",
        "\n",
        "for s in seg_iter:\n",
        "    pct = int(min(100, round((s.end / duration) * 100)))\n",
        "    print(f\"[{pct:3d}%] {fmt_ts_srt(s.start)} → {fmt_ts_srt(s.end)}  {s.text.strip()}\", flush=True)\n",
        "    segments.append(s)\n",
        "\n",
        "    # Low confidence/high no-speech short segment filtering (no blacklist)\n",
        "    keep = True\n",
        "    seg_dur = float(s.end - s.start)\n",
        "    if seg_dur < FILTER_MIN_DURATION_SHORT and getattr(s, \"avg_logprob\", None) is not None and s.avg_logprob < FILTER_AVG_LOGPROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if seg_dur < FILTER_MIN_DURATION_SPEECH_PROB and getattr(s, \"no_speech_prob\", None) is not None and s.no_speech_prob > FILTER_NO_SPEECH_PROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if keep:\n",
        "        filtered.append(s)\n",
        "\n",
        "if DEBUG_MODE: print(f\"  - Number of segments: Before filtering {len(segments)} → After filtering {len(filtered)}\")\n",
        "\n",
        "# ---- OpenCC Normalization (for output text) ----\n",
        "pipeline = build_opencc_pipeline(text_postprocess)\n",
        "def norm(txt: str) -> str:\n",
        "    return apply_opencc(txt, pipeline) if pipeline else txt\n",
        "\n",
        "# [8/8] Output (text after OpenCC)\n",
        "print(\"[8/8] 輸出 SRT / TXT ...\")\n",
        "out_dir = out_base_dir; out_dir.mkdir(exist_ok=True, parents=True)\n",
        "stem = src_path.stem\n",
        "SRT = out_dir / f\"{stem}.srt\"; TXT = out_dir / f\"{stem}.txt\"\n",
        "\n",
        "with open(SRT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, s in enumerate(filtered, 1):\n",
        "        text_out = norm(s.text.strip())\n",
        "        f.write(f\"{i}\\n{fmt_ts_srt(s.start)} --> {fmt_ts_srt(s.end)}\\n{text_out}\\n\\n\")\n",
        "\n",
        "with open(TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in filtered:\n",
        "        f.write(norm(s.text.strip()) + \"\\n\")  # Each segment on a new line\n",
        "\n",
        "print(f\"→ 完成！\\n  SRT: {SRT}\\n  TXT: {TXT}\")\n",
        "\n",
        "# Release model (release GPU memory)\n",
        "try: del model\n",
        "except: pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"→ Model released; can run again directly if needed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 🔎 Whisper Transcription Summary (GPT-OSS-20B / llama.cpp / CUDA) 【Only output .md | Retain original installation process, only fix truncated output and system prompt issues】\n",
        "#@markdown - Keep your currently working \"Installation section\" (srt / huggingface_hub / llama-cpp-python with extra-index / source code compilation fallback) general flow and parameters unchanged.\n",
        "#@markdown - Only adjust the \"Inference and output\" logic: **Use the official chat completion normal usage**, **overwrite chat_format='chatml'** (to avoid Unsloth's `<|channel|>` tag overflow), **correct stop sequence**, **increase return limit**, **remove rule cleaning**, and display the generated character count per segment in real-time in the terminal.\n",
        "\n",
        "from pathlib import Path\n",
        "import os, sys, re, math, gc, time, importlib, subprocess as sp, textwrap\n",
        "from typing import List, Tuple\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# ===== User Parameters =====\n",
        "srt_path   = \"\"  #@param {type:\"string\"}\n",
        "topic_hint = \"\"  #@param {type:\"string\"}\n",
        "output_dir = \"/content/gdrive/MyDrive/whisper\"  #@param {type:\"string\"}\n",
        "\n",
        "# If srt_path is empty, use the output from the previous cell\n",
        "if not srt_path:\n",
        "    # Assuming the previous cell's output SRT path is available in a variable\n",
        "    # For this specific notebook, we know the output path structure\n",
        "    # You might need to adjust this based on how the previous cell's output is stored\n",
        "    # or if you want to make this more general.\n",
        "    try:\n",
        "        # Access the output path from the previous cell's scope if possible\n",
        "        # This might not work directly in all cases due to Colab's cell execution scope\n",
        "        # A more robust solution might involve saving the output path to a file\n",
        "        # or a dedicated variable shared between cells.\n",
        "        prev_cell_output_stem = Path(src_path).stem\n",
        "        srt_path = str(out_dir / f\"{prev_cell_output_stem}.srt\")\n",
        "        if DEBUG_MODE: print(f\"Using SRT from previous cell: {srt_path}\")\n",
        "    except NameError:\n",
        "        print(\"Warning: Could not access previous cell's output path. Please specify srt_path manually.\")\n",
        "\n",
        "# Developer Options (Do not put in Markdown form)\n",
        "# These options allow fine-tuning parameters without affecting normal operation.\n",
        "DEBUG_MODE = False # Set to True for more detailed logging\n",
        "\n",
        "# --- Model Parameters ---\n",
        "REPO_ID   = \"unsloth/gpt-oss-20b-GGUF\"   # GGUF Model Repository\n",
        "GGUF_FILE = \"gpt-oss-20b-Q4_K_M.gguf\"    # Approx. 10.8GiB, T4 can run\n",
        "\n",
        "# --- Inference Parameters (Increase available generation space to avoid truncation) ---\n",
        "ctx_window            = 8192\n",
        "map_max_new_tokens    = 512   # Segment output: original 256 -> 512 (approx. 350-450 chars)\n",
        "reduce_max_new_tokens = 1024  # Summary output: original 512 -> 1024 (approx. 700-900+ chars)\n",
        "temperature           = 0.2\n",
        "top_p                 = 0.9\n",
        "repeat_penalty        = 1.05\n",
        "\n",
        "# ===== 1) Check GPU and Install Dependencies (Maintain original process, no changes) =====\n",
        "if DEBUG_MODE: print(\"[1/6] Checking GPU and installing dependencies ...\")\n",
        "\n",
        "def pip_install(pkgs, extra_args=None, env=None):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"]\n",
        "    if extra_args:\n",
        "        cmd += extra_args\n",
        "    cmd += pkgs\n",
        "    return sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True, env=env)\n",
        "\n",
        "missing = []\n",
        "try:\n",
        "    import srt\n",
        "except ModuleNotFoundError:\n",
        "    missing.append(\"srt>=3.5.3\")\n",
        "try:\n",
        "    from huggingface_hub import snapshot_download\n",
        "except ModuleNotFoundError:\n",
        "    missing.append(\"huggingface_hub>=0.23.0\")\n",
        "\n",
        "if missing:\n",
        "    if DEBUG_MODE: print(\"→ Installing missing packages:\", \", \".join(missing))\n",
        "    r = pip_install(missing)\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"基礎依賴安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "def detect_cuda_tag():\n",
        "    try:\n",
        "        out = sp.check_output([\"nvidia-smi\"], text=True)\n",
        "        m = re.search(r\"CUDA Version:\\s*([\\d.]+)\", out)\n",
        "        if not m:\n",
        "            return \"cu124\"\n",
        "        major, minor = [int(x) for x in m.group(1).split(\".\")[:2]]\n",
        "        if major > 12 or (major == 12 and minor >= 5):\n",
        "            return \"cu125\"\n",
        "        return \"cu124\"\n",
        "    except Exception:\n",
        "        return \"cu124\"\n",
        "\n",
        "cuda_tag = detect_cuda_tag()\n",
        "if DEBUG_MODE: print(f\"GPU 0: Detected CUDA version tag {cuda_tag}\")\n",
        "\n",
        "def try_import_llama():\n",
        "    try:\n",
        "        from llama_cpp import Llama\n",
        "        return Llama\n",
        "    except ModuleNotFoundError:\n",
        "        return None\n",
        "\n",
        "Llama = try_import_llama()\n",
        "if Llama is None:\n",
        "    # Keep your existing installation strategy: extra-index -> fallback to source compilation on failure\n",
        "    candidates = [cuda_tag, \"cu125\", \"cu124\", \"cu122\", \"cu121\"]\n",
        "    ok = False\n",
        "    for tag in candidates:\n",
        "        idx = f\"https://abetlen.github.io/llama-cpp-python/whl/{tag}\"\n",
        "        if DEBUG_MODE: print(f\"→ Attempting to install llama-cpp-python ({tag}) ...\")\n",
        "        r = pip_install([\"llama-cpp-python\"], extra_args=[\"--extra-index-url\", idx])\n",
        "        if r.returncode == 0:\n",
        "            Llama = try_import_llama()\n",
        "            if Llama is not None:\n",
        "                ok = True\n",
        "                break\n",
        "        else:\n",
        "            if DEBUG_MODE: print(\"  ✗ Installation failed (summary):\", \"\\n\".join(r.stdout.splitlines()[-5:]))\n",
        "    if not ok:\n",
        "        if DEBUG_MODE: print(\"→ Pre-compiled wheels not available, switching to 'source compilation (CUDA=ON)' ... (takes longer)\")\n",
        "        try:\n",
        "            import ninja  # noqa\n",
        "        except ModuleNotFoundError:\n",
        "            if DEBUG_MODE: print(\"→ Installing missing package: ninja\")\n",
        "            r = pip_install([\"ninja\"])\n",
        "            if r.returncode != 0:\n",
        "                if DEBUG_MODE: print(r.stdout)\n",
        "                raise RuntimeError(\"安裝 ninja 失敗。請重啟後重試。\")\n",
        "        env = os.environ.copy()\n",
        "        env[\"CMAKE_ARGS\"] = \"-DGGML_CUDA=on -DLLAMA_CUBLAS=on\"\n",
        "        env[\"FORCE_CMAKE\"] = \"1\"\n",
        "        r = pip_install([\"llama-cpp-python\"], env=env)\n",
        "        if r.returncode != 0:\n",
        "            if DEBUG_MODE: print(r.stdout)\n",
        "            raise RuntimeError(\"無法安裝 GPU 版 llama-cpp-python。\")\n",
        "        Llama = try_import_llama()\n",
        "\n",
        "# ===== 2) Read SRT (Maintain original logic) =====\n",
        "if DEBUG_MODE: print(\"[2/6] Reading SRT ...\")\n",
        "import srt as _srt\n",
        "srt_path = Path(srt_path)\n",
        "assert srt_path.exists(), f\"SRT 檔不存在：{srt_path}\"\n",
        "with open(srt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    srt_text = f.read()\n",
        "subs = list(_srt.parse(srt_text))\n",
        "def td2s(td): return td.total_seconds()\n",
        "segments = []\n",
        "for it in subs:\n",
        "    txt = it.content.strip()\n",
        "    if not txt: continue\n",
        "    segments.append((td2s(it.start), td2s(it.end), txt))\n",
        "total_secs = (segments[-1][1] - segments[0][0]) if segments else 0\n",
        "if DEBUG_MODE: print(f\"→ Number of subtitle segments: {len(segments)}；Video length (est): {total_secs/60:.1f} minutes\")\n",
        "\n",
        "# ===== 3) Download and Load GGUF Model (Only add chat_format='chatml' and verbose=True) =====\n",
        "if DEBUG_MODE: print(\"[3/6] Loading GPT-OSS-20B (GGUF, CUDA) ...\")\n",
        "from huggingface_hub import snapshot_download\n",
        "local_repo = snapshot_download(REPO_ID, allow_patterns=[GGUF_FILE])\n",
        "gguf_path = str(Path(local_repo)/GGUF_FILE)\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=gguf_path,\n",
        "    n_ctx=ctx_window,\n",
        "    n_gpu_layers=-1,\n",
        "    seed=0,\n",
        "    logits_all=False,\n",
        "    verbose=True,          # Display the actual chat format used\n",
        "    chat_format=\"chatml\",  # Directly override the GGUF built-in Unsloth template to avoid outputting <|channel|> tags\n",
        ")\n",
        "if DEBUG_MODE: print(\"→ Model loaded successfully (GPU)\")\n",
        "\n",
        "# ===== 4) Token-aware Segmentation (Maintain original logic) =====\n",
        "if DEBUG_MODE: print(\"[4/6] Generating segments (token-aware; single segment ≤ safety limit) ...\")\n",
        "\n",
        "def count_tokens_text(text: str) -> int:\n",
        "    return len(llm.tokenize(text.encode(\"utf-8\")))\n",
        "\n",
        "SYSTEM_INSTR = (\n",
        "  \"你是一個會議總結機器人。根據使用者提供的逐字稿（可能雜訊、重複、錯字），\"\n",
        "  \"請去除雜訊與重複、嚴守事實、不腦補。遇到不明確資訊以「待補充／未明確」標註。\"\n",
        "  \"輸出為 Markdown（繁體中文），不要輸出任何系統／思考標記。\"\n",
        ")\n",
        "\n",
        "# — Segment Summary Prompt: More concise request, avoid verbosity and system language\n",
        "MAP_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是逐字稿片段（非完整全文）：\n",
        "{chunk}\n",
        "\n",
        "請就此片段輸出「條列式重點摘要」（500–900 字，繁體中文），注意：\n",
        "- 只寫最終內容，不要寫解題想法、不要出現任何系統提示或中英括號標記。\n",
        "- 聚焦可驗證事實（時間、人物、任務、結論、未決事項、行動）。\n",
        "- 結構：可用小標題＋項目符號，語句務必短、準確、無贅詞。\n",
        "\"\"\")\n",
        "\n",
        "# — Summary Prompt: Maintain your three-section output structure\n",
        "REDUCE_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是所有片段的重點摘要彙整（仍可能有重疊）：\n",
        "{maps}\n",
        "\n",
        "請整合為一份會議筆記（Markdown，繁體）：\n",
        "1) **整體提要**（3–6 句，避免冗言）\n",
        "2) **章節要點（含時間脈絡）**：條列呈現，每點一行，可附粗略時間\n",
        "3) **可執行重點**：具體待辦（每條以動詞開頭）\n",
        "請只輸出最終筆記，不要出現系統或思考標記，不要加入未出現的新資訊。\n",
        "\"\"\")\n",
        "\n",
        "# Single segment token budget (reserve space for prompt and generation)\n",
        "prompt_overhead = 700\n",
        "chunk_target    = max(1024, min(3072, ctx_window - prompt_overhead - map_max_new_tokens))\n",
        "\n",
        "chunks: List[Tuple[float,float,str]] = []\n",
        "buf, t0, t1, cur = [], None, None, 0\n",
        "for (s, e, txt) in segments:\n",
        "    t = count_tokens_text(txt)\n",
        "    if not buf:\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "        continue\n",
        "    if cur + t <= chunk_target:\n",
        "        buf.append(txt); t1 = e; cur += t\n",
        "    else:\n",
        "        chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "if buf:\n",
        "    chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ Generated {len(chunks)} segments (target ~{chunk_target} tokens per segment)\")\n",
        "\n",
        "# ===== Common: Streaming Tools (No regex cleaning; use correct stop sequence) =====\n",
        "def llm_stream(messages, max_tokens):\n",
        "    # ChatML messages end with <|im_end|>; use stop to cut off, preventing the closing tag from being written to the file\n",
        "    gen = llm.create_chat_completion(\n",
        "        messages=messages,\n",
        "        temperature=float(temperature),\n",
        "        top_p=float(top_p),\n",
        "        repeat_penalty=float(repeat_penalty),\n",
        "        max_tokens=int(max_tokens),\n",
        "        stream=True,\n",
        "        stop=[\"<|im_end|>\"],  # Key: Prevent outputting the ending template\n",
        "    )\n",
        "    for ev in gen:\n",
        "        # Compatible with different fields\n",
        "        piece = \"\"\n",
        "        try:\n",
        "            piece = ev[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "        except Exception:\n",
        "            piece = ev[\"choices\"][0].get(\"text\", \"\")\n",
        "        if piece:\n",
        "            yield piece\n",
        "\n",
        "# ===== 5) Segment Summary (map) =====\n",
        "if DEBUG_MODE: print(\"[5/6] Segment summarization (map) ...\")\n",
        "live = display(Markdown(\"\"), display_id=True)\n",
        "maps: List[str] = []\n",
        "\n",
        "for i, (s, e, body) in enumerate(chunks, 1):\n",
        "    pct = i / max(len(chunks),1) * 100\n",
        "    sys.stdout.write(f\"  - 處理分段 {i}/{len(chunks)}（~{pct:.1f}%）\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Shrink to safe budget before sending (prevent prompt+segment from exceeding window and causing model to terminate early)\n",
        "    budget_tokens = max(512, ctx_window - map_max_new_tokens - prompt_overhead)\n",
        "    def shrink_to_budget(text: str, budget_tokens: int) -> str:\n",
        "        cur = text\n",
        "        for _ in range(6):\n",
        "            if count_tokens_text(cur) <= budget_tokens:\n",
        "                return cur\n",
        "            keep = max(800, int(len(cur) * 0.85))\n",
        "            cur = cur[:keep]\n",
        "        return cur\n",
        "    body2 = shrink_to_budget(body, budget_tokens)\n",
        "\n",
        "    user_txt = MAP_USER_TMPL.format(topic=(topic_hint or \"（無）\"), chunk=body2)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n",
        "        {\"role\": \"user\",   \"content\": user_txt},\n",
        "    ]\n",
        "\n",
        "    part_buf, shown = [], 0\n",
        "    for token in llm_stream(messages, map_max_new_tokens):\n",
        "        part_buf.append(token)\n",
        "        # Update live display and terminal character count periodically\n",
        "        if len(part_buf) % 24 == 0:\n",
        "            cur_txt = \"\".join(part_buf)\n",
        "            live.update(Markdown(cur_txt))\n",
        "            sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "    cur_txt = \"\".join(part_buf)\n",
        "    live.update(Markdown(cur_txt))\n",
        "    sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Include the model's final output directly, no regex cleaning\n",
        "    maps.append(cur_txt.strip())\n",
        "\n",
        "if DEBUG_MODE: print(\"→ Segment summarization complete\")\n",
        "\n",
        "# ===== 6) Consolidate (reduce) & Only write .md =====\n",
        "if DEBUG_MODE: print(\"[6/6] Consolidating summary (reduce) ...\")\n",
        "maps_md = \"\\n\\n---\\n\\n\".join(f\"### 片段 {i+1} 要點\\n\\n{m}\" for i, m in enumerate(maps))\n",
        "\n",
        "# If combined text exceeds window, truncate proportionally first (without changing text within segments to avoid breaking meaning)\n",
        "def fit_reduce_payload(md_text: str, max_ctx_tokens: int) -> str:\n",
        "    for _ in range(8):\n",
        "        need = count_tokens_text(md_text)\n",
        "        if need + reduce_max_new_tokens + 400 <= max_ctx_tokens:\n",
        "            return md_text\n",
        "        md_text = md_text[: int(len(md_text) * 0.9)]\n",
        "    return md_text\n",
        "\n",
        "md_cur = fit_reduce_payload(maps_md, ctx_window)\n",
        "\n",
        "user_txt = REDUCE_USER_TMPL.format(topic=(topic_hint or \"（無）\"), maps=md_cur)\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_INSTR},\n",
        "            {\"role\":\"user\",\"content\":user_txt}]\n",
        "\n",
        "live2 = display(Markdown(\"\"), display_id=True)\n",
        "final_buf = []\n",
        "for token in llm_stream(messages, reduce_max_new_tokens):\n",
        "    final_buf.append(token)\n",
        "    if len(final_buf) % 24 == 0:\n",
        "        live2.update(Markdown(\"\".join(final_buf)))\n",
        "        sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "live2.update(Markdown(\"\".join(final_buf)))\n",
        "sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "\n",
        "final_text = \"\".join(final_buf).strip()\n",
        "\n",
        "out_dir = Path(output_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_md = out_dir / f\"{Path(srt_path).stem}_summary.md\"\n",
        "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_text)\n",
        "\n",
        "print(f\"→ 完成 ✅  {out_md}\")\n",
        "try:\n",
        "    del llm\n",
        "except Exception:\n",
        "    pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"（顯存已釋放，如需重跑可直接再次執行）\")"
      ],
      "metadata": {
        "id": "5F_bvq0megb9",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6a3f127d"
      },
      "source": [
        "# Task\n",
        "Merge the code from the two provided cells into a single cell. Consolidate dependencies and imports. Create a unified Colab form at the top of the cell combining parameters from both original forms, grouping them logically. Integrate the code logic to use the new form variables and ensure the correct execution flow. Keep the developer options section separate within the code, clearly commented. Verify and update output path logic. Generate the final merged code cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13784b93"
      },
      "source": [
        "## Merge code\n",
        "\n",
        "### Subtask:\n",
        "Combine the code from the two existing cells into a single code block.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48b067c4"
      },
      "source": [
        "**Reasoning**:\n",
        "Combine the code from the two cells into a single code block as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9512cda9"
      },
      "source": [
        "**Reasoning**:\n",
        "Correct the syntax error in the combined code block and regenerate it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1564fadc93cb47258fb24d74c5214e68",
            "37a4b92fa712448881d3cdae1804721e",
            "616e9b69038643d5b8a486e06b0d9eb7",
            "12c41eb6345743c2b13e7c154339e4a5",
            "50a445d112cc421ab44d2b9bbae61dd5",
            "1945236303394653b4d948a71249655a",
            "579c1d04c4294f02863c8935c689fdbd",
            "a5afc8f51b1b43f2bad1ee9fa11106b2",
            "06f32deb89054f1f81662dd32bf48d48",
            "7ecf9e19c5a4414eac74b9d989bdc6b6",
            "e6d70e1c30a4452986e634a0e0a4b7c0",
            "1704c3adb542403daa6c5fcd88b68573",
            "c1ada565d1f34cdba81621fe31a9fda6",
            "6ccb5d7166ff403b8b4c90641c94b0f1",
            "68f9c9c396144256a527c46809331f29",
            "302c4bf146584c05a87025656cbe64ae",
            "92682e36a9cb450b95fb3283f47be2ae",
            "681a9c16a72d407ba1bbf71b84513359",
            "4acfbe4811554b12a1b708dac3dc0a0f",
            "1985a6be6599498889e1c2627a5805de",
            "96c9d86c400f4f4188f40cf540505732",
            "4a1d8834277c4b008c01532ce94821fb",
            "ca4fe1da6cd14b1daca42e73924209b9",
            "bf52035b8aa14d008967415bae3fc2ab",
            "2478eba1b77a473d8942305898273e0c",
            "3e9c540784034a2aaf795c4621370f03",
            "3bff6412e2a346b688285581dbd55fb9",
            "7c6f787cc32149d7a773e40f6795bd5f",
            "a0298322cea84cf09462d83f881466d1",
            "cb0efe9d451741d9abdcf0300cafaf19",
            "1f7b3d10e4ca4c4088dc191d3e14a2b0",
            "4fb61bc2b84a4cb4a0a71290569891eb",
            "d5ee299dace344db8e2bbc838006f87e",
            "198e13ae302845f4b087e5f5229d98a3",
            "406ce394133a43f884b51eb82d9b3d28",
            "ba20062b8f3943f7857202ef085ab2af",
            "7d929da5ad104f868e2d31d8e38f79a0",
            "0ec622a496b74200aaaebeb4932273b5",
            "850bcb0854e64a79b47cf8e6bb82a39f",
            "d668a267c4cf4ed2aa57475a62c22f5c",
            "4a2a795fc3964570b34ba7f1ac295b55",
            "798fdac0fe8149a88d9024156a462f7a",
            "ece5871ea32141ee97e73348a85bf9db",
            "7d854b340ad64a6ea95b09d506c89032",
            "d7b2a8d77258494f8457cb9dce734f24",
            "3694133570964ce39a66238bcc3a57af",
            "65da845ed9074aa5af0cb66efa14aed4",
            "00ab2f80a1e84958be2377176ad31353",
            "951a27ac40fd4e8e9b5111c513bd557d",
            "d492c41a8060471783027613374a9d4e",
            "7609d0567151435d93e7a7a683f8cd33",
            "f99295ff35ae40ec8055bb9478823c4c",
            "e20eafa7fd6e467cb16828efcb20557b",
            "d185afb010e74650bf89081d9fc10b26",
            "0396995662e240d4bf368f3f67e3ead5",
            "03679313e38c4c0ba18e9bfec031beba",
            "86f0a340d9254bd98be02af00112c19f",
            "d05dad97913d4ab0a00d51704d23a6d1",
            "77ae3eaa29544dcc8ddf2f67a35b4abf",
            "73f871f1f1aa44db8a91f029d07eab01",
            "fcbb711d8ea94e37975b83adf501d464",
            "be00a9ad739f49e79e6522d33101d9e4",
            "2137ee94b63b4450b4e569a351f03161",
            "d33cd7cfde5145e192df1fd8496a9ac1",
            "221840795acc49b48bad748bb55e5e6f",
            "a03672df0ec24fd681888898c238ffad",
            "ece8f8cf5e204ef888b582888b6630a6",
            "457c30be1bd240978e1a004c7f7f742d",
            "3dd11ad8896844a3914282ad5d214656",
            "6f6e1fd3552348d49062340242d4eb46",
            "c8e14e9335744935a418efa2ac291580",
            "db7dd6f122b34438987d7ef5174209a1",
            "f013a30d92af467a932c4193990aec19",
            "104ab3e9ba2d43858671872d8bc2ebcc",
            "e27acefe56ee4fd0bbe64fbdd9fcb289",
            "0ddb3c5fcf6c465f88bfdbd08c06085a",
            "c9b2f4f98f0c456cbad4b8a23e21471e"
          ]
        },
        "id": "HjIro39b2wCC",
        "outputId": "1922004c-3f93-4416-f86f-97a64b19292c"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Whisper Automatic Subtitle Generation: GPU Transcription + CPU Denoising + OpenCC Post-processing (Traditional/Simplified Conversion)\n",
        "# - Transcription: faster-whisper (CUDA, compute: int8_float16→float16→int8)\n",
        "# - Denoising: ffmpeg afftdn (CPU)\n",
        "# - Progress: Real-time printing of \"current sentence + video total length percentage\"\n",
        "# - Network source download and output: MyDrive/whisper; Files in Drive: Output to the same folder\n",
        "# - Prompts \"Delete runtime and restart\" if download is blocked or abnormal\n",
        "# =========================================================\n",
        "\n",
        "# Restrict multithreading (more stable)\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# [1/8] Mount Google Drive\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "except:\n",
        "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "import sys, gc, shutil, datetime, subprocess\n",
        "from pathlib import Path\n",
        "\n",
        "ROOT = Path(\"/content/gdrive/MyDrive\")\n",
        "WHISPER_DIR = ROOT / \"whisper\"\n",
        "WHISPER_DIR.mkdir(exist_ok=True, parents=True)\n",
        "os.chdir(ROOT)\n",
        "print(f\"→ 當前工作目錄：{os.getcwd()}\")\n",
        "\n",
        "# [2/8] User Form Parameters\n",
        "#@markdown # Whisper / Faster-Whisper（GPU 轉錄 + CPU 降噪 + OpenCC）\n",
        "#@markdown # 輸入雲端硬碟檔案（相對於 MyDrive）或影片網址（YouTube/HTTP）\n",
        "filename = \"whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\"  #@param {type:\"string\"}\n",
        "#@markdown ✔ 網路來源是否另存到 MyDrive/whisper\n",
        "save_video_to_google_drive = True  #@param {type:\"boolean\"}\n",
        "#@markdown # 模型（GPU 可用 large-v3；若 VRAM 吃緊可降 medium）\n",
        "model_size = \"large-v3\"  #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\"]\n",
        "#@markdown # 語言（不翻譯，只轉錄）\n",
        "language = \"自動偵測\"  #@param [\"自動偵測\", \"中文\", \"英文\"]\n",
        "#@markdown # 降噪方法（CPU）\n",
        "denoise_method = \"afftdn (建議)\"  #@param [\"afftdn (建議)\", \"none\"]\n",
        "#@markdown # 文字正規化：OpenCC 轉換（套用在輸出 SRT/TXT）\n",
        "text_postprocess = \"臺灣繁體中文（預設）\"  #@param [\"臺灣繁體中文（預設）\",\"香港繁體中文\",\"大陸簡體中文\",\"關閉\"]\n",
        "#@markdown （選填）YouTube cookies 檔（相對 MyDrive；Netscape 格式，如 `cookies/youtube.txt`）\n",
        "youtube_cookies_txt_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "language_code_map = {\"自動偵測\": None, \"中文\":\"zh\", \"英文\":\"en\"}\n",
        "language_code = language_code_map[language]\n",
        "\n",
        "# Developer Options (Do not put in Markdown form)\n",
        "# These options allow fine-tuning parameters without affecting normal operation.\n",
        "DEBUG_MODE = False # Set to True for more detailed logging\n",
        "\n",
        "# --- Transcription Parameters ---\n",
        "TRANSCRIPTION_BEAM_SIZE_PRIMARY = 3\n",
        "TRANSCRIPTION_CHUNK_LENGTH_PRIMARY = 20\n",
        "TRANSCRIPTION_BEAM_SIZE_FALLBACK = 1 # Used if primary fails\n",
        "TRANSCRIPTION_CHUNK_LENGTH_FALLBACK = 15 # Used if primary fails\n",
        "\n",
        "# --- Denoising Parameters ---\n",
        "DENOISE_NOISE_FLOOR_DB = -25\n",
        "\n",
        "# --- Filtering Parameters ---\n",
        "FILTER_MIN_DURATION_SHORT = 1.5 # Minimum duration for short segments\n",
        "FILTER_AVG_LOGPROB_THRESHOLD = -1.0 # Avg log probability threshold for short segments\n",
        "FILTER_MIN_DURATION_SPEECH_PROB = 2.0 # Minimum duration for speech probability filtering\n",
        "FILTER_NO_SPEECH_PROB_THRESHOLD = 0.6 # No speech probability threshold\n",
        "\n",
        "# [3/8] Install Dependencies\n",
        "if DEBUG_MODE: print(\"[Install] faster-whisper / yt-dlp / soundfile / opencc ...\")\n",
        "!pip -q install -U faster-whisper yt-dlp soundfile opencc-python-reimplemented > /dev/null\n",
        "\n",
        "import soundfile as sf\n",
        "from faster_whisper import WhisperModel\n",
        "from opencc import OpenCC\n",
        "\n",
        "# ---------- Utility Functions ----------\n",
        "def suggest_runtime_reset():\n",
        "    print(\"\\n🧹 建議動作（Colab）\")\n",
        "    print(\"1) 依序：『執行階段 Runtime』 → 『刪除執行階段/還原出廠設定 Factory reset runtime』\")\n",
        "    print(\"2) 重新執行本 Notebook（從掛載雲端硬碟那格開始）\\n\", flush=True)\n",
        "\n",
        "def run_cmd(cmd:list, check=True):\n",
        "    if DEBUG_MODE: print(\"  $\", \" \".join(cmd))\n",
        "    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"命令失敗：{' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "def is_youtube_url(s:str)->bool:\n",
        "    return isinstance(s, str) and (\"youtu.be\" in s or \"youtube.com\" in s)\n",
        "def is_http_url(s:str)->bool:\n",
        "    return isinstance(s, str) and s.lower().startswith(\"http\")\n",
        "def to_abs_mydrive(p:str)->Path:\n",
        "    return (Path(p) if p.startswith(\"/\") else (ROOT / p)).resolve()\n",
        "def fmt_ts_srt(t:float)->str:\n",
        "    h = int(t//3600); m = int((t%3600)//60); s = t - h*3600 - m*60\n",
        "    return f\"{h:02d}:{m:02d}:{int(s):02d},{int(round((s-int(s))*1000)):03d}\"\n",
        "def verify_wav_ok(path: Path)->bool:\n",
        "    try:\n",
        "        info = sf.info(str(path))\n",
        "        return info.samplerate > 0 and info.channels in (1, 2)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# OpenCC converter setup\n",
        "def build_opencc_pipeline(choice:str):\n",
        "    if choice.startswith(\"臺灣\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2tw')]\n",
        "    if choice.startswith(\"香港\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2hk')]\n",
        "    if choice.startswith(\"大陸\"):\n",
        "        return [OpenCC('t2s')]\n",
        "    return []  # Disable\n",
        "\n",
        "def apply_opencc(text:str, pipeline)->str:\n",
        "    for cc in pipeline:\n",
        "        text = cc.convert(text)\n",
        "    return text\n",
        "\n",
        "def ytdl(yturl:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting YouTube video ...\")\n",
        "    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        if \"Sign in to confirm\" in (p.stdout or \"\"):\n",
        "            print(\"\\n❗YouTube 要求登入/驗證，請提供 cookies 或先自行下載到雲端硬碟。\")\n",
        "        print(\"🔄 若多次失敗，請刪除執行階段並重啟後重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise RuntimeError(\"yt-dlp 下載失敗\")\n",
        "    files = list(tmp.glob(\"*\"))\n",
        "    if not files:\n",
        "        print(\"🔄 下載為空，建議刪除執行階段再重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise FileNotFoundError(\"YouTube 下載失敗：/tmp/dl 為空\")\n",
        "    f = files[0]\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(f, WHISPER_DIR / f.name)\n",
        "    return f\n",
        "\n",
        "def http_dl(url:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting HTTP(S) video ...\")\n",
        "    run_cmd([\"curl\", \"-L\", \"-o\", str(out), url])\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(out, WHISPER_DIR / out.name)\n",
        "    return out\n",
        "\n",
        "# Extract audio: ffmpeg -> 16k/mono WAV\n",
        "def ffmpeg_extract_wav(in_path:Path, out_wav:Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-vn\",\"-ac\",\"1\",\"-ar\",str(sr),\"-f\",\"wav\",str(out_wav)]\n",
        "    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 轉 WAV 失敗\")\n",
        "\n",
        "# CPU Denoising: ffmpeg afftdn\n",
        "def ffmpeg_afftdn(in_wav: Path, out_wav: Path, noise_floor_db=DENOISE_NOISE_FLOOR_DB):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-af\",f\"afftdn=nf={noise_floor_db}\",\n",
        "           \"-ac\",\"1\",\"-ar\",\"16000\",\"-f\",\"wav\",str(out_wav)]\n",
        "    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg afftdn 失敗\")\n",
        "\n",
        "# Safeguard: Repack WAV header if format is strange\n",
        "def ffmpeg_repack_wav(in_wav: Path, out_wav: Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-acodec\",\"pcm_s16le\",\"-ac\",\"1\",\"-ar\",str(sr),str(out_wav)]\n",
        "    p = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 重包 WAV 失敗\")\n",
        "\n",
        "# [4/8] Parse Source\n",
        "if DEBUG_MODE: print(\"[4/8] Parsing input source ...\")\n",
        "try:\n",
        "    if is_youtube_url(filename):\n",
        "        src_path = ytdl(filename); out_base_dir = WHISPER_DIR\n",
        "    elif is_http_url(filename):\n",
        "        src_path = http_dl(filename); out_base_dir = WHISPER_DIR\n",
        "    else:\n",
        "        src_path = to_abs_mydrive(filename)\n",
        "        if not src_path.exists(): raise FileNotFoundError(f\"找不到檔案：{src_path}\")\n",
        "        out_base_dir = src_path.parent\n",
        "except Exception as e:\n",
        "    print(f\"\\n⛔ 來源解析/下載失敗：{e}\")\n",
        "    print(\"🔄 請刪除執行階段並重新啟動後重跑。\"); suggest_runtime_reset(); raise\n",
        "\n",
        "print(f\"→ 來源檔：{src_path}\")\n",
        "print(f\"→ 輸出資料夾：{out_base_dir}\")\n",
        "\n",
        "# [5/8] Extract Audio & CPU Denoising\n",
        "AUDIO_16K = Path(\"/tmp/audio_16k.wav\")\n",
        "if DEBUG_MODE: print(\"[5/8] Extracting audio (ffmpeg → 16k/mono WAV) ...\")\n",
        "ffmpeg_extract_wav(src_path, AUDIO_16K, sr=16000)\n",
        "\n",
        "if denoise_method.startswith(\"afftdn\"):\n",
        "    if DEBUG_MODE: print(\"[5.5/8] Denoising (ffmpeg afftdn, CPU) ...\")\n",
        "    DENOISED = Path(\"/tmp/audio_16k_denoised.wav\")\n",
        "    ffmpeg_afftdn(AUDIO_16K, DENOISED, noise_floor_db=DENOISE_NOISE_FLOOR_DB)\n",
        "    denoised_audio = DENOISED if verify_wav_ok(DENOISED) else AUDIO_16K\n",
        "else:\n",
        "    denoised_audio = AUDIO_16K\n",
        "\n",
        "if not verify_wav_ok(denoised_audio):\n",
        "    if DEBUG_MODE: print(\"  - 音訊格式異常；嘗試重包 WAV ...\")\n",
        "    FIXED = Path(\"/tmp/audio_16k_fixed.wav\")\n",
        "    ffmpeg_repack_wav(denoised_audio, FIXED, sr=16000)\n",
        "    denoised_audio = FIXED\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ 最終輸入音訊：{denoised_audio}\")\n",
        "\n",
        "# [6/8] Load faster-whisper (GPU enforced)\n",
        "if DEBUG_MODE: print(\"[6/8] Loading faster-whisper model (GPU) ...\")\n",
        "device = \"cuda\"  # Enforce GPU\n",
        "model = None; last_err = None\n",
        "for ctype in [\"int8_float16\", \"float16\", \"int8\"]:\n",
        "    try:\n",
        "        if DEBUG_MODE: print(f\"  - Trying compute_type={ctype}\")\n",
        "        model = WhisperModel(model_size, device=device, compute_type=ctype)\n",
        "        if DEBUG_MODE: print(\"  - Model loaded successfully\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        last_err = e\n",
        "        if DEBUG_MODE: print(f\"  - Load failed: {e}\")\n",
        "if model is None:\n",
        "    print(\"\\n⛔ GPU 模型載入失敗。請確認『變更執行階段類型』選了 GPU（T4/A100），或刪除執行階段後重試。\")\n",
        "    suggest_runtime_reset()\n",
        "    raise RuntimeError(f\"無法載入模型：{last_err}\")\n",
        "\n",
        "gc.collect()  # Clean up before transcription (safety)\n",
        "\n",
        "# [7/8] Transcribe (GPU; real-time progress per segment)\n",
        "if DEBUG_MODE: print(f\"[7/8] Starting transcription (GPU: beam={TRANSCRIPTION_BEAM_SIZE_PRIMARY} / chunk={TRANSCRIPTION_CHUNK_LENGTH_PRIMARY}s / no VAD) ...\")\n",
        "\n",
        "def transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY):\n",
        "    return model.transcribe(\n",
        "        str(denoised_audio),\n",
        "        task=\"transcribe\",\n",
        "        language=language_code,\n",
        "        temperature=0.0,\n",
        "        condition_on_previous_text=False,\n",
        "        compression_ratio_threshold=2.4,\n",
        "        log_prob_threshold=-1.0,\n",
        "        no_speech_threshold=0.6,\n",
        "        beam_size=_beam,\n",
        "        chunk_length=_chunk,\n",
        "        vad_filter=False,\n",
        "        word_timestamps=False\n",
        "    )\n",
        "\n",
        "try:\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY)\n",
        "except Exception as e:\n",
        "    if DEBUG_MODE: print(f\"  - First transcription failed: {e}\\n    → Trying more conservative (beam={TRANSCRIPTION_BEAM_SIZE_FALLBACK}, chunk={TRANSCRIPTION_CHUNK_LENGTH_FALLBACK}) ...\")\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_FALLBACK, _chunk=TRANSCRIPTION_CHUNK_LENGTH_FALLBACK)\n",
        "\n",
        "# Display percentage based on total video duration\n",
        "duration = float(getattr(info, \"duration\", 0.0) or 0.0)\n",
        "if duration <= 0: duration = 1.0\n",
        "\n",
        "segments = []\n",
        "filtered = []\n",
        "\n",
        "if DEBUG_MODE:\n",
        "    print(f\"  - Detected language: {getattr(info,'language','未知')} (p={getattr(info,'language_probability',0):.2f})\")\n",
        "    print(f\"  - Audio length: {duration:.2f}s\")\n",
        "\n",
        "for s in seg_iter:\n",
        "    pct = int(min(100, round((s.end / duration) * 100)))\n",
        "    print(f\"[{pct:3d}%] {fmt_ts_srt(s.start)} → {fmt_ts_srt(s.end)}  {s.text.strip()}\", flush=True)\n",
        "    segments.append(s)\n",
        "\n",
        "    # Low confidence/high no-speech short segment filtering (no blacklist)\n",
        "    keep = True\n",
        "    seg_dur = float(s.end - s.start)\n",
        "    if seg_dur < FILTER_MIN_DURATION_SHORT and getattr(s, \"avg_logprob\", None) is not None and s.avg_logprob < FILTER_AVG_LOGPROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if seg_dur < FILTER_MIN_DURATION_SPEECH_PROB and getattr(s, \"no_speech_prob\", None) is not None and s.no_speech_prob > FILTER_NO_SPEECH_PROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if keep:\n",
        "        filtered.append(s)\n",
        "\n",
        "if DEBUG_MODE: print(f\"  - Number of segments: Before filtering {len(segments)} → After filtering {len(filtered)}\")\n",
        "\n",
        "# ---- OpenCC Normalization (for output text) ----\n",
        "pipeline = build_opencc_pipeline(text_postprocess)\n",
        "def norm(txt: str) -> str:\n",
        "    return apply_opencc(txt, pipeline) if pipeline else txt\n",
        "\n",
        "# [8/8] Output (text after OpenCC)\n",
        "print(\"[8/8] 輸出 SRT / TXT ...\")\n",
        "out_dir = out_base_dir; out_dir.mkdir(exist_ok=True, parents=True)\n",
        "stem = src_path.stem\n",
        "SRT = out_dir / f\"{stem}.srt\"; TXT = out_dir / f\"{stem}.txt\"\n",
        "\n",
        "with open(SRT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, s in enumerate(filtered, 1):\n",
        "        text_out = norm(s.text.strip())\n",
        "        f.write(f\"{i}\\n{fmt_ts_srt(s.start)} --> {fmt_ts_srt(s.end)}\\n{text_out}\\n\\n\")\n",
        "\n",
        "with open(TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in filtered:\n",
        "        f.write(norm(s.text.strip()) + \"\\n\")  # Each segment on a new line\n",
        "\n",
        "print(f\"→ 完成！\\n  SRT: {SRT}\\n  TXT: {TXT}\")\n",
        "\n",
        "# Release model (release GPU memory)\n",
        "try: del model\n",
        "except: pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"→ Model released; can run again directly if needed.\")\n",
        "\n",
        "#@markdown # 🔎 Whisper Transcription Summary (GPT-OSS-20B / llama.cpp / CUDA) 【Only output .md | Retain original installation process, only fix truncated output and system prompt issues】\n",
        "#@markdown - Keep your currently working \"Installation section\" (srt / huggingface_hub / llama-cpp-python with extra-index / source code compilation fallback) general flow and parameters unchanged.\n",
        "#@markdown - Only adjust the \"Inference and output\" logic: **Use the official chat completion normal usage**, **overwrite chat_format='chatml'** (to avoid Unsloth's `<|channel|>` tag overflow), **correct stop sequence**, **increase return limit**, **remove rule cleaning**, and display the generated character count per segment in real-time in the terminal.\n",
        "\n",
        "# from pathlib import Path # Already imported\n",
        "# import os, sys, re, math, gc, time, importlib, subprocess as sp, textwrap # Some already imported\n",
        "import re, math, time, importlib, subprocess as sp, textwrap # Import remaining\n",
        "from typing import List, Tuple\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# ===== User Parameters =====\n",
        "srt_path   = \"\"  #@param {type:\"string\"}\n",
        "topic_hint = \"\"  #@param {type:\"string\"}\n",
        "output_dir = \"/content/gdrive/MyDrive/whisper\"  #@param {type:\"string\"}\n",
        "\n",
        "# If srt_path is empty, use the output from the previous cell\n",
        "if not srt_path:\n",
        "    # Assuming the previous cell's output SRT path is available in a variable\n",
        "    # For this specific notebook, we know the output path structure\n",
        "    # You might need to adjust this based on how the previous cell's output is stored\n",
        "    # or if you want to make this more general.\n",
        "    try:\n",
        "        # Access the output path from the previous cell's scope if possible\n",
        "        # This might not work directly in all cases due to Colab's cell execution scope\n",
        "        # A more robust solution might involve saving the output path to a file\n",
        "        # or a dedicated variable shared between cells.\n",
        "        # prev_cell_output_stem = Path(src_path).stem # src_path is from the first cell\n",
        "        srt_path = str(out_dir / f\"{Path(src_path).stem}.srt\") # Use src_path from first cell\n",
        "        if DEBUG_MODE: print(f\"Using SRT from previous cell: {srt_path}\")\n",
        "    except NameError:\n",
        "        print(\"Warning: Could not access previous cell's output path. Please specify srt_path manually.\")\n",
        "\n",
        "# Developer Options (Do not put in Markdown form)\n",
        "# These options allow fine-tuning parameters without affecting normal operation.\n",
        "# DEBUG_MODE = False # Already defined at the top\n",
        "\n",
        "# --- Model Parameters ---\n",
        "REPO_ID   = \"unsloth/gpt-oss-20b-GGUF\"   # GGUF Model Repository\n",
        "GGUF_FILE = \"gpt-oss-20b-Q4_K_M.gguf\"    # Approx. 10.8GiB, T4 can run\n",
        "\n",
        "# --- Inference Parameters (Increase available generation space to avoid truncation) ---\n",
        "ctx_window            = 8192\n",
        "map_max_new_tokens    = 512   # Segment output: original 256 -> 512 (approx. 350-450 chars)\n",
        "reduce_max_new_tokens = 1024  # Summary output: original 512 -> 1024 (approx. 700-900+ chars)\n",
        "temperature           = 0.2\n",
        "top_p                 = 0.9\n",
        "repeat_penalty        = 1.05\n",
        "\n",
        "# ===== 1) Check GPU and Install Dependencies (Maintain original process, no changes) =====\n",
        "if DEBUG_MODE: print(\"[1/6] Checking GPU and installing dependencies ...\")\n",
        "\n",
        "def pip_install(pkgs, extra_args=None, env=None):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"]\n",
        "    if extra_args:\n",
        "        cmd += extra_args\n",
        "    cmd += pkgs\n",
        "    return sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True, env=env)\n",
        "\n",
        "missing = []\n",
        "try:\n",
        "    import srt\n",
        "except ModuleNotFoundError:\n",
        "    missing.append(\"srt>=3.5.3\")\n",
        "try:\n",
        "    from huggingface_hub import snapshot_download\n",
        "except ModuleNotFoundError:\n",
        "    missing.append(\"huggingface_hub>=0.23.0\")\n",
        "\n",
        "if missing:\n",
        "    if DEBUG_MODE: print(\"→ Installing missing packages:\", \", \".join(missing))\n",
        "    r = pip_install(missing)\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"基礎依賴安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "def detect_cuda_tag():\n",
        "    try:\n",
        "        out = sp.check_output([\"nvidia-smi\"], text=True)\n",
        "        m = re.search(r\"CUDA Version:\\s*([\\d.]+)\", out)\n",
        "        if not m:\n",
        "            return \"cu124\"\n",
        "        major, minor = [int(x) for x in m.group(1).split(\".\")[:2]]\n",
        "        if major > 12 or (major == 12 and minor >= 5):\n",
        "            return \"cu125\"\n",
        "        return \"cu124\"\n",
        "    except Exception:\n",
        "        return \"cu124\"\n",
        "\n",
        "cuda_tag = detect_cuda_tag()\n",
        "if DEBUG_MODE: print(f\"GPU 0: Detected CUDA version tag {cuda_tag}\")\n",
        "\n",
        "def try_import_llama():\n",
        "    try:\n",
        "        from llama_cpp import Llama\n",
        "        return Llama\n",
        "    except ModuleNotFoundError:\n",
        "        return None\n",
        "\n",
        "Llama = try_import_llama()\n",
        "if Llama is None:\n",
        "    # Keep your existing installation strategy: extra-index -> fallback to source compilation on failure\n",
        "    candidates = [cuda_tag, \"cu125\", \"cu124\", \"cu122\", \"cu121\"]\n",
        "    ok = False\n",
        "    for tag in candidates:\n",
        "        idx = f\"https://abetlen.github.io/llama-cpp-python/whl/{tag}\"\n",
        "        if DEBUG_MODE: print(f\"→ Attempting to install llama-cpp-python ({tag}) ...\")\n",
        "        r = pip_install([\"llama-cpp-python\"], extra_args=[\"--extra-index-url\", idx])\n",
        "        if r.returncode == 0:\n",
        "            Llama = try_import_llama()\n",
        "            if Llama is not None:\n",
        "                ok = True\n",
        "                break\n",
        "        else:\n",
        "            if DEBUG_MODE: print(\"  ✗ Installation failed (summary):\", \"\\n\".join(r.stdout.splitlines()[-5:]))\n",
        "    if not ok:\n",
        "        if DEBUG_MODE: print(\"→ Pre-compiled wheels not available, switching to 'source compilation (CUDA=ON)' ... (takes longer)\")\n",
        "        try:\n",
        "            import ninja  # noqa\n",
        "        except ModuleNotFoundError:\n",
        "            if DEBUG_MODE: print(\"→ Installing missing package: ninja\")\n",
        "            r = pip_install([\"ninja\"])\n",
        "            if r.returncode != 0:\n",
        "                if DEBUG_MODE: print(r.stdout)\n",
        "                raise RuntimeError(\"安裝 ninja 失敗。請重啟後重試。\")\n",
        "        env = os.environ.copy()\n",
        "        env[\"CMAKE_ARGS\"] = \"-DGGML_CUDA=on -DLLAMA_CUBLAS=on\"\n",
        "        env[\"FORCE_CMAKE\"] = \"1\"\n",
        "        r = pip_install([\"llama-cpp-python\"], env=env)\n",
        "        if r.returncode != 0:\n",
        "            if DEBUG_MODE: print(r.stdout)\n",
        "            raise RuntimeError(\"無法安裝 GPU 版 llama-cpp-python。\")\n",
        "        Llama = try_import_llama()\n",
        "\n",
        "# ===== 2) Read SRT (Maintain original logic) =====\n",
        "if DEBUG_MODE: print(\"[2/6] Reading SRT ...\")\n",
        "import srt as _srt\n",
        "srt_path = Path(srt_path)\n",
        "assert srt_path.exists(), f\"SRT 檔不存在：{srt_path}\"\n",
        "with open(srt_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    srt_text = f.read()\n",
        "subs = list(_srt.parse(srt_text))\n",
        "def td2s(td): return td.total_seconds()\n",
        "segments = []\n",
        "for it in subs:\n",
        "    txt = it.content.strip()\n",
        "    if not txt: continue\n",
        "    segments.append((td2s(it.start), td2s(it.end), txt))\n",
        "total_secs = (segments[-1][1] - segments[0][0]) if segments else 0\n",
        "if DEBUG_MODE: print(f\"→ Number of subtitle segments: {len(segments)}；Video length (est): {total_secs/60:.1f} minutes\")\n",
        "\n",
        "# ===== 3) Download and Load GGUF Model (Only add chat_format='chatml' and verbose=True) =====\n",
        "if DEBUG_MODE: print(\"[3/6] Loading GPT-OSS-20B (GGUF, CUDA) ...\")\n",
        "from huggingface_hub import snapshot_download\n",
        "local_repo = snapshot_download(REPO_ID, allow_patterns=[GGUF_FILE])\n",
        "gguf_path = str(Path(local_repo)/GGUF_FILE)\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=gguf_path,\n",
        "    n_ctx=ctx_window,\n",
        "    n_gpu_layers=-1,\n",
        "    seed=0,\n",
        "    logits_all=False,\n",
        "    verbose=True,          # Display the actual chat format used\n",
        "    chat_format=\"chatml\",  # Directly override the GGUF built-in Unsloth template to avoid outputting <|channel|> tags\n",
        ")\n",
        "if DEBUG_MODE: print(\"→ Model loaded successfully (GPU)\")\n",
        "\n",
        "# ===== 4) Token-aware Segmentation (Maintain original logic) =====\n",
        "if DEBUG_MODE: print(\"[4/6] Generating segments (token-aware; single segment ≤ safety limit) ...\")\n",
        "\n",
        "def count_tokens_text(text: str) -> int:\n",
        "    return len(llm.tokenize(text.encode(\"utf-8\")))\n",
        "\n",
        "SYSTEM_INSTR = (\n",
        "  \"你是一個會議總結機器人。根據使用者提供的逐字稿（可能雜訊、重複、錯字），\"\n",
        "  \"請去除雜訊與重複、嚴守事實、不腦補。遇到不明確資訊以「待補充／未明確」標註。\"\n",
        "  \"輸出為 Markdown（繁體中文），不要輸出任何系統／思考標記。\"\n",
        ")\n",
        "\n",
        "# — Segment Summary Prompt: More concise request, avoid verbosity and system language\n",
        "MAP_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是逐字稿片段（非完整全文）：\n",
        "{chunk}\n",
        "\n",
        "請就此片段輸出「條列式重點摘要」（500–900 字，繁體中文），注意：\n",
        "- 只寫最終內容，不要寫解題想法、不要出現任何系統提示或中英括號標記。\n",
        "- 聚焦可驗證事實（時間、人物、任務、結論、未決事項、行動）。\n",
        "- 結構：可用小標題＋項目符號，語句務必短、準確、無贅詞。\n",
        "\"\"\")\n",
        "\n",
        "# — Summary Prompt: Maintain your three-section output structure\n",
        "REDUCE_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是所有片段的重點摘要彙整（仍可能有重疊）：\n",
        "{maps}\n",
        "\n",
        "請整合為一份會議筆記（Markdown，繁體）：\n",
        "1) **整體提要**（3–6 句，避免冗言）\n",
        "2) **章節要點（含時間脈絡）**：條列呈現，每點一行，可附粗略時間\n",
        "3) **可執行重點**：具體待辦（每條以動詞開頭）\n",
        "請只輸出最終筆記，不要出現系統或思考標記，不要加入未出現的新資訊。\n",
        "\"\"\")\n",
        "\n",
        "# Single segment token budget (reserve space for prompt and generation)\n",
        "prompt_overhead = 700\n",
        "chunk_target    = max(1024, min(3072, ctx_window - prompt_overhead - map_max_new_tokens))\n",
        "\n",
        "chunks: List[Tuple[float,float,str]] = []\n",
        "buf, t0, t1, cur = [], None, None, 0\n",
        "for (s, e, txt) in segments:\n",
        "    t = count_tokens_text(txt)\n",
        "    if not buf:\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "        continue\n",
        "    if cur + t <= chunk_target:\n",
        "        buf.append(txt); t1 = e; cur += t\n",
        "    else:\n",
        "        chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "if buf:\n",
        "    chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ Generated {len(chunks)} segments (target ~{chunk_target} tokens per segment)\")\n",
        "\n",
        "# ===== Common: Streaming Tools (No regex cleaning; use correct stop sequence) =====\n",
        "def llm_stream(messages, max_tokens):\n",
        "    # ChatML messages end with <|im_end|>; use stop to cut off, preventing the closing tag from being written to the file\n",
        "    gen = llm.create_chat_completion(\n",
        "        messages=messages,\n",
        "        temperature=float(temperature),\n",
        "        top_p=float(top_p),\n",
        "        repeat_penalty=float(repeat_penalty),\n",
        "        max_tokens=int(max_tokens),\n",
        "        stream=True,\n",
        "        stop=[\"<|im_end|>\"],  # Key: Prevent outputting the ending template\n",
        "    )\n",
        "    for ev in gen:\n",
        "        # Compatible with different fields\n",
        "        piece = \"\"\n",
        "        try:\n",
        "            piece = ev[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "        except Exception:\n",
        "            piece = ev[\"choices\"][0].get(\"text\", \"\")\n",
        "        if piece:\n",
        "            yield piece\n",
        "\n",
        "# ===== 5) Segment Summary (map) =====\n",
        "if DEBUG_MODE: print(\"[5/6] Segment summarization (map) ...\")\n",
        "live = display(Markdown(\"\"), display_id=True)\n",
        "maps: List[str] = []\n",
        "\n",
        "for i, (s, e, body) in enumerate(chunks, 1):\n",
        "    pct = i / max(len(chunks),1) * 100\n",
        "    sys.stdout.write(f\"  - 處理分段 {i}/{len(chunks)}（~{pct:.1f}%）\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Shrink to safe budget before sending (prevent prompt+segment from exceeding window and causing model to terminate early)\n",
        "    budget_tokens = max(512, ctx_window - map_max_new_tokens - prompt_overhead)\n",
        "    def shrink_to_budget(text: str, budget_tokens: int) -> str:\n",
        "        cur = text\n",
        "        for _ in range(6):\n",
        "            if count_tokens_text(cur) <= budget_tokens:\n",
        "                return cur\n",
        "            keep = max(800, int(len(cur) * 0.85))\n",
        "            cur = cur[:keep]\n",
        "        return cur\n",
        "    body2 = shrink_to_budget(body, budget_tokens)\n",
        "\n",
        "    user_txt = MAP_USER_TMPL.format(topic=(topic_hint or \"（無）\"), chunk=body2)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n",
        "        {\"role\": \"user\",   \"content\": user_txt},\n",
        "    ]\n",
        "\n",
        "    part_buf, shown = [], 0\n",
        "    for token in llm_stream(messages, map_max_new_tokens):\n",
        "        part_buf.append(token)\n",
        "        # Update live display and terminal character count periodically\n",
        "        if len(part_buf) % 24 == 0:\n",
        "            cur_txt = \"\".join(part_buf)\n",
        "            live.update(Markdown(cur_txt))\n",
        "            sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "    cur_txt = \"\".join(part_buf)\n",
        "    live.update(Markdown(cur_txt))\n",
        "    sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Include the model's final output directly, no regex cleaning\n",
        "    maps.append(cur_txt.strip())\n",
        "\n",
        "if DEBUG_MODE: print(\"→ Segment summarization complete\")\n",
        "\n",
        "# ===== 6) Consolidate (reduce) & Only write .md =====\n",
        "if DEBUG_MODE: print(\"[6/6] Consolidating summary (reduce) ...\")\n",
        "maps_md = \"\\n\\n---\\n\\n\".join(f\"### 片段 {i+1} 要點\\n\\n{m}\" for i, m in enumerate(maps))\n",
        "\n",
        "# If combined text exceeds window, truncate proportionally first (without changing text within segments to avoid breaking meaning)\n",
        "def fit_reduce_payload(md_text: str, max_ctx_tokens: int) -> str:\n",
        "    for _ in range(8):\n",
        "        need = count_tokens_text(md_text)\n",
        "        if need + reduce_max_new_tokens + 400 <= max_ctx_tokens:\n",
        "            return md_text\n",
        "        md_text = md_text[: int(len(md_text) * 0.9)]\n",
        "    return md_text\n",
        "\n",
        "md_cur = fit_reduce_payload(maps_md, ctx_window)\n",
        "\n",
        "user_txt = REDUCE_USER_TMPL.format(topic=(topic_hint or \"（無）\"), maps=md_cur)\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_INSTR},\n",
        "            {\"role\":\"user\",\"content\":user_txt}]\n",
        "\n",
        "live2 = display(Markdown(\"\"), display_id=True)\n",
        "final_buf = []\n",
        "for token in llm_stream(messages, reduce_max_new_tokens):\n",
        "    final_buf.append(token)\n",
        "    if len(final_buf) % 24 == 0:\n",
        "        live2.update(Markdown(\"\".join(final_buf)))\n",
        "        sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "live2.update(Markdown(\"\".join(final_buf)))\n",
        "sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "\n",
        "final_text = \"\".join(final_buf).strip()\n",
        "\n",
        "out_dir = Path(output_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_md = out_dir / f\"{Path(srt_path).stem}_summary.md\"\n",
        "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_text)\n",
        "\n",
        "print(f\"→ 完成 ✅  {out_md}\")\n",
        "try:\n",
        "    del llm\n",
        "except Exception:\n",
        "    pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"（顯存已釋放，如需重跑可直接再次執行）\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "→ 當前工作目錄：/content/gdrive/MyDrive\n",
            "→ 來源檔：/content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\n",
            "→ 輸出資料夾：/content/gdrive/MyDrive/whisper\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/340 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1564fadc93cb47258fb24d74c5214e68"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocabulary.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1704c3adb542403daa6c5fcd88b68573"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca4fe1da6cd14b1daca42e73924209b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.bin:   0%|          | 0.00/3.09G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "198e13ae302845f4b087e5f5229d98a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7b2a8d77258494f8457cb9dce734f24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  1%] 00:00:00,000 → 00:00:29,980  Teksting av Nicolai Winther\n",
            "[  1%] 00:00:20,000 → 00:00:49,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:00:40,000 → 00:01:09,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:00,000 → 00:01:29,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:20,000 → 00:01:49,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:01:40,000 → 00:02:09,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:02:00,000 → 00:02:29,980  Teksting av Nicolai Winther\n",
            "[  4%] 00:02:20,000 → 00:02:49,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:00,000 → 00:03:29,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:20,000 → 00:03:49,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:03:40,000 → 00:04:09,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:04:00,000 → 00:04:18,900  聽得到聲音嗎?\n",
            "[  6%] 00:04:20,000 → 00:04:24,000  Ok,ok\n",
            "[  6%] 00:04:24,000 → 00:04:28,000  Ok,那我想先確定\n",
            "[  6%] 00:04:28,000 → 00:04:32,000  威神你那邊在看完教證手冊之後\n",
            "[  6%] 00:04:32,000 → 00:04:36,000  你目前有任何的想法嗎?\n",
            "[  6%] 00:04:36,000 → 00:04:40,000  我覺得因為那時候是說\n",
            "[  6%] 00:04:40,000 → 00:04:45,240  八月底先寫完那個內容的部分嘛\n",
            "[  6%] 00:04:45,240 → 00:04:48,440  但是我覺得看完之後應該要大概\n",
            "[  6%] 00:04:48,440 → 00:04:51,180  我覺得八月底前應該沒辦法寫完\n",
            "[  7%] 00:04:51,180 → 00:04:54,040  那你覺得你什麼時候可以完成得了\n",
            "[  7%] 00:04:54,040 → 00:04:56,480  十月左右嗎\n",
            "[  7%] 00:04:56,480 → 00:04:58,400  你是說單子內容嗎\n",
            "[  7%] 00:05:00,000 → 00:05:06,000  嗯,對。\n",
            "[  7%] 00:05:06,000 → 00:05:09,500  呃,十月底。\n",
            "[  7%] 00:05:09,500 → 00:05:11,580  十月底。\n",
            "[  7%] 00:05:11,580 → 00:05:12,160  好。\n",
            "[  7%] 00:05:12,160 → 00:05:14,780  前,看看吧。\n",
            "[  7%] 00:05:14,780 → 00:05:20,040  因為我也還沒有開始,就是,照他的那個方向去改,所以我...\n",
            "[  7%] 00:05:20,000 → 00:05:23,000  I don't know how long it will take.\n",
            "[  7%] 00:05:23,000 → 00:05:25,000  Ok, ok, I got it.\n",
            "[  7%] 00:05:25,000 → 00:05:27,000  Ok, then I would like to...\n",
            "[  7%] 00:05:27,000 → 00:05:29,000  If you can speak now,\n",
            "[  7%] 00:05:29,000 → 00:05:32,000  you can briefly introduce to Wei-Chen\n",
            "[  7%] 00:05:32,000 → 00:05:35,000  the anti-epidemic prevention method.\n",
            "[  8%] 00:05:40,000 → 00:06:00,000  你要先跟他講一下,就是...\n",
            "[  8%] 00:06:00,000 → 00:06:05,000  我覺得這是一個知識存在的方面嘛 就是框架然後核心特色這樣子\n",
            "[  8%] 00:06:05,000 → 00:06:09,000  好,我發現我只要轉手機跟電腦\n",
            "[  8%] 00:06:09,000 → 00:06:13,000  你們剛剛是問到說就是未成什麼時候可以完成這本書\n",
            "[  8%] 00:06:13,000 → 00:06:18,000  然後是說是十月,十月但是不確定是什麼時候是嗎?\n",
            "[  8%] 00:06:18,000 → 00:06:20,000  Yes\n",
            "[  9%] 00:06:20,000 → 00:06:35,000  我做出這個交戰手冊主要是想說我不知道能不能去陪軍做一些類似跟AI相關的工具\n",
            "[  9%] 00:06:35,000 → 00:06:40,000  因為我的經驗會是如果有了一個標準的準則\n",
            "[  9%] 00:06:40,000 → 00:06:43,600  算是這種抽象的邏輯的話\n",
            "[  9%] 00:06:43,600 → 00:06:48,800  就能夠讓實際在寫獎益的時候\n",
            "[  9%] 00:06:48,800 → 00:06:53,200  可能就可以搭配給AI去自動生成一些類似的東西\n",
            "[  9%] 00:06:53,200 → 00:06:57,600  或是甚至可以去檢驗說這份獎益有沒有包含到\n",
            "[  9%] 00:06:57,600 → 00:07:00,000  這個交戰手冊裡面鎖定\n",
            "[  9%] 00:07:00,000 → 00:07:08,000  我覺得這可能也會讓微塵在寫講義的時候再更快一點。\n",
            "[ 10%] 00:07:08,000 → 00:07:15,000  然後具體來說這裡面的這些校章手冊裡面的所有東西,\n",
            "[ 10%] 00:07:15,000 → 00:07:20,000  玉茜你剛是問我說\n",
            "[ 10%] 00:07:20,000 → 00:07:21,200  我要講什麼\n",
            "[ 10%] 00:07:21,200 → 00:07:24,040  就你可能要稍微跟他說明一下\n",
            "[ 10%] 00:07:24,040 → 00:07:25,240  然後介紹一下\n",
            "[ 10%] 00:07:27,240 → 00:07:28,040  很多耶\n",
            "[ 10%] 00:07:32,500 → 00:07:35,240  維承目前我有幫你按照那個\n",
            "[ 10%] 00:07:35,240 → 00:07:37,400  我覺得的優先順序去排\n",
            "[ 10%] 00:07:37,400 → 00:07:39,600  就是第一個姿勢框架的話\n",
            "[ 10%] 00:07:39,600 → 00:07:40,400  就是我覺得\n",
            "[ 10%] 00:07:40,000 → 00:07:44,000  我覺得這份獎益會最迫切需要的東西\n",
            "[ 10%] 00:07:44,000 → 00:07:47,000  然後所謂的知識框架你可以把它想像成\n",
            "[ 10%] 00:07:47,000 → 00:07:51,000  或寫一個法律系的那個解題的東西\n",
            "[ 11%] 00:07:51,000 → 00:07:55,000  就是我好像記得你有學過民法\n",
            "[ 11%] 00:07:55,000 → 00:07:58,000  還是其他的法律相關的東西\n",
            "[ 11%] 00:07:58,000 → 00:08:00,000  但你也大概可以知道\n",
            "[ 11%] 00:08:00,000 → 00:08:14,980  當你面對一個複雜的案件的時候,你一定要有一套固定的思考方式跟答題方式,你才能夠快速進入到那個理解的框架裡面,然後按照這些步驟去解那個題。\n",
            "[ 11%] 00:08:14,980 → 00:08:20,000  那即便這個步驟可能有一些是形同虛設的,有一些可能在...\n",
            "[ 11%] 00:08:20,000 → 00:08:23,340  在某些題目當中其實根本就是非必要的\n",
            "[ 11%] 00:08:23,340 → 00:08:26,880  可是一旦你有了一個固定的解題框\n",
            "[ 11%] 00:08:26,880 → 00:08:28,000  這樣的思考流程\n",
            "[ 11%] 00:08:28,000 → 00:08:30,440  你在解題的時候就會更有確定感\n",
            "[ 11%] 00:08:30,440 → 00:08:34,580  然後一方面是讓學生能夠感覺自己學到\n",
            "[ 11%] 00:08:34,580 → 00:08:37,660  很具體的感受到自己有學到一套策略\n",
            "[ 12%] 00:08:37,660 → 00:08:40,000  另外一方面也是我們在行銷的\n",
            "[ 12%] 00:08:40,000 → 00:08:46,000  也會更能夠拿這一個策略,這套方法論去推廣出去。\n",
            "[ 12%] 00:08:46,000 → 00:08:54,000  所以我自己是有幫你舉的一個物理上面的例子是先聚焦再發散。\n",
            "[ 12%] 00:08:54,000 → 00:09:00,000  然後我就直接幫你寫了先聚焦再發散這個東西的\n",
            "[ 12%] 00:09:00,000 → 00:09:03,000  This is...wait a minute, the jade line is sliding down\n",
            "[ 12%] 00:09:03,000 → 00:09:06,000  Sliding down, sliding down, sliding down\n",
            "[ 12%] 00:09:06,000 → 00:09:08,000  Hey, this is the correct one\n",
            "[ 12%] 00:09:08,000 → 00:09:11,000  I forgot to delete the top\n",
            "[ 12%] 00:09:11,000 → 00:09:15,000  And then there is a physical demonstration down there\n",
            "[ 12%] 00:09:15,000 → 00:09:20,000  I will want to see that the microcosm may be speaking again\n",
            "[ 13%] 00:09:20,000 → 00:09:28,000  內容的部分先去告訴學生說所謂的先聚焦再發散這個答題策略的核心觀念是什麼\n",
            "[ 13%] 00:09:28,000 → 00:09:34,000  就是什麼是聚焦什麼是發散為什麼聚焦什麼發散然後如何聚焦如何發散\n",
            "[ 13%] 00:09:34,000 → 00:09:40,000  接下來就是透過各種抽象的步驟整理各種抽象的策略\n",
            "[ 13%] 00:09:40,000 → 00:09:46,000  一步一步的去告訴學生說這一個知識框架到底想要傳達的是什麼\n",
            "[ 13%] 00:09:46,000 → 00:09:49,000  然後進到你的題目部分\n",
            "[ 13%] 00:09:49,000 → 00:09:53,000  題目我們等下還會討論說它是要做成就是多少頁數\n",
            "[ 13%] 00:09:53,000 → 00:09:55,000  然後要不要做成電子檔\n",
            "[ 13%] 00:09:55,000 → 00:09:59,000  然後等下育前也會補充說學生對於電子檔的看法這些的\n",
            "[ 14%] 00:10:00,000 → 00:10:12,760  不論如何把題目每一題的解題過程還有每一個詳節都去套用這個不管是三步驟的發賽也好還是先聚焦的發賽\n",
            "[ 14%] 00:10:12,760 → 00:10:19,760  只要固定有一個解題的框架固定的一個算是一個噱頭或是一個包裝\n",
            "[ 14%] 00:10:20,000 → 00:10:22,560  它都可以讓學生更有一個確定感\n",
            "[ 14%] 00:10:22,560 → 00:10:25,760  所以我就會希望這本書最少最少最少最少最少\n",
            "[ 14%] 00:10:25,760 → 00:10:28,000  其他可以慢慢再補上\n",
            "[ 14%] 00:10:28,000 → 00:10:33,000  但是我覺得這個是我會希望可以加進去書\n",
            "[ 14%] 00:10:33,000 → 00:10:34,600  然後再出版會比較好\n",
            "[ 14%] 00:10:34,600 → 00:10:37,000  看我講完了\n",
            "[ 14%] 00:10:40,000 → 00:10:44,000  你目前對這部分有任何的問題嗎?\n",
            "[ 15%] 00:10:49,000 → 00:10:59,000  我要再想就是怎麼具體去把它落實到書的每個章節裡面\n",
            "[ 15%] 00:11:00,000 → 00:11:04,000  OK\n",
            "[ 15%] 00:11:04,000 → 00:11:10,000  我可以問你你自己在打題的時候也會有這樣子的\n",
            "[ 15%] 00:11:10,000 → 00:11:16,000  它會給你一種感覺嗎?就是說物理每個題目好像都有一個感覺\n",
            "[ 15%] 00:11:16,000 → 00:11:20,000  還是你是每個題目有不同的感覺?\n",
            "[ 15%] 00:11:20,000 → 00:11:24,000  好像沒有一個固定的流程\n",
            "[ 15%] 00:11:24,000 → 00:11:31,000  就是覺得可能是\n",
            "[ 15%] 00:11:31,000 → 00:11:33,000  我不會啊\n",
            "[ 15%] 00:11:33,000 → 00:11:35,000  但我覺得他們可能要先\n",
            "[ 15%] 00:11:35,000 → 00:11:37,000  抓到情況再說什麼\n",
            "[ 15%] 00:11:37,000 → 00:11:39,000  但是我就\n",
            "[ 16%] 00:11:40,000 → 00:11:44,000  我覺得我可以抓到,但我覺得他們可能是沒辦法抓到,所以寫不出來。\n",
            "[ 16%] 00:11:46,000 → 00:11:51,000  所以我覺得要先教他們怎麼把題目的點抓出來。\n",
            "[ 16%] 00:11:53,000 → 00:12:00,000  還是我在想會不會你可以跟TradeGVD聊,就你把你看的那些,你可能跟...\n",
            "[ 16%] 00:12:00,000 → 00:12:04,000  跟ChangeGPT聊個十個題目到二十個題目\n",
            "[ 16%] 00:12:04,000 → 00:12:07,000  然後你可能就請他幫你總結一下你這套思路\n",
            "[ 16%] 00:12:07,000 → 00:12:12,000  它背後的核心的步驟\n",
            "[ 16%] 00:12:12,000 → 00:12:15,000  還有你關注的重點\n",
            "[ 16%] 00:12:15,000 → 00:12:18,000  怎麼樣變成一套固定的策略\n",
            "[ 16%] 00:12:18,000 → 00:12:20,000  你可以試試看這個\n",
            "[ 16%] 00:12:20,000 → 00:12:20,500  Ok\n",
            "[ 17%] 00:12:40,000 → 00:12:43,000  你這本書最主要的核心的點是什麼東西 你這本書最主要的核心的點是什麼東西\n",
            "[ 17%] 00:12:47,000 → 00:12:52,000  如果以英文英文的書去舉例的話 就會像是作文書的話\n",
            "[ 17%] 00:12:52,000 → 00:12:58,000  雖然說它有很多很多的內容 但是我們會推出一個最主要的基點 就是它的八條公式\n",
            "[ 17%] 00:12:58,000 → 00:13:00,000  然後這個八條公式也是我們\n",
            "[ 17%] 00:13:00,000 → 00:13:04,500  主要不管是拿在書籍的生存或在社群的行銷上\n",
            "[ 17%] 00:13:04,500 → 00:13:06,700  我們都會拿著八條公式去主打\n",
            "[ 18%] 00:13:06,700 → 00:13:10,580  所以它對於學生的記憶或是這本書的整體\n",
            "[ 18%] 00:13:10,580 → 00:13:14,060  它就會有一個固定的記憶格式\n",
            "[ 18%] 00:13:14,060 → 00:13:16,040  就是大家對於這本書就會是\n",
            "[ 18%] 00:13:16,040 → 00:13:18,900  這個就是那個八條公式就是那個很屌\n",
            "[ 18%] 00:13:18,900 → 00:13:19,980  然後一模獨創的那個\n",
            "[ 18%] 00:13:20,000 → 00:13:24,640  所以也會需要你在幫我寫這本書的時候\n",
            "[ 18%] 00:13:24,640 → 00:13:27,700  也去稍微想一下你這本書的核心特色\n",
            "[ 18%] 00:13:27,700 → 00:13:29,160  最主要的那個點會是什麼\n",
            "[ 18%] 00:13:29,160 → 00:13:30,840  然後是什麼東西是可以對\n",
            "[ 18%] 00:13:30,840 → 00:13:33,760  拿出去打給社群媒體的\n",
            "[ 18%] 00:13:33,760 → 00:13:35,900  這部分有問題嗎\n",
            "[ 18%] 00:13:35,900 → 00:13:37,900  OK\n",
            "[ 18%] 00:13:37,900 → 00:13:39,220  好\n",
            "[ 18%] 00:13:40,000 → 00:13:44,960  好 子明請說\n",
            "[ 18%] 00:13:44,960 → 00:13:48,960  好 我剛剛的那個核心特色\n",
            "[ 18%] 00:13:48,960 → 00:13:53,020  如果我以前在寫物理的內容跟題目的時候\n",
            "[ 18%] 00:13:53,020 → 00:13:54,920  想不到這個特色的話\n",
            "[ 19%] 00:13:54,920 → 00:13:57,340  其實也可以就是照個路\n",
            "[ 19%] 00:13:57,340 → 00:13:59,980  把它變成說是在讀物\n",
            "[ 19%] 00:14:00,000 → 00:14:03,000  你覺得物理這個科目上面的策略\n",
            "[ 19%] 00:14:03,000 → 00:14:05,000  可能就可以想一個什麼循環圖啊\n",
            "[ 19%] 00:14:05,000 → 00:14:09,000  還是什麼正面加強的理論啊什麼的\n",
            "[ 19%] 00:14:09,000 → 00:14:13,000  但就是不一定要是物理的那些章節\n",
            "[ 19%] 00:14:13,000 → 00:14:16,000  你也可以是講你的讀書方法或筆記方法\n",
            "[ 19%] 00:14:16,000 → 00:14:18,000  它也可以變成是一個核心特色\n",
            "[ 19%] 00:14:20,000 → 00:14:23,000  我再想想。\n",
            "[ 19%] 00:14:25,000 → 00:14:35,000  那我也想順便確認一下,你有預計什麼時候可能會確定這本書的整個核心特色嗎?\n",
            "[ 19%] 00:14:35,000 → 00:14:40,000  會需要等你內容寫完嗎?還是你在這中間的過程中你可以先...\n",
            "[ 20%] 00:14:40,000 → 00:14:41,920  跟我確定\n",
            "[ 20%] 00:14:41,920 → 00:14:47,960  應該可以比內容早確定\n",
            "[ 20%] 00:14:47,960 → 00:14:49,680  但是我現在還沒有\n",
            "[ 20%] 00:14:49,680 → 00:14:52,060  就是想出來它是什麼\n",
            "[ 20%] 00:14:52,060 → 00:14:54,940  OK好沒有問題\n",
            "[ 20%] 00:14:54,940 → 00:14:58,180  然後再來下一個的話\n",
            "[ 20%] 00:14:58,180 → 00:14:59,980  會是學習方式跟記憶策略\n",
            "[ 20%] 00:15:00,000 → 00:15:08,000  因為我知道你有先看過整個的內容,所以我想確認你對於這部分有任何問題嗎?\n",
            "[ 20%] 00:15:08,000 → 00:15:17,000  或是有特別想詢問的點嗎?如果沒有的話我們就加快進度,就不用這樣一個一個特別的去講解。\n",
            "[ 21%] 00:15:20,000 → 00:15:27,000  因為就是這邊看起來比較想要說就是要理解\n",
            "[ 21%] 00:15:27,000 → 00:15:35,000  但是我不確定就是他們要理解全盤理解的話會耗費的成本要多少\n",
            "[ 21%] 00:15:35,000 → 00:15:40,000  還是有些人是不是只是想要把它把固定的流程背起來\n",
            "[ 21%] 00:15:40,000 → 00:15:42,800  然後就可以去解題\n",
            "[ 21%] 00:15:42,800 → 00:15:46,200  所以我要著重在\n",
            "[ 21%] 00:15:46,200 → 00:15:48,000  就是不用全盤理解\n",
            "[ 21%] 00:15:48,000 → 00:15:49,200  但是比較好解題\n",
            "[ 21%] 00:15:49,200 → 00:15:51,600  還是希望他們比較好理解\n",
            "[ 21%] 00:15:51,600 → 00:15:56,100  然後就是底子很穩這樣\n",
            "[ 21%] 00:15:56,100 → 00:15:58,400  方向應該在那邊\n",
            "[ 21%] 00:15:58,400 → 00:16:00,000  我覺得會比較看\n",
            "[ 21%] 00:16:00,000 → 00:16:04,200  你這本書的定位點在哪裡?\n",
            "[ 21%] 00:16:04,200 → 00:16:09,800  子民剛說有要講話,我有看到你那個框框。\n",
            "[ 22%] 00:16:09,800 → 00:16:14,000  好像上次跟維城討論的時候你是說,\n",
            "[ 22%] 00:16:14,000 → 00:16:20,000  你希望事實上不知道怎麼開始讀物理的人也可以找到一個方向。\n",
            "[ 22%] 00:16:20,000 → 00:16:25,440  所以你可能打的比較算是中間的族群,是嗎?\n",
            "[ 22%] 00:16:25,440 → 00:16:27,240  算是。\n",
            "[ 22%] 00:16:27,240 → 00:16:28,240  喔。\n",
            "[ 22%] 00:16:34,900 → 00:16:40,000  我會去做這個學習策略的這個地方其實是想說你...\n",
            "[ 22%] 00:16:40,000 → 00:16:48,220  你如果在傳達你的想法跟知識的時候,能夠不要做任何的刪減,\n",
            "[ 23%] 00:16:49,040 → 00:16:58,500  而是你就把最難的東西端出來給學生,可是呢,你還是可以面對初級跟總級的學生,\n",
            "[ 23%] 00:16:58,500 → 00:17:00,500  但是你的...\n",
            "[ 23%] 00:17:00,000 → 00:17:20,120  實施卻是最難的,那這中間的那個gap,中間的那個就是轟溝,你就要透過這些學習方式跟記憶策略的引導,就是如果你的觀念越難,你中間就要解釋越多這樣子的學習策略,然後讓這些重等到初級的學生,\n",
            "[ 23%] 00:17:20,000 → 00:17:22,000  學生也能夠學起來\n",
            "[ 23%] 00:17:22,000 → 00:17:26,000  我當初設計就有這樣的想法\n",
            "[ 23%] 00:17:26,000 → 00:17:36,000  所以我就先把全部東西都最難的部分也寫出來\n",
            "[ 23%] 00:17:36,000 → 00:17:40,000  然後我想往後面再做一個\n",
            "[ 24%] 00:17:40,000 → 00:17:58,260  比較重點的整理,這樣,就是如果你對前面的深入學習沒有興趣的話,那你就直接看重點就好了,這樣應該比較好,就是兩邊都照顧到,也可以,又或者是說你其實也可以,\n",
            "[ 24%] 00:18:00,000 → 00:18:01,840  這點我可能還是會存疑啦\n",
            "[ 24%] 00:18:01,840 → 00:18:03,760  我其實也沒有很確定\n",
            "[ 24%] 00:18:03,760 → 00:18:07,900  就是因為我自己的作文書也是寫到最難\n",
            "[ 24%] 00:18:07,900 → 00:18:10,800  確實也是有學生會覺得太難\n",
            "[ 24%] 00:18:10,800 → 00:18:14,840  但我會傾向是說如果你能夠用這些\n",
            "[ 24%] 00:18:14,840 → 00:18:17,460  就是我有給你一個檔案\n",
            "[ 24%] 00:18:17,460 → 00:18:20,000  就是在這個頁面裡面還有一個連接\n",
            "[ 24%] 00:18:20,000 → 00:18:23,000  我有一個可以出去的檔案叫核心學習策略\n",
            "[ 24%] 00:18:23,000 → 00:18:25,000  你有看過這個嗎?一個\n",
            "[ 25%] 00:18:25,000 → 00:18:28,000  對對對對現在有打開了這個\n",
            "[ 25%] 00:18:28,000 → 00:18:33,000  就是你就可以把一些這裡面的讀書策略跟技巧\n",
            "[ 25%] 00:18:37,000 → 00:18:39,000  這個檔案我還沒看過\n",
            "[ 25%] 00:18:40,000 → 00:18:43,000  你可以先把它看一下。\n",
            "[ 25%] 00:18:43,000 → 00:18:54,000  我自己教學的經驗是讓我發現說這些策略它其實不是只用在英文。\n",
            "[ 25%] 00:18:54,000 → 00:18:59,000  我昨天也是用這個東西去跟學生講數學什麼學。\n",
            "[ 25%] 00:19:00,000 → 00:19:07,000  我想說這東西其實可以一定程度幫助學生理解一些太複雜或太困難的觀念。\n",
            "[ 26%] 00:19:07,000 → 00:19:16,000  然後我就會覺得你跟他解釋越多這些學習策略,他們可能就會越能夠理解你想要傳達的物理專業知識。\n",
            "[ 26%] 00:19:16,000 → 00:19:20,000  所以就是取決於你想要寫多難的東西,然後就加多少。\n",
            "[ 26%] 00:19:20,000 → 00:19:25,000  好,講完嘅。\n",
            "[ 26%] 00:19:25,000 → 00:19:29,000  威神那邊有問題嗎?\n",
            "[ 26%] 00:19:29,000 → 00:19:31,000  暫時沒有。\n",
            "[ 26%] 00:19:31,000 → 00:19:35,000  到時候再麻煩你會後花一些時間幫我看過,\n",
            "[ 26%] 00:19:35,000 → 00:19:39,000  然後如果有不懂的地方可以再隨時跟我們講。\n",
            "[ 26%] 00:19:39,000 → 00:19:40,000  好。\n",
            "[ 26%] 00:19:40,000 → 00:19:45,100  再嚟嘅話就會系梳集咗一個大嘅架構,\n",
            "[ 26%] 00:19:45,100 → 00:19:51,880  佢就跟其實就跟你現在嗰個章節都系很像,\n",
            "[ 26%] 00:19:52,160 → 00:19:55,420  但就系我哋嘅章節架構可能要再清楚明確一點,\n",
            "[ 27%] 00:19:57,760 → 00:19:59,960  然後像呢些可能\n",
            "[ 27%] 00:20:00,000 → 00:20:07,000  你可以先幫我列完,然後如果你需要一些圖示的話,這些我們都可以直接再幫你做。\n",
            "[ 27%] 00:20:11,000 → 00:20:20,000  所以大致上那個架構的話就會是講,就是可能這本書的蓋欄,然後跟這本書的使用說明,然後第一個的大張點。\n",
            "[ 27%] 00:20:20,000 → 00:20:39,000  第二個大章節,然後可能你大章節完之後你會有一個小的,你會先有一個小的總結,然後你的小章節一樣會有一個小的總結,然後才會是這個小章節裡面的氣象,然後最後你還是需要再幫他附一個總結,這樣會是一個比較完整的架構,然後也比較能幫助學生達到一個比較好的學習方式。\n",
            "[ 27%] 00:20:40,000 → 00:20:42,000  所以書籍加關可以參考這邊\n",
            "[ 28%] 00:20:42,000 → 00:20:44,000  好 子明起說\n",
            "[ 28%] 00:20:44,000 → 00:20:46,000  我喔 我又有話要說了\n",
            "[ 28%] 00:20:46,000 → 00:20:48,000  就是你除了\n",
            "[ 28%] 00:20:48,000 → 00:20:50,000  我要說什麼\n",
            "[ 28%] 00:20:50,000 → 00:20:52,000  你的大架構裡面\n",
            "[ 28%] 00:20:52,000 → 00:20:54,000  其實可以多加入一些些\n",
            "[ 28%] 00:20:54,000 → 00:20:56,000  就是比較感性一點的東西\n",
            "[ 28%] 00:20:56,000 → 00:20:58,000  就是你在書籍的可能\n",
            "[ 28%] 00:20:58,000 → 00:21:00,000  在那個章節的開頭\n",
            "[ 28%] 00:21:00,000 → 00:21:03,400  會需要先有一個簡單的總結或是一個概覽\n",
            "[ 28%] 00:21:03,400 → 00:21:05,100  然後讓學生可以進入這個章節\n",
            "[ 28%] 00:21:05,100 → 00:21:07,560  那章節的最後結束也會有一個總結\n",
            "[ 28%] 00:21:07,560 → 00:21:10,480  只是你的那個開始跟那個總結\n",
            "[ 28%] 00:21:10,480 → 00:21:13,220  就是不一定要是很理性\n",
            "[ 28%] 00:21:13,220 → 00:21:18,420  然後很踏實的那種知識上面的整理\n",
            "[ 28%] 00:21:18,420 → 00:21:19,980  你也可以在這邊加一些\n",
            "[ 28%] 00:21:20,000 → 00:21:22,500  讓學生可以心情好一點的東西\n",
            "[ 28%] 00:21:22,500 → 00:21:24,500  譬如說剛開始就是\n",
            "[ 28%] 00:21:24,500 → 00:21:26,500  在章節開始的時候就說\n",
            "[ 29%] 00:21:26,500 → 00:21:29,500  這張適合有哪一些問題的學生\n",
            "[ 29%] 00:21:29,500 → 00:21:31,500  然後就列很多學生常見的問題\n",
            "[ 29%] 00:21:31,500 → 00:21:34,500  那學生可能就會自己跳進去對號入座\n",
            "[ 29%] 00:21:34,500 → 00:21:36,500  就領了一個身份標籤之後\n",
            "[ 29%] 00:21:36,500 → 00:21:38,000  就開始讀這個章節的時候\n",
            "[ 29%] 00:21:38,000 → 00:21:40,000  就會覺得自己的\n",
            "[ 29%] 00:21:40,000 → 00:21:42,000  問題就可以被妥善的解決\n",
            "[ 29%] 00:21:42,000 → 00:21:44,000  然後你到總結的地方再跟他說\n",
            "[ 29%] 00:21:44,000 → 00:21:48,000  恭喜你就是已經解決了這樣子的問題\n",
            "[ 29%] 00:21:48,000 → 00:21:50,000  你一定會越來越好啊什麼的\n",
            "[ 29%] 00:21:50,000 → 00:21:52,000  就可以給一些情緒上面的\n",
            "[ 29%] 00:21:52,000 → 00:21:53,000  給一些情緒價值\n",
            "[ 29%] 00:21:53,000 → 00:21:55,000  學生讀起來會比較\n",
            "[ 29%] 00:21:55,000 → 00:21:57,000  算是堅持得下去吧\n",
            "[ 29%] 00:21:57,000 → 00:22:00,000  如果你會把內容加得深入一點點的話\n",
            "[ 29%] 00:22:00,000 → 00:22:02,000  還有腳外的\n",
            "[ 29%] 00:22:02,000 → 00:22:04,000  咚\n",
            "[ 29%] 00:22:04,000 → 00:22:06,000  好\n",
            "[ 29%] 00:22:06,000 → 00:22:08,000  再來的話就是說幾個小架構\n",
            "[ 29%] 00:22:08,000 → 00:22:10,000  那個小架構就是偏\n",
            "[ 29%] 00:22:10,000 → 00:22:12,000  理論跟案例\n",
            "[ 30%] 00:22:12,000 → 00:22:14,000  這個的話前面其實也有提到\n",
            "[ 30%] 00:22:14,000 → 00:22:16,000  然後這個你可以\n",
            "[ 30%] 00:22:16,000 → 00:22:18,000  如果你沒有很懂的話可以再問我\n",
            "[ 30%] 00:22:18,000 → 00:22:20,000  然後\n",
            "[ 30%] 00:22:20,000 → 00:22:25,000  理論的主要呈現原則就是你要以系統性的東西去取代流水帳\n",
            "[ 30%] 00:22:25,000 → 00:22:30,000  就是系統性就比較像是可能第一步第二步然後原則一原則二原則三\n",
            "[ 30%] 00:22:30,000 → 00:22:34,000  然後或者是你可以用一個表格呈現可以用流程圖可以用矩陣都可以\n",
            "[ 30%] 00:22:34,000 → 00:22:40,000  然後這種方式會比起你只是跟他講說我今天去買了蘋果\n",
            "[ 30%] 00:22:40,000 → 00:22:44,500  如果怎麼樣怎麼樣,這種流水的方式好很多很多很多。\n",
            "[ 30%] 00:22:44,500 → 00:22:46,500  然後再來是案例的呈現原則。\n",
            "[ 30%] 00:22:46,500 → 00:22:50,800  你要盡量讓,就是用故事的方式去讓理論去落地。\n",
            "[ 30%] 00:22:50,800 → 00:22:56,000  就是你可以去多講幾個例子,然後但是你不能只是單純的講例子。\n",
            "[ 31%] 00:22:56,000 → 00:23:00,000  你要去刻意的選擇可以提出這些理論的關鍵點的案例。\n",
            "[ 31%] 00:23:00,000 → 00:23:03,820  然後讓案例的順序跟理論的分點是一致的\n",
            "[ 31%] 00:23:03,820 → 00:23:05,620  就是學生他可以互相對照\n",
            "[ 31%] 00:23:05,620 → 00:23:07,800  他不會覺得我現在看了這個理論\n",
            "[ 31%] 00:23:07,800 → 00:23:09,500  但是我找不到對應的案例\n",
            "[ 31%] 00:23:09,500 → 00:23:10,720  或者是我現在看了這個案例\n",
            "[ 31%] 00:23:10,720 → 00:23:12,820  但我也不知道你在講哪一個理論這樣子\n",
            "[ 31%] 00:23:12,820 → 00:23:15,740  目前這邊是OK的\n",
            "[ 31%] 00:23:15,740 → 00:23:16,920  OK\n",
            "[ 31%] 00:23:16,920 → 00:23:17,980  好\n",
            "[ 31%] 00:23:17,980 → 00:23:20,020  然後因為我們收集的內容\n",
            "[ 31%] 00:23:20,000 → 00:23:22,260  我们会以黑白色为主\n",
            "[ 31%] 00:23:22,260 → 00:23:25,540  所以如果你今天在帮我写里面的内容\n",
            "[ 31%] 00:23:25,540 → 00:23:28,920  然后有些比较想要让他们强调的重点\n",
            "[ 31%] 00:23:28,920 → 00:23:31,640  你可能需要帮我使用色块或是粗体\n",
            "[ 31%] 00:23:31,640 → 00:23:34,860  或是一些其他的框框标记都可以\n",
            "[ 31%] 00:23:34,860 → 00:23:37,840  但是你需要有一个让他们可以很好get到说\n",
            "[ 31%] 00:23:37,840 → 00:23:39,980  这里可能是相对于其他内容性\n",
            "[ 31%] 00:23:40,000 → 00:23:42,000  較為重要的地方\n",
            "[ 32%] 00:23:44,000 → 00:23:45,000  好\n",
            "[ 32%] 00:23:45,000 → 00:23:48,000  然後下面你應該也都有看過\n",
            "[ 32%] 00:23:48,000 → 00:23:50,000  那你有什麼地方有不了解\n",
            "[ 32%] 00:23:50,000 → 00:23:52,000  然後有想問的嗎\n",
            "[ 32%] 00:23:56,000 → 00:23:58,000  看起來沒有\n",
            "[ 32%] 00:23:58,000 → 00:23:59,000  好\n",
            "[ 32%] 00:23:59,000 → 00:24:00,000  線上話\n",
            "[ 32%] 00:24:00,000 → 00:24:01,200  與配套工具\n",
            "[ 32%] 00:24:01,200 → 00:24:05,040  啊沒事\n",
            "[ 32%] 00:24:05,040 → 00:24:05,720  在下面\n",
            "[ 32%] 00:24:05,720 → 00:24:08,000  對不起我插嘴了\n",
            "[ 32%] 00:24:08,000 → 00:24:08,420  對不起\n",
            "[ 32%] 00:24:08,420 → 00:24:10,940  好然後順便跟維成提\n",
            "[ 32%] 00:24:10,940 → 00:24:13,260  就是因為我知道你有做那個\n",
            "[ 32%] 00:24:13,260 → 00:24:14,180  就是\n",
            "[ 32%] 00:24:14,180 → 00:24:16,440  立貼題目\n",
            "[ 32%] 00:24:16,440 → 00:24:16,840  然後\n",
            "[ 32%] 00:24:16,840 → 00:24:18,660  就是他如果\n",
            "[ 32%] 00:24:18,660 → 00:24:20,000  如果你今天還是要把他寫在\n",
            "[ 32%] 00:24:20,000 → 00:24:27,180  你在書裡面或是你今天在書本裡面有提到,然後你不知道怎麼拍板的話,就是知名右相有一個是比較好的方式。\n",
            "[ 33%] 00:24:27,180 → 00:24:40,000  如果你今天想要讓學生,他是可以先看完題目,然後先有一個答案,然後再繼續看詳解的話,你可以變成說第一頁他有三題的題目,然後你翻頁之後是那三題的講解。\n",
            "[ 33%] 00:24:40,000 → 00:25:00,000  然後就稍微對一下拍板,才不會讓他們馬上就可以找到答案,然後也沒有,就如果直接讓他們看到答案,他們就會不去思考,所以你可以先讓他們思考完之後,然後再去翻譯了,去對照那個答案,然後去看你的想解步都是什麼,然後這樣子,一方面是它有一個比較好的拍板格式,另外一方面是可以主動去引導他們去思考。\n",
            "[ 33%] 00:25:00,000 → 00:25:02,940  而不是直接仰賴你的解答\n",
            "[ 33%] 00:25:02,940 → 00:25:04,940  OK\n",
            "[ 33%] 00:25:04,940 → 00:25:05,500  OK\n",
            "[ 33%] 00:25:05,500 → 00:25:09,540  但是上次不是說那個解答要用呈現上嗎\n",
            "[ 33%] 00:25:09,540 → 00:25:11,680  不然頁數就已經爆了\n",
            "[ 33%] 00:25:11,680 → 00:25:12,540  對\n",
            "[ 34%] 00:25:12,540 → 00:25:15,040  就只是如果你今天有在內容裡面\n",
            "[ 34%] 00:25:15,040 → 00:25:16,620  有稍微稍稍的提到\n",
            "[ 34%] 00:25:16,620 → 00:25:19,260  就是你可以有一兩題或是三四題的話\n",
            "[ 34%] 00:25:19,260 → 00:25:19,960  是可以用這樣的\n",
            "[ 34%] 00:25:20,000 → 00:25:39,940  然後關於題目答案線上話這個點,我們需要,好我先跟你抓出來討論這個點好了,因為我們有收到學生的回饋是說他們的父母其實沒有很希望讓他們嘗試這樣用平板手機或是電腦,所以關於\n",
            "[ 35%] 00:25:40,000 → 00:25:59,960  解答線上話這一點,我們可能需要再思考一下,因為不是所有的學生都可以達到很好的學習效果,也不是所有的學生都可以這樣做自由,所以我們需要想一個解決方法,讓他們不是只能完全的仰賴這個AI工具,而是AI工具會變成是輔助他們的學習效果,而不是讓他們去\n",
            "[ 35%] 00:26:00,000 → 00:26:02,000  從AI工具中\n",
            "[ 35%] 00:26:02,000 → 00:26:04,000  就他們不能只是用AI工具找到答案\n",
            "[ 35%] 00:26:04,000 → 00:26:06,000  他們應該要從其他地方也可以找到答案\n",
            "[ 35%] 00:26:06,000 → 00:26:08,000  AI工具只是一個輔助\n",
            "[ 35%] 00:26:08,000 → 00:26:10,000  所以我們可能要先解決這個\n",
            "[ 35%] 00:26:10,000 → 00:26:12,000  點\n",
            "[ 35%] 00:26:16,000 → 00:26:18,000  然後我自己有稍微想了一下\n",
            "[ 35%] 00:26:18,000 → 00:26:20,000  如果說你今天是\n",
            "[ 35%] 00:26:20,000 → 00:26:40,000  因為如果有太多業績的話,其實它是可以用一個比較簡略版的複測,就是它反正只是西馬丁,然後完完全全就是黑白印刷,那他們的題目跟解析是可以分開來的,然後當然對於印刷成本也不會跟原本一樣那麼高,然後學生也不會說如果我今天不能用手機,要不能用手機,\n",
            "[ 35%] 00:26:40,000 → 00:26:42,700  我就完全沒有辦法找到這題的答案\n",
            "[ 36%] 00:26:42,700 → 00:26:45,780  或是我也沒辦法找到這題的相接是什麼東西\n",
            "[ 36%] 00:26:45,780 → 00:26:46,640  對\n",
            "[ 36%] 00:26:46,640 → 00:26:50,020  所以想順便問問看你那邊有任何的想法嗎\n",
            "[ 36%] 00:26:50,020 → 00:26:54,780  所以\n",
            "[ 36%] 00:26:54,780 → 00:26:55,780  嗯\n",
            "[ 36%] 00:26:55,780 → 00:26:59,920  就是解答還是要包含在\n",
            "[ 36%] 00:27:00,000 → 00:27:04,000  裡面,就是包含在整份裡面嘛\n",
            "[ 36%] 00:27:04,000 → 00:27:08,900  這樣頁數不是還是一樣,只是超出\n",
            "[ 36%] 00:27:08,900 → 00:27:13,740  就會變成是以主側跟副側的方式去呈現\n",
            "[ 36%] 00:27:13,740 → 00:27:16,580  那副側的話我們的印刷品質就會是比較\n",
            "[ 36%] 00:27:16,580 → 00:27:19,260  沒有到跟主側一樣那麼好的\n",
            "[ 36%] 00:27:19,260 → 00:27:19,960  那它的印刷\n",
            "[ 36%] 00:27:20,000 → 00:27:25,000  雖然說會增加,但是不會像原本高的那麼誇張。\n",
            "[ 37%] 00:27:28,000 → 00:27:30,000  或者是有如果...\n",
            "[ 37%] 00:27:30,000 → 00:27:31,000  請說。\n",
            "[ 37%] 00:27:31,000 → 00:27:35,000  我想題目分享解葉樹很多耶,比較不像作文那樣子。\n",
            "[ 37%] 00:27:35,000 → 00:27:38,000  只有少少的就是葉。\n",
            "[ 37%] 00:27:40,000 → 00:27:53,000  因為它如果現在是要寫成題目一頁相接一頁,或是一頁三個題目,然後相接三頁的話,那個頁數應該都會比作文還要多很多。\n",
            "[ 37%] 00:28:00,000 → 00:28:05,360  但我哋冇辦法完全就把佢現場化\n",
            "[ 37%] 00:28:05,360 → 00:28:11,900  因為學生也確實冇辦法讓佢哋有個好的學習方式\n",
            "[ 38%] 00:28:11,900 → 00:28:17,060  那我哋現在壓業數是因為硬抓成本跟定價嗎?\n",
            "[ 38%] 00:28:17,060 → 00:28:20,000  就是說我哋定價如果就是要定在\n",
            "[ 38%] 00:28:20,000 → 00:28:26,000  500塊以內,業數就是不可以到300,350到400\n",
            "[ 38%] 00:28:26,000 → 00:28:27,000  對\n",
            "[ 38%] 00:28:31,000 → 00:28:34,000  你如果今天要到,就是真的業數要到三四百\n",
            "[ 38%] 00:28:34,000 → 00:28:38,000  其實是,就是沒有什麼關係啦\n",
            "[ 38%] 00:28:38,000 → 00:28:40,000  但是一方面\n",
            "[ 38%] 00:28:40,000 → 00:28:45,020  因為成本很高,所以我們分下來的利潤可能覺得是不多的。\n",
            "[ 38%] 00:28:45,020 → 00:28:58,020  第二方面是,如果我們今天是推一個他可以很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:28:58,020 → 00:29:09,980  然後這就會延伸到,如果我們今天是推一個很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:29:00,000 → 00:29:20,000  如果我們今天把排板放大,如果以A4尺寸去製作的話,A4它很吃排板功力,所以如果說你今天有任何一個排板點沒有排板好,或者是你的圖示效果不是那麼好的話,其實對於學生的學習狀況也不是到很良好。\n",
            "[ 39%] 00:29:20,000 → 00:29:22,000  如果你今天是一頁密密麻麻的文字\n",
            "[ 39%] 00:29:22,000 → 00:29:24,000  他們可能看到一半也不會想看\n",
            "[ 39%] 00:29:24,000 → 00:29:26,000  所以對於他們學習長相之後\n",
            "[ 39%] 00:29:26,000 → 00:29:28,000  不是那麼的佳\n",
            "[ 39%] 00:29:28,000 → 00:29:31,000  所以這個點我們可能要稍微想一下\n",
            "[ 39%] 00:29:31,000 → 00:29:33,000  我們去解決\n",
            "[ 39%] 00:29:35,000 → 00:29:40,000  以前如果你說學生有些會不想要用電子廠\n",
            "[ 40%] 00:29:40,000 → 00:29:46,000  那就代表之前說想借跟題目要做成線上資料庫\n",
            "[ 40%] 00:29:46,000 → 00:29:48,000  這個就等於是不可行的\n",
            "[ 40%] 00:29:48,000 → 00:29:51,000  對,會變成說如果真的要做的話\n",
            "[ 40%] 00:29:51,000 → 00:29:55,000  它更像是一個我給你一個更好的輔助工具\n",
            "[ 40%] 00:29:55,000 → 00:29:56,000  然後你如果今天想要\n",
            "[ 40%] 00:29:56,000 → 00:29:58,000  就你如果今天書籍沒有帶在身上的話\n",
            "[ 40%] 00:29:58,000 → 00:30:00,000  你也可以有一個\n",
            "[ 40%] 00:30:00,000 → 00:30:02,000  可以學習的地方\n",
            "[ 40%] 00:30:02,000 → 00:30:04,000  但現在問題點就是\n",
            "[ 40%] 00:30:04,000 → 00:30:06,000  很多家長他不願意讓學生\n",
            "[ 40%] 00:30:06,000 → 00:30:08,000  這樣去做\n",
            "[ 40%] 00:30:08,000 → 00:30:10,000  那如果\n",
            "[ 40%] 00:30:10,000 → 00:30:12,000  我們今天變成是\n",
            "[ 40%] 00:30:12,000 → 00:30:14,000  把題目跟\n",
            "[ 40%] 00:30:14,000 → 00:30:16,000  相借獨立成一本\n",
            "[ 40%] 00:30:16,000 → 00:30:18,000  複冊 然後\n",
            "[ 40%] 00:30:18,000 → 00:30:20,000  這本複冊的話\n",
            "[ 41%] 00:30:20,000 → 00:30:39,000  如果是買這本物理書,我們就會只給電子檔的複測,就是複測是用電子檔去給,然後他們可以自己印,又或是我們可以,他可以再加購,然後我們再把它印。\n",
            "[ 41%] 00:30:40,000 → 00:30:44,200  我覺得可能會以他們架構然後我們幫他印的方式\n",
            "[ 41%] 00:30:44,200 → 00:30:48,700  然後主要的話就是會印出的地方出去\n",
            "[ 41%] 00:30:48,700 → 00:30:53,000  不然我們成本一方面會拉高\n",
            "[ 41%] 00:30:53,000 → 00:30:57,900  另外一方面是他們好像不太擅長自己去印書\n",
            "[ 42%] 00:31:00,000 → 00:31:17,000  Ok,所以會需要麻煩維城,他可能還是要幫我把題目跟相機的都一樣有,就是可以有資本化的方式,就是你需要幫我拆開來寫,因為我們到時候會是以兩本書的形式推出去。\n",
            "[ 42%] 00:31:20,000 → 00:31:22,000  好,我可以提一個點嗎?\n",
            "[ 42%] 00:31:22,000 → 00:31:23,000  嗯。\n",
            "[ 42%] 00:31:23,000 → 00:31:36,000  就是微塵你可能現階段在做題目跟詳解的時候,你可能不要直接把它寫到 Word 檔,就是不要直接寫到你最後要出版的那個書上面。\n",
            "[ 42%] 00:31:36,000 → 00:31:40,000  而是你先用一個第三方的\n",
            "[ 42%] 00:31:40,000 → 00:31:43,000  另外一個的編輯的平台\n",
            "[ 42%] 00:31:43,000 → 00:31:47,000  你可能就先做在Notion上面\n",
            "[ 42%] 00:31:47,000 → 00:31:51,000  然後你把這些題目跟小節都做在Notion上面的時候\n",
            "[ 42%] 00:31:51,000 → 00:31:56,000  你一方面就是確保了我們剛剛講到的一個點是說\n",
            "[ 43%] 00:31:56,000 → 00:32:00,000  我們實體的東西要讓學生光看實體就看得懂\n",
            "[ 43%] 00:32:00,000 → 00:32:03,240  但是我們還是可以提供線上的輔助\n",
            "[ 43%] 00:32:03,240 → 00:32:06,340  這樣如果他們可能沒有帶到輔助\n",
            "[ 43%] 00:32:06,340 → 00:32:08,240  或是出了哪些狀況\n",
            "[ 43%] 00:32:08,240 → 00:32:10,340  或是他們想要用電子的方式去學\n",
            "[ 43%] 00:32:10,340 → 00:32:12,540  他們還是可以用電子的方式去做\n",
            "[ 43%] 00:32:12,540 → 00:32:14,840  所以就會變成說\n",
            "[ 43%] 00:32:14,840 → 00:32:17,000  利益\n",
            "[ 43%] 00:32:17,000 → 00:32:20,000  玉千你可不可以幫我開那個\n",
            "[ 43%] 00:32:20,000 → 00:32:25,000  英文共筆 英文選擇的那個檔案\n",
            "[ 43%] 00:32:25,000 → 00:32:27,000  對對對對\n",
            "[ 43%] 00:32:27,000 → 00:32:29,000  就是像現在的這個畫面\n",
            "[ 43%] 00:32:29,000 → 00:32:31,000  它就是一個英文的\n",
            "[ 43%] 00:32:31,000 → 00:32:33,000  英文選擇題的講義裡面的\n",
            "[ 43%] 00:32:33,000 → 00:32:36,000  線上的一個資料庫\n",
            "[ 43%] 00:32:36,000 → 00:32:39,000  你在寫你的那個題目跟詳解的時候\n",
            "[ 43%] 00:32:39,000 → 00:32:40,000  就建議你可以\n",
            "[ 44%] 00:32:40,000 → 00:33:00,000  寫在線上,然後就是在線上是一個已經有整理過的,有系統化的一個地方,然後這一個連結就可以直接分享給學生,然後學生就會有更多的自由度可以去在實體和電子上面同時的閱讀,就他們讀電子也得讀得懂,然後讀實體\n",
            "[ 44%] 00:33:00,000 → 00:33:11,060  你可以讀得懂,那你再把這個現在資料庫上面的東西再轉成實際書的排版跟內容就可以了,你這樣能聽得懂嗎?\n",
            "[ 44%] 00:33:13,860 → 00:33:19,940  我就是,因為我現在是把它拆在\n",
            "[ 44%] 00:33:20,000 → 00:33:29,000  因為我拿其他檔案,我的檔案,所以我之後寫完的話我再把它弄到 Notion上面。\n",
            "[ 45%] 00:33:29,000 → 00:33:31,000  這樣可以吧。\n",
            "[ 45%] 00:33:31,000 → 00:33:36,000  我覺得這樣應該會好一點,因為你我的檔不是會比較零散嗎?\n",
            "[ 45%] 00:33:40,000 → 00:33:44,000  欸可是notion上面就不能做那個公司那些咧?\n",
            "[ 45%] 00:33:46,000 → 00:33:48,000  Notion上可以做公司的\n",
            "[ 45%] 00:33:48,000 → 00:33:49,000  喔真的喔?\n",
            "[ 45%] 00:33:49,000 → 00:33:51,000  用Datex寫\n",
            "[ 45%] 00:33:53,000 → 00:33:55,000  你搜尋LATEX\n",
            "[ 45%] 00:34:00,000 → 00:34:02,000  等下等下等下\n",
            "[ 45%] 00:34:05,200 → 00:34:07,200  它是一個特定的滴刷\n",
            "[ 46%] 00:34:14,560 → 00:34:16,560  上面那個\n",
            "[ 46%] 00:34:20,000 → 00:34:30,340  就變成翅方,然後就要打一個固定的,就是一個字串進去,它就會變成翅方。\n",
            "[ 46%] 00:34:30,340 → 00:34:33,400  對,對,差不多了。\n",
            "[ 46%] 00:34:33,400 → 00:34:36,500  沃德裡面的公司應該是可以轉成這種模式的。\n",
            "[ 46%] 00:34:40,000 → 00:34:48,000  好,如果這方面維生不太會用的話,可以再問我,或是直接問培鈞也可以。\n",
            "[ 46%] 00:34:48,000 → 00:34:54,000  或是你也可以就直接在 Word 檔上面編輯,但是你截圖截到 Notion。\n",
            "[ 46%] 00:34:54,000 → 00:34:55,000  對。\n",
            "[ 46%] 00:34:55,000 → 00:34:59,000  因為 Notion 會有這種資料庫,就會比 Word 還要清楚一點。\n",
            "[ 47%] 00:35:00,000 → 00:35:05,000  好,那我就先在我的上面寫好了。\n",
            "[ 47%] 00:35:05,000 → 00:35:09,000  好,沒有問題。\n",
            "[ 47%] 00:35:09,000 → 00:35:20,000  然後這個的話其實剛剛子明就講到,你可以寫一個很深很深的關鍵,但是你要想辦法也要教會可能不是成都的嗎?\n",
            "[ 47%] 00:35:20,000 → 00:35:20,720  好的學生\n",
            "[ 47%] 00:35:20,720 → 00:35:26,800  那這部分剛剛你在聽的時候有問題嗎\n",
            "[ 47%] 00:35:26,800 → 00:35:34,340  你是說線上化跟配套工具\n",
            "[ 47%] 00:35:34,340 → 00:35:34,900  對\n",
            "[ 47%] 00:35:34,900 → 00:35:38,620  就是我們剛剛\n",
            "[ 47%] 00:35:40,000 → 00:35:45,000  我想講到自信框架的地方還有學習方式跟記憶策略的選擇\n",
            "[ 48%] 00:35:45,000 → 00:35:49,000  前面全部嗎?\n",
            "[ 48%] 00:35:49,000 → 00:35:52,000  對,它其實就是一樣的東西\n",
            "[ 48%] 00:35:52,000 → 00:35:55,000  就是教學理念的話我們希望它是以不間隔的方式\n",
            "[ 48%] 00:35:55,000 → 00:36:00,000  就是你要是寫好寫滿但是你要需要用方式讓可能\n",
            "[ 48%] 00:36:00,000 → 00:36:06,080  我比較沒有程度那麼高的學生去理解一個比較深奧的觀念\n",
            "[ 48%] 00:36:06,080 → 00:36:16,500  然後如果延續到前面剛剛提到的說\n",
            "[ 48%] 00:36:16,500 → 00:36:18,380  你要怎麼樣有一個很深奧的觀念\n",
            "[ 48%] 00:36:18,380 → 00:36:20,000  但是你卻不是只針對聰明\n",
            "[ 48%] 00:36:20,000 → 00:36:25,000  你只要把這個東西插成一個很碎片化的東西可以呈現。\n",
            "[ 48%] 00:36:25,000 → 00:36:28,000  它可能是三到五個獨立然後可以理解的小單元。\n",
            "[ 49%] 00:36:28,000 → 00:36:33,000  就你小單元小單元小單元讓他們去吸收,他們就比較可以接受。\n",
            "[ 49%] 00:36:33,000 → 00:36:37,000  然後再來的話是你每個單元只要專注一個最核心核心的點就好。\n",
            "[ 49%] 00:36:37,000 → 00:36:40,000  然後你可以搭配一些立體跟一些互動練習。\n",
            "[ 49%] 00:36:40,000 → 00:36:54,000  另外就是你要把那個包裝把它簡化簡化得很簡單,就是你可以用可能比較生物化的方式去解釋,或者是你可以用剩下一些視覺化的工具。\n",
            "[ 49%] 00:36:54,000 → 00:37:00,000  對,然後再來的話就是視超化落地,就是你這樣每個觀念都可以搭配一個可以讓它\n",
            "[ 49%] 00:37:00,000 → 00:37:12,000  所以我剛才會提到說你可能一個章節裡面你可能會有二到三題的練習題,你就可以搭配到視察化落地的這個部分。\n",
            "[ 50%] 00:37:12,000 → 00:37:20,000  好,然後再來的話就是剛其實就有稍微提到配套工具。\n",
            "[ 50%] 00:37:20,000 → 00:37:24,600  這幾個是我們覺得也可以用在物理講義裡面的配套工具\n",
            "[ 50%] 00:37:24,600 → 00:37:26,600  第一個就是Notion的筆記模板\n",
            "[ 50%] 00:37:26,600 → 00:37:28,600  然後再來的話就是SharedGPC的機器人\n",
            "[ 50%] 00:37:28,600 → 00:37:31,900  這個的話會是就是你先跟他聊聊聊\n",
            "[ 50%] 00:37:31,900 → 00:37:33,500  然後聊到說有一定的格式\n",
            "[ 50%] 00:37:33,500 → 00:37:37,100  然後之後我們再去轉成我們自己寫的機器人\n",
            "[ 50%] 00:37:37,100 → 00:37:40,100  就會是可能當學生輸入哪一些提示詞\n",
            "[ 50%] 00:37:40,000 → 00:37:44,420  他可以按照我們一開始就規定好的格式 然後產出相對應的內容\n",
            "[ 50%] 00:37:44,420 → 00:37:46,400  然後再來是Notebook LN\n",
            "[ 50%] 00:37:46,400 → 00:37:52,320  Notebook LN的話會比較偏向是我們一開始就先把我們的講義就先都上傳好\n",
            "[ 50%] 00:37:52,320 → 00:37:54,400  然後讓他的觀念是完整清楚的\n",
            "[ 50%] 00:37:54,400 → 00:37:56,780  那當學生他有什麼問題想要問的時候\n",
            "[ 50%] 00:37:56,780 → 00:37:59,020  他可以直接上Notebook LN然後問一個問題\n",
            "[ 50%] 00:37:59,020 → 00:37:59,300  然後\n",
            "[ 51%] 00:38:00,000 → 00:38:04,000  機器人就會想把相對應講義的內容輸出給他\n",
            "[ 51%] 00:38:04,000 → 00:38:07,000  就是一個很即時的問答\n",
            "[ 51%] 00:38:07,000 → 00:38:11,000  然後再來的話就是剛剛有給你看過的那個共編檔案\n",
            "[ 51%] 00:38:11,000 → 00:38:13,000  物理也可以這樣子做\n",
            "[ 51%] 00:38:13,000 → 00:38:17,000  但是這個的話就會很仰賴說\n",
            "[ 51%] 00:38:17,000 → 00:38:20,000  如果今天學生真的有上來留言\n",
            "[ 51%] 00:38:20,000 → 00:38:40,000  然後問問題的話,我們會需要很,就是至少在一定的時間內就可以幫他解完這樣的問題,然後並把這樣的東西再重新整理成新的內容,然後放上來,所以那個沒有到這麼急迫,但是我們還是會希望未來可以。\n",
            "[ 51%] 00:38:40,000 → 00:38:41,000  做\n",
            "[ 51%] 00:38:41,000 → 00:38:45,740  然後再來就是Notion的問答會診區\n",
            "[ 52%] 00:38:45,740 → 00:38:47,520  這個的話會是\n",
            "[ 52%] 00:38:47,520 → 00:38:49,900  譬如說我們有在IG啊\n",
            "[ 52%] 00:38:49,900 → 00:38:51,940  或者是在LINE的社群裡面\n",
            "[ 52%] 00:38:51,940 → 00:38:54,760  如果有任何人提到物理檢驗裡面的問題\n",
            "[ 52%] 00:38:54,760 → 00:38:57,020  我們都可以把它統整起來\n",
            "[ 52%] 00:38:57,020 → 00:38:58,500  然後就是你回答完之後\n",
            "[ 52%] 00:38:58,500 → 00:38:59,580  我們再把它統整起來\n",
            "[ 52%] 00:38:59,580 → 00:39:00,000  然後之後\n",
            "[ 52%] 00:39:00,000 → 00:39:03,320  有遇到一样的问题的时候学生就可以直接上来这边看\n",
            "[ 52%] 00:39:03,320 → 00:39:09,040  好那以上现在有问题吗\n",
            "[ 52%] 00:39:09,040 → 00:39:12,440  刚刚有说到那个notebook\n",
            "[ 52%] 00:39:12,440 → 00:39:16,140  它是就是上次是说它提供上来\n",
            "[ 52%] 00:39:16,140 → 00:39:17,700  然后它就会呈现解答\n",
            "[ 52%] 00:39:17,700 → 00:39:19,800  所以它是一个\n",
            "[ 52%] 00:39:20,000 → 00:39:25,020  它是AI嗎?還是它只是單純的查找的工具?\n",
            "[ 52%] 00:39:25,640 → 00:39:27,920  還是它是會生內容的那種AI?\n",
            "[ 53%] 00:39:30,120 → 00:39:33,000  它是一個幫助你去...\n",
            "[ 53%] 00:39:33,000 → 00:39:37,760  它是會自己生內容嗎?\n",
            "[ 53%] 00:39:38,360 → 00:39:39,980  還是它是拿出...\n",
            "[ 53%] 00:39:40,000 → 00:39:59,220  他會自己按照你給他的觀念格式,還有你給他的內容,然後去升,他裡面知道既有的內容,所以他不會去延伸說那些其實你並沒有輸入給他的東西,因為像ShareGP的話,他就很有可能是輸出一些\n",
            "[ 53%] 00:40:00,000 → 00:40:02,300  並唔係嗰麼正確性嘅嘢\n",
            "[ 53%] 00:40:02,300 → 00:40:06,400  但係NOPLM 佢就係完全按照你輸入乜嘢給佢\n",
            "[ 53%] 00:40:06,400 → 00:40:09,100  佢就會輸出相對應嘅嘢給學生\n",
            "[ 53%] 00:40:09,100 → 00:40:12,400  所以佢能確保佢裡面輸出嘅嘢一定係完整嘅\n",
            "[ 53%] 00:40:12,400 → 00:40:13,400  而且係正確嘅\n",
            "[ 53%] 00:40:15,600 → 00:40:16,400  好\n",
            "[ 54%] 00:40:16,400 → 00:40:19,900  對 所以會需要你完成獎益跟一些\n",
            "[ 54%] 00:40:20,000 → 00:40:23,000  我们再喂进去给那部LA\n",
            "[ 54%] 00:40:23,000 → 00:40:26,080  那到时候再用好\n",
            "[ 54%] 00:40:26,080 → 00:40:27,220  因为我现在也不会用它\n",
            "[ 54%] 00:40:27,220 → 00:40:29,160  好没有问题\n",
            "[ 54%] 00:40:29,160 → 00:40:32,440  然后善用比喻的话\n",
            "[ 54%] 00:40:32,440 → 00:40:34,380  上面也有讲过\n",
            "[ 54%] 00:40:34,380 → 00:40:35,780  然后你自己也有稍微看过\n",
            "[ 54%] 00:40:35,780 → 00:40:38,260  那这部分你有问题想询问的吗\n",
            "[ 54%] 00:40:40,000 → 00:40:44,000  應該比較還好,這部分應該比較簡單。\n",
            "[ 54%] 00:40:44,000 → 00:40:48,000  OK,那關於立場切換的部分呢?\n",
            "[ 54%] 00:40:51,000 → 00:41:00,000  這個就是子明剛剛跟你講到說,如果你今天是一個蓋籃的時候,你可以不要那麼的過於理性,或是就是一些文綽綽的\n",
            "[ 55%] 00:41:00,000 → 00:41:11,000  你可以是給他們一個對號入座的感覺,或是給他們一個比較偏向感性上面的支持,或是一些情緒支持這樣子,這就是舉例。\n",
            "[ 55%] 00:41:11,000 → 00:41:20,000  然後這個的話也是用在作文上的一個小小的行銷手段,它就是讓學生自己去想他們有什麼想法。\n",
            "[ 55%] 00:41:20,000 → 00:41:24,500  然後我們引導牠去對號入座到你真的有這個症狀\n",
            "[ 55%] 00:41:24,500 → 00:41:26,180  然後其實你很需要這個書\n",
            "[ 55%] 00:41:26,180 → 00:41:29,280  就是物理也可以用這樣的方式呈現\n",
            "[ 55%] 00:41:29,280 → 00:41:35,160  然後下面這些你在看的時候你有任何的問題嗎\n",
            "[ 55%] 00:41:35,160 → 00:41:37,300  或是有不太懂的地方嗎\n",
            "[ 56%] 00:41:40,000 → 00:42:00,000  應該都還好,剛剛前面說要給他們一些標籤,讓他們對好入座,我現在是沒想到有什麼啦,我想問你們,在寫物理的時候。\n",
            "[ 56%] 00:42:00,000 → 00:42:01,240  會有什麼問題嗎?\n",
            "[ 56%] 00:42:01,240 → 00:42:03,500  還是平常沒有在寫物理?\n",
            "[ 56%] 00:42:06,840 → 00:42:07,800  我有寫過\n",
            "[ 56%] 00:42:09,000 → 00:42:10,160  那你有什麼問題嗎?\n",
            "[ 56%] 00:42:11,540 → 00:42:12,660  我覺得從\n",
            "[ 56%] 00:42:13,660 → 00:42:16,560  如果是緯程那邊要整理這些問題的話\n",
            "[ 56%] 00:42:16,560 → 00:42:17,800  我反而會覺得\n",
            "[ 56%] 00:42:18,500 → 00:42:19,960  育謙那邊可能可以看\n",
            "[ 57%] 00:42:20,000 → 00:42:38,000  開一個物理的問答,限動的問答,然後藉由這樣子蒐集問題去知道學生的症節點在哪邊,然後就把那些問題全部灌到 CheckGPT,然後請CheckGPT整理學生有哪些類型,這樣應該就很快就可以找到那些問題。\n",
            "[ 57%] 00:42:38,000 → 00:42:40,000  但是問完那些問題之後……\n",
            "[ 57%] 00:42:40,000 → 00:42:47,000  可能未曾要幫忙簡單回答一下 因為育成可能沒辦法自己去回答物理的專業問題\n",
            "[ 57%] 00:42:47,000 → 00:42:52,000  被問問了但是沒有打算回答 這樣過分\n",
            "[ 57%] 00:42:52,000 → 00:43:00,000  我想舉一個例子就是我覺得我自己寫物理最大的祕訣是腦中藥\n",
            "[ 58%] 00:43:00,000 → 00:43:20,000  老公要有畫面,老公要有那個東西在跑的畫面,所以就可以把它當成是一個技巧,比如說看的那些物理的公式,看的那些數字,它沒有感覺怎麼樣,就可以去提。\n",
            "[ 58%] 00:43:20,000 → 00:43:28,000  提供他一些,譬如說像我剛剛講的那種讓自己比較有感覺的技巧這樣\n",
            "[ 58%] 00:43:28,000 → 00:43:30,000  類似這種方向\n",
            "[ 58%] 00:43:32,000 → 00:43:37,000  我有想過就是腦中要有畫面這件事情\n",
            "[ 58%] 00:43:37,000 → 00:43:40,000  但我後來發現就是好像不是每個人都可以做\n",
            "[ 58%] 00:43:40,000 → 00:43:44,000  就有些人特別沒有想像力\n",
            "[ 58%] 00:43:44,000 → 00:43:48,000  我要想一下就是要給我給他這個想像力\n",
            "[ 58%] 00:43:48,000 → 00:43:50,000  你要引導他去構思\n",
            "[ 58%] 00:43:50,000 → 00:43:52,000  對引導他去構思這個想像力\n",
            "[ 58%] 00:43:52,000 → 00:44:00,000  或是你也可以找一些線上的視覺化\n",
            "[ 59%] 00:44:00,000 → 00:44:04,000  現在有一些線上的物理方面的視覺化的工具\n",
            "[ 59%] 00:44:04,000 → 00:44:07,000  也可以引導他們去使用這些工具\n",
            "[ 59%] 00:44:07,000 → 00:44:10,000  然後自己去拉拉看那個訊息之類的\n",
            "[ 59%] 00:44:12,000 → 00:44:14,000  我可以稍微跟你提一個\n",
            "[ 59%] 00:44:14,000 → 00:44:17,000  可能比較像是聯想或者一個小技巧\n",
            "[ 59%] 00:44:17,000 → 00:44:20,000  像英文作文裡那個字名它就會\n",
            "[ 59%] 00:44:20,000 → 00:44:23,660  用break pin去講一些公式跟觀念\n",
            "[ 59%] 00:44:23,660 → 00:44:28,960  讓學生他們的想像畫面是以他們熟悉的東西去帶入\n",
            "[ 59%] 00:44:28,960 → 00:44:32,860  那他們就會比較好聯想到你要跟他們講什麼\n",
            "[ 59%] 00:44:32,860 → 00:44:38,020  然後當他們真的對於那個畫面沒有太大的感受的時候\n",
            "[ 59%] 00:44:38,020 → 00:44:39,900  他們也可以因為這個東西是他們比較\n",
            "[ 59%] 00:44:40,000 → 00:44:42,400  日常生活化就有在接觸的東西。\n",
            "[ 59%] 00:44:42,400 → 00:44:45,200  所以進而聯想到那個很抽象的畫面。\n",
            "[ 60%] 00:44:47,200 → 00:44:49,100  這就會是我們剛剛上面有講到的,\n",
            "[ 60%] 00:44:49,100 → 00:44:51,700  就是你可能要再多運用一些生活化\n",
            "[ 60%] 00:44:51,700 → 00:44:55,300  或是很日常的東西去做比喻,\n",
            "[ 60%] 00:44:55,300 → 00:44:57,100  然後去做例子的講解。\n",
            "[ 60%] 00:45:00,000 → 00:45:09,300  好,然後再來的話,學生需要會有一個固定的,固定默契的emoji,\n",
            "[ 60%] 00:45:09,460 → 00:45:13,680  因為它會是讓學生知道,我今天看到這個圖示的時候,\n",
            "[ 60%] 00:45:13,900 → 00:45:18,000  我就是接下來會看到什麼樣的內容,讓他們有一個小小的概念點。\n",
            "[ 61%] 00:45:20,000 → 00:45:40,000  但是如果以英文中文來講的話,這個東西就會是對應到總結的重點,然後小燈泡的話就會是一個口訣或是一個記憶法,然後如果你今天是一個手加一個筆的話,那就是你的動手練習,就是你可以稍微去幫他設計一個固定的符號,讓他們有一個小概念,他們才不會覺得...\n",
            "[ 61%] 00:45:40,000 → 00:45:44,000  看起來很亂,然後台板上我們也會比較整齊一點點。\n",
            "[ 61%] 00:45:44,000 → 00:45:48,140  然後如果今天是你想要自己跟學生講的話,\n",
            "[ 61%] 00:45:48,240 → 00:45:53,320  你也可以用一個可能老師的符號,或者是一個男生的符號,\n",
            "[ 61%] 00:45:53,500 → 00:45:56,440  然後跟他們講說這比較像是你心裡的話,\n",
            "[ 61%] 00:45:56,600 → 00:45:59,000  那他就不用那麼文綴綴,他就是真的可以很...\n",
            "[ 61%] 00:46:00,000 → 00:46:03,000  就是比較日常口語化的東西就可以了\n",
            "[ 61%] 00:46:03,000 → 00:46:06,000  然後再來就是上次就有提到的東西\n",
            "[ 61%] 00:46:06,000 → 00:46:08,000  就是說表達高用AI論搞過\n",
            "[ 61%] 00:46:08,000 → 00:46:11,000  因為現在的物理講義內容比較像是\n",
            "[ 61%] 00:46:11,000 → 00:46:13,000  你真的想到什麼然後就打什麼出來\n",
            "[ 61%] 00:46:13,000 → 00:46:15,000  它沒有一個固定的格式\n",
            "[ 62%] 00:46:15,000 → 00:46:18,000  然後甚至這樣的內容可能比較像是\n",
            "[ 62%] 00:46:18,000 → 00:46:20,000  只有你自己看得懂\n",
            "[ 62%] 00:46:20,000 → 00:46:22,000  所有的表達我們都可以丟到TradeGPT\n",
            "[ 62%] 00:46:22,000 → 00:46:24,000  就你只要把你的想法丟上去\n",
            "[ 62%] 00:46:24,000 → 00:46:26,000  然後剛才你說你可以幫我run稿嗎\n",
            "[ 62%] 00:46:26,000 → 00:46:28,000  或是你可以幫我修飾成\n",
            "[ 62%] 00:46:28,000 → 00:46:30,000  可能高中生也看得懂的話語\n",
            "[ 62%] 00:46:30,000 → 00:46:32,000  它就會直接幫你寫出來\n",
            "[ 62%] 00:46:32,000 → 00:46:34,000  但是它生成的內容\n",
            "[ 62%] 00:46:34,000 → 00:46:36,000  你還是需要再去檢查過\n",
            "[ 62%] 00:46:36,000 → 00:46:38,000  因為它有時候不一定是那麼正確\n",
            "[ 62%] 00:46:38,000 → 00:46:40,000  或是不一定那麼貼近你想要表達的\n",
            "[ 62%] 00:46:40,000 → 00:46:45,000  所以你就跟他多聊幾次就可以了。\n",
            "[ 62%] 00:46:45,000 → 00:46:47,000  好,以上是知識存在的方面。\n",
            "[ 62%] 00:46:47,000 → 00:46:51,000  然後如果是使用者體驗方面的話,\n",
            "[ 62%] 00:46:51,000 → 00:46:54,000  像是AI化、線上化跟連結種整理,\n",
            "[ 62%] 00:46:54,000 → 00:46:58,000  就會需要麻煩你在編寫獎益的內容之後,\n",
            "[ 62%] 00:46:58,000 → 00:47:00,000  在編寫獎益內容的之中,\n",
            "[ 62%] 00:47:00,000 → 00:47:02,800  我就邊想還有哪些東西可以去製作\n",
            "[ 63%] 00:47:02,800 → 00:47:04,900  然後在你撰寫的過程中\n",
            "[ 63%] 00:47:04,900 → 00:47:07,500  也可以邊製作一些AI工具\n",
            "[ 63%] 00:47:07,500 → 00:47:09,000  或是把東西線上畫\n",
            "[ 63%] 00:47:10,500 → 00:47:14,200  然後全球地圖廣告頁跟意見回饋購買東西調查\n",
            "[ 63%] 00:47:14,200 → 00:47:16,600  這些都會由e-mall這邊直接處理\n",
            "[ 63%] 00:47:18,000 → 00:47:19,500  然後再來是格式的話\n",
            "[ 63%] 00:47:20,000 → 00:47:30,000  因為我知道你現在跟小助手的方式 好像是你會先把他整理過 然後再傳檔案給他 對嗎?\n",
            "[ 63%] 00:47:32,000 → 00:47:33,000  對\n",
            "[ 63%] 00:47:33,000 → 00:47:38,000  對 所以格式的話可能要 就是從你那邊一開始打的時候\n",
            "[ 63%] 00:47:38,000 → 00:47:40,000  就是你開始編輯這個書的時候\n",
            "[ 63%] 00:47:40,000 → 00:47:42,240  你可能就要稍微幫我注意一下格式\n",
            "[ 63%] 00:47:42,240 → 00:47:43,980  我們就是以B5為主\n",
            "[ 63%] 00:47:43,980 → 00:47:46,060  然後那個初期線要稍微注意\n",
            "[ 64%] 00:47:46,060 → 00:47:48,780  至少邊邊要預留三面面\n",
            "[ 64%] 00:47:48,780 → 00:47:49,500  它會比較\n",
            "[ 64%] 00:47:49,500 → 00:47:53,520  就硬刷的時候才會比較不會卡到板\n",
            "[ 64%] 00:47:53,520 → 00:47:54,420  然後需要\n",
            "[ 64%] 00:47:54,420 → 00:47:55,620  預留多少\n",
            "[ 64%] 00:47:55,620 → 00:47:58,560  就是你開word\n",
            "[ 64%] 00:47:58,560 → 00:48:00,000  然後它會有那個\n",
            "[ 64%] 00:48:00,000 → 00:48:02,000  至少要窄\n",
            "[ 64%] 00:48:02,000 → 00:48:04,000  它有一個版面配飾\n",
            "[ 64%] 00:48:04,000 → 00:48:06,000  然後你最多最多只能選擇窄\n",
            "[ 64%] 00:48:06,000 → 00:48:08,000  然後不能再往下縮\n",
            "[ 64%] 00:48:10,000 → 00:48:12,000  等一下我再開給你看好了\n",
            "[ 64%] 00:48:12,000 → 00:48:14,000  稍等我一下\n",
            "[ 65%] 00:48:20,000 → 00:48:39,240  好,就是你在用Word等的時候,它其實有一個版面配置,然後你就,你需要先一開始就先幫我把大小分到。\n",
            "[ 65%] 00:48:40,000 → 00:48:42,640  啊我冇覆好,稍等我\n",
            "[ 65%] 00:48:42,640 → 00:48:44,080  奈咦阿捏\n",
            "[ 65%] 00:48:44,080 → 00:48:50,540  這樣有咩\n",
            "[ 65%] 00:48:50,540 → 00:48:55,720  所以你一開始就需要幫我把大小\n",
            "[ 65%] 00:48:55,720 → 00:48:57,880  就直接先選成B5的大小\n",
            "[ 65%] 00:48:57,880 → 00:48:59,780  然後邊界這邊\n",
            "[ 65%] 00:49:00,000 → 00:49:02,000  最多最多就是以窄為主\n",
            "[ 65%] 00:49:02,000 → 00:49:04,000  就是盡量不要再往下縮\n",
            "[ 65%] 00:49:04,000 → 00:49:08,000  不然我們的印刷照片可能會踩到旁邊\n",
            "[ 65%] 00:49:08,000 → 00:49:10,000  這部分OK咩?\n",
            "[ 65%] 00:49:10,000 → 00:49:12,000  OK\n",
            "[ 65%] 00:49:12,000 → 00:49:14,000  再超出一點點\n",
            "[ 65%] 00:49:14,000 → 00:49:16,000  一點點\n",
            "[ 65%] 00:49:16,000 → 00:49:18,000  對對對就是一點點\n",
            "[ 66%] 00:49:18,000 → 00:49:20,000  但不要壓得太緊\n",
            "[ 66%] 00:49:20,000 → 00:49:22,000  你可以回去剛那個地方嗎?\n",
            "[ 66%] 00:49:22,000 → 00:49:26,000  你看它的右上角\n",
            "[ 66%] 00:49:26,000 → 00:49:29,000  右上角是不是有一個L形的東西?\n",
            "[ 66%] 00:49:32,000 → 00:49:36,000  在紙張上有一個L形的框架\n",
            "[ 66%] 00:49:36,000 → 00:49:38,000  對這個\n",
            "[ 66%] 00:49:38,000 → 00:49:40,000  就是它的那個死角的那個\n",
            "[ 66%] 00:49:40,000 → 00:49:42,000  你的字可以寫到那邊\n",
            "[ 66%] 00:49:42,000 → 00:49:47,000  然後如果你字真的想要在外面再延伸一點點的話\n",
            "[ 66%] 00:49:47,000 → 00:49:52,000  就是不可以超過那個L型的中端\n",
            "[ 66%] 00:49:52,000 → 00:49:55,000  就不可以寫出L型的外面\n",
            "[ 66%] 00:49:55,000 → 00:49:59,000  就會是不會被拆到的格式\n",
            "[ 67%] 00:50:00,000 → 00:50:07,000  但是今天還是幫我縮在L型裡面會比較保險一點點\n",
            "[ 67%] 00:50:07,000 → 00:50:15,000  然後再來的話其他目前都有講過\n",
            "[ 67%] 00:50:15,000 → 00:50:20,000  這個呼籲社群宣傳\n",
            "[ 67%] 00:50:20,000 → 00:50:22,700  比較會像是你寫書已經寫到後半段之後\n",
            "[ 67%] 00:50:22,700 → 00:50:24,700  我們可以再來進行的東西\n",
            "[ 67%] 00:50:24,700 → 00:50:27,800  所以這個我們可以之後在開會的時候跟你講一下\n",
            "[ 67%] 00:50:29,800 → 00:50:33,300  然後誓願內容商品化會\n",
            "[ 67%] 00:50:33,300 → 00:50:34,800  這個就是範例\n",
            "[ 67%] 00:50:34,800 → 00:50:38,200  我們以英文作文或是英文文法\n",
            "[ 67%] 00:50:38,200 → 00:50:39,400  或是英文單字說的話\n",
            "[ 67%] 00:50:39,400 → 00:50:40,000  我們可能都會\n",
            "[ 67%] 00:50:40,000 → 00:50:46,320  給他一個備單的機器人 然後拿這個機器人去推廣我們的作文書跟其他的產品\n",
            "[ 68%] 00:50:46,320 → 00:50:49,560  就是當你使用這個機器人的時候 它底下其實會生成\n",
            "[ 68%] 00:50:49,560 → 00:50:54,860  如果你想看更多完整的內容 或者如果你想要看什麼更完整的文法解說\n",
            "[ 68%] 00:50:54,860 → 00:50:58,640  你可以購買一模一模的那本書 然後會貼一個下一個連結給他\n",
            "[ 68%] 00:50:58,640 → 00:51:00,000  就是到時候物理也可以用\n",
            "[ 68%] 00:51:00,000 → 00:51:02,800  用這種方式去做一個行銷宣傳。\n",
            "[ 68%] 00:51:02,800 → 00:51:06,800  在這裡,就是想知道如果背一個單字補輸一個觀念,\n",
            "[ 68%] 00:51:06,800 → 00:51:09,800  然後這就會是我們完整的書籍內容宣傳。\n",
            "[ 68%] 00:51:12,800 → 00:51:18,800  好,那目前以上有任何問題或是有任何想問的嗎?\n",
            "[ 68%] 00:51:20,000 → 00:51:26,120  因為Himoji那邊現在的樹就有了,所以還好。\n",
            "[ 68%] 00:51:26,120 → 00:51:31,440  然後你有一個MBTI那個是沒有要理它嗎?\n",
            "[ 69%] 00:51:34,960 → 00:51:40,020  因為這個可能就是對於物理...\n",
            "[ 69%] 00:51:40,000 → 00:51:43,200  講義有點難運用\n",
            "[ 69%] 00:51:43,200 → 00:51:43,840  其實\n",
            "[ 69%] 00:51:43,840 → 00:51:45,960  哦好那我就不理他\n",
            "[ 69%] 00:51:45,960 → 00:51:47,340  好好\n",
            "[ 69%] 00:51:47,340 → 00:51:48,280  子明你可以說\n",
            "[ 69%] 00:51:48,280 → 00:51:53,080  我寫那個其實只是一個紀錄\n",
            "[ 69%] 00:51:53,080 → 00:51:54,980  它不一定要寫NBT\n",
            "[ 69%] 00:51:54,980 → 00:51:56,820  我想講的只是說\n",
            "[ 69%] 00:51:56,820 → 00:51:59,240  你可以去設想\n",
            "[ 69%] 00:52:00,000 → 00:52:02,000  學生有千千百百多\n",
            "[ 69%] 00:52:02,000 → 00:52:04,000  就是有一些人\n",
            "[ 69%] 00:52:04,000 → 00:52:08,000  因為你自己怎麼學物理\n",
            "[ 69%] 00:52:08,000 → 00:52:10,000  跟其他人怎麼學物理\n",
            "[ 69%] 00:52:10,000 → 00:52:11,000  一定是非常不同的\n",
            "[ 69%] 00:52:11,000 → 00:52:13,000  然後除了是專業知識\n",
            "[ 69%] 00:52:13,000 → 00:52:15,000  觀念上面的落差之外\n",
            "[ 69%] 00:52:15,000 → 00:52:17,000  其實他們在理解知識\n",
            "[ 70%] 00:52:17,000 → 00:52:20,000  還有如何讀完這本書上面\n",
            "[ 70%] 00:52:20,000 → 00:52:22,500  本身就會有很大的不同\n",
            "[ 70%] 00:52:22,500 → 00:52:24,500  像譬如說喻謙好了\n",
            "[ 70%] 00:52:24,500 → 00:52:26,500  他如果今天讀到一本書\n",
            "[ 70%] 00:52:26,500 → 00:52:28,500  然後事實上他覺得很用心\n",
            "[ 70%] 00:52:33,500 → 00:52:35,500  如果是那本書讓喻謙覺得很用心\n",
            "[ 70%] 00:52:35,500 → 00:52:37,500  然後很有溫度\n",
            "[ 70%] 00:52:37,500 → 00:52:39,500  然後是很想把學徒顧好\n",
            "[ 70%] 00:52:39,500 → 00:52:40,500  喻謙就會想\n",
            "[ 70%] 00:52:40,000 → 00:52:42,000  你想把它讀完,你說是不是?\n",
            "[ 70%] 00:52:42,000 → 00:52:44,000  對\n",
            "[ 70%] 00:52:44,000 → 00:52:46,000  但是我的個性可能就會是\n",
            "[ 70%] 00:52:46,000 → 00:52:48,000  我想要看到超級爆炸具體的東西\n",
            "[ 70%] 00:52:48,000 → 00:52:50,000  你不要給我扯一些有的沒的的\n",
            "[ 70%] 00:52:50,000 → 00:52:52,000  剛才跟我講的重點\n",
            "[ 70%] 00:52:52,000 → 00:52:57,000  然後其他學生有些可能會喜歡圖像化的解說\n",
            "[ 70%] 00:52:57,000 → 00:53:00,000  然後就是你比起用文字去寫\n",
            "[ 70%] 00:53:00,000 → 00:53:01,800  寫第一步驟第二步驟第三步驟\n",
            "[ 71%] 00:53:01,800 → 00:53:05,300  你還不如直接用一張圖片或Canva的字圖\n",
            "[ 71%] 00:53:05,300 → 00:53:07,300  去告訴他三步驟是什麼\n",
            "[ 71%] 00:53:07,300 → 00:53:09,500  那又會有一些可能又會喜歡\n",
            "[ 71%] 00:53:09,500 → 00:53:13,100  就是兩個人的對話去推進一個觀念\n",
            "[ 71%] 00:53:13,100 → 00:53:14,600  就大家都有不同學習方式\n",
            "[ 71%] 00:53:14,600 → 00:53:16,900  然後我覺得你不一定要用MVTI\n",
            "[ 71%] 00:53:16,900 → 00:53:19,100  去把16個全部都想過一次\n",
            "[ 71%] 00:53:19,100 → 00:53:19,900  而是你\n",
            "[ 71%] 00:53:20,000 → 00:53:21,640  至少在寫獎音的時候\n",
            "[ 71%] 00:53:21,640 → 00:53:25,760  你要先抓幾個學生的標籤跟概念出來\n",
            "[ 71%] 00:53:25,760 → 00:53:28,640  可能是圖像化學生、理論化學生\n",
            "[ 71%] 00:53:28,640 → 00:53:31,040  然後比較情緒化的學生\n",
            "[ 71%] 00:53:31,040 → 00:53:32,000  抓幾個標籤出來\n",
            "[ 71%] 00:53:32,000 → 00:53:35,240  然後去寫獎音的時候照顧到這些學生的需求\n",
            "[ 71%] 00:53:37,240 → 00:53:39,040  好,我講完了\n",
            "[ 71%] 00:53:40,000 → 00:53:43,000  Ok, this part, do you think it's ok?\n",
            "[ 71%] 00:53:44,000 → 00:53:45,000  Yes, it's ok.\n",
            "[ 71%] 00:53:46,000 → 00:53:48,000  Ok, and then...\n",
            "[ 72%] 00:53:51,000 → 00:53:56,000  If you are in the process of making it, or you need some AI tools to help you,\n",
            "[ 72%] 00:53:56,000 → 00:54:00,000  you can find Pei Jun, he is a very good...\n",
            "[ 72%] 00:54:00,000 → 00:54:04,200  所以如果你在這雙方沒有問題的話都可以問他\n",
            "[ 72%] 00:54:04,200 → 00:54:16,000  我們不是還有一個是要問Pedro的事情嗎\n",
            "[ 72%] 00:54:20,000 → 00:54:22,000  我可以分享我的畫面嗎?\n",
            "[ 72%] 00:54:22,000 → 00:54:24,000  欸等一下,物理那邊都講完了吧?\n",
            "[ 72%] 00:54:24,000 → 00:54:26,000  對\n",
            "[ 72%] 00:54:26,000 → 00:54:30,000  好,那我想要問一下裴娟一個東西\n",
            "[ 72%] 00:54:30,000 → 00:54:32,000  我分享一下我的畫面\n",
            "[ 73%] 00:54:40,000 → 00:54:59,920  我们刚刚有讲到很多写讲义上面的东西,只是如果我们这边有这套准则,但是像伟臣可能写的时候还是会需要时不时回去看交战手册,然后有时候可能还是会不小心漏掉一些东西,或不知道怎么去使用,然后我在想如果我们未来\n",
            "[ 73%] 00:55:00,000 → 00:55:06,000  可能會需要同時跑很多本書 很多個合作者一起寫這樣一個話\n",
            "[ 73%] 00:55:06,000 → 00:55:09,000  我們來回溝通可能會需要花很多時間\n",
            "[ 73%] 00:55:09,000 → 00:55:14,000  然後就想到說 之前我在學SEO的時候\n",
            "[ 73%] 00:55:14,000 → 00:55:17,000  有一個像這樣子的工具\n",
            "[ 74%] 00:55:17,000 → 00:55:20,000  就是它的左邊是你在寫書\n",
            "[ 74%] 00:55:20,000 → 00:55:40,000  文章的頁面,然後右邊他就會告訴你說你現在拿到多少分,就是你有做到多少需求之內的事情,然後他就會一直提醒你說你還要再寫什麼,你還要再寫什麼才會足夠完整,然後在想就是這樣子的一個工具他製作的難度。\n",
            "[ 74%] 00:55:40,000 → 00:55:59,100  我覺得應該,這個東西他看起來是有機會整合在Notion裡面,但是我覺得他看起來,因為我們獎勵的內容其實是非常多嘛,我覺得他看起來對於Token的開銷會非常大,就是\n",
            "[ 75%] 00:56:00,000 → 00:56:10,000  我覺得我們透過應用程式去跟AI做串接,它中間其實是以量計價的。\n",
            "[ 75%] 00:56:10,000 → 00:56:20,000  我覺得這東西它或許是可以嘗試看看來做,但是因為\n",
            "[ 75%] 00:56:20,000 → 00:56:27,000  另一方面講義的內容很多,另一方面教單手字的內容也蠻多的\n",
            "[ 75%] 00:56:27,000 → 00:56:32,000  我覺得這個可能使用量的部分會比較大一點點\n",
            "[ 75%] 00:56:32,000 → 00:56:36,000  但這個東西會越來越便宜啦\n",
            "[ 75%] 00:56:36,000 → 00:56:40,000  所以或許我可以嘗試看看用\n",
            "[ 75%] 00:56:40,000 → 00:56:45,640  比較之前的,應該說用量比較小比較便宜的模型來試試看\n",
            "[ 75%] 00:56:46,660 → 00:56:49,720  因為畢竟他這個東西他不會要求說\n",
            "[ 76%] 00:56:49,980 → 00:56:53,320  就是我AI傳出的內容要到多進去\n",
            "[ 76%] 00:56:55,360 → 00:56:59,960  我覺得可以研究看看有沒有機會把它整合在Notion裡面\n",
            "[ 76%] 00:57:00,000 → 00:57:02,760  可能他更新頻率不會到這麼的高\n",
            "[ 76%] 00:57:02,760 → 00:57:09,760  可能就是寫作者完成一整階段的工作之後\n",
            "[ 76%] 00:57:09,760 → 00:57:14,500  再去再用AI去做這個提醒這樣\n",
            "[ 76%] 00:57:18,240 → 00:57:19,000  那如果\n",
            "[ 76%] 00:57:20,000 → 00:57:29,300  如果把這個工具切成是很多個更小的工具 那如果把這個工具切成是很多個更小的工具\n",
            "[ 76%] 00:57:29,300 → 00:57:33,780  就是我們不一定要是一戰式的解決所有講義變形的問題\n",
            "[ 77%] 00:57:33,780 → 00:57:40,000  可能把剛剛教授的手冊細分成五個層面或三個層面\n",
            "[ 77%] 00:57:40,000 → 00:57:47,000  要分別套這樣子的工具,它的用量這樣子會再更大,還是可以節省一點。\n",
            "[ 77%] 00:58:00,000 → 00:58:07,000  要怎麼切我覺得後續可以再來想了,目前就是我覺得可能要再研究一下。\n",
            "[ 77%] 00:58:07,000 → 00:58:14,000  好,不然我也先用ChangeGPT做做看好了,我先打一張手冊寫ChangeGPT。\n",
            "[ 77%] 00:58:14,000 → 00:58:20,000  然後維城如果會,如果想要看看說自己有沒有\n",
            "[ 78%] 00:58:20,000 → 00:58:24,680  有一些東西漏掉的話,你就可以先把你的獎金丟進去,change your VT\n",
            "[ 78%] 00:58:24,680 → 00:58:27,680  但是你一次可能就只能丟個十頁\n",
            "[ 78%] 00:58:27,680 → 00:58:30,680  就不能一次丟那個幾百頁進去\n",
            "[ 78%] 00:58:30,680 → 00:58:34,680  然後他可能就會告訴你說你還有哪些地方需要再錄\n",
            "[ 78%] 00:58:34,680 → 00:58:40,680  現階段先這樣子,然後這個可以之後有研究出來\n",
            "[ 78%] 00:58:40,000 → 00:58:43,000  讓我們再拿出來討論看看。\n",
            "[ 78%] 00:58:45,000 → 00:58:47,000  好,我講完了。\n",
            "[ 78%] 00:58:47,000 → 00:58:49,000  好耶。\n",
            "[ 78%] 00:58:49,000 → 00:58:52,000  那目前維生有任何想問的嗎?\n",
            "[ 78%] 00:58:52,000 → 00:58:56,000  或者也想分享看看你的想法也都可以。\n",
            "[ 79%] 00:59:00,000 → 00:59:09,440  我問個問題,就是之前不是有說你要開另外一個物理的帳號嗎?\n",
            "[ 79%] 00:59:09,440 → 00:59:11,440  嗯\n",
            "[ 79%] 00:59:11,440 → 00:59:20,000  就是我覺得應該要開另外一個跟英文獨立的帳號會比較好,不管你之後有沒有要掛e-mail的問題\n",
            "[ 79%] 00:59:20,000 → 00:59:22,000  我覺得分開會比較好\n",
            "[ 79%] 00:59:22,000 → 00:59:24,000  有原因嗎?\n",
            "[ 79%] 00:59:24,000 → 00:59:26,000  就是覺得分開會比較好\n",
            "[ 79%] 00:59:26,000 → 00:59:28,000  因為emote本來就是文科嘛\n",
            "[ 79%] 00:59:28,000 → 00:59:30,000  然後如果突然變成理科的話\n",
            "[ 79%] 00:59:30,000 → 00:59:32,000  就是你如果發的內容都混在一起\n",
            "[ 80%] 00:59:40,000 → 00:59:59,000  至少理科跟文科一個比較專業的分別,我會傾向把它分開,至少我看到這個帳號的時候我也知道它的專業是英文,這個帳號的專業是什麼,雖然它背後的人可能是同一批人。\n",
            "[ 80%] 01:00:00,000 → 01:00:02,000  我覺得它好像是不同的處理邏輯\n",
            "[ 80%] 01:00:02,000 → 01:00:04,000  就是我們現在如果把物理\n",
            "[ 80%] 01:00:04,000 → 01:00:06,000  它是兩種都是正確的狀況\n",
            "[ 80%] 01:00:06,000 → 01:00:08,000  然後我可能先跟你分享看看\n",
            "[ 80%] 01:00:08,000 → 01:00:10,000  要看你會不會有不同想法\n",
            "[ 80%] 01:00:20,000 → 01:00:25,000  如果是把講義掛到英文帳號的話\n",
            "[ 80%] 01:00:25,000 → 01:00:33,000  那其實是變成我們是幫助你在私領域去找客人\n",
            "[ 81%] 01:00:33,000 → 01:00:37,000  就是我們的瀏覽\n",
            "[ 81%] 01:00:37,000 → 01:00:40,000  我有做過一張圖秀給你看一下\n",
            "[ 81%] 01:00:40,000 → 01:00:48,300  就是我們的流量入口 IG的那些貼文就不太會真的去做物理專業知識相關的東西\n",
            "[ 81%] 01:00:48,300 → 01:00:52,580  那個就是真的跟英文真的太不相關\n",
            "[ 81%] 01:00:52,580 → 01:00:56,840  然後那個內容這樣跳來跳去也比較不符合學生的習慣\n",
            "[ 81%] 01:00:56,840 → 01:00:59,880  所以物理的專業知識不會\n",
            "[ 81%] 01:01:00,000 → 01:01:09,000  作為流量入口,我們的流量入口都會是以內容為主,只是那些流量進來之後\n",
            "[ 81%] 01:01:14,000 → 01:01:16,000  這邊沒有斷掉\n",
            "[ 82%] 01:01:20,000 → 01:01:34,080  他們還會被導到像是我們的節目或Line群然後限動\n",
            "[ 82%] 01:01:34,080 → 01:01:37,940  等於說是可能有6萬個追蹤者是追我們的IG\n",
            "[ 82%] 01:01:37,940 → 01:01:39,980  但是可能進入到死領域的\n",
            "[ 82%] 01:01:40,000 → 01:01:41,000  可能就只有一萬個\n",
            "[ 82%] 01:01:41,000 → 01:01:44,000  然後一萬個當中我們再想辦法幫你推銷\n",
            "[ 82%] 01:01:44,000 → 01:01:46,000  最後推銷出來\n",
            "[ 82%] 01:01:46,000 → 01:01:51,000  成交的數量就會比英文還要少\n",
            "[ 82%] 01:01:51,000 → 01:01:53,000  這是比較正常的狀況\n",
            "[ 82%] 01:01:53,000 → 01:01:55,000  但是相對來說\n",
            "[ 82%] 01:01:55,000 → 01:01:57,000  如果我們今天就開個全新的帳號\n",
            "[ 82%] 01:01:57,000 → 01:02:00,000  那我們那個全新的帳號也必須達到一定的粉絲級\n",
            "[ 82%] 01:02:00,000 → 01:02:02,760  才可以去平衡掉我剛剛說\n",
            "[ 82%] 01:02:02,760 → 01:02:04,800  比如說導到死領域的可能有一萬個\n",
            "[ 83%] 01:02:04,800 → 01:02:06,980  那就代表如果我們要重開一個帳號\n",
            "[ 83%] 01:02:06,980 → 01:02:10,300  那個帳號可能至少就要光靠自然科\n",
            "[ 83%] 01:02:10,300 → 01:02:14,060  光靠物理可能就要至少達到一萬個粉絲\n",
            "[ 83%] 01:02:14,060 → 01:02:16,220  它才會比較有機率\n",
            "[ 83%] 01:02:16,220 → 01:02:18,480  可以達到跟英文一樣的宣傳效果\n",
            "[ 83%] 01:02:18,480 → 01:02:19,980  就有點像我這邊\n",
            "[ 83%] 01:02:20,000 → 01:02:22,000  我沒有做一個圖\n",
            "[ 83%] 01:02:22,000 → 01:02:27,000  就是打開熱量漏斗的地方其實是我們會用英文去做\n",
            "[ 83%] 01:02:27,000 → 01:02:29,000  但是其他的這個地方\n",
            "[ 83%] 01:02:29,000 → 01:02:31,000  YouTube 跟 IG 限動\n",
            "[ 83%] 01:02:31,000 → 01:02:34,000  還有專業的一些課程\n",
            "[ 83%] 01:02:34,000 → 01:02:35,000  就是講義啊\n",
            "[ 83%] 01:02:35,000 → 01:02:38,000  然後現在是沒有在做直播跟團課啦\n",
            "[ 83%] 01:02:38,000 → 01:02:40,000  但是其他的一些專業的\n",
            "[ 83%] 01:02:40,000 → 01:02:46,600  像私訊的問題回答還有Line群的問題回答都會幫你的物理數據倒流\n",
            "[ 83%] 01:02:46,600 → 01:02:49,000  這樣你要懂意思嗎\n",
            "[ 84%] 01:02:49,000 → 01:03:00,000  但我剛意思其實是說如果你要發物理的文章的話或什麼東西的話我覺得就是要有另外一個帳號\n",
            "[ 84%] 01:03:00,000 → 01:03:02,000  喔對啊確實\n",
            "[ 84%] 01:03:02,000 → 01:03:06,000  可是誰要來發物理的文章\n",
            "[ 84%] 01:03:06,000 → 01:03:08,000  你會想要發物理的文章嗎\n",
            "[ 84%] 01:03:08,000 → 01:03:10,000  如果我有寫的話\n",
            "[ 84%] 01:03:10,000 → 01:03:14,000  或者就是你之前不是說要做一些奇怪的實驗\n",
            "[ 84%] 01:03:14,000 → 01:03:16,000  所以我不知道你要做什麼實驗\n",
            "[ 84%] 01:03:16,000 → 01:03:20,000  喔對啊我之前不是有傳給你一個\n",
            "[ 84%] 01:03:20,000 → 01:03:23,000  你有看過這個嗎?\n",
            "[ 84%] 01:03:23,000 → 01:03:25,000  你有傳給我嗎?\n",
            "[ 84%] 01:03:25,000 → 01:03:28,000  我傳在 Slack 啦\n",
            "[ 84%] 01:03:28,000 → 01:03:30,000  就是我們會\n",
            "[ 84%] 01:03:30,000 → 01:03:33,000  如果是我幫你做內容的話\n",
            "[ 84%] 01:03:33,000 → 01:03:35,000  我理想上會是\n",
            "[ 85%] 01:03:35,000 → 01:03:37,000  我找一下那個\n",
            "[ 85%] 01:03:37,000 → 01:03:39,000  如果是專業的物理知識\n",
            "[ 85%] 01:03:39,000 → 01:03:41,000  就會是需要你來幫忙\n",
            "[ 85%] 01:03:40,000 → 01:03:45,000  如果是我們幫你做內容可能會做的比較類似這種\n",
            "[ 85%] 01:03:45,000 → 01:03:47,000  欸這個\n",
            "[ 85%] 01:03:51,000 → 01:03:53,000  喔我有看到這個\n",
            "[ 85%] 01:03:54,000 → 01:03:58,000  喔就只能做的比較娛樂化一點\n",
            "[ 85%] 01:03:59,000 → 01:04:00,000  然後再把你放寡\n",
            "[ 85%] 01:04:00,000 → 01:04:02,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:02,000 → 01:04:04,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:04,000 → 01:04:06,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:06,000 → 01:04:08,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:08,000 → 01:04:10,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:10,000 → 01:04:12,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:12,000 → 01:04:14,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:14,000 → 01:04:16,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:16,000 → 01:04:18,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:18,000 → 01:04:20,000  如果你是開一個全新的賬號\n",
            "[ 86%] 01:04:20,000 → 01:04:24,600  其實會需要有穩定的內容才處理\n",
            "[ 86%] 01:04:24,600 → 01:04:29,600  就是你可能不能是想到文章再發\n",
            "[ 86%] 01:04:29,600 → 01:04:33,000  然後我們這邊就會是需要\n",
            "[ 86%] 01:04:33,000 → 01:04:35,800  每次都就是幫你去做布林的帖文\n",
            "[ 86%] 01:04:40,000 → 01:05:00,000  如果是掛在英文上的話,有時候就可以像我之前有給你看單字數的ChangeGPT,有時候我覺得把那個ChangeGPT放在英文,然後讓它流傳下去的話,像現在的ChangeGPT就有三千多個對話,然後如果三千多個對話,每一次對話都會有三千多個對話,\n",
            "[ 86%] 01:05:00,000 → 01:05:02,000  如果有一個肯定的廣告的話\n",
            "[ 86%] 01:05:02,000 → 01:05:04,000  我覺得導流效果也蠻不錯的\n",
            "[ 86%] 01:05:04,000 → 01:05:06,000  所以這個可以再想想看\n",
            "[ 87%] 01:05:06,000 → 01:05:08,000  但如果你會希望\n",
            "[ 87%] 01:05:08,000 → 01:05:10,000  開個線上號\n",
            "[ 87%] 01:05:10,000 → 01:05:12,000  然後希望可以做一些\n",
            "[ 87%] 01:05:12,000 → 01:05:14,000  專門輸入的內容\n",
            "[ 87%] 01:05:14,000 → 01:05:16,000  我覺得也沒有問題\n",
            "[ 87%] 01:05:16,000 → 01:05:18,000  但是我們之後可以再一起把細節\n",
            "[ 87%] 01:05:18,000 → 01:05:20,000  就是我可以\n",
            "[ 87%] 01:05:20,000 → 01:05:22,500  直接先開帳號,然後可能先做做看\n",
            "[ 87%] 01:05:22,500 → 01:05:24,400  然後再告訴你有沒有困難的點\n",
            "[ 87%] 01:05:25,700 → 01:05:28,600  那如果你現在要發一個立刻的東西\n",
            "[ 87%] 01:05:28,600 → 01:05:29,800  你是要發在哪邊?\n",
            "[ 87%] 01:05:32,100 → 01:05:34,100  現在要發一個立刻的東西\n",
            "[ 87%] 01:05:34,800 → 01:05:38,100  就是如果你沒有打算再開一個行政帳號的話\n",
            "[ 87%] 01:05:38,700 → 01:05:40,100  啊,立刻的東西\n",
            "[ 88%] 01:05:40,000 → 01:05:59,380  我就會把他放在YouTube的影片,我會幫你講,然後再用IG去引導學生去YouTube的影片,然後會是IG行動,還有Threads的,在Threads上面我就不會教物理,而是我會直接\n",
            "[ 88%] 01:06:00,000 → 01:06:06,800  丟免費的工具給學生,然後讓那個免費的工具自己下去學生之間流傳。\n",
            "[ 88%] 01:06:06,800 → 01:06:16,360  比如說你的事業檔案,那就算是一種免費的工具。\n",
            "[ 88%] 01:06:16,360 → 01:06:17,240  大概理解。\n",
            "[ 88%] 01:06:20,000 → 01:06:27,000  還有你的商品掛在蝦皮機就會有一定的流量\n",
            "[ 88%] 01:06:27,000 → 01:06:33,000  因為我們賣場也會有既定的客源進來\n",
            "[ 89%] 01:06:33,000 → 01:06:38,000  還有LINE群\n",
            "[ 89%] 01:06:38,000 → 01:06:40,000  LINE群會有選手喔\n",
            "[ 89%] 01:06:40,000 → 01:06:42,760  喔對之前有講到Live群\n",
            "[ 89%] 01:06:42,760 → 01:06:46,940  所以現在是有學生在問物理的問題嗎\n",
            "[ 89%] 01:06:46,940 → 01:06:48,360  還是還沒有\n",
            "[ 89%] 01:06:48,360 → 01:06:49,620  還沒有\n",
            "[ 89%] 01:06:49,620 → 01:06:55,740  可能我們也還沒有引導他們去問物理的\n",
            "[ 89%] 01:06:55,740 → 01:06:59,980  你現在有在這個群組\n",
            "[ 89%] 01:07:00,000 → 01:07:14,400  還有其他問題呢?\n",
            "[ 89%] 01:07:18,400 → 01:07:20,400  這部分應該就到這裡了\n",
            "[ 90%] 01:07:20,000 → 01:07:26,100  然後我提問一下,這是你的公司名稱嗎?\n",
            "[ 90%] 01:07:27,140 → 01:07:31,000  公司名稱是成學文教有限公司,\n",
            "[ 90%] 01:07:31,600 → 01:07:33,840  陰謀比較像是品牌名稱。\n",
            "[ 90%] 01:07:33,840 → 01:07:36,540  所以那你的陰謀是申請商標嗎?\n",
            "[ 90%] 01:07:37,420 → 01:07:38,000  我是好奇。\n",
            "[ 90%] 01:07:40,000 → 01:07:42,000  喔好\n",
            "[ 90%] 01:07:42,000 → 01:07:45,820  你要搶住嗎\n",
            "[ 90%] 01:07:45,820 → 01:07:47,420  我都沒想到\n",
            "[ 90%] 01:07:47,420 → 01:07:49,880  惡意搶住\n",
            "[ 90%] 01:07:49,880 → 01:07:53,340  你是學了民法之後學壞了是不是\n",
            "[ 90%] 01:07:53,340 → 01:07:57,720  我好像記得有的是法律系\n",
            "[ 90%] 01:07:57,720 → 01:08:00,000  我是法律系\n",
            "[ 90%] 01:08:00,000 → 01:08:05,000  好\n",
            "[ 91%] 01:08:05,000 → 01:08:07,700  那應該沒有其他問題耶\n",
            "[ 91%] 01:08:07,700 → 01:08:08,940  好\n",
            "[ 91%] 01:08:08,940 → 01:08:10,620  你應該沒有\n",
            "[ 91%] 01:08:10,620 → 01:08:12,160  打算先註冊對吧\n",
            "[ 91%] 01:08:12,160 → 01:08:12,660  沒有沒有\n",
            "[ 91%] 01:08:12,660 → 01:08:13,460  OKOK\n",
            "[ 91%] 01:08:13,460 → 01:08:15,180  有點麻煩\n",
            "[ 91%] 01:08:15,180 → 01:08:16,300  沒有想要做這種事\n",
            "[ 91%] 01:08:20,000 → 01:08:28,000  如果沒有的話,我們今天會先到這邊喔。\n",
            "[ 91%] 01:08:28,000 → 01:08:30,000  好。\n",
            "[ 91%] 01:08:30,000 → 01:08:32,000  好,辛苦了,謝謝你。\n",
            "[ 91%] 01:08:32,000 → 01:08:34,000  掰掰。\n",
            "[ 91%] 01:08:34,000 → 01:08:36,000  掰掰。\n",
            "[ 91%] 01:08:40,000 → 01:08:49,860  我要影片嗎?想要影片?\n",
            "[ 91%] 01:08:50,000 → 01:08:51,440  我有,好,我再傳\n",
            "[ 92%] 01:08:51,440 → 01:08:53,280  做完可以改AI\n",
            "[ 92%] 01:08:53,280 → 01:08:54,060  OK\n",
            "[ 92%] 01:08:54,060 → 01:08:57,760  為什麼我媽留著?\n",
            "[ 92%] 01:08:57,860 → 01:08:59,320  我媽有什麼事情要討論嗎?\n",
            "[ 92%] 01:09:00,000 → 01:09:02,000  沒有啊\n",
            "[ 92%] 01:09:02,000 → 01:09:04,000  那我先撤囉\n",
            "[ 92%] 01:09:04,000 → 01:09:05,000  好嘞\n",
            "[ 92%] 01:09:05,000 → 01:09:08,000  我會去玩國粹職之後再去你那邊喔\n",
            "[ 92%] 01:09:08,000 → 01:09:09,000  好喔沒問題\n",
            "[ 92%] 01:09:09,000 → 01:09:10,000  你就直接進來就好\n",
            "[ 92%] 01:09:10,000 → 01:09:11,000  我會穿褲子\n",
            "[ 92%] 01:09:11,000 → 01:09:12,000  好掰掰\n",
            "[ 92%] 01:09:12,000 → 01:09:14,000  好掰掰\n",
            "[ 92%] 01:09:16,000 → 01:09:17,000  拜啦老孫\n",
            "[ 92%] 01:09:17,000 → 01:09:19,000  你剛聽起來有什麼問題嗎\n",
            "[ 92%] 01:09:20,000 → 01:09:26,000  沒有,但是我想到有很嚴重的事情要做\n",
            "[ 92%] 01:09:26,000 → 01:09:27,400  你說?\n",
            "[ 92%] 01:09:27,400 → 01:09:32,240  就是那個那個那個那個常常需要驗證的問題\n",
            "[ 92%] 01:09:32,240 → 01:09:35,760  我們現在把它解決掉了嘛\n",
            "[ 92%] 01:09:35,760 → 01:09:37,360  會很久嗎?\n",
            "[ 93%] 01:09:37,360 → 01:09:39,960  不會不會\n",
            "[ 93%] 01:09:40,000 → 01:09:50,000  比較就是我開個分享的分享分享\n",
            "[ 93%] 01:09:50,000 → 01:09:54,000  我的IG快快的\n",
            "[ 93%] 01:09:54,000 → 01:09:58,000  你的IG快快的\n",
            "[ 93%] 01:09:58,000 → 01:10:00,000  等一下你說\n",
            "[ 93%] 01:10:00,000 → 01:10:19,940  我來新增一下,因為目前都是要發去你的手機,然後\n",
            "[ 93%] 01:10:20,000 → 01:10:23,000  你的手機去做驗證嗎?\n",
            "[ 94%] 01:10:23,000 → 01:10:24,000  嗯\n",
            "[ 94%] 01:10:24,000 → 01:10:29,000  對 然後我是想說就是我們直接來進入這個\n",
            "[ 94%] 01:10:29,000 → 01:10:33,000  就是我們直接弄一個這個動態驗證嘛\n",
            "[ 94%] 01:10:33,000 → 01:10:34,000  就是它可以\n",
            "[ 94%] 01:10:34,000 → 01:10:35,000  原來我們有這個東西啊\n",
            "[ 94%] 01:10:35,000 → 01:10:36,000  蛤?\n",
            "[ 94%] 01:10:36,000 → 01:10:38,000  我們有這個東西啊\n",
            "[ 94%] 01:10:38,000 → 01:10:40,000  你們有這個東西\n",
            "[ 94%] 01:10:40,000 → 01:10:44,000  不是不是不是 不是我們有動態驗證碼\n",
            "[ 94%] 01:10:44,000 → 01:10:48,000  你們有動態驗證碼 可是我在帳號裡面沒看到你\n",
            "[ 94%] 01:10:48,000 → 01:10:52,000  因為我們是綁openai跟ig消息\n",
            "[ 94%] 01:10:52,000 → 01:10:56,000  那你這個要不要綁一下 可以可以 四十嗎\n",
            "[ 94%] 01:10:56,000 → 01:11:00,000  不然我每次半夜在搞東西\n",
            "[ 94%] 01:11:00,000 → 01:11:02,000  都會卡住\n",
            "[ 94%] 01:11:02,000 → 01:11:04,000  好有嗎?\n",
            "[ 94%] 01:11:04,000 → 01:11:06,000  有啊它進去了\n",
            "[ 94%] 01:11:06,000 → 01:11:08,000  等等等\n",
            "[ 95%] 01:11:08,000 → 01:11:10,000  那我現在新增一個然後截圖給你們\n",
            "[ 95%] 01:11:10,000 → 01:11:12,000  沒有好等一下我直接\n",
            "[ 95%] 01:11:12,000 → 01:11:14,000  我只新增\n",
            "[ 95%] 01:11:14,000 → 01:11:16,000  沒有我是截個圖啊\n",
            "[ 95%] 01:11:16,000 → 01:11:18,000  它不是會一直跑嗎?\n",
            "[ 95%] 01:11:18,000 → 01:11:20,000  它一直都會跑啊\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  沒有沒有這個不會\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  這個圖不會\n",
            "[ 95%] 01:11:22,000 → 01:11:24,000  這個圖不會 為什麼\n",
            "[ 95%] 01:11:24,000 → 01:11:26,000  因為它跑的不是這個圖\n",
            "[ 95%] 01:11:26,000 → 01:11:28,000  它跑的是這個圖裡面有精藥\n",
            "[ 95%] 01:11:28,000 → 01:11:30,000  然後它會根據這個精藥\n",
            "[ 95%] 01:11:30,000 → 01:11:32,000  加上時間\n",
            "[ 95%] 01:11:32,000 → 01:11:34,000  那個數字不是一直都會跑嗎\n",
            "[ 95%] 01:11:34,000 → 01:11:36,000  對 但是這個圖不會跑\n",
            "[ 95%] 01:11:38,000 → 01:11:40,000  對 它是用這個圖加上時間去\n",
            "[ 95%] 01:11:40,000 → 01:11:42,000  你去算出那個數字\n",
            "[ 95%] 01:11:42,000 → 01:11:44,000  這樣這樣\n",
            "[ 95%] 01:11:45,120 → 01:11:47,120  那我要放在notion裡面了\n",
            "[ 95%] 01:11:48,580 → 01:11:50,580  這樣會太危險嗎\n",
            "[ 95%] 01:11:50,580 → 01:11:52,580  你直接幫我查個指名好不好\n",
            "[ 96%] 01:11:54,840 → 01:11:56,840  等等等等等等\n",
            "[ 96%] 01:11:56,840 → 01:11:58,840  等等喔\n",
            "[ 96%] 01:11:58,840 → 01:12:00,840  我要建個頻道\n",
            "[ 96%] 01:12:00,000 → 01:12:02,000  你用平常名稱叫什麼?\n",
            "[ 96%] 01:12:04,000 → 01:12:06,000  工程部門\n",
            "[ 96%] 01:12:15,000 → 01:12:18,000  為什麼你現在用的那個Gmail是你自己的嗎?\n",
            "[ 96%] 01:12:18,000 → 01:12:20,000  你幫我貼在那個工程部門\n",
            "[ 97%] 01:12:20,000 → 01:12:40,000  我哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋\n",
            "[ 97%] 01:12:40,000 → 01:12:40,840  還是你本來就有在用?\n",
            "[ 97%] 01:12:40,840 → 01:12:41,340  沒有啊\n",
            "[ 97%] 01:12:42,000 → 01:12:43,840  那是我的主力帳號啊\n",
            "[ 97%] 01:12:43,840 → 01:12:45,160  因為這個帳號\n",
            "[ 97%] 01:12:45,160 → 01:12:46,460  幼稚園的時候就創了\n",
            "[ 97%] 01:12:46,460 → 01:12:48,500  所以那個名字是亂打的\n",
            "[ 97%] 01:12:49,340 → 01:12:50,000  打動了\n",
            "[ 97%] 01:12:55,800 → 01:12:58,500  啊你剛剛那個婚姻紀錄有開完嗎?\n",
            "[ 97%] 01:12:58,840 → 01:12:59,340  你有打動嗎?\n",
            "[ 97%] 01:12:59,340 → 01:12:59,840  有有有\n",
            "[ 97%] 01:13:00,000 → 01:13:04,600  你可能要跟他講一下那個東西是幹嘛的\n",
            "[ 97%] 01:13:04,600 → 01:13:09,700  就是你傳到工程部門那個東西是幹嘛的\n",
            "[ 97%] 01:13:09,700 → 01:13:10,760  他可能不太知道\n",
            "[ 97%] 01:13:10,760 → 01:13:14,520  他拿iPhone還安儲\n",
            "[ 97%] 01:13:14,520 → 01:13:16,060  他拿iPhone\n",
            "[ 98%] 01:13:20,000 → 01:13:24,000  好了,我們要去尿尿,然後我要出發了,bye!\n",
            "[ 98%] 01:13:25,280 → 01:13:25,520  好\n",
            "[ 98%] 01:13:25,520 → 01:13:29,780  下午的會議如果需要你,我再call你進來可以嗎?\n",
            "[ 98%] 01:13:34,400 → 01:13:35,080  可以嗎?\n",
            "[ 98%] 01:13:37,020 → 01:13:39,540  哇,那我怎麼知道你什麼時候要call我進來?\n",
            "[ 98%] 01:13:40,000 → 01:13:42,800  好吧,那你就去忙,你就去做你自己的生意\n",
            "[ 98%] 01:13:42,800 → 01:13:43,800  如果你剛好有\n",
            "[ 98%] 01:13:43,800 → 01:13:45,600  我可以進來沒關係啊\n",
            "[ 98%] 01:13:45,600 → 01:13:47,100  好,那你就順便停\n",
            "[ 98%] 01:13:47,100 → 01:13:49,140  OK,好,Bye\n",
            "[ 98%] 01:13:49,140 → 01:13:52,360  2點啊,2點到4點\n",
            "[ 98%] 01:13:52,360 → 01:13:53,180  好\n",
            "[ 98%] 01:13:53,180 → 01:13:53,840  再見\n",
            "[ 99%] 01:14:00,000 → 01:14:29,980  Teksting av Nicolai Winther\n",
            "[ 99%] 01:14:20,000 → 01:14:49,980  Takk for att du så med.\n",
            "[100%] 01:14:40,000 → 01:15:09,980  Teksting av Nicolai Winther\n",
            "[100%] 01:15:00,000 → 01:15:29,980  Teksting av Nicolai Winther\n",
            "[8/8] 輸出 SRT / TXT ...\n",
            "→ 完成！\n",
            "  SRT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).srt\n",
            "  TXT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03679313e38c4c0ba18e9bfec031beba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "gpt-oss-20b-Q4_K_M.gguf:   0%|          | 0.00/11.6G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ece8f8cf5e204ef888b582888b6630a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:    yes\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_CUBLAS: no\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llama_model_load_from_file_impl: using device CUDA0 (Tesla T4) - 14986 MiB free\n",
            "llama_model_loader: loaded meta data with 37 key-value pairs and 459 tensors from /root/.cache/huggingface/hub/models--unsloth--gpt-oss-20b-GGUF/snapshots/c6cedd4259adbfe7e4d4d983a0400bf4cc38e7db/gpt-oss-20b-Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gpt-oss\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   3:                           general.basename str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   4:                       general.quantized_by str              = Unsloth\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 20B\n",
            "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
            "llama_model_loader: - kv   7:                           general.repo_url str              = https://huggingface.co/unsloth\n",
            "llama_model_loader: - kv   8:                               general.tags arr[str,2]       = [\"vllm\", \"text-generation\"]\n",
            "llama_model_loader: - kv   9:                        gpt-oss.block_count u32              = 24\n",
            "llama_model_loader: - kv  10:                     gpt-oss.context_length u32              = 131072\n",
            "llama_model_loader: - kv  11:                   gpt-oss.embedding_length u32              = 2880\n",
            "llama_model_loader: - kv  12:                gpt-oss.feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  13:               gpt-oss.attention.head_count u32              = 64\n",
            "llama_model_loader: - kv  14:            gpt-oss.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  15:                     gpt-oss.rope.freq_base f32              = 150000.000000\n",
            "llama_model_loader: - kv  16:   gpt-oss.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  17:                       gpt-oss.expert_count u32              = 32\n",
            "llama_model_loader: - kv  18:                  gpt-oss.expert_used_count u32              = 4\n",
            "llama_model_loader: - kv  19:               gpt-oss.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  20:             gpt-oss.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  21:           gpt-oss.attention.sliding_window u32              = 128\n",
            "llama_model_loader: - kv  22:         gpt-oss.expert_feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  23:                  gpt-oss.rope.scaling.type str              = yarn\n",
            "llama_model_loader: - kv  24:                gpt-oss.rope.scaling.factor f32              = 32.000000\n",
            "llama_model_loader: - kv  25: gpt-oss.rope.scaling.original_context_length u32              = 4096\n",
            "llama_model_loader: - kv  26:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  27:                         tokenizer.ggml.pre str              = gpt-4o\n",
            "llama_model_loader: - kv  28:                      tokenizer.ggml.tokens arr[str,201088]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  29:                  tokenizer.ggml.token_type arr[i32,201088]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  30:                      tokenizer.ggml.merges arr[str,446189]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  31:                tokenizer.ggml.bos_token_id u32              = 199998\n",
            "llama_model_loader: - kv  32:                tokenizer.ggml.eos_token_id u32              = 200002\n",
            "llama_model_loader: - kv  33:            tokenizer.ggml.padding_token_id u32              = 200017\n",
            "llama_model_loader: - kv  34:                    tokenizer.chat_template str              = {# Chat template fixes by Unsloth #}\\n...\n",
            "llama_model_loader: - kv  35:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  36:                          general.file_type u32              = 15\n",
            "llama_model_loader: - type  f32:  289 tensors\n",
            "llama_model_loader: - type q5_0:   61 tensors\n",
            "llama_model_loader: - type q8_0:   13 tensors\n",
            "llama_model_loader: - type q4_K:   24 tensors\n",
            "llama_model_loader: - type mxfp4:   72 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 10.81 GiB (4.44 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 200017 '<|reserved_200017|>' is not marked as EOG\n",
            "load: control token: 200014 '<|reserved_200014|>' is not marked as EOG\n",
            "load: control token: 200011 '<|reserved_200011|>' is not marked as EOG\n",
            "load: control token: 200009 '<|reserved_200009|>' is not marked as EOG\n",
            "load: control token: 200008 '<|message|>' is not marked as EOG\n",
            "load: control token: 200006 '<|start|>' is not marked as EOG\n",
            "load: control token: 200004 '<|reserved_200004|>' is not marked as EOG\n",
            "load: control token: 200003 '<|constrain|>' is not marked as EOG\n",
            "load: control token: 200000 '<|reserved_200000|>' is not marked as EOG\n",
            "load: control token: 200005 '<|channel|>' is not marked as EOG\n",
            "load: control token: 200010 '<|reserved_200010|>' is not marked as EOG\n",
            "load: control token: 200016 '<|reserved_200016|>' is not marked as EOG\n",
            "load: control token: 200013 '<|reserved_200013|>' is not marked as EOG\n",
            "load: control token: 199998 '<|startoftext|>' is not marked as EOG\n",
            "load: control token: 200018 '<|endofprompt|>' is not marked as EOG\n",
            "load: control token: 200001 '<|reserved_200001|>' is not marked as EOG\n",
            "load: control token: 200015 '<|reserved_200015|>' is not marked as EOG\n",
            "load: printing all EOG tokens:\n",
            "load:   - 199999 ('<|endoftext|>')\n",
            "load:   - 200002 ('<|return|>')\n",
            "load:   - 200007 ('<|end|>')\n",
            "load:   - 200012 ('<|call|>')\n",
            "load: special_eog_ids contains both '<|return|>' and '<|call|>' tokens, removing '<|end|>' token from EOG list\n",
            "load: special tokens cache size = 21\n",
            "load: token to piece cache size = 1.3332 MB\n",
            "print_info: arch             = gpt-oss\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 131072\n",
            "print_info: n_embd           = 2880\n",
            "print_info: n_layer          = 24\n",
            "print_info: n_head           = 64\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 64\n",
            "print_info: n_swa            = 128\n",
            "print_info: is_swa_any       = 1\n",
            "print_info: n_embd_head_k    = 64\n",
            "print_info: n_embd_head_v    = 64\n",
            "print_info: n_gqa            = 8\n",
            "print_info: n_embd_k_gqa     = 512\n",
            "print_info: n_embd_v_gqa     = 512\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 2880\n",
            "print_info: n_expert         = 32\n",
            "print_info: n_expert_used    = 4\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 2\n",
            "print_info: rope scaling     = yarn\n",
            "print_info: freq_base_train  = 150000.0\n",
            "print_info: freq_scale_train = 0.03125\n",
            "print_info: n_ctx_orig_yarn  = 4096\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = ?B\n",
            "print_info: model params     = 20.91 B\n",
            "print_info: general.name     = Gpt-Oss-20B\n",
            "print_info: n_ff_exp         = 2880\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 201088\n",
            "print_info: n_merges         = 446189\n",
            "print_info: BOS token        = 199998 '<|startoftext|>'\n",
            "print_info: EOS token        = 200002 '<|return|>'\n",
            "print_info: EOT token        = 199999 '<|endoftext|>'\n",
            "print_info: PAD token        = 200017 '<|reserved_200017|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 199999 '<|endoftext|>'\n",
            "print_info: EOG token        = 200002 '<|return|>'\n",
            "print_info: EOG token        = 200012 '<|call|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   1 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   3 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   5 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   7 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   9 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  11 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  13 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  15 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  17 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  19 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  21 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  23 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q5_0) (and 0 others) cannot be used with preferred buffer type CUDA_Host, using CPU instead\n",
            "load_tensors: offloading 24 repeating layers to GPU\n",
            "load_tensors: offloading output layer to GPU\n",
            "load_tensors: offloaded 25/25 layers to GPU\n",
            "load_tensors:        CUDA0 model buffer size = 10694.15 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =   379.71 MiB\n",
            "...............................................................................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 8192\n",
            "llama_context: n_ctx_per_seq = 8192\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 150000.0\n",
            "llama_context: freq_scale    = 0.03125\n",
            "llama_context: n_ctx_per_seq (8192) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:  CUDA_Host  output buffer size =     0.77 MiB\n",
            "create_memory: n_ctx = 8192 (padded)\n",
            "llama_kv_cache_unified_iswa: using full-size SWA cache (ref: https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)\n",
            "llama_kv_cache_unified_iswa: creating non-SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: skipped\n",
            "llama_kv_cache_unified: layer   1: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   2: skipped\n",
            "llama_kv_cache_unified: layer   3: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   4: skipped\n",
            "llama_kv_cache_unified: layer   5: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   6: skipped\n",
            "llama_kv_cache_unified: layer   7: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   8: skipped\n",
            "llama_kv_cache_unified: layer   9: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  10: skipped\n",
            "llama_kv_cache_unified: layer  11: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  12: skipped\n",
            "llama_kv_cache_unified: layer  13: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  14: skipped\n",
            "llama_kv_cache_unified: layer  15: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  16: skipped\n",
            "llama_kv_cache_unified: layer  17: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  18: skipped\n",
            "llama_kv_cache_unified: layer  19: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  20: skipped\n",
            "llama_kv_cache_unified: layer  21: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  22: skipped\n",
            "llama_kv_cache_unified: layer  23: dev = CUDA0\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_kv_cache_unified_iswa: creating     SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   1: skipped\n",
            "llama_kv_cache_unified: layer   2: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   3: skipped\n",
            "llama_kv_cache_unified: layer   4: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   5: skipped\n",
            "llama_kv_cache_unified: layer   6: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   7: skipped\n",
            "llama_kv_cache_unified: layer   8: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   9: skipped\n",
            "llama_kv_cache_unified: layer  10: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  11: skipped\n",
            "llama_kv_cache_unified: layer  12: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  13: skipped\n",
            "llama_kv_cache_unified: layer  14: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  15: skipped\n",
            "llama_kv_cache_unified: layer  16: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  17: skipped\n",
            "llama_kv_cache_unified: layer  18: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  19: skipped\n",
            "llama_kv_cache_unified: layer  20: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  21: skipped\n",
            "llama_kv_cache_unified: layer  22: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  23: skipped\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 2\n",
            "llama_context: max_nodes = 3672\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "llama_context:      CUDA0 compute buffer size =  1087.26 MiB\n",
            "llama_context:  CUDA_Host compute buffer size =    41.64 MiB\n",
            "llama_context: graph nodes  = 1446\n",
            "llama_context: graph splits = 2\n",
            "CUDA : ARCHS = 500,520,530,600,610,620,700,720,750,800,860,870,890,900 | FORCE_MMQ = 1 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'general.file_type': '15', 'general.quantization_version': '2', 'tokenizer.chat_template': '{# Chat template fixes by Unsloth #}\\n{#-\\n  In addition to the normal inputs of `messages` and `tools`, this template also accepts the\\n  following kwargs:\\n  - \"builtin_tools\": A list, can contain \"browser\" and/or \"python\".\\n  - \"model_identity\": A string that optionally describes the model identity.\\n  - \"reasoning_effort\": A string that describes the reasoning effort, defaults to \"medium\".\\n #}\\n\\n{#- Tool Definition Rendering ============================================== #}\\n{%- macro render_typescript_type(param_spec, required_params, is_nullable=false) -%}\\n    {%- if param_spec.type == \"array\" -%}\\n        {%- if param_spec[\\'items\\'] -%}\\n            {%- if param_spec[\\'items\\'][\\'type\\'] == \"string\" -%}\\n                {{- \"string[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"number\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"integer\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"boolean\" -%}\\n                {{- \"boolean[]\" }}\\n            {%- else -%}\\n                {%- set inner_type = render_typescript_type(param_spec[\\'items\\'], required_params) -%}\\n                {%- if inner_type == \"object | object\" or inner_type|length > 50 -%}\\n                    {{- \"any[]\" }}\\n                {%- else -%}\\n                    {{- inner_type + \"[]\" }}\\n                {%- endif -%}\\n            {%- endif -%}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- else -%}\\n            {{- \"any[]\" }}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type is defined and param_spec.type is iterable and param_spec.type is not string and param_spec.type is not mapping and param_spec.type[0] is defined -%}\\n        {#- Handle array of types like [\"object\", \"object\"] from Union[dict, list] #}\\n        {%- if param_spec.type | length > 1 -%}\\n            {{- param_spec.type | join(\" | \") }}\\n        {%- else -%}\\n            {{- param_spec.type[0] }}\\n        {%- endif -%}\\n    {%- elif param_spec.oneOf -%}\\n        {#- Handle oneOf schemas - check for complex unions and fallback to any #}\\n        {%- set has_object_variants = false -%}\\n        {%- for variant in param_spec.oneOf -%}\\n            {%- if variant.type == \"object\" -%}\\n                {%- set has_object_variants = true -%}\\n            {%- endif -%}\\n        {%- endfor -%}\\n        {%- if has_object_variants and param_spec.oneOf|length > 1 -%}\\n            {{- \"any\" }}\\n        {%- else -%}\\n            {%- for variant in param_spec.oneOf -%}\\n                {{- render_typescript_type(variant, required_params) -}}\\n                {%- if variant.description %}\\n                    {{- \"// \" + variant.description }}\\n                {%- endif -%}\\n                {%- if variant.default is defined %}\\n                    {{ \"// default: \" + variant.default|tojson }}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \" | \" }}\\n                {% endif -%}\\n            {%- endfor -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"string\" -%}\\n        {%- if param_spec.enum -%}\\n            {{- \\'\"\\' + param_spec.enum|join(\\'\" | \"\\') + \\'\"\\' -}}\\n        {%- else -%}\\n            {{- \"string\" }}\\n            {%- if param_spec.nullable %}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"number\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"integer\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"boolean\" -%}\\n        {{- \"boolean\" }}\\n\\n    {%- elif param_spec.type == \"object\" -%}\\n        {%- if param_spec.properties -%}\\n            {{- \"{\\\\n\" }}\\n            {%- for prop_name, prop_spec in param_spec.properties.items() -%}\\n                {{- prop_name -}}\\n                {%- if prop_name not in (param_spec.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{ render_typescript_type(prop_spec, param_spec.required or []) }}\\n                {%- if not loop.last -%}\\n                    {{-\", \" }}\\n                {%- endif -%}\\n            {%- endfor -%}\\n            {{- \"}\" }}\\n        {%- else -%}\\n            {{- \"object\" }}\\n        {%- endif -%}\\n    {%- else -%}\\n        {{- \"any\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{%- macro render_tool_namespace(namespace_name, tools) -%}\\n    {{- \"## \" + namespace_name + \"\\\\n\\\\n\" }}\\n    {{- \"namespace \" + namespace_name + \" {\\\\n\\\\n\" }}\\n    {%- for tool in tools %}\\n        {%- set tool = tool.function %}\\n        {{- \"// \" + tool.description + \"\\\\n\" }}\\n        {{- \"type \"+ tool.name + \" = \" }}\\n        {%- if tool.parameters and tool.parameters.properties %}\\n            {{- \"(_: {\\\\n\" }}\\n            {%- for param_name, param_spec in tool.parameters.properties.items() %}\\n                {%- if param_spec.description %}\\n                    {{- \"// \" + param_spec.description + \"\\\\n\" }}\\n                {%- endif %}\\n                {{- param_name }}\\n                {%- if param_name not in (tool.parameters.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{- render_typescript_type(param_spec, tool.parameters.required or []) }}\\n                {%- if param_spec.default is defined -%}\\n                    {%- if param_spec.enum %}\\n                        {{- \", // default: \" + param_spec.default }}\\n                    {%- elif param_spec.oneOf %}\\n                        {{- \"// default: \" + param_spec.default }}\\n                    {%- else %}\\n                        {{- \", // default: \" + param_spec.default|tojson }}\\n                    {%- endif -%}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \",\\\\n\" }}\\n                {%- else %}\\n                    {{- \",\\\\n\" }}\\n                {%- endif -%}\\n            {%- endfor %}\\n            {{- \"}) => any;\\\\n\\\\n\" }}\\n        {%- else -%}\\n            {{- \"() => any;\\\\n\\\\n\" }}\\n        {%- endif -%}\\n    {%- endfor %}\\n    {{- \"} // namespace \" + namespace_name }}\\n{%- endmacro -%}\\n\\n{%- macro render_builtin_tools(browser_tool, python_tool) -%}\\n    {%- if browser_tool %}\\n        {{- \"## browser\\\\n\\\\n\" }}\\n        {{- \"// Tool for browsing.\\\\n\" }}\\n        {{- \"// The `cursor` appears in brackets before each browsing display: `[{cursor}]`.\\\\n\" }}\\n        {{- \"// Cite information from the tool using the following format:\\\\n\" }}\\n        {{- \"// `【{cursor}†L{line_start}(-L{line_end})?】`, for example: `【6†L9-L11】` or `【8†L3】`.\\\\n\" }}\\n        {{- \"// Do not quote more than 10 words directly from the tool output.\\\\n\" }}\\n        {{- \"// sources=web (default: web)\\\\n\" }}\\n        {{- \"namespace browser {\\\\n\\\\n\" }}\\n        {{- \"// Searches for information related to `query` and displays `topn` results.\\\\n\" }}\\n        {{- \"type search = (_: {\\\\n\" }}\\n        {{- \"query: string,\\\\n\" }}\\n        {{- \"topn?: number, // default: 10\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Opens the link `id` from the page indicated by `cursor` starting at line number `loc`, showing `num_lines` lines.\\\\n\" }}\\n        {{- \"// Valid link ids are displayed with the formatting: `【{id}†.*】`.\\\\n\" }}\\n        {{- \"// If `cursor` is not provided, the most recent page is implied.\\\\n\" }}\\n        {{- \"// If `id` is a string, it is treated as a fully qualified URL associated with `source`.\\\\n\" }}\\n        {{- \"// If `loc` is not provided, the viewport will be positioned at the beginning of the document or centered on the most relevant passage, if available.\\\\n\" }}\\n        {{- \"// Use this function without `id` to scroll to a new location of an opened page.\\\\n\" }}\\n        {{- \"type open = (_: {\\\\n\" }}\\n        {{- \"id?: number | string, // default: -1\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"loc?: number, // default: -1\\\\n\" }}\\n        {{- \"num_lines?: number, // default: -1\\\\n\" }}\\n        {{- \"view_source?: boolean, // default: false\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Finds exact matches of `pattern` in the current page, or the page given by `cursor`.\\\\n\" }}\\n        {{- \"type find = (_: {\\\\n\" }}\\n        {{- \"pattern: string,\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"} // namespace browser\\\\n\\\\n\" }}\\n    {%- endif -%}\\n\\n    {%- if python_tool %}\\n        {{- \"## python\\\\n\\\\n\" }}\\n        {{- \"Use this tool to execute Python code in your chain of thought. The code will not be shown to the user. This tool should be used for internal reasoning, but not for code that is intended to be visible to the user (e.g. when creating plots, tables, or files).\\\\n\\\\n\" }}\\n        {{- \"When you send a message containing Python code to python, it will be executed in a stateful Jupyter notebook environment. python will respond with the output of the execution or time out after 120.0 seconds. The drive at \\'/mnt/data\\' can be used to save and persist user files. Internet access for this session is UNKNOWN. Depends on the cluster.\\\\n\\\\n\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- System Message Construction ============================================ #}\\n{%- macro build_system_message() -%}\\n    {%- if model_identity is not defined %}\\n        {%- set model_identity = \"You are ChatGPT, a large language model trained by OpenAI.\" %}\\n    {%- endif %}\\n    {{- model_identity + \"\\\\n\" }}\\n    {{- \"Knowledge cutoff: 2024-06\\\\n\" }}\\n    {{- \"Current date: \" + strftime_now(\"%Y-%m-%d\") + \"\\\\n\\\\n\" }}\\n    {%- if reasoning_effort is not defined %}\\n        {%- set reasoning_effort = \"medium\" %}\\n    {%- endif %}\\n    {{- \"Reasoning: \" + reasoning_effort + \"\\\\n\\\\n\" }}\\n    {%- if builtin_tools is defined and builtin_tools is not none %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {%- set available_builtin_tools = namespace(browser=false, python=false) %}\\n        {%- for tool in builtin_tools %}\\n            {%- if tool == \"browser\" %}\\n                {%- set available_builtin_tools.browser = true %}\\n            {%- elif tool == \"python\" %}\\n                {%- set available_builtin_tools.python = true %}\\n            {%- endif %}\\n        {%- endfor %}\\n        {{- render_builtin_tools(available_builtin_tools.browser, available_builtin_tools.python) }}\\n    {%- endif -%}\\n    {{- \"# Valid channels: analysis, commentary, final. Channel must be included for every message.\" }}\\n    {%- if tools -%}\\n        {{- \"\\\\nCalls to these tools must go to the commentary channel: \\'functions\\'.\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- Main Template Logic ================================================= #}\\n{#- Set defaults #}\\n\\n{#- Render system message #}\\n{{- \"<|start|>system<|message|>\" }}\\n{{- build_system_message() }}\\n{{- \"<|end|>\" }}\\n\\n{#- Extract developer message #}\\n{%- if developer_instructions is defined and developer_instructions is not none %}\\n    {%- set developer_message = developer_instructions %}\\n    {%- set loop_messages = messages %}\\n{%- elif messages[0].role == \"developer\" or messages[0].role == \"system\" %}\\n    {%- set developer_message = messages[0].content %}\\n    {%- set loop_messages = messages[1:] %}\\n{%- else %}\\n    {%- set developer_message = \"\" %}\\n    {%- set loop_messages = messages %}\\n{%- endif %}\\n\\n{#- Render developer message #}\\n{%- if developer_message or tools %}\\n    {{- \"<|start|>developer<|message|>\" }}\\n    {%- if developer_message %}\\n        {{- \"# Instructions\\\\n\\\\n\" }}\\n        {{- developer_message }}\\n    {%- endif %}\\n    {%- if tools -%}\\n        {%- if developer_message %}\\n            {{- \"\\\\n\\\\n\" }}\\n        {%- endif %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {{- render_tool_namespace(\"functions\", tools) }}\\n    {%- endif -%}\\n    {{- \"<|end|>\" }}\\n{%- endif %}\\n\\n{#- Render messages #}\\n{%- set last_tool_call = namespace(name=none) %}\\n{%- for message in loop_messages -%}\\n    {#- At this point only assistant/user/tool messages should remain #}\\n    {%- if message.role == \\'assistant\\' -%}\\n        {#- Checks to ensure the messages are being passed in the format we expect #}\\n        {%- if \"thinking\" in message %}\\n            {%- if \"<|channel|>analysis<|message|>\" in message.thinking or \"<|channel|>final<|message|>\" in message.thinking %}\\n                {{- raise_exception(\"You have passed a message containing <|channel|> tags in the thinking field. Instead of doing this, you should pass analysis messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'thinking\\' field, and final messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'content\\' field.\") }}\\n            {%- endif %}\\n        {%- endif %}\\n        {%- if \"tool_calls\" in message %}\\n            {#- We need very careful handling here - we want to drop the tool call analysis message if the model #}\\n            {#- has output a later <|final|> message, but otherwise we want to retain it. This is the only case #}\\n            {#- when we render CoT/analysis messages in inference. #}\\n            {%- set future_final_message = namespace(found=false) %}\\n            {%- for future_message in loop_messages[loop.index:] %}\\n                {%- if future_message.role == \\'assistant\\' and \"tool_calls\" not in future_message %}\\n                    {%- set future_final_message.found = true %}\\n                {%- endif %}\\n            {%- endfor %}\\n            {#- We assume max 1 tool call per message, and so we infer the tool call name #}\\n            {#- in \"tool\" messages from the most recent assistant tool call name #}\\n            {%- set tool_call = message.tool_calls[0] %}\\n            {%- if tool_call.function %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {%- if message.content and message.thinking %}\\n                {{- raise_exception(\"Cannot pass both content and thinking in an assistant message with tool calls! Put the analysis message in one or the other, but not both.\") }}\\n            {%- elif message.content and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- elif message.thinking and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {{- \"<|start|>assistant to=\" }}\\n            {{- \"functions.\" + tool_call.name + \"<|channel|>commentary \" }}\\n            {{- (tool_call.content_type if tool_call.content_type is defined else \"json\") + \"<|message|>\" }}\\n            {%- if tool_call.arguments is string %}\\n                {{- tool_call.arguments }}\\n            {%- else %}\\n                {{- tool_call.arguments|tojson }}\\n            {%- endif %}\\n            {{- \"<|call|>\" }}\\n            {%- set last_tool_call.name = tool_call.name %}\\n        {%- elif loop.last and not add_generation_prompt %}\\n            {#- Only render the CoT if the final turn is an assistant turn and add_generation_prompt is false #}\\n            {#- This is a situation that should only occur in training, never in inference. #}\\n            {%- if \"thinking\" in message %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {#- <|return|> indicates the end of generation, but <|end|> does not #}\\n            {#- <|return|> should never be an input to the model, but we include it as the final token #}\\n            {#- when training, so the model learns to emit it. #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- elif \"thinking\" in message %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- else %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- endif %}\\n    {%- elif message.role == \\'tool\\' -%}\\n        {%- if last_tool_call.name is none %}\\n            {{- raise_exception(\"Message has tool role, but there was no previous assistant message with a tool call!\") }}\\n        {%- endif %}\\n        {{- \"<|start|>functions.\" + last_tool_call.name }}\\n        {%- if message.content is string %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- else %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content|tojson + \"<|end|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \\'user\\' -%}\\n        {{- \"<|start|>user<|message|>\" + message.content + \"<|end|>\" }}\\n    {%- endif -%}\\n{%- endfor -%}\\n\\n{#- Generation prompt #}\\n{%- if add_generation_prompt -%}\\n<|start|>assistant\\n{%- endif -%}\\n{# Copyright 2025-present Unsloth. Apache 2.0 License. Unsloth chat template fixes. Edited from ggml-org & OpenAI #}', 'gpt-oss.attention.head_count': '64', 'gpt-oss.rope.scaling.original_context_length': '4096', 'gpt-oss.feed_forward_length': '2880', 'general.repo_url': 'https://huggingface.co/unsloth', 'general.license': 'apache-2.0', 'general.size_label': '20B', 'general.type': 'model', 'tokenizer.ggml.padding_token_id': '200017', 'gpt-oss.context_length': '131072', 'general.quantized_by': 'Unsloth', 'gpt-oss.embedding_length': '2880', 'gpt-oss.block_count': '24', 'gpt-oss.attention.sliding_window': '128', 'tokenizer.ggml.pre': 'gpt-4o', 'general.architecture': 'gpt-oss', 'gpt-oss.rope.freq_base': '150000.000000', 'gpt-oss.attention.head_count_kv': '8', 'gpt-oss.attention.layer_norm_rms_epsilon': '0.000010', 'gpt-oss.expert_count': '32', 'general.basename': 'Gpt-Oss-20B', 'gpt-oss.attention.key_length': '64', 'gpt-oss.expert_used_count': '4', 'gpt-oss.expert_feed_forward_length': '2880', 'gpt-oss.rope.scaling.type': 'yarn', 'tokenizer.ggml.eos_token_id': '200002', 'gpt-oss.rope.scaling.factor': '32.000000', 'tokenizer.ggml.model': 'gpt2', 'general.name': 'Gpt-Oss-20B', 'gpt-oss.attention.value_length': '64', 'tokenizer.ggml.bos_token_id': '199998'}\n",
            "Available chat formats from metadata: chat_template.default\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**會議摘要**\n\n**1. 主要討論內容**  \n- 會議中提到「可再想想看」的方案，並未決定具體行動。  \n- 討討開設線上號、專門輸入內容之計畫，並確認無問題。  \n- 會議者提出將帳號先開，後續做實驗，並說「直接先開帳號」  \n- **重點：** 會議決定先開帳號，並以 YouTube、IG、Threads 等平台推廣  \n- **重點**： 其實務流程：先開帳號，先前往下列…  \n\n> …….  \nWe need to produce a concise summary of the transcript. The transcript is messy, but we need to extract key points: time, persons, tasks, conclusions, unresolved items, actions. Provide bullet list with headings. 500-900 Chinese characters? Actually 500-900 words? The instruction says 500–900 字 (characters). So we need about 500-900 Chinese characters. That's roughly 300-400 words. Provide bullet points.\n\nWe must avoid system messages, no brackets, no English. Use Chinese. Provide headings and bullet items. Ensure no extraneous commentary. Provide final answer. Let's craft.\n\nWe need to identify key participants: seems like speaker is \"Nicolai Winther\" maybe? Actually transcript includes \"Teksting av Nicolai Winther\". So maybe the speaker is Nicolai Winther. Also mention \"老孫\" etc. But we can just refer to \"會議者\".\n\nKey points:\n\n- They discuss opening an online account, possibly for a brand or company.\n- They plan to use YouTube, IG, Threads to promote content, free tools, etc.\n- They talk about using a free tool for students, maybe physics? They mention \"物理\" but not sure.\n- They mention \"成學文教有限公司\" as company name; \"陰謀\" maybe brand name; ask if trademark application.\n- They discuss registration of account, no plan to register now.\n- They talk about verifying dynamic verification code for phone, using OpenAI and IG messages.\n- They talk about building a channel, naming it \"工程部門\".\n- They mention Gmail account used is personal.\n- They talk about Notion integration.\n- They mention \"notion\" and \"Threads\" and \"IG\" etc.\n\nWe need to"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - 處理分段 1/5（~20.0%）\n",
            "    ↳ 分段 1 已產生字元：35\n",
            "    ↳ 分段 1 已產生字元：67\n",
            "    ↳ 分段 1 已產生字元：102\n",
            "    ↳ 分段 1 已產生字元：130\n",
            "    ↳ 分段 1 已產生字元：161\n",
            "    ↳ 分段 1 已產生字元：198\n",
            "    ↳ 分段 1 已產生字元：223\n",
            "    ↳ 分段 1 已產生字元：265\n",
            "    ↳ 分段 1 已產生字元：362\n",
            "    ↳ 分段 1 已產生字元：499\n",
            "    ↳ 分段 1 已產生字元：622\n",
            "    ↳ 分段 1 已產生字元：736\n",
            "    ↳ 分段 1 已產生字元：860\n",
            "    ↳ 分段 1 已產生字元：970\n",
            "    ↳ 分段 1 已產生字元：1086\n",
            "    ↳ 分段 1 已產生字元：1179\n",
            "    ↳ 分段 1 已產生字元：1279\n",
            "    ↳ 分段 1 已產生字元：1413\n",
            "    ↳ 分段 1 已產生字元：1527\n",
            "    ↳ 分段 1 已產生字元：1649\n",
            "    ↳ 分段 1 已產生字元：1764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6459.12 ms\n",
            "llama_perf_context_print: prompt eval time =    6458.40 ms /  3472 tokens (    1.86 ms per token,   537.59 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12331.63 ms /   511 runs   (   24.13 ms per token,    41.44 tokens per second)\n",
            "llama_perf_context_print:       total time =   21546.03 ms /  3983 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 1 已產生字元：1767\n",
            "  - 處理分段 2/5（~40.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3358 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 2 已產生字元：35\n",
            "    ↳ 分段 2 已產生字元：61\n",
            "    ↳ 分段 2 已產生字元：89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6459.12 ms\n",
            "llama_perf_context_print: prompt eval time =    4893.43 ms /  3358 tokens (    1.46 ms per token,   686.23 tokens per second)\n",
            "llama_perf_context_print:        eval time =    2056.04 ms /    84 runs   (   24.48 ms per token,    40.86 tokens per second)\n",
            "llama_perf_context_print:       total time =    7337.72 ms /  3442 tokens\n",
            "llama_perf_context_print:    graphs reused =         81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 2 已產生字元：103\n",
            "  - 處理分段 3/5（~60.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3325 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 3 已產生字元：51\n",
            "    ↳ 分段 3 已產生字元：92\n",
            "    ↳ 分段 3 已產生字元：125\n",
            "    ↳ 分段 3 已產生字元：163\n",
            "    ↳ 分段 3 已產生字元：192\n",
            "    ↳ 分段 3 已產生字元：228\n",
            "    ↳ 分段 3 已產生字元：263\n",
            "    ↳ 分段 3 已產生字元：292\n",
            "    ↳ 分段 3 已產生字元：328\n",
            "    ↳ 分段 3 已產生字元：406\n",
            "    ↳ 分段 3 已產生字元：528\n",
            "    ↳ 分段 3 已產生字元：631\n",
            "    ↳ 分段 3 已產生字元：747\n",
            "    ↳ 分段 3 已產生字元：845\n",
            "    ↳ 分段 3 已產生字元：950\n",
            "    ↳ 分段 3 已產生字元：1054\n",
            "    ↳ 分段 3 已產生字元：1119\n",
            "    ↳ 分段 3 已產生字元：1159\n",
            "    ↳ 分段 3 已產生字元：1194\n",
            "    ↳ 分段 3 已產生字元：1230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6459.12 ms\n",
            "llama_perf_context_print: prompt eval time =    4821.62 ms /  3325 tokens (    1.45 ms per token,   689.60 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12701.47 ms /   511 runs   (   24.86 ms per token,    40.23 tokens per second)\n",
            "llama_perf_context_print:       total time =   20454.58 ms /  3836 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 3 已產生字元：1259\n",
            "  - 處理分段 4/5（~80.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3387 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 4 已產生字元：39\n",
            "    ↳ 分段 4 已產生字元：76\n",
            "    ↳ 分段 4 已產生字元：165\n",
            "    ↳ 分段 4 已產生字元：282\n",
            "    ↳ 分段 4 已產生字元：383\n",
            "    ↳ 分段 4 已產生字元：483\n",
            "    ↳ 分段 4 已產生字元：602\n",
            "    ↳ 分段 4 已產生字元：716\n",
            "    ↳ 分段 4 已產生字元：818\n",
            "    ↳ 分段 4 已產生字元：937\n",
            "    ↳ 分段 4 已產生字元：1056\n",
            "    ↳ 分段 4 已產生字元：1138\n",
            "    ↳ 分段 4 已產生字元：1256\n",
            "    ↳ 分段 4 已產生字元：1379\n",
            "    ↳ 分段 4 已產生字元：1527\n",
            "    ↳ 分段 4 已產生字元：1643\n",
            "    ↳ 分段 4 已產生字元：1763\n",
            "    ↳ 分段 4 已產生字元：1883\n",
            "    ↳ 分段 4 已產生字元：1990\n",
            "    ↳ 分段 4 已產生字元：2112\n",
            "    ↳ 分段 4 已產生字元：2217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6459.12 ms\n",
            "llama_perf_context_print: prompt eval time =    5012.19 ms /  3387 tokens (    1.48 ms per token,   675.75 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12846.32 ms /   511 runs   (   25.14 ms per token,    39.78 tokens per second)\n",
            "llama_perf_context_print:       total time =   20699.21 ms /  3898 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 4 已產生字元：2257\n",
            "  - 處理分段 5/5（~100.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 141 prefix-match hit, remaining 1792 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 5 已產生字元：35\n",
            "    ↳ 分段 5 已產生字元：63\n",
            "    ↳ 分段 5 已產生字元：93\n",
            "    ↳ 分段 5 已產生字元：122\n",
            "    ↳ 分段 5 已產生字元：162\n",
            "    ↳ 分段 5 已產生字元：192\n",
            "    ↳ 分段 5 已產生字元：290\n",
            "    ↳ 分段 5 已產生字元：408\n",
            "    ↳ 分段 5 已產生字元：501\n",
            "    ↳ 分段 5 已產生字元：605\n",
            "    ↳ 分段 5 已產生字元：725\n",
            "    ↳ 分段 5 已產生字元：849\n",
            "    ↳ 分段 5 已產生字元：953\n",
            "    ↳ 分段 5 已產生字元：1026\n",
            "    ↳ 分段 5 已產生字元：1136\n",
            "    ↳ 分段 5 已產生字元：1234\n",
            "    ↳ 分段 5 已產生字元：1316\n",
            "    ↳ 分段 5 已產生字元：1426\n",
            "    ↳ 分段 5 已產生字元：1546\n",
            "    ↳ 分段 5 已產生字元：1649\n",
            "    ↳ 分段 5 已產生字元：1735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6459.12 ms\n",
            "llama_perf_context_print: prompt eval time =    2431.33 ms /  1792 tokens (    1.36 ms per token,   737.05 tokens per second)\n",
            "llama_perf_context_print:        eval time =   11867.41 ms /   511 runs   (   23.22 ms per token,    43.06 tokens per second)\n",
            "llama_perf_context_print:       total time =   17234.20 ms /  2303 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 5 已產生字元：1752\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**會議筆記（Markdown，繁體）**\n\n---\n\n## 整體提要  \n- 會議主題為「開設線上號並推廣內容」；  \n- 主要平台包括 YouTube、IG、Threads；  \n- 討討使用免費工具與 AI 產生內容；  \n- 需確認帳號名稱、商標及資料保護；  \n- 會議決定先開帳號，後續實驗推廣策略。  \n\n---\n\n## 章節要點（含時間脈絡）\n\n| 時間 | 要點 |\n|------|------|\n| 0:00 | 會議者提到「可再想想看」的方案，未決定具體行動。 |\n| 0:05 | 討討開設線上號、專門輸入內容之計畫，並確認無問題。 |\n| 0:10 | 會議者提出將帳號先開，後續做實驗，說「直接先開帳號」。 |\n| 0:15 | 會議決定先開帳號，並以 YouTube、IG、Threads 等平台推廣。 |\n| 0:20 | 其實務流程：先開帳號，先前往下列…（未完整說明）。 |\n| 0:25 | 會議者提到「成學文教有限公司」與「陰謀」作為公司名，詢問是否已申請商標。 |\n| 0:30 | 會議者表示目前不打算註冊帳號，先以 Gmail 個人帳號做測試。 |\n| 0:35 | 會議者說明將使用 Notion、Threads、IG 等工具來管理與推廣內容。 |\n| 0:40 | 會議者提到「動態驗證碼」的流程，並說要用 OpenAI 及 IG 訊息確認。 |\n| 0:45 | 會議者說明將建立「工程部門」為頻道名稱。 |\n\n---\n\n## 可執行重點（具體待辦）\n\n- **開設線上號**：先以 Gmail 個人帳號做測試，後續正式註冊。  \n- **確認商標**：查詢「陰謀」是否已申請商標，並確保不侵權。  \n- **設定平台**：決定 YouTube、IG、Threads 為主要推廣平台。  \n- **管理工具**：整合 Notion 以管理內容與進度。  \n- **驗證流程**：使用 OpenAI 及 IG 訊息確認動態驗證碼。  \n- **頻道名稱**：確定「工程部門」為正式頻道名稱。  \n\n---"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 129 prefix-match hit, remaining 2330 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 彙整 已產生字元：43\n",
            "    ↳ 彙整 已產生字元：80\n",
            "    ↳ 彙整 已產生字元：122\n",
            "    ↳ 彙整 已產生字元：150\n",
            "    ↳ 彙整 已產生字元：189\n",
            "    ↳ 彙整 已產生字元：228\n",
            "    ↳ 彙整 已產生字元：258\n",
            "    ↳ 彙整 已產生字元：288\n",
            "    ↳ 彙整 已產生字元：315\n",
            "    ↳ 彙整 已產生字元：350\n",
            "    ↳ 彙整 已產生字元：388\n",
            "    ↳ 彙整 已產生字元：418\n",
            "    ↳ 彙整 已產生字元：447\n",
            "    ↳ 彙整 已產生字元：477\n",
            "    ↳ 彙整 已產生字元：511\n",
            "    ↳ 彙整 已產生字元：554\n",
            "    ↳ 彙整 已產生字元：586\n",
            "    ↳ 彙整 已產生字元：620\n",
            "    ↳ 彙整 已產生字元：658\n",
            "    ↳ 彙整 已產生字元：690\n",
            "    ↳ 彙整 已產生字元：721\n",
            "    ↳ 彙整 已產生字元：768\n",
            "    ↳ 彙整 已產生字元：810\n",
            "    ↳ 彙整 已產生字元：850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6459.12 ms\n",
            "llama_perf_context_print: prompt eval time =    3261.43 ms /  2330 tokens (    1.40 ms per token,   714.41 tokens per second)\n",
            "llama_perf_context_print:        eval time =   14407.15 ms /   606 runs   (   23.77 ms per token,    42.06 tokens per second)\n",
            "llama_perf_context_print:       total time =   20949.14 ms /  2936 tokens\n",
            "llama_perf_context_print:    graphs reused =        586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 彙整 已產生字元：878\n",
            "→ 完成 ✅  /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8)_summary.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "303e6ad4"
      },
      "source": [
        "## Consolidate dependencies\n",
        "\n",
        "### Subtask:\n",
        "Identify and remove duplicate dependency installations and imports. Ensure all necessary libraries are imported once at the beginning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98111c8f"
      },
      "source": [
        "**Reasoning**:\n",
        "Review the merged code for duplicate imports and remove them to ensure each library is imported only once at the beginning.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7f145246fe0c4ec39d57b620556528d2",
            "6ba1445af6a04d6993a5b8f699ab54dd",
            "44936da86ad04f09897756c1814e13d9",
            "210cb9c5190048ed92c46ac847cc1059",
            "7879a598aeb94f08945a3f00bc694d94",
            "ac2bca7bb35b452e90bfcd1dab7f6744",
            "3e9487be9bb445fe914ff92254d86869",
            "912464d86c4346f79558f43da65ac8ba",
            "c6c15def5dd1414381faad3a71324c44",
            "2e8b014908464d69aa5357dd0c5caf0c",
            "a5cd0f452523415686f4dc25bdfb6a2a"
          ]
        },
        "id": "deeedd95",
        "outputId": "ce14919a-6b73-42a5-d592-51dcf9f0c7bb"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Whisper Automatic Subtitle Generation: GPU Transcription + CPU Denoising + OpenCC Post-processing (Traditional/Simplified Conversion)\n",
        "# - Transcription: faster-whisper (CUDA, compute: int8_float16→float16→int8)\n",
        "# - Denoising: ffmpeg afftdn (CPU)\n",
        "# - Progress: Real-time printing of \"current sentence + video total length percentage\"\n",
        "# - Network source download and output: MyDrive/whisper; Files in Drive: Output to the same folder\n",
        "# - Prompts \"Delete runtime and restart\" if download is blocked or abnormal\n",
        "# =========================================================\n",
        "\n",
        "# Restrict multithreading (more stable)\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# [1/8] Mount Google Drive\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "except:\n",
        "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "# Consolidated Imports\n",
        "import sys, gc, shutil, datetime, subprocess as sp\n",
        "from pathlib import Path\n",
        "import re, math, time, importlib, textwrap\n",
        "from typing import List, Tuple\n",
        "from IPython.display import display, Markdown\n",
        "import soundfile as sf\n",
        "from faster_whisper import WhisperModel\n",
        "from opencc import OpenCC\n",
        "import srt as _srt # Import srt as _srt to avoid name conflict later with the module itself\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "ROOT = Path(\"/content/gdrive/MyDrive\")\n",
        "WHISPER_DIR = ROOT / \"whisper\"\n",
        "WHISPER_DIR.mkdir(exist_ok=True, parents=True)\n",
        "os.chdir(ROOT)\n",
        "print(f\"→ 當前工作目錄：{os.getcwd()}\")\n",
        "\n",
        "# [2/8] User Form Parameters\n",
        "#@markdown # Whisper Transcription & Summary\n",
        "#@markdown ## Transcription (GPU + CPU)\n",
        "#@markdown Input: Google Drive file (relative to MyDrive) or video URL (YouTube/HTTP)\n",
        "filename = \"whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\"  #@param {type:\"string\"}\n",
        "#@markdown ✔ Save network source to MyDrive/whisper\n",
        "save_video_to_google_drive = True  #@param {type:\"boolean\"}\n",
        "#@markdown Model (large-v3 for GPU; medium if VRAM is tight)\n",
        "model_size = \"large-v3\"  #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\"]\n",
        "#@markdown Language (transcribe only, no translation)\n",
        "language = \"自動偵測\"  #@param [\"自動偵測\", \"中文\", \"英文\"]\n",
        "#@markdown Denoising Method (CPU)\n",
        "denoise_method = \"afftdn (建議)\"  #@param [\"afftdn (建議)\", \"none\"]\n",
        "#@markdown Text Normalization: OpenCC Conversion (applied to output SRT/TXT)\n",
        "text_postprocess = \"臺灣繁體中文（預設）\"  #@param [\"臺灣繁體中文（預設）\",\"香港繁體中文\",\"大陸簡體中文\",\"關閉\"]\n",
        "#@markdown (Optional) YouTube cookies file (relative to MyDrive; Netscape format, e.g., `cookies/youtube.txt`)\n",
        "youtube_cookies_txt_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Summarization (GPU)\n",
        "#@markdown (Optional) Specify the SRT file path for summarization (relative to MyDrive or absolute); Leave empty to use the output from the transcription step.\n",
        "summary_srt_path = \"\"  #@param {type:\"string\"}\n",
        "#@markdown (Optional) Topic hint for summarization\n",
        "topic_hint = \"\"  #@param {type:\"string\"}\n",
        "#@markdown Output directory for the summary Markdown file (relative to MyDrive or absolute)\n",
        "summary_output_dir = \"/content/gdrive/MyDrive/whisper\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "language_code_map = {\"自動偵測\": None, \"中文\":\"zh\", \"英文\":\"en\"}\n",
        "language_code = language_code_map[language]\n",
        "\n",
        "# Developer Options (Do not put in Markdown form)\n",
        "# These options allow fine-tuning parameters without affecting normal operation.\n",
        "DEBUG_MODE = False # Set to True for more detailed logging\n",
        "\n",
        "# --- Transcription Parameters ---\n",
        "TRANSCRIPTION_BEAM_SIZE_PRIMARY = 3\n",
        "TRANSCRIPTION_CHUNK_LENGTH_PRIMARY = 20\n",
        "TRANSCRIPTION_BEAM_SIZE_FALLBACK = 1 # Used if primary fails\n",
        "TRANSCRIPTION_CHUNK_LENGTH_FALLBACK = 15 # Used if primary fails\n",
        "\n",
        "# --- Denoising Parameters ---\n",
        "DENOISE_NOISE_FLOOR_DB = -25\n",
        "\n",
        "# --- Filtering Parameters ---\n",
        "FILTER_MIN_DURATION_SHORT = 1.5 # Minimum duration for short segments\n",
        "FILTER_AVG_LOGPROB_THRESHOLD = -1.0 # Avg log probability threshold for short segments\n",
        "FILTER_MIN_DURATION_SPEECH_PROB = 2.0 # Minimum duration for speech probability filtering\n",
        "FILTER_NO_SPEECH_PROB_THRESHOLD = 0.6 # No speech probability threshold\n",
        "\n",
        "# --- Summary Model Parameters ---\n",
        "REPO_ID   = \"unsloth/gpt-oss-20b-GGUF\"   # GGUF Model Repository\n",
        "GGUF_FILE = \"gpt-oss-20b-Q4_K_M.gguf\"    # Approx. 10.8GiB, T4 can run\n",
        "\n",
        "# --- Summary Inference Parameters (Increase available generation space to avoid truncation) ---\n",
        "ctx_window            = 8192\n",
        "map_max_new_tokens    = 512   # Segment output: original 256 -> 512 (approx. 350-450 chars)\n",
        "reduce_max_new_tokens = 1024  # Summary output: original 512 -> 1024 (approx. 700-900+ chars)\n",
        "temperature           = 0.2\n",
        "top_p                 = 0.9\n",
        "repeat_penalty        = 1.05\n",
        "\n",
        "\n",
        "# [3/8] Install Dependencies\n",
        "# Combine installation steps from both original cells\n",
        "if DEBUG_MODE: print(\"[Install] faster-whisper / yt-dlp / soundfile / opencc / srt / huggingface_hub / llama-cpp-python ...\")\n",
        "\n",
        "def pip_install(pkgs, extra_args=None, env=None):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"]\n",
        "    if extra_args:\n",
        "        cmd += extra_args\n",
        "    cmd += pkgs\n",
        "    return sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True, env=env)\n",
        "\n",
        "# Install common dependencies first\n",
        "common_missing = []\n",
        "try: import srt # check srt module directly after import as _srt\n",
        "except ModuleNotFoundError: common_missing.append(\"srt>=3.5.3\")\n",
        "try: from huggingface_hub import snapshot_download # check huggingface_hub module directly\n",
        "except ModuleNotFoundError: common_missing.append(\"huggingface_hub>=0.23.0\")\n",
        "try: import soundfile # check soundfile\n",
        "except ModuleNotFoundError: common_missing.append(\"soundfile\")\n",
        "try: import opencc # check opencc\n",
        "except ModuleNotFoundError: common_missing.append(\"opencc-python-reimplemented\")\n",
        "\n",
        "if common_missing:\n",
        "    if DEBUG_MODE: print(\"→ Installing common missing packages:\", \", \".join(common_missing))\n",
        "    r = pip_install(common_missing)\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"基礎依賴安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "# Install faster-whisper and yt-dlp separately as they were in the first cell\n",
        "try: from faster_whisper import WhisperModel # check faster_whisper\n",
        "except ModuleNotFoundError:\n",
        "    if DEBUG_MODE: print(\"→ Installing missing package: faster-whisper yt-dlp\")\n",
        "    r = pip_install([\"faster-whisper\", \"yt-dlp\"])\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"faster-whisper / yt-dlp 安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "\n",
        "def suggest_runtime_reset():\n",
        "    print(\"\\n🧹 建議動作（Colab）\")\n",
        "    print(\"1) 依序：『執行階段 Runtime』 → 『刪除執行階段/還原出廠設定 Factory reset runtime』\")\n",
        "    print(\"2) 重新執行本 Notebook（從掛載雲端硬碟那格開始）\\n\", flush=True)\n",
        "\n",
        "def run_cmd(cmd:list, check=True):\n",
        "    if DEBUG_MODE: print(\"  $\", \" \".join(cmd))\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"命令失敗：{' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "def is_youtube_url(s:str)->bool:\n",
        "    return isinstance(s, str) and (\"youtu.be\" in s or \"youtube.com\" in s)\n",
        "def is_http_url(s:str)->bool:\n",
        "    return isinstance(s, str) and s.lower().startswith(\"http\")\n",
        "def to_abs_mydrive(p:str)->Path:\n",
        "    return (Path(p) if p.startswith(\"/\") else (ROOT / p)).resolve()\n",
        "def fmt_ts_srt(t:float)->str:\n",
        "    h = int(t//3600); m = int((t%3600)//60); s = t - h*3600 - m*60\n",
        "    return f\"{h:02d}:{m:02d}:{int(s):02d},{int(round((s-int(s))*1000)):03d}\"\n",
        "def verify_wav_ok(path: Path)->bool:\n",
        "    try:\n",
        "        info = sf.info(str(path))\n",
        "        return info.samplerate > 0 and info.channels in (1, 2)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# OpenCC converter setup\n",
        "def build_opencc_pipeline(choice:str):\n",
        "    if choice.startswith(\"臺灣\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2tw')]\n",
        "    if choice.startswith(\"香港\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2hk')]\n",
        "    if choice.startswith(\"大陸\"):\n",
        "        return [OpenCC('t2s')]\n",
        "    return []  # Disable\n",
        "\n",
        "def apply_opencc(text:str, pipeline)->str:\n",
        "    for cc in pipeline:\n",
        "        text = cc.convert(text)\n",
        "    return text\n",
        "\n",
        "def ytdl(yturl:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting YouTube video ...\")\n",
        "    # Use sp.run instead of subprocess.run directly\n",
        "    p = sp.run([\"yt-dlp\", \"-f\", \"mp4\", \"-o\", str(tmp / \"%(title)s.%(ext)s\"), yturl], stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        if \"Sign in to confirm\" in (p.stdout or \"\"):\n",
        "            print(\"\\n❗YouTube 要求登入/驗證，請提供 cookies 或先自行下載到雲端硬碟。\")\n",
        "        print(\"🔄 若多次失敗，請刪除執行階段並重啟後重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise RuntimeError(\"yt-dlp 下載失敗\")\n",
        "    files = list(tmp.glob(\"*\"))\n",
        "    if not files:\n",
        "        print(\"🔄 下載為空，建議刪除執行階段再重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise FileNotFoundError(\"YouTube 下載失敗：/tmp/dl 為空\")\n",
        "    f = files[0]\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(f, WHISPER_DIR / f.name)\n",
        "    return f\n",
        "\n",
        "def http_dl(url:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting HTTP(S) video ...\")\n",
        "    run_cmd([\"curl\", \"-L\", \"-o\", str(out), url])\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(out, WHISPER_DIR / out.name)\n",
        "    return out\n",
        "\n",
        "# Extract audio: ffmpeg -> 16k/mono WAV\n",
        "def ffmpeg_extract_wav(in_path:Path, out_wav:Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-vn\",\"-ac\",\"1\",\"-ar\",str(sr),\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 轉 WAV 失敗\")\n",
        "\n",
        "# CPU Denoising: ffmpeg afftdn\n",
        "def ffmpeg_afftdn(in_wav: Path, out_wav: Path, noise_floor_db=DENOISE_NOISE_FLOOR_DB):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-af\",f\"afftdn=nf={noise_floor_db}\",\n",
        "           \"-ac\",\"1\",\"-ar\",\"16000\",\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg afftdn 失敗\")\n",
        "\n",
        "# Safeguard: Repack WAV header if format is strange\n",
        "def ffmpeg_repack_wav(in_wav: Path, out_wav: Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-acodec\",\"pcm_s16le\",\"-ac\",\"1\",\"-ar\",str(sr),str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 重包 WAV 失敗\")\n",
        "\n",
        "# [4/8] Parse Source (Transcription)\n",
        "if DEBUG_MODE: print(\"[4/8] Parsing input source ...\")\n",
        "try:\n",
        "    if is_youtube_url(filename):\n",
        "        src_path = ytdl(filename); out_base_dir = WHISPER_DIR\n",
        "    elif is_http_url(filename):\n",
        "        src_path = http_dl(filename); out_base_dir = WHISPER_DIR\n",
        "    else:\n",
        "        src_path = to_abs_mydrive(filename)\n",
        "        if not src_path.exists(): raise FileNotFoundError(f\"找不到檔案：{src_path}\")\n",
        "        out_base_dir = src_path.parent\n",
        "except Exception as e:\n",
        "    print(f\"\\n⛔ 來源解析/下載失敗：{e}\")\n",
        "    print(\"🔄 請刪除執行階段並重新啟動後重跑。\"); suggest_runtime_reset(); raise\n",
        "\n",
        "print(f\"→ 來源檔：{src_path}\")\n",
        "print(f\"→ 輸出資料夾：{out_base_dir}\")\n",
        "\n",
        "# [5/8] Extract Audio & CPU Denoising (Transcription)\n",
        "AUDIO_16K = Path(\"/tmp/audio_16k.wav\")\n",
        "if DEBUG_MODE: print(\"[5/8] Extracting audio (ffmpeg → 16k/mono WAV) ...\")\n",
        "ffmpeg_extract_wav(src_path, AUDIO_16K, sr=16000)\n",
        "\n",
        "if denoise_method.startswith(\"afftdn\"):\n",
        "    if DEBUG_MODE: print(\"[5.5/8] Denoising (ffmpeg afftdn, CPU) ...\")\n",
        "    DENOISED = Path(\"/tmp/audio_16k_denoised.wav\")\n",
        "    ffmpeg_afftdn(AUDIO_16K, DENOISED, noise_floor_db=DENOISE_NOISE_FLOOR_DB)\n",
        "    denoised_audio = DENOISED if verify_wav_ok(DENOISED) else AUDIO_16K\n",
        "else:\n",
        "    denoised_audio = AUDIO_16K\n",
        "\n",
        "if not verify_wav_ok(denoised_audio):\n",
        "    if DEBUG_MODE: print(\"  - 音訊格式異常；嘗試重包 WAV ...\")\n",
        "    FIXED = Path(\"/tmp/audio_16k_fixed.wav\")\n",
        "    ffmpeg_repack_wav(denoised_audio, FIXED, sr=16000)\n",
        "    denoised_audio = FIXED\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ 最終輸入音訊：{denoised_audio}\")\n",
        "\n",
        "# [6/8] Load faster-whisper (GPU enforced)\n",
        "if DEBUG_MODE: print(\"[6/8] Loading faster-whisper model (GPU) ...\")\n",
        "device = \"cuda\"  # Enforce GPU\n",
        "model = None; last_err = None\n",
        "for ctype in [\"int8_float16\", \"float16\", \"int8\"]:\n",
        "    try:\n",
        "        if DEBUG_MODE: print(f\"  - Trying compute_type={ctype}\")\n",
        "        model = WhisperModel(model_size, device=device, compute_type=ctype)\n",
        "        if DEBUG_MODE: print(\"  - Model loaded successfully\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        last_err = e\n",
        "        if DEBUG_MODE: print(f\"  - Load failed: {e}\")\n",
        "if model is None:\n",
        "    print(\"\\n⛔ GPU 模型載入失敗。請確認『變更執行階段類型』選了 GPU（T4/A100），或刪除執行階段後重試。\")\n",
        "    suggest_runtime_reset()\n",
        "    raise RuntimeError(f\"無法載入模型：{last_err}\")\n",
        "\n",
        "gc.collect()  # Clean up before transcription (safety)\n",
        "\n",
        "# [7/8] Transcribe (GPU; real-time progress per segment)\n",
        "if DEBUG_MODE: print(f\"[7/8] Starting transcription (GPU: beam={TRANSCRIPTION_BEAM_SIZE_PRIMARY} / chunk={TRANSCRIPTION_CHUNK_LENGTH_PRIMARY}s / no VAD) ...\")\n",
        "\n",
        "def transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY):\n",
        "    return model.transcribe(\n",
        "        str(denoised_audio),\n",
        "        task=\"transcribe\",\n",
        "        language=language_code,\n",
        "        temperature=0.0,\n",
        "        condition_on_previous_text=False,\n",
        "        compression_ratio_threshold=2.4,\n",
        "        log_prob_threshold=-1.0,\n",
        "        no_speech_threshold=0.6,\n",
        "        beam_size=_beam,\n",
        "        chunk_length=_chunk,\n",
        "        vad_filter=False,\n",
        "        word_timestamps=False\n",
        "    )\n",
        "\n",
        "try:\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY)\n",
        "except Exception as e:\n",
        "    if DEBUG_MODE: print(f\"  - First transcription failed: {e}\\n    → Trying more conservative (beam={TRANSCRIPTION_BEAM_SIZE_FALLBACK}, chunk={TRANSCRIPTION_CHUNK_LENGTH_FALLBACK}) ...\")\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_FALLBACK, _chunk=TRANSCRIPTION_CHUNK_LENGTH_FALLBACK)\n",
        "\n",
        "# Display percentage based on total video duration\n",
        "duration = float(getattr(info, \"duration\", 0.0) or 0.0)\n",
        "if duration <= 0: duration = 1.0\n",
        "\n",
        "segments = []\n",
        "filtered = []\n",
        "\n",
        "if DEBUG_MODE:\n",
        "    print(f\"  - Detected language: {getattr(info,'language','未知')} (p={getattr(info,'language_probability',0):.2f})\")\n",
        "    print(f\"  - Audio length: {duration:.2f}s\")\n",
        "\n",
        "for s in seg_iter:\n",
        "    pct = int(min(100, round((s.end / duration) * 100)))\n",
        "    print(f\"[{pct:3d}%] {fmt_ts_srt(s.start)} → {fmt_ts_srt(s.end)}  {s.text.strip()}\", flush=True)\n",
        "    segments.append(s)\n",
        "\n",
        "    # Low confidence/high no-speech short segment filtering (no blacklist)\n",
        "    keep = True\n",
        "    seg_dur = float(s.end - s.start)\n",
        "    if seg_dur < FILTER_MIN_DURATION_SHORT and getattr(s, \"avg_logprob\", None) is not None and s.avg_logprob < FILTER_AVG_LOGPROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if seg_dur < FILTER_MIN_DURATION_SPEECH_PROB and getattr(s, \"no_speech_prob\", None) is not None and s.no_speech_prob > FILTER_NO_SPEECH_PROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if keep:\n",
        "        filtered.append(s)\n",
        "\n",
        "if DEBUG_MODE: print(f\"  - Number of segments: Before filtering {len(segments)} → After filtering {len(filtered)}\")\n",
        "\n",
        "# ---- OpenCC Normalization (for output text) ----\n",
        "pipeline = build_opencc_pipeline(text_postprocess)\n",
        "def norm(txt: str) -> str:\n",
        "    return apply_opencc(txt, pipeline) if pipeline else txt\n",
        "\n",
        "# [8/8] Output (text after OpenCC)\n",
        "print(\"[8/8] 輸出 SRT / TXT ...\")\n",
        "out_dir = out_base_dir; out_dir.mkdir(exist_ok=True, parents=True)\n",
        "stem = src_path.stem\n",
        "SRT = out_dir / f\"{stem}.srt\"; TXT = out_dir / f\"{stem}.txt\"\n",
        "\n",
        "with open(SRT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, s in enumerate(filtered, 1):\n",
        "        text_out = norm(s.text.strip())\n",
        "        f.write(f\"{i}\\n{fmt_ts_srt(s.start)} --> {fmt_ts_srt(s.end)}\\n{text_out}\\n\\n\")\n",
        "\n",
        "with open(TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in filtered:\n",
        "        f.write(norm(s.text.strip()) + \"\\n\")  # Each segment on a new line\n",
        "\n",
        "print(f\"→ 完成！\\n  SRT: {SRT}\\n  TXT: {TXT}\")\n",
        "\n",
        "# Release model (release GPU memory)\n",
        "try: del model\n",
        "except: pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"→ Model released; can run again directly if needed.\")\n",
        "\n",
        "\n",
        "# ===== Summarization Logic Starts Here =====\n",
        "\n",
        "# If srt_path is empty, use the output from the transcription step\n",
        "if not summary_srt_path:\n",
        "    summary_srt_path_abs = SRT # Use the SRT path generated by the transcription\n",
        "    if DEBUG_MODE: print(f\"Using SRT from transcription step: {summary_srt_path_abs}\")\n",
        "else:\n",
        "    summary_srt_path_abs = to_abs_mydrive(summary_srt_path)\n",
        "\n",
        "\n",
        "# ===== 1) Check GPU and Install Dependencies (llama-cpp-python specific) =====\n",
        "# llama-cpp-python installation logic - Keep this separate as it has specific CUDA requirements\n",
        "if DEBUG_MODE: print(\"[Summary 1/6] Checking GPU and installing llama-cpp-python ...\")\n",
        "\n",
        "def detect_cuda_tag():\n",
        "    try:\n",
        "        out = sp.check_output([\"nvidia-smi\"], text=True)\n",
        "        m = re.search(r\"CUDA Version:\\s*([\\d.]+)\", out)\n",
        "        if not m:\n",
        "            return \"cu124\"\n",
        "        major, minor = [int(x) for x in m.group(1).split(\".\")[:2]]\n",
        "        if major > 12 or (major == 12 and minor >= 5):\n",
        "            return \"cu125\"\n",
        "        return \"cu124\"\n",
        "    except Exception:\n",
        "        return \"cu124\"\n",
        "\n",
        "cuda_tag = detect_cuda_tag()\n",
        "if DEBUG_MODE: print(f\"GPU 0: Detected CUDA version tag {cuda_tag}\")\n",
        "\n",
        "def try_import_llama():\n",
        "    try:\n",
        "        from llama_cpp import Llama\n",
        "        return Llama\n",
        "    except ModuleNotFoundError:\n",
        "        return None\n",
        "\n",
        "Llama = try_import_llama()\n",
        "if Llama is None:\n",
        "    # Keep your existing installation strategy: extra-index -> fallback to source compilation on failure\n",
        "    candidates = [cuda_tag, \"cu125\", \"cu124\", \"cu122\", \"cu121\"]\n",
        "    ok = False\n",
        "    for tag in candidates:\n",
        "        idx = f\"https://abetlen.github.io/llama-cpp-python/whl/{tag}\"\n",
        "        if DEBUG_MODE: print(f\"→ Attempting to install llama-cpp-python ({tag}) ...\")\n",
        "        r = pip_install([\"llama-cpp-python\"], extra_args=[\"--extra-index-url\", idx])\n",
        "        if r.returncode == 0:\n",
        "            Llama = try_import_llama()\n",
        "            if Llama is not None:\n",
        "                ok = True\n",
        "                break\n",
        "        else:\n",
        "            if DEBUG_MODE: print(\"  ✗ Installation failed (summary):\", \"\\n\".join(r.stdout.splitlines()[-5:]))\n",
        "    if not ok:\n",
        "        if DEBUG_MODE: print(\"→ Pre-compiled wheels not available, switching to 'source compilation (CUDA=ON)' ... (takes longer)\")\n",
        "        try:\n",
        "            import ninja  # noqa: F401 # Import ninja to check if installed\n",
        "        except ModuleNotFoundError:\n",
        "            if DEBUG_MODE: print(\"→ Installing missing package: ninja\")\n",
        "            r = pip_install([\"ninja\"])\n",
        "            if r.returncode != 0:\n",
        "                if DEBUG_MODE: print(r.stdout)\n",
        "                raise RuntimeError(\"安裝 ninja 失敗。請重啟後重試。\")\n",
        "        env = os.environ.copy()\n",
        "        env[\"CMAKE_ARGS\"] = \"-DGGML_CUDA=on -DLLAMA_CUBLAS=on\"\n",
        "        env[\"FORCE_CMAKE\"] = \"1\"\n",
        "        r = pip_install([\"llama-cpp-python\"], env=env)\n",
        "        if r.returncode != 0:\n",
        "            if DEBUG_MODE: print(r.stdout)\n",
        "            raise RuntimeError(\"無法安裝 GPU 版 llama-cpp-python。\")\n",
        "        Llama = try_import_llama()\n",
        "\n",
        "# ===== 2) Read SRT (Summary) =====\n",
        "if DEBUG_MODE: print(\"[Summary 2/6] Reading SRT ...\")\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "with open(summary_srt_path_abs, \"r\", encoding=\"utf-8\") as f:\n",
        "    srt_text = f.read()\n",
        "subs = list(_srt.parse(srt_text)) # Use _srt as srt module was imported as _srt\n",
        "def td2s(td): return td.total_seconds()\n",
        "segments = []\n",
        "for it in subs:\n",
        "    txt = it.content.strip()\n",
        "    if not txt: continue\n",
        "    segments.append((td2s(it.start), td2s(it.end), txt))\n",
        "total_secs = (segments[-1][1] - segments[0][0]) if segments else 0\n",
        "if DEBUG_MODE: print(f\"→ Number of subtitle segments: {len(segments)}；Video length (est): {total_secs/60:.1f} minutes\")\n",
        "\n",
        "\n",
        "# ===== 3) Download and Load GGUF Model (Summary) =====\n",
        "if DEBUG_MODE: print(\"[Summary 3/6] Loading GPT-OSS-20B (GGUF, CUDA) ...\")\n",
        "local_repo = snapshot_download(REPO_ID, allow_patterns=[GGUF_FILE])\n",
        "gguf_path = str(Path(local_repo)/GGUF_FILE)\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=gguf_path,\n",
        "    n_ctx=ctx_window,\n",
        "    n_gpu_layers=-1,\n",
        "    seed=0,\n",
        "    logits_all=False,\n",
        "    verbose=True,          # Display the actual chat format used\n",
        "    chat_format=\"chatml\",  # Directly override the GGUF built-in Unsloth template to avoid outputting <|channel|> tags\n",
        ")\n",
        "if DEBUG_MODE: print(\"→ Model loaded successfully (GPU)\")\n",
        "\n",
        "# ===== 4) Token-aware Segmentation (Summary) =====\n",
        "if DEBUG_MODE: print(\"[Summary 4/6] Generating segments (token-aware; single segment ≤ safety limit) ...\")\n",
        "\n",
        "def count_tokens_text(text: str) -> int:\n",
        "    return len(llm.tokenize(text.encode(\"utf-8\")))\n",
        "\n",
        "SYSTEM_INSTR = (\n",
        "  \"你是一個會議總結機器人。根據使用者提供的逐字稿（可能雜訊、重複、錯字），\"\n",
        "  \"請去除雜訊與重複、嚴守事實、不腦補。遇到不明確資訊以「待補充／未明確」標註。\"\n",
        "  \"輸出為 Markdown（繁體中文），不要輸出任何系統／思考標記。\"\n",
        ")\n",
        "\n",
        "# — Segment Summary Prompt: More concise request, avoid verbosity and system language\n",
        "MAP_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是逐字稿片段（非完整全文）：\n",
        "{chunk}\n",
        "\n",
        "請就此片段輸出「條列式重點摘要」（500–900 字，繁體中文），注意：\n",
        "- 只寫最終內容，不要寫解題想法、不要出現任何系統提示或中英括號標記。\n",
        "- 聚焦可驗證事實（時間、人物、任務、結論、未決事項、行動）。\n",
        "- 結構：可用小標題＋項目符號，語句務必短、準確、無贅詞。\n",
        "\"\"\")\n",
        "\n",
        "# — Summary Prompt: Maintain your three-section output structure\n",
        "REDUCE_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是所有片段的重點摘要彙整（仍可能有重疊）：\n",
        "{maps}\n",
        "\n",
        "請整合為一份會議筆記（Markdown，繁體）：\n",
        "1) **整體提要**（3–6 句，避免冗言）\n",
        "2) **章節要點（含時間脈絡）**：條列呈現，每點一行，可附粗略時間\n",
        "3) **可執行重點**：具體待辦（每條以動詞開頭）\n",
        "請只輸出最終筆記，不要出現系統或思考標記，不要加入未出現的新資訊。\n",
        "\"\"\")\n",
        "\n",
        "# Single segment token budget (reserve space for prompt and generation)\n",
        "prompt_overhead = 700\n",
        "chunk_target    = max(1024, min(3072, ctx_window - prompt_overhead - map_max_new_tokens))\n",
        "\n",
        "chunks: List[Tuple[float,float,str]] = []\n",
        "buf, t0, t1, cur = [], None, None, 0\n",
        "for (s, e, txt) in segments:\n",
        "    t = count_tokens_text(txt)\n",
        "    if not buf:\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "        continue\n",
        "    if cur + t <= chunk_target:\n",
        "        buf.append(txt); t1 = e; cur += t\n",
        "    else:\n",
        "        chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "if buf:\n",
        "    chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ Generated {len(chunks)} segments (target ~{chunk_target} tokens per segment)\")\n",
        "\n",
        "# ===== Common: Streaming Tools (No regex cleaning; use correct stop sequence) =====\n",
        "def llm_stream(messages, max_tokens):\n",
        "    # ChatML messages end with <|im_end|>; use stop to cut off, preventing the closing tag from being written to the file\n",
        "    gen = llm.create_chat_completion(\n",
        "        messages=messages,\n",
        "        temperature=float(temperature),\n",
        "        top_p=float(top_p),\n",
        "        repeat_penalty=float(repeat_penalty),\n",
        "        max_tokens=int(max_tokens),\n",
        "        stream=True,\n",
        "        stop=[\"<|im_end|>\"],  # Key: Prevent outputting the ending template\n",
        "    )\n",
        "    for ev in gen:\n",
        "        # Compatible with different fields\n",
        "        piece = \"\"\n",
        "        try:\n",
        "            piece = ev[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "        except Exception:\n",
        "            piece = ev[\"choices\"][0].get(\"text\", \"\")\n",
        "        if piece:\n",
        "            yield piece\n",
        "\n",
        "# ===== 5) Segment Summary (map) =====\n",
        "if DEBUG_MODE: print(\"[Summary 5/6] Segment summarization (map) ...\")\n",
        "live = display(Markdown(\"\"), display_id=True)\n",
        "maps: List[str] = []\n",
        "\n",
        "for i, (s, e, body) in enumerate(chunks, 1):\n",
        "    pct = i / max(len(chunks),1) * 100\n",
        "    sys.stdout.write(f\"  - 處理分段 {i}/{len(chunks)}（~{pct:.1f}%）\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Shrink to safe budget before sending (prevent prompt+segment from exceeding window and causing model to terminate early)\n",
        "    budget_tokens = max(512, ctx_window - map_max_new_tokens - prompt_overhead)\n",
        "    def shrink_to_budget(text: str, budget_tokens: int) -> str:\n",
        "        cur = text\n",
        "        for _ in range(6):\n",
        "            if count_tokens_text(cur) <= budget_tokens:\n",
        "                return cur\n",
        "            keep = max(800, int(len(cur) * 0.85))\n",
        "            cur = cur[:keep]\n",
        "        return cur\n",
        "    body2 = shrink_to_budget(body, budget_tokens)\n",
        "\n",
        "    user_txt = MAP_USER_TMPL.format(topic=(topic_hint or \"（無）\"), chunk=body2)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n",
        "        {\"role\": \"user\",   \"content\": user_txt},\n",
        "    ]\n",
        "\n",
        "    part_buf = [] # Reset part_buf for each segment\n",
        "    # removed shown variable as it's not used in the loop condition or logic\n",
        "    for token in llm_stream(messages, map_max_new_tokens):\n",
        "        part_buf.append(token)\n",
        "        # Update live display and terminal character count periodically\n",
        "        if len(part_buf) % 24 == 0:\n",
        "            cur_txt = \"\".join(part_buf)\n",
        "            live.update(Markdown(cur_txt))\n",
        "            sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "    cur_txt = \"\".join(part_buf)\n",
        "    live.update(Markdown(cur_txt))\n",
        "    sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Include the model's final output directly, no regex cleaning\n",
        "    maps.append(cur_txt.strip())\n",
        "\n",
        "if DEBUG_MODE: print(\"→ Segment summarization complete\")\n",
        "\n",
        "# ===== 6) Consolidate (reduce) & Only write .md (Summary) =====\n",
        "if DEBUG_MODE: print(\"[Summary 6/6] Consolidating summary (reduce) ...\")\n",
        "maps_md = \"\\n\\n---\\n\\n\".join(f\"### 片段 {i+1} 要點\\n\\n{m}\" for i, m in enumerate(maps))\n",
        "\n",
        "# If combined text exceeds window, truncate proportionally first (without changing text within segments to avoid breaking meaning)\n",
        "def fit_reduce_payload(md_text: str, max_ctx_tokens: int) -> str:\n",
        "    for _ in range(8):\n",
        "        need = count_tokens_text(md_text)\n",
        "        if need + reduce_max_new_tokens + 400 <= max_ctx_tokens:\n",
        "            return md_text\n",
        "        md_text = md_text[: int(len(md_text) * 0.9)]\n",
        "    return md_text\n",
        "\n",
        "md_cur = fit_reduce_payload(maps_md, ctx_window)\n",
        "\n",
        "user_txt = REDUCE_USER_TMPL.format(topic=(topic_hint or \"（無）\"), maps=md_cur)\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_INSTR},\n",
        "            {\"role\":\"user\",\"content\":user_txt}]\n",
        "\n",
        "live2 = display(Markdown(\"\"), display_id=True)\n",
        "final_buf = []\n",
        "for token in llm_stream(messages, reduce_max_new_tokens):\n",
        "    final_buf.append(token)\n",
        "    if len(final_buf) % 24 == 0:\n",
        "        live2.update(Markdown(\"\".join(final_buf)))\n",
        "        sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "live2.update(Markdown(\"\".join(final_buf)))\n",
        "sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "\n",
        "final_text = \"\".join(final_buf).strip()\n",
        "\n",
        "out_dir = Path(summary_output_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_md = out_dir / f\"{Path(summary_srt_path_abs).stem}_summary.md\" # Use the stem from the actual SRT file used for summarization\n",
        "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_text)\n",
        "\n",
        "print(f\"→ 完成 ✅  {out_md}\")\n",
        "try:\n",
        "    del llm\n",
        "except Exception:\n",
        "    pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"（顯存已釋放，如需重跑可直接再次執行）\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "→ 當前工作目錄：/content/gdrive/MyDrive\n",
            "→ 來源檔：/content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\n",
            "→ 輸出資料夾：/content/gdrive/MyDrive/whisper\n",
            "[  1%] 00:00:00,000 → 00:00:29,980  Teksting av Nicolai Winther\n",
            "[  1%] 00:00:20,000 → 00:00:49,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:00:40,000 → 00:01:09,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:00,000 → 00:01:29,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:20,000 → 00:01:49,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:01:40,000 → 00:02:09,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:02:00,000 → 00:02:29,980  Teksting av Nicolai Winther\n",
            "[  4%] 00:02:20,000 → 00:02:49,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:00,000 → 00:03:29,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:20,000 → 00:03:49,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:03:40,000 → 00:04:09,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:04:00,000 → 00:04:18,900  聽得到聲音嗎?\n",
            "[  6%] 00:04:20,000 → 00:04:24,000  Ok,ok\n",
            "[  6%] 00:04:24,000 → 00:04:28,000  Ok,那我想先確定\n",
            "[  6%] 00:04:28,000 → 00:04:32,000  威神你那邊在看完教證手冊之後\n",
            "[  6%] 00:04:32,000 → 00:04:36,000  你目前有任何的想法嗎?\n",
            "[  6%] 00:04:36,000 → 00:04:40,000  我覺得因為那時候是說\n",
            "[  6%] 00:04:40,000 → 00:04:45,240  八月底先寫完那個內容的部分嘛\n",
            "[  6%] 00:04:45,240 → 00:04:48,440  但是我覺得看完之後應該要大概\n",
            "[  6%] 00:04:48,440 → 00:04:51,180  我覺得八月底前應該沒辦法寫完\n",
            "[  7%] 00:04:51,180 → 00:04:54,040  那你覺得你什麼時候可以完成得了\n",
            "[  7%] 00:04:54,040 → 00:04:56,480  十月左右嗎\n",
            "[  7%] 00:04:56,480 → 00:04:58,400  你是說單子內容嗎\n",
            "[  7%] 00:05:00,000 → 00:05:06,000  嗯,對。\n",
            "[  7%] 00:05:06,000 → 00:05:09,500  呃,十月底。\n",
            "[  7%] 00:05:09,500 → 00:05:11,580  十月底。\n",
            "[  7%] 00:05:11,580 → 00:05:12,160  好。\n",
            "[  7%] 00:05:12,160 → 00:05:14,780  前,看看吧。\n",
            "[  7%] 00:05:14,780 → 00:05:20,040  因為我也還沒有開始,就是,照他的那個方向去改,所以我...\n",
            "[  7%] 00:05:20,000 → 00:05:23,000  I don't know how long it will take.\n",
            "[  7%] 00:05:23,000 → 00:05:25,000  Ok, ok, I got it.\n",
            "[  7%] 00:05:25,000 → 00:05:27,000  Ok, then I would like to...\n",
            "[  7%] 00:05:27,000 → 00:05:29,000  If you can speak now,\n",
            "[  7%] 00:05:29,000 → 00:05:32,000  you can briefly introduce to Wei-Chen\n",
            "[  7%] 00:05:32,000 → 00:05:35,000  the anti-epidemic prevention method.\n",
            "[  8%] 00:05:40,000 → 00:06:00,000  你要先跟他講一下,就是...\n",
            "[  8%] 00:06:00,000 → 00:06:05,000  我覺得這是一個知識存在的方面嘛 就是框架然後核心特色這樣子\n",
            "[  8%] 00:06:05,000 → 00:06:09,000  好,我發現我只要轉手機跟電腦\n",
            "[  8%] 00:06:09,000 → 00:06:13,000  你們剛剛是問到說就是未成什麼時候可以完成這本書\n",
            "[  8%] 00:06:13,000 → 00:06:18,000  然後是說是十月,十月但是不確定是什麼時候是嗎?\n",
            "[  8%] 00:06:18,000 → 00:06:20,000  Yes\n",
            "[  9%] 00:06:20,000 → 00:06:35,000  我做出這個交戰手冊主要是想說我不知道能不能去陪軍做一些類似跟AI相關的工具\n",
            "[  9%] 00:06:35,000 → 00:06:40,000  因為我的經驗會是如果有了一個標準的準則\n",
            "[  9%] 00:06:40,000 → 00:06:43,600  算是這種抽象的邏輯的話\n",
            "[  9%] 00:06:43,600 → 00:06:48,800  就能夠讓實際在寫獎益的時候\n",
            "[  9%] 00:06:48,800 → 00:06:53,200  可能就可以搭配給AI去自動生成一些類似的東西\n",
            "[  9%] 00:06:53,200 → 00:06:57,600  或是甚至可以去檢驗說這份獎益有沒有包含到\n",
            "[  9%] 00:06:57,600 → 00:07:00,000  這個交戰手冊裡面鎖定\n",
            "[  9%] 00:07:00,000 → 00:07:08,000  我覺得這可能也會讓微塵在寫講義的時候再更快一點。\n",
            "[ 10%] 00:07:08,000 → 00:07:15,000  然後具體來說這裡面的這些校章手冊裡面的所有東西,\n",
            "[ 10%] 00:07:15,000 → 00:07:20,000  玉茜你剛是問我說\n",
            "[ 10%] 00:07:20,000 → 00:07:21,200  我要講什麼\n",
            "[ 10%] 00:07:21,200 → 00:07:24,040  就你可能要稍微跟他說明一下\n",
            "[ 10%] 00:07:24,040 → 00:07:25,240  然後介紹一下\n",
            "[ 10%] 00:07:27,240 → 00:07:28,040  很多耶\n",
            "[ 10%] 00:07:32,500 → 00:07:35,240  維承目前我有幫你按照那個\n",
            "[ 10%] 00:07:35,240 → 00:07:37,400  我覺得的優先順序去排\n",
            "[ 10%] 00:07:37,400 → 00:07:39,600  就是第一個姿勢框架的話\n",
            "[ 10%] 00:07:39,600 → 00:07:40,400  就是我覺得\n",
            "[ 10%] 00:07:40,000 → 00:07:44,000  我覺得這份獎益會最迫切需要的東西\n",
            "[ 10%] 00:07:44,000 → 00:07:47,000  然後所謂的知識框架你可以把它想像成\n",
            "[ 10%] 00:07:47,000 → 00:07:51,000  或寫一個法律系的那個解題的東西\n",
            "[ 11%] 00:07:51,000 → 00:07:55,000  就是我好像記得你有學過民法\n",
            "[ 11%] 00:07:55,000 → 00:07:58,000  還是其他的法律相關的東西\n",
            "[ 11%] 00:07:58,000 → 00:08:00,000  但你也大概可以知道\n",
            "[ 11%] 00:08:00,000 → 00:08:14,980  當你面對一個複雜的案件的時候,你一定要有一套固定的思考方式跟答題方式,你才能夠快速進入到那個理解的框架裡面,然後按照這些步驟去解那個題。\n",
            "[ 11%] 00:08:14,980 → 00:08:20,000  那即便這個步驟可能有一些是形同虛設的,有一些可能在...\n",
            "[ 11%] 00:08:20,000 → 00:08:23,340  在某些題目當中其實根本就是非必要的\n",
            "[ 11%] 00:08:23,340 → 00:08:26,880  可是一旦你有了一個固定的解題框\n",
            "[ 11%] 00:08:26,880 → 00:08:28,000  這樣的思考流程\n",
            "[ 11%] 00:08:28,000 → 00:08:30,440  你在解題的時候就會更有確定感\n",
            "[ 11%] 00:08:30,440 → 00:08:34,580  然後一方面是讓學生能夠感覺自己學到\n",
            "[ 11%] 00:08:34,580 → 00:08:37,660  很具體的感受到自己有學到一套策略\n",
            "[ 12%] 00:08:37,660 → 00:08:40,000  另外一方面也是我們在行銷的\n",
            "[ 12%] 00:08:40,000 → 00:08:46,000  也會更能夠拿這一個策略,這套方法論去推廣出去。\n",
            "[ 12%] 00:08:46,000 → 00:08:54,000  所以我自己是有幫你舉的一個物理上面的例子是先聚焦再發散。\n",
            "[ 12%] 00:08:54,000 → 00:09:00,000  然後我就直接幫你寫了先聚焦再發散這個東西的\n",
            "[ 12%] 00:09:00,000 → 00:09:03,000  This is...wait a minute, the jade line is sliding down\n",
            "[ 12%] 00:09:03,000 → 00:09:06,000  Sliding down, sliding down, sliding down\n",
            "[ 12%] 00:09:06,000 → 00:09:08,000  Hey, this is the correct one\n",
            "[ 12%] 00:09:08,000 → 00:09:11,000  I forgot to delete the top\n",
            "[ 12%] 00:09:11,000 → 00:09:15,000  And then there is a physical demonstration down there\n",
            "[ 12%] 00:09:15,000 → 00:09:20,000  I will want to see that the microcosm may be speaking again\n",
            "[ 13%] 00:09:20,000 → 00:09:28,000  內容的部分先去告訴學生說所謂的先聚焦再發散這個答題策略的核心觀念是什麼\n",
            "[ 13%] 00:09:28,000 → 00:09:34,000  就是什麼是聚焦什麼是發散為什麼聚焦什麼發散然後如何聚焦如何發散\n",
            "[ 13%] 00:09:34,000 → 00:09:40,000  接下來就是透過各種抽象的步驟整理各種抽象的策略\n",
            "[ 13%] 00:09:40,000 → 00:09:46,000  一步一步的去告訴學生說這一個知識框架到底想要傳達的是什麼\n",
            "[ 13%] 00:09:46,000 → 00:09:49,000  然後進到你的題目部分\n",
            "[ 13%] 00:09:49,000 → 00:09:53,000  題目我們等下還會討論說它是要做成就是多少頁數\n",
            "[ 13%] 00:09:53,000 → 00:09:55,000  然後要不要做成電子檔\n",
            "[ 13%] 00:09:55,000 → 00:09:59,000  然後等下育前也會補充說學生對於電子檔的看法這些的\n",
            "[ 14%] 00:10:00,000 → 00:10:12,760  不論如何把題目每一題的解題過程還有每一個詳節都去套用這個不管是三步驟的發賽也好還是先聚焦的發賽\n",
            "[ 14%] 00:10:12,760 → 00:10:19,760  只要固定有一個解題的框架固定的一個算是一個噱頭或是一個包裝\n",
            "[ 14%] 00:10:20,000 → 00:10:22,560  它都可以讓學生更有一個確定感\n",
            "[ 14%] 00:10:22,560 → 00:10:25,760  所以我就會希望這本書最少最少最少最少最少\n",
            "[ 14%] 00:10:25,760 → 00:10:28,000  其他可以慢慢再補上\n",
            "[ 14%] 00:10:28,000 → 00:10:33,000  但是我覺得這個是我會希望可以加進去書\n",
            "[ 14%] 00:10:33,000 → 00:10:34,600  然後再出版會比較好\n",
            "[ 14%] 00:10:34,600 → 00:10:37,000  看我講完了\n",
            "[ 14%] 00:10:40,000 → 00:10:44,000  你目前對這部分有任何的問題嗎?\n",
            "[ 15%] 00:10:49,000 → 00:10:59,000  我要再想就是怎麼具體去把它落實到書的每個章節裡面\n",
            "[ 15%] 00:11:00,000 → 00:11:04,000  OK\n",
            "[ 15%] 00:11:04,000 → 00:11:10,000  我可以問你你自己在打題的時候也會有這樣子的\n",
            "[ 15%] 00:11:10,000 → 00:11:16,000  它會給你一種感覺嗎?就是說物理每個題目好像都有一個感覺\n",
            "[ 15%] 00:11:16,000 → 00:11:20,000  還是你是每個題目有不同的感覺?\n",
            "[ 15%] 00:11:20,000 → 00:11:24,000  好像沒有一個固定的流程\n",
            "[ 15%] 00:11:24,000 → 00:11:31,000  就是覺得可能是\n",
            "[ 15%] 00:11:31,000 → 00:11:33,000  我不會啊\n",
            "[ 15%] 00:11:33,000 → 00:11:35,000  但我覺得他們可能要先\n",
            "[ 15%] 00:11:35,000 → 00:11:37,000  抓到情況再說什麼\n",
            "[ 15%] 00:11:37,000 → 00:11:39,000  但是我就\n",
            "[ 16%] 00:11:40,000 → 00:11:44,000  我覺得我可以抓到,但我覺得他們可能是沒辦法抓到,所以寫不出來。\n",
            "[ 16%] 00:11:46,000 → 00:11:51,000  所以我覺得要先教他們怎麼把題目的點抓出來。\n",
            "[ 16%] 00:11:53,000 → 00:12:00,000  還是我在想會不會你可以跟TradeGVD聊,就你把你看的那些,你可能跟...\n",
            "[ 16%] 00:12:00,000 → 00:12:04,000  跟ChangeGPT聊個十個題目到二十個題目\n",
            "[ 16%] 00:12:04,000 → 00:12:07,000  然後你可能就請他幫你總結一下你這套思路\n",
            "[ 16%] 00:12:07,000 → 00:12:12,000  它背後的核心的步驟\n",
            "[ 16%] 00:12:12,000 → 00:12:15,000  還有你關注的重點\n",
            "[ 16%] 00:12:15,000 → 00:12:18,000  怎麼樣變成一套固定的策略\n",
            "[ 16%] 00:12:18,000 → 00:12:20,000  你可以試試看這個\n",
            "[ 16%] 00:12:20,000 → 00:12:20,500  Ok\n",
            "[ 17%] 00:12:40,000 → 00:12:43,000  你這本書最主要的核心的點是什麼東西 你這本書最主要的核心的點是什麼東西\n",
            "[ 17%] 00:12:47,000 → 00:12:52,000  如果以英文英文的書去舉例的話 就會像是作文書的話\n",
            "[ 17%] 00:12:52,000 → 00:12:58,000  雖然說它有很多很多的內容 但是我們會推出一個最主要的基點 就是它的八條公式\n",
            "[ 17%] 00:12:58,000 → 00:13:00,000  然後這個八條公式也是我們\n",
            "[ 17%] 00:13:00,000 → 00:13:04,500  主要不管是拿在書籍的生存或在社群的行銷上\n",
            "[ 17%] 00:13:04,500 → 00:13:06,700  我們都會拿著八條公式去主打\n",
            "[ 18%] 00:13:06,700 → 00:13:10,580  所以它對於學生的記憶或是這本書的整體\n",
            "[ 18%] 00:13:10,580 → 00:13:14,060  它就會有一個固定的記憶格式\n",
            "[ 18%] 00:13:14,060 → 00:13:16,040  就是大家對於這本書就會是\n",
            "[ 18%] 00:13:16,040 → 00:13:18,900  這個就是那個八條公式就是那個很屌\n",
            "[ 18%] 00:13:18,900 → 00:13:19,980  然後一模獨創的那個\n",
            "[ 18%] 00:13:20,000 → 00:13:24,640  所以也會需要你在幫我寫這本書的時候\n",
            "[ 18%] 00:13:24,640 → 00:13:27,700  也去稍微想一下你這本書的核心特色\n",
            "[ 18%] 00:13:27,700 → 00:13:29,160  最主要的那個點會是什麼\n",
            "[ 18%] 00:13:29,160 → 00:13:30,840  然後是什麼東西是可以對\n",
            "[ 18%] 00:13:30,840 → 00:13:33,760  拿出去打給社群媒體的\n",
            "[ 18%] 00:13:33,760 → 00:13:35,900  這部分有問題嗎\n",
            "[ 18%] 00:13:35,900 → 00:13:37,900  OK\n",
            "[ 18%] 00:13:37,900 → 00:13:39,220  好\n",
            "[ 18%] 00:13:40,000 → 00:13:44,960  好 子明請說\n",
            "[ 18%] 00:13:44,960 → 00:13:48,960  好 我剛剛的那個核心特色\n",
            "[ 18%] 00:13:48,960 → 00:13:53,020  如果我以前在寫物理的內容跟題目的時候\n",
            "[ 18%] 00:13:53,020 → 00:13:54,920  想不到這個特色的話\n",
            "[ 19%] 00:13:54,920 → 00:13:57,340  其實也可以就是照個路\n",
            "[ 19%] 00:13:57,340 → 00:13:59,980  把它變成說是在讀物\n",
            "[ 19%] 00:14:00,000 → 00:14:03,000  你覺得物理這個科目上面的策略\n",
            "[ 19%] 00:14:03,000 → 00:14:05,000  可能就可以想一個什麼循環圖啊\n",
            "[ 19%] 00:14:05,000 → 00:14:09,000  還是什麼正面加強的理論啊什麼的\n",
            "[ 19%] 00:14:09,000 → 00:14:13,000  但就是不一定要是物理的那些章節\n",
            "[ 19%] 00:14:13,000 → 00:14:16,000  你也可以是講你的讀書方法或筆記方法\n",
            "[ 19%] 00:14:16,000 → 00:14:18,000  它也可以變成是一個核心特色\n",
            "[ 19%] 00:14:20,000 → 00:14:23,000  我再想想。\n",
            "[ 19%] 00:14:25,000 → 00:14:35,000  那我也想順便確認一下,你有預計什麼時候可能會確定這本書的整個核心特色嗎?\n",
            "[ 19%] 00:14:35,000 → 00:14:40,000  會需要等你內容寫完嗎?還是你在這中間的過程中你可以先...\n",
            "[ 20%] 00:14:40,000 → 00:14:41,920  跟我確定\n",
            "[ 20%] 00:14:41,920 → 00:14:47,960  應該可以比內容早確定\n",
            "[ 20%] 00:14:47,960 → 00:14:49,680  但是我現在還沒有\n",
            "[ 20%] 00:14:49,680 → 00:14:52,060  就是想出來它是什麼\n",
            "[ 20%] 00:14:52,060 → 00:14:54,940  OK好沒有問題\n",
            "[ 20%] 00:14:54,940 → 00:14:58,180  然後再來下一個的話\n",
            "[ 20%] 00:14:58,180 → 00:14:59,980  會是學習方式跟記憶策略\n",
            "[ 20%] 00:15:00,000 → 00:15:08,000  因為我知道你有先看過整個的內容,所以我想確認你對於這部分有任何問題嗎?\n",
            "[ 20%] 00:15:08,000 → 00:15:17,000  或是有特別想詢問的點嗎?如果沒有的話我們就加快進度,就不用這樣一個一個特別的去講解。\n",
            "[ 21%] 00:15:20,000 → 00:15:27,000  因為就是這邊看起來比較想要說就是要理解\n",
            "[ 21%] 00:15:27,000 → 00:15:35,000  但是我不確定就是他們要理解全盤理解的話會耗費的成本要多少\n",
            "[ 21%] 00:15:35,000 → 00:15:40,000  還是有些人是不是只是想要把它把固定的流程背起來\n",
            "[ 21%] 00:15:40,000 → 00:15:42,800  然後就可以去解題\n",
            "[ 21%] 00:15:42,800 → 00:15:46,200  所以我要著重在\n",
            "[ 21%] 00:15:46,200 → 00:15:48,000  就是不用全盤理解\n",
            "[ 21%] 00:15:48,000 → 00:15:49,200  但是比較好解題\n",
            "[ 21%] 00:15:49,200 → 00:15:51,600  還是希望他們比較好理解\n",
            "[ 21%] 00:15:51,600 → 00:15:56,100  然後就是底子很穩這樣\n",
            "[ 21%] 00:15:56,100 → 00:15:58,400  方向應該在那邊\n",
            "[ 21%] 00:15:58,400 → 00:16:00,000  我覺得會比較看\n",
            "[ 21%] 00:16:00,000 → 00:16:04,200  你這本書的定位點在哪裡?\n",
            "[ 21%] 00:16:04,200 → 00:16:09,800  子民剛說有要講話,我有看到你那個框框。\n",
            "[ 22%] 00:16:09,800 → 00:16:14,000  好像上次跟維城討論的時候你是說,\n",
            "[ 22%] 00:16:14,000 → 00:16:20,000  你希望事實上不知道怎麼開始讀物理的人也可以找到一個方向。\n",
            "[ 22%] 00:16:20,000 → 00:16:25,440  所以你可能打的比較算是中間的族群,是嗎?\n",
            "[ 22%] 00:16:25,440 → 00:16:27,240  算是。\n",
            "[ 22%] 00:16:27,240 → 00:16:28,240  喔。\n",
            "[ 22%] 00:16:34,900 → 00:16:40,000  我會去做這個學習策略的這個地方其實是想說你...\n",
            "[ 22%] 00:16:40,000 → 00:16:48,220  你如果在傳達你的想法跟知識的時候,能夠不要做任何的刪減,\n",
            "[ 23%] 00:16:49,040 → 00:16:58,500  而是你就把最難的東西端出來給學生,可是呢,你還是可以面對初級跟總級的學生,\n",
            "[ 23%] 00:16:58,500 → 00:17:00,500  但是你的...\n",
            "[ 23%] 00:17:00,000 → 00:17:20,120  實施卻是最難的,那這中間的那個gap,中間的那個就是轟溝,你就要透過這些學習方式跟記憶策略的引導,就是如果你的觀念越難,你中間就要解釋越多這樣子的學習策略,然後讓這些重等到初級的學生,\n",
            "[ 23%] 00:17:20,000 → 00:17:22,000  學生也能夠學起來\n",
            "[ 23%] 00:17:22,000 → 00:17:26,000  我當初設計就有這樣的想法\n",
            "[ 23%] 00:17:26,000 → 00:17:36,000  所以我就先把全部東西都最難的部分也寫出來\n",
            "[ 23%] 00:17:36,000 → 00:17:40,000  然後我想往後面再做一個\n",
            "[ 24%] 00:17:40,000 → 00:17:58,260  比較重點的整理,這樣,就是如果你對前面的深入學習沒有興趣的話,那你就直接看重點就好了,這樣應該比較好,就是兩邊都照顧到,也可以,又或者是說你其實也可以,\n",
            "[ 24%] 00:18:00,000 → 00:18:01,840  這點我可能還是會存疑啦\n",
            "[ 24%] 00:18:01,840 → 00:18:03,760  我其實也沒有很確定\n",
            "[ 24%] 00:18:03,760 → 00:18:07,900  就是因為我自己的作文書也是寫到最難\n",
            "[ 24%] 00:18:07,900 → 00:18:10,800  確實也是有學生會覺得太難\n",
            "[ 24%] 00:18:10,800 → 00:18:14,840  但我會傾向是說如果你能夠用這些\n",
            "[ 24%] 00:18:14,840 → 00:18:17,460  就是我有給你一個檔案\n",
            "[ 24%] 00:18:17,460 → 00:18:20,000  就是在這個頁面裡面還有一個連接\n",
            "[ 24%] 00:18:20,000 → 00:18:23,000  我有一個可以出去的檔案叫核心學習策略\n",
            "[ 24%] 00:18:23,000 → 00:18:25,000  你有看過這個嗎?一個\n",
            "[ 25%] 00:18:25,000 → 00:18:28,000  對對對對現在有打開了這個\n",
            "[ 25%] 00:18:28,000 → 00:18:33,000  就是你就可以把一些這裡面的讀書策略跟技巧\n",
            "[ 25%] 00:18:37,000 → 00:18:39,000  這個檔案我還沒看過\n",
            "[ 25%] 00:18:40,000 → 00:18:43,000  你可以先把它看一下。\n",
            "[ 25%] 00:18:43,000 → 00:18:54,000  我自己教學的經驗是讓我發現說這些策略它其實不是只用在英文。\n",
            "[ 25%] 00:18:54,000 → 00:18:59,000  我昨天也是用這個東西去跟學生講數學什麼學。\n",
            "[ 25%] 00:19:00,000 → 00:19:07,000  我想說這東西其實可以一定程度幫助學生理解一些太複雜或太困難的觀念。\n",
            "[ 26%] 00:19:07,000 → 00:19:16,000  然後我就會覺得你跟他解釋越多這些學習策略,他們可能就會越能夠理解你想要傳達的物理專業知識。\n",
            "[ 26%] 00:19:16,000 → 00:19:20,000  所以就是取決於你想要寫多難的東西,然後就加多少。\n",
            "[ 26%] 00:19:20,000 → 00:19:25,000  好,講完嘅。\n",
            "[ 26%] 00:19:25,000 → 00:19:29,000  威神那邊有問題嗎?\n",
            "[ 26%] 00:19:29,000 → 00:19:31,000  暫時沒有。\n",
            "[ 26%] 00:19:31,000 → 00:19:35,000  到時候再麻煩你會後花一些時間幫我看過,\n",
            "[ 26%] 00:19:35,000 → 00:19:39,000  然後如果有不懂的地方可以再隨時跟我們講。\n",
            "[ 26%] 00:19:39,000 → 00:19:40,000  好。\n",
            "[ 26%] 00:19:40,000 → 00:19:45,100  再嚟嘅話就會系梳集咗一個大嘅架構,\n",
            "[ 26%] 00:19:45,100 → 00:19:51,880  佢就跟其實就跟你現在嗰個章節都系很像,\n",
            "[ 26%] 00:19:52,160 → 00:19:55,420  但就系我哋嘅章節架構可能要再清楚明確一點,\n",
            "[ 27%] 00:19:57,760 → 00:19:59,960  然後像呢些可能\n",
            "[ 27%] 00:20:00,000 → 00:20:07,000  你可以先幫我列完,然後如果你需要一些圖示的話,這些我們都可以直接再幫你做。\n",
            "[ 27%] 00:20:11,000 → 00:20:20,000  所以大致上那個架構的話就會是講,就是可能這本書的蓋欄,然後跟這本書的使用說明,然後第一個的大張點。\n",
            "[ 27%] 00:20:20,000 → 00:20:39,000  第二個大章節,然後可能你大章節完之後你會有一個小的,你會先有一個小的總結,然後你的小章節一樣會有一個小的總結,然後才會是這個小章節裡面的氣象,然後最後你還是需要再幫他附一個總結,這樣會是一個比較完整的架構,然後也比較能幫助學生達到一個比較好的學習方式。\n",
            "[ 27%] 00:20:40,000 → 00:20:42,000  所以書籍加關可以參考這邊\n",
            "[ 28%] 00:20:42,000 → 00:20:44,000  好 子明起說\n",
            "[ 28%] 00:20:44,000 → 00:20:46,000  我喔 我又有話要說了\n",
            "[ 28%] 00:20:46,000 → 00:20:48,000  就是你除了\n",
            "[ 28%] 00:20:48,000 → 00:20:50,000  我要說什麼\n",
            "[ 28%] 00:20:50,000 → 00:20:52,000  你的大架構裡面\n",
            "[ 28%] 00:20:52,000 → 00:20:54,000  其實可以多加入一些些\n",
            "[ 28%] 00:20:54,000 → 00:20:56,000  就是比較感性一點的東西\n",
            "[ 28%] 00:20:56,000 → 00:20:58,000  就是你在書籍的可能\n",
            "[ 28%] 00:20:58,000 → 00:21:00,000  在那個章節的開頭\n",
            "[ 28%] 00:21:00,000 → 00:21:03,400  會需要先有一個簡單的總結或是一個概覽\n",
            "[ 28%] 00:21:03,400 → 00:21:05,100  然後讓學生可以進入這個章節\n",
            "[ 28%] 00:21:05,100 → 00:21:07,560  那章節的最後結束也會有一個總結\n",
            "[ 28%] 00:21:07,560 → 00:21:10,480  只是你的那個開始跟那個總結\n",
            "[ 28%] 00:21:10,480 → 00:21:13,220  就是不一定要是很理性\n",
            "[ 28%] 00:21:13,220 → 00:21:18,420  然後很踏實的那種知識上面的整理\n",
            "[ 28%] 00:21:18,420 → 00:21:19,980  你也可以在這邊加一些\n",
            "[ 28%] 00:21:20,000 → 00:21:22,500  讓學生可以心情好一點的東西\n",
            "[ 28%] 00:21:22,500 → 00:21:24,500  譬如說剛開始就是\n",
            "[ 28%] 00:21:24,500 → 00:21:26,500  在章節開始的時候就說\n",
            "[ 29%] 00:21:26,500 → 00:21:29,500  這張適合有哪一些問題的學生\n",
            "[ 29%] 00:21:29,500 → 00:21:31,500  然後就列很多學生常見的問題\n",
            "[ 29%] 00:21:31,500 → 00:21:34,500  那學生可能就會自己跳進去對號入座\n",
            "[ 29%] 00:21:34,500 → 00:21:36,500  就領了一個身份標籤之後\n",
            "[ 29%] 00:21:36,500 → 00:21:38,000  就開始讀這個章節的時候\n",
            "[ 29%] 00:21:38,000 → 00:21:40,000  就會覺得自己的\n",
            "[ 29%] 00:21:40,000 → 00:21:42,000  問題就可以被妥善的解決\n",
            "[ 29%] 00:21:42,000 → 00:21:44,000  然後你到總結的地方再跟他說\n",
            "[ 29%] 00:21:44,000 → 00:21:48,000  恭喜你就是已經解決了這樣子的問題\n",
            "[ 29%] 00:21:48,000 → 00:21:50,000  你一定會越來越好啊什麼的\n",
            "[ 29%] 00:21:50,000 → 00:21:52,000  就可以給一些情緒上面的\n",
            "[ 29%] 00:21:52,000 → 00:21:53,000  給一些情緒價值\n",
            "[ 29%] 00:21:53,000 → 00:21:55,000  學生讀起來會比較\n",
            "[ 29%] 00:21:55,000 → 00:21:57,000  算是堅持得下去吧\n",
            "[ 29%] 00:21:57,000 → 00:22:00,000  如果你會把內容加得深入一點點的話\n",
            "[ 29%] 00:22:00,000 → 00:22:02,000  還有腳外的\n",
            "[ 29%] 00:22:02,000 → 00:22:04,000  咚\n",
            "[ 29%] 00:22:04,000 → 00:22:06,000  好\n",
            "[ 29%] 00:22:06,000 → 00:22:08,000  再來的話就是說幾個小架構\n",
            "[ 29%] 00:22:08,000 → 00:22:10,000  那個小架構就是偏\n",
            "[ 29%] 00:22:10,000 → 00:22:12,000  理論跟案例\n",
            "[ 30%] 00:22:12,000 → 00:22:14,000  這個的話前面其實也有提到\n",
            "[ 30%] 00:22:14,000 → 00:22:16,000  然後這個你可以\n",
            "[ 30%] 00:22:16,000 → 00:22:18,000  如果你沒有很懂的話可以再問我\n",
            "[ 30%] 00:22:18,000 → 00:22:20,000  然後\n",
            "[ 30%] 00:22:20,000 → 00:22:25,000  理論的主要呈現原則就是你要以系統性的東西去取代流水帳\n",
            "[ 30%] 00:22:25,000 → 00:22:30,000  就是系統性就比較像是可能第一步第二步然後原則一原則二原則三\n",
            "[ 30%] 00:22:30,000 → 00:22:34,000  然後或者是你可以用一個表格呈現可以用流程圖可以用矩陣都可以\n",
            "[ 30%] 00:22:34,000 → 00:22:40,000  然後這種方式會比起你只是跟他講說我今天去買了蘋果\n",
            "[ 30%] 00:22:40,000 → 00:22:44,500  如果怎麼樣怎麼樣,這種流水的方式好很多很多很多。\n",
            "[ 30%] 00:22:44,500 → 00:22:46,500  然後再來是案例的呈現原則。\n",
            "[ 30%] 00:22:46,500 → 00:22:50,800  你要盡量讓,就是用故事的方式去讓理論去落地。\n",
            "[ 30%] 00:22:50,800 → 00:22:56,000  就是你可以去多講幾個例子,然後但是你不能只是單純的講例子。\n",
            "[ 31%] 00:22:56,000 → 00:23:00,000  你要去刻意的選擇可以提出這些理論的關鍵點的案例。\n",
            "[ 31%] 00:23:00,000 → 00:23:03,820  然後讓案例的順序跟理論的分點是一致的\n",
            "[ 31%] 00:23:03,820 → 00:23:05,620  就是學生他可以互相對照\n",
            "[ 31%] 00:23:05,620 → 00:23:07,800  他不會覺得我現在看了這個理論\n",
            "[ 31%] 00:23:07,800 → 00:23:09,500  但是我找不到對應的案例\n",
            "[ 31%] 00:23:09,500 → 00:23:10,720  或者是我現在看了這個案例\n",
            "[ 31%] 00:23:10,720 → 00:23:12,820  但我也不知道你在講哪一個理論這樣子\n",
            "[ 31%] 00:23:12,820 → 00:23:15,740  目前這邊是OK的\n",
            "[ 31%] 00:23:15,740 → 00:23:16,920  OK\n",
            "[ 31%] 00:23:16,920 → 00:23:17,980  好\n",
            "[ 31%] 00:23:17,980 → 00:23:20,020  然後因為我們收集的內容\n",
            "[ 31%] 00:23:20,000 → 00:23:22,260  我们会以黑白色为主\n",
            "[ 31%] 00:23:22,260 → 00:23:25,540  所以如果你今天在帮我写里面的内容\n",
            "[ 31%] 00:23:25,540 → 00:23:28,920  然后有些比较想要让他们强调的重点\n",
            "[ 31%] 00:23:28,920 → 00:23:31,640  你可能需要帮我使用色块或是粗体\n",
            "[ 31%] 00:23:31,640 → 00:23:34,860  或是一些其他的框框标记都可以\n",
            "[ 31%] 00:23:34,860 → 00:23:37,840  但是你需要有一个让他们可以很好get到说\n",
            "[ 31%] 00:23:37,840 → 00:23:39,980  这里可能是相对于其他内容性\n",
            "[ 31%] 00:23:40,000 → 00:23:42,000  較為重要的地方\n",
            "[ 32%] 00:23:44,000 → 00:23:45,000  好\n",
            "[ 32%] 00:23:45,000 → 00:23:48,000  然後下面你應該也都有看過\n",
            "[ 32%] 00:23:48,000 → 00:23:50,000  那你有什麼地方有不了解\n",
            "[ 32%] 00:23:50,000 → 00:23:52,000  然後有想問的嗎\n",
            "[ 32%] 00:23:56,000 → 00:23:58,000  看起來沒有\n",
            "[ 32%] 00:23:58,000 → 00:23:59,000  好\n",
            "[ 32%] 00:23:59,000 → 00:24:00,000  線上話\n",
            "[ 32%] 00:24:00,000 → 00:24:01,200  與配套工具\n",
            "[ 32%] 00:24:01,200 → 00:24:05,040  啊沒事\n",
            "[ 32%] 00:24:05,040 → 00:24:05,720  在下面\n",
            "[ 32%] 00:24:05,720 → 00:24:08,000  對不起我插嘴了\n",
            "[ 32%] 00:24:08,000 → 00:24:08,420  對不起\n",
            "[ 32%] 00:24:08,420 → 00:24:10,940  好然後順便跟維成提\n",
            "[ 32%] 00:24:10,940 → 00:24:13,260  就是因為我知道你有做那個\n",
            "[ 32%] 00:24:13,260 → 00:24:14,180  就是\n",
            "[ 32%] 00:24:14,180 → 00:24:16,440  立貼題目\n",
            "[ 32%] 00:24:16,440 → 00:24:16,840  然後\n",
            "[ 32%] 00:24:16,840 → 00:24:18,660  就是他如果\n",
            "[ 32%] 00:24:18,660 → 00:24:20,000  如果你今天還是要把他寫在\n",
            "[ 32%] 00:24:20,000 → 00:24:27,180  你在書裡面或是你今天在書本裡面有提到,然後你不知道怎麼拍板的話,就是知名右相有一個是比較好的方式。\n",
            "[ 33%] 00:24:27,180 → 00:24:40,000  如果你今天想要讓學生,他是可以先看完題目,然後先有一個答案,然後再繼續看詳解的話,你可以變成說第一頁他有三題的題目,然後你翻頁之後是那三題的講解。\n",
            "[ 33%] 00:24:40,000 → 00:25:00,000  然後就稍微對一下拍板,才不會讓他們馬上就可以找到答案,然後也沒有,就如果直接讓他們看到答案,他們就會不去思考,所以你可以先讓他們思考完之後,然後再去翻譯了,去對照那個答案,然後去看你的想解步都是什麼,然後這樣子,一方面是它有一個比較好的拍板格式,另外一方面是可以主動去引導他們去思考。\n",
            "[ 33%] 00:25:00,000 → 00:25:02,940  而不是直接仰賴你的解答\n",
            "[ 33%] 00:25:02,940 → 00:25:04,940  OK\n",
            "[ 33%] 00:25:04,940 → 00:25:05,500  OK\n",
            "[ 33%] 00:25:05,500 → 00:25:09,540  但是上次不是說那個解答要用呈現上嗎\n",
            "[ 33%] 00:25:09,540 → 00:25:11,680  不然頁數就已經爆了\n",
            "[ 33%] 00:25:11,680 → 00:25:12,540  對\n",
            "[ 34%] 00:25:12,540 → 00:25:15,040  就只是如果你今天有在內容裡面\n",
            "[ 34%] 00:25:15,040 → 00:25:16,620  有稍微稍稍的提到\n",
            "[ 34%] 00:25:16,620 → 00:25:19,260  就是你可以有一兩題或是三四題的話\n",
            "[ 34%] 00:25:19,260 → 00:25:19,960  是可以用這樣的\n",
            "[ 34%] 00:25:20,000 → 00:25:39,940  然後關於題目答案線上話這個點,我們需要,好我先跟你抓出來討論這個點好了,因為我們有收到學生的回饋是說他們的父母其實沒有很希望讓他們嘗試這樣用平板手機或是電腦,所以關於\n",
            "[ 35%] 00:25:40,000 → 00:25:59,960  解答線上話這一點,我們可能需要再思考一下,因為不是所有的學生都可以達到很好的學習效果,也不是所有的學生都可以這樣做自由,所以我們需要想一個解決方法,讓他們不是只能完全的仰賴這個AI工具,而是AI工具會變成是輔助他們的學習效果,而不是讓他們去\n",
            "[ 35%] 00:26:00,000 → 00:26:02,000  從AI工具中\n",
            "[ 35%] 00:26:02,000 → 00:26:04,000  就他們不能只是用AI工具找到答案\n",
            "[ 35%] 00:26:04,000 → 00:26:06,000  他們應該要從其他地方也可以找到答案\n",
            "[ 35%] 00:26:06,000 → 00:26:08,000  AI工具只是一個輔助\n",
            "[ 35%] 00:26:08,000 → 00:26:10,000  所以我們可能要先解決這個\n",
            "[ 35%] 00:26:10,000 → 00:26:12,000  點\n",
            "[ 35%] 00:26:16,000 → 00:26:18,000  然後我自己有稍微想了一下\n",
            "[ 35%] 00:26:18,000 → 00:26:20,000  如果說你今天是\n",
            "[ 35%] 00:26:20,000 → 00:26:40,000  因為如果有太多業績的話,其實它是可以用一個比較簡略版的複測,就是它反正只是西馬丁,然後完完全全就是黑白印刷,那他們的題目跟解析是可以分開來的,然後當然對於印刷成本也不會跟原本一樣那麼高,然後學生也不會說如果我今天不能用手機,要不能用手機,\n",
            "[ 35%] 00:26:40,000 → 00:26:42,700  我就完全沒有辦法找到這題的答案\n",
            "[ 36%] 00:26:42,700 → 00:26:45,780  或是我也沒辦法找到這題的相接是什麼東西\n",
            "[ 36%] 00:26:45,780 → 00:26:46,640  對\n",
            "[ 36%] 00:26:46,640 → 00:26:50,020  所以想順便問問看你那邊有任何的想法嗎\n",
            "[ 36%] 00:26:50,020 → 00:26:54,780  所以\n",
            "[ 36%] 00:26:54,780 → 00:26:55,780  嗯\n",
            "[ 36%] 00:26:55,780 → 00:26:59,920  就是解答還是要包含在\n",
            "[ 36%] 00:27:00,000 → 00:27:04,000  裡面,就是包含在整份裡面嘛\n",
            "[ 36%] 00:27:04,000 → 00:27:08,900  這樣頁數不是還是一樣,只是超出\n",
            "[ 36%] 00:27:08,900 → 00:27:13,740  就會變成是以主側跟副側的方式去呈現\n",
            "[ 36%] 00:27:13,740 → 00:27:16,580  那副側的話我們的印刷品質就會是比較\n",
            "[ 36%] 00:27:16,580 → 00:27:19,260  沒有到跟主側一樣那麼好的\n",
            "[ 36%] 00:27:19,260 → 00:27:19,960  那它的印刷\n",
            "[ 36%] 00:27:20,000 → 00:27:25,000  雖然說會增加,但是不會像原本高的那麼誇張。\n",
            "[ 37%] 00:27:28,000 → 00:27:30,000  或者是有如果...\n",
            "[ 37%] 00:27:30,000 → 00:27:31,000  請說。\n",
            "[ 37%] 00:27:31,000 → 00:27:35,000  我想題目分享解葉樹很多耶,比較不像作文那樣子。\n",
            "[ 37%] 00:27:35,000 → 00:27:38,000  只有少少的就是葉。\n",
            "[ 37%] 00:27:40,000 → 00:27:53,000  因為它如果現在是要寫成題目一頁相接一頁,或是一頁三個題目,然後相接三頁的話,那個頁數應該都會比作文還要多很多。\n",
            "[ 37%] 00:28:00,000 → 00:28:05,360  但我哋冇辦法完全就把佢現場化\n",
            "[ 37%] 00:28:05,360 → 00:28:11,900  因為學生也確實冇辦法讓佢哋有個好的學習方式\n",
            "[ 38%] 00:28:11,900 → 00:28:17,060  那我哋現在壓業數是因為硬抓成本跟定價嗎?\n",
            "[ 38%] 00:28:17,060 → 00:28:20,000  就是說我哋定價如果就是要定在\n",
            "[ 38%] 00:28:20,000 → 00:28:26,000  500塊以內,業數就是不可以到300,350到400\n",
            "[ 38%] 00:28:26,000 → 00:28:27,000  對\n",
            "[ 38%] 00:28:31,000 → 00:28:34,000  你如果今天要到,就是真的業數要到三四百\n",
            "[ 38%] 00:28:34,000 → 00:28:38,000  其實是,就是沒有什麼關係啦\n",
            "[ 38%] 00:28:38,000 → 00:28:40,000  但是一方面\n",
            "[ 38%] 00:28:40,000 → 00:28:45,020  因為成本很高,所以我們分下來的利潤可能覺得是不多的。\n",
            "[ 38%] 00:28:45,020 → 00:28:58,020  第二方面是,如果我們今天是推一個他可以很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:28:58,020 → 00:29:09,980  然後這就會延伸到,如果我們今天是推一個很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:29:00,000 → 00:29:20,000  如果我們今天把排板放大,如果以A4尺寸去製作的話,A4它很吃排板功力,所以如果說你今天有任何一個排板點沒有排板好,或者是你的圖示效果不是那麼好的話,其實對於學生的學習狀況也不是到很良好。\n",
            "[ 39%] 00:29:20,000 → 00:29:22,000  如果你今天是一頁密密麻麻的文字\n",
            "[ 39%] 00:29:22,000 → 00:29:24,000  他們可能看到一半也不會想看\n",
            "[ 39%] 00:29:24,000 → 00:29:26,000  所以對於他們學習長相之後\n",
            "[ 39%] 00:29:26,000 → 00:29:28,000  不是那麼的佳\n",
            "[ 39%] 00:29:28,000 → 00:29:31,000  所以這個點我們可能要稍微想一下\n",
            "[ 39%] 00:29:31,000 → 00:29:33,000  我們去解決\n",
            "[ 39%] 00:29:35,000 → 00:29:40,000  以前如果你說學生有些會不想要用電子廠\n",
            "[ 40%] 00:29:40,000 → 00:29:46,000  那就代表之前說想借跟題目要做成線上資料庫\n",
            "[ 40%] 00:29:46,000 → 00:29:48,000  這個就等於是不可行的\n",
            "[ 40%] 00:29:48,000 → 00:29:51,000  對,會變成說如果真的要做的話\n",
            "[ 40%] 00:29:51,000 → 00:29:55,000  它更像是一個我給你一個更好的輔助工具\n",
            "[ 40%] 00:29:55,000 → 00:29:56,000  然後你如果今天想要\n",
            "[ 40%] 00:29:56,000 → 00:29:58,000  就你如果今天書籍沒有帶在身上的話\n",
            "[ 40%] 00:29:58,000 → 00:30:00,000  你也可以有一個\n",
            "[ 40%] 00:30:00,000 → 00:30:02,000  可以學習的地方\n",
            "[ 40%] 00:30:02,000 → 00:30:04,000  但現在問題點就是\n",
            "[ 40%] 00:30:04,000 → 00:30:06,000  很多家長他不願意讓學生\n",
            "[ 40%] 00:30:06,000 → 00:30:08,000  這樣去做\n",
            "[ 40%] 00:30:08,000 → 00:30:10,000  那如果\n",
            "[ 40%] 00:30:10,000 → 00:30:12,000  我們今天變成是\n",
            "[ 40%] 00:30:12,000 → 00:30:14,000  把題目跟\n",
            "[ 40%] 00:30:14,000 → 00:30:16,000  相借獨立成一本\n",
            "[ 40%] 00:30:16,000 → 00:30:18,000  複冊 然後\n",
            "[ 40%] 00:30:18,000 → 00:30:20,000  這本複冊的話\n",
            "[ 41%] 00:30:20,000 → 00:30:39,000  如果是買這本物理書,我們就會只給電子檔的複測,就是複測是用電子檔去給,然後他們可以自己印,又或是我們可以,他可以再加購,然後我們再把它印。\n",
            "[ 41%] 00:30:40,000 → 00:30:44,200  我覺得可能會以他們架構然後我們幫他印的方式\n",
            "[ 41%] 00:30:44,200 → 00:30:48,700  然後主要的話就是會印出的地方出去\n",
            "[ 41%] 00:30:48,700 → 00:30:53,000  不然我們成本一方面會拉高\n",
            "[ 41%] 00:30:53,000 → 00:30:57,900  另外一方面是他們好像不太擅長自己去印書\n",
            "[ 42%] 00:31:00,000 → 00:31:17,000  Ok,所以會需要麻煩維城,他可能還是要幫我把題目跟相機的都一樣有,就是可以有資本化的方式,就是你需要幫我拆開來寫,因為我們到時候會是以兩本書的形式推出去。\n",
            "[ 42%] 00:31:20,000 → 00:31:22,000  好,我可以提一個點嗎?\n",
            "[ 42%] 00:31:22,000 → 00:31:23,000  嗯。\n",
            "[ 42%] 00:31:23,000 → 00:31:36,000  就是微塵你可能現階段在做題目跟詳解的時候,你可能不要直接把它寫到 Word 檔,就是不要直接寫到你最後要出版的那個書上面。\n",
            "[ 42%] 00:31:36,000 → 00:31:40,000  而是你先用一個第三方的\n",
            "[ 42%] 00:31:40,000 → 00:31:43,000  另外一個的編輯的平台\n",
            "[ 42%] 00:31:43,000 → 00:31:47,000  你可能就先做在Notion上面\n",
            "[ 42%] 00:31:47,000 → 00:31:51,000  然後你把這些題目跟小節都做在Notion上面的時候\n",
            "[ 42%] 00:31:51,000 → 00:31:56,000  你一方面就是確保了我們剛剛講到的一個點是說\n",
            "[ 43%] 00:31:56,000 → 00:32:00,000  我們實體的東西要讓學生光看實體就看得懂\n",
            "[ 43%] 00:32:00,000 → 00:32:03,240  但是我們還是可以提供線上的輔助\n",
            "[ 43%] 00:32:03,240 → 00:32:06,340  這樣如果他們可能沒有帶到輔助\n",
            "[ 43%] 00:32:06,340 → 00:32:08,240  或是出了哪些狀況\n",
            "[ 43%] 00:32:08,240 → 00:32:10,340  或是他們想要用電子的方式去學\n",
            "[ 43%] 00:32:10,340 → 00:32:12,540  他們還是可以用電子的方式去做\n",
            "[ 43%] 00:32:12,540 → 00:32:14,840  所以就會變成說\n",
            "[ 43%] 00:32:14,840 → 00:32:17,000  利益\n",
            "[ 43%] 00:32:17,000 → 00:32:20,000  玉千你可不可以幫我開那個\n",
            "[ 43%] 00:32:20,000 → 00:32:25,000  英文共筆 英文選擇的那個檔案\n",
            "[ 43%] 00:32:25,000 → 00:32:27,000  對對對對\n",
            "[ 43%] 00:32:27,000 → 00:32:29,000  就是像現在的這個畫面\n",
            "[ 43%] 00:32:29,000 → 00:32:31,000  它就是一個英文的\n",
            "[ 43%] 00:32:31,000 → 00:32:33,000  英文選擇題的講義裡面的\n",
            "[ 43%] 00:32:33,000 → 00:32:36,000  線上的一個資料庫\n",
            "[ 43%] 00:32:36,000 → 00:32:39,000  你在寫你的那個題目跟詳解的時候\n",
            "[ 43%] 00:32:39,000 → 00:32:40,000  就建議你可以\n",
            "[ 44%] 00:32:40,000 → 00:33:00,000  寫在線上,然後就是在線上是一個已經有整理過的,有系統化的一個地方,然後這一個連結就可以直接分享給學生,然後學生就會有更多的自由度可以去在實體和電子上面同時的閱讀,就他們讀電子也得讀得懂,然後讀實體\n",
            "[ 44%] 00:33:00,000 → 00:33:11,060  你可以讀得懂,那你再把這個現在資料庫上面的東西再轉成實際書的排版跟內容就可以了,你這樣能聽得懂嗎?\n",
            "[ 44%] 00:33:13,860 → 00:33:19,940  我就是,因為我現在是把它拆在\n",
            "[ 44%] 00:33:20,000 → 00:33:29,000  因為我拿其他檔案,我的檔案,所以我之後寫完的話我再把它弄到 Notion上面。\n",
            "[ 45%] 00:33:29,000 → 00:33:31,000  這樣可以吧。\n",
            "[ 45%] 00:33:31,000 → 00:33:36,000  我覺得這樣應該會好一點,因為你我的檔不是會比較零散嗎?\n",
            "[ 45%] 00:33:40,000 → 00:33:44,000  欸可是notion上面就不能做那個公司那些咧?\n",
            "[ 45%] 00:33:46,000 → 00:33:48,000  Notion上可以做公司的\n",
            "[ 45%] 00:33:48,000 → 00:33:49,000  喔真的喔?\n",
            "[ 45%] 00:33:49,000 → 00:33:51,000  用Datex寫\n",
            "[ 45%] 00:33:53,000 → 00:33:55,000  你搜尋LATEX\n",
            "[ 45%] 00:34:00,000 → 00:34:02,000  等下等下等下\n",
            "[ 45%] 00:34:05,200 → 00:34:07,200  它是一個特定的滴刷\n",
            "[ 46%] 00:34:14,560 → 00:34:16,560  上面那個\n",
            "[ 46%] 00:34:20,000 → 00:34:30,340  就變成翅方,然後就要打一個固定的,就是一個字串進去,它就會變成翅方。\n",
            "[ 46%] 00:34:30,340 → 00:34:33,400  對,對,差不多了。\n",
            "[ 46%] 00:34:33,400 → 00:34:36,500  沃德裡面的公司應該是可以轉成這種模式的。\n",
            "[ 46%] 00:34:40,000 → 00:34:48,000  好,如果這方面維生不太會用的話,可以再問我,或是直接問培鈞也可以。\n",
            "[ 46%] 00:34:48,000 → 00:34:54,000  或是你也可以就直接在 Word 檔上面編輯,但是你截圖截到 Notion。\n",
            "[ 46%] 00:34:54,000 → 00:34:55,000  對。\n",
            "[ 46%] 00:34:55,000 → 00:34:59,000  因為 Notion 會有這種資料庫,就會比 Word 還要清楚一點。\n",
            "[ 47%] 00:35:00,000 → 00:35:05,000  好,那我就先在我的上面寫好了。\n",
            "[ 47%] 00:35:05,000 → 00:35:09,000  好,沒有問題。\n",
            "[ 47%] 00:35:09,000 → 00:35:20,000  然後這個的話其實剛剛子明就講到,你可以寫一個很深很深的關鍵,但是你要想辦法也要教會可能不是成都的嗎?\n",
            "[ 47%] 00:35:20,000 → 00:35:20,720  好的學生\n",
            "[ 47%] 00:35:20,720 → 00:35:26,800  那這部分剛剛你在聽的時候有問題嗎\n",
            "[ 47%] 00:35:26,800 → 00:35:34,340  你是說線上化跟配套工具\n",
            "[ 47%] 00:35:34,340 → 00:35:34,900  對\n",
            "[ 47%] 00:35:34,900 → 00:35:38,620  就是我們剛剛\n",
            "[ 47%] 00:35:40,000 → 00:35:45,000  我想講到自信框架的地方還有學習方式跟記憶策略的選擇\n",
            "[ 48%] 00:35:45,000 → 00:35:49,000  前面全部嗎?\n",
            "[ 48%] 00:35:49,000 → 00:35:52,000  對,它其實就是一樣的東西\n",
            "[ 48%] 00:35:52,000 → 00:35:55,000  就是教學理念的話我們希望它是以不間隔的方式\n",
            "[ 48%] 00:35:55,000 → 00:36:00,000  就是你要是寫好寫滿但是你要需要用方式讓可能\n",
            "[ 48%] 00:36:00,000 → 00:36:06,080  我比較沒有程度那麼高的學生去理解一個比較深奧的觀念\n",
            "[ 48%] 00:36:06,080 → 00:36:16,500  然後如果延續到前面剛剛提到的說\n",
            "[ 48%] 00:36:16,500 → 00:36:18,380  你要怎麼樣有一個很深奧的觀念\n",
            "[ 48%] 00:36:18,380 → 00:36:20,000  但是你卻不是只針對聰明\n",
            "[ 48%] 00:36:20,000 → 00:36:25,000  你只要把這個東西插成一個很碎片化的東西可以呈現。\n",
            "[ 48%] 00:36:25,000 → 00:36:28,000  它可能是三到五個獨立然後可以理解的小單元。\n",
            "[ 49%] 00:36:28,000 → 00:36:33,000  就你小單元小單元小單元讓他們去吸收,他們就比較可以接受。\n",
            "[ 49%] 00:36:33,000 → 00:36:37,000  然後再來的話是你每個單元只要專注一個最核心核心的點就好。\n",
            "[ 49%] 00:36:37,000 → 00:36:40,000  然後你可以搭配一些立體跟一些互動練習。\n",
            "[ 49%] 00:36:40,000 → 00:36:54,000  另外就是你要把那個包裝把它簡化簡化得很簡單,就是你可以用可能比較生物化的方式去解釋,或者是你可以用剩下一些視覺化的工具。\n",
            "[ 49%] 00:36:54,000 → 00:37:00,000  對,然後再來的話就是視超化落地,就是你這樣每個觀念都可以搭配一個可以讓它\n",
            "[ 49%] 00:37:00,000 → 00:37:12,000  所以我剛才會提到說你可能一個章節裡面你可能會有二到三題的練習題,你就可以搭配到視察化落地的這個部分。\n",
            "[ 50%] 00:37:12,000 → 00:37:20,000  好,然後再來的話就是剛其實就有稍微提到配套工具。\n",
            "[ 50%] 00:37:20,000 → 00:37:24,600  這幾個是我們覺得也可以用在物理講義裡面的配套工具\n",
            "[ 50%] 00:37:24,600 → 00:37:26,600  第一個就是Notion的筆記模板\n",
            "[ 50%] 00:37:26,600 → 00:37:28,600  然後再來的話就是SharedGPC的機器人\n",
            "[ 50%] 00:37:28,600 → 00:37:31,900  這個的話會是就是你先跟他聊聊聊\n",
            "[ 50%] 00:37:31,900 → 00:37:33,500  然後聊到說有一定的格式\n",
            "[ 50%] 00:37:33,500 → 00:37:37,100  然後之後我們再去轉成我們自己寫的機器人\n",
            "[ 50%] 00:37:37,100 → 00:37:40,100  就會是可能當學生輸入哪一些提示詞\n",
            "[ 50%] 00:37:40,000 → 00:37:44,420  他可以按照我們一開始就規定好的格式 然後產出相對應的內容\n",
            "[ 50%] 00:37:44,420 → 00:37:46,400  然後再來是Notebook LN\n",
            "[ 50%] 00:37:46,400 → 00:37:52,320  Notebook LN的話會比較偏向是我們一開始就先把我們的講義就先都上傳好\n",
            "[ 50%] 00:37:52,320 → 00:37:54,400  然後讓他的觀念是完整清楚的\n",
            "[ 50%] 00:37:54,400 → 00:37:56,780  那當學生他有什麼問題想要問的時候\n",
            "[ 50%] 00:37:56,780 → 00:37:59,020  他可以直接上Notebook LN然後問一個問題\n",
            "[ 50%] 00:37:59,020 → 00:37:59,300  然後\n",
            "[ 51%] 00:38:00,000 → 00:38:04,000  機器人就會想把相對應講義的內容輸出給他\n",
            "[ 51%] 00:38:04,000 → 00:38:07,000  就是一個很即時的問答\n",
            "[ 51%] 00:38:07,000 → 00:38:11,000  然後再來的話就是剛剛有給你看過的那個共編檔案\n",
            "[ 51%] 00:38:11,000 → 00:38:13,000  物理也可以這樣子做\n",
            "[ 51%] 00:38:13,000 → 00:38:17,000  但是這個的話就會很仰賴說\n",
            "[ 51%] 00:38:17,000 → 00:38:20,000  如果今天學生真的有上來留言\n",
            "[ 51%] 00:38:20,000 → 00:38:40,000  然後問問題的話,我們會需要很,就是至少在一定的時間內就可以幫他解完這樣的問題,然後並把這樣的東西再重新整理成新的內容,然後放上來,所以那個沒有到這麼急迫,但是我們還是會希望未來可以。\n",
            "[ 51%] 00:38:40,000 → 00:38:41,000  做\n",
            "[ 51%] 00:38:41,000 → 00:38:45,740  然後再來就是Notion的問答會診區\n",
            "[ 52%] 00:38:45,740 → 00:38:47,520  這個的話會是\n",
            "[ 52%] 00:38:47,520 → 00:38:49,900  譬如說我們有在IG啊\n",
            "[ 52%] 00:38:49,900 → 00:38:51,940  或者是在LINE的社群裡面\n",
            "[ 52%] 00:38:51,940 → 00:38:54,760  如果有任何人提到物理檢驗裡面的問題\n",
            "[ 52%] 00:38:54,760 → 00:38:57,020  我們都可以把它統整起來\n",
            "[ 52%] 00:38:57,020 → 00:38:58,500  然後就是你回答完之後\n",
            "[ 52%] 00:38:58,500 → 00:38:59,580  我們再把它統整起來\n",
            "[ 52%] 00:38:59,580 → 00:39:00,000  然後之後\n",
            "[ 52%] 00:39:00,000 → 00:39:03,320  有遇到一样的问题的时候学生就可以直接上来这边看\n",
            "[ 52%] 00:39:03,320 → 00:39:09,040  好那以上现在有问题吗\n",
            "[ 52%] 00:39:09,040 → 00:39:12,440  刚刚有说到那个notebook\n",
            "[ 52%] 00:39:12,440 → 00:39:16,140  它是就是上次是说它提供上来\n",
            "[ 52%] 00:39:16,140 → 00:39:17,700  然后它就会呈现解答\n",
            "[ 52%] 00:39:17,700 → 00:39:19,800  所以它是一个\n",
            "[ 52%] 00:39:20,000 → 00:39:25,020  它是AI嗎?還是它只是單純的查找的工具?\n",
            "[ 52%] 00:39:25,640 → 00:39:27,920  還是它是會生內容的那種AI?\n",
            "[ 53%] 00:39:30,120 → 00:39:33,000  它是一個幫助你去...\n",
            "[ 53%] 00:39:33,000 → 00:39:37,760  它是會自己生內容嗎?\n",
            "[ 53%] 00:39:38,360 → 00:39:39,980  還是它是拿出...\n",
            "[ 53%] 00:39:40,000 → 00:39:59,220  他會自己按照你給他的觀念格式,還有你給他的內容,然後去升,他裡面知道既有的內容,所以他不會去延伸說那些其實你並沒有輸入給他的東西,因為像ShareGP的話,他就很有可能是輸出一些\n",
            "[ 53%] 00:40:00,000 → 00:40:02,300  並唔係嗰麼正確性嘅嘢\n",
            "[ 53%] 00:40:02,300 → 00:40:06,400  但係NOPLM 佢就係完全按照你輸入乜嘢給佢\n",
            "[ 53%] 00:40:06,400 → 00:40:09,100  佢就會輸出相對應嘅嘢給學生\n",
            "[ 53%] 00:40:09,100 → 00:40:12,400  所以佢能確保佢裡面輸出嘅嘢一定係完整嘅\n",
            "[ 53%] 00:40:12,400 → 00:40:13,400  而且係正確嘅\n",
            "[ 53%] 00:40:15,600 → 00:40:16,400  好\n",
            "[ 54%] 00:40:16,400 → 00:40:19,900  對 所以會需要你完成獎益跟一些\n",
            "[ 54%] 00:40:20,000 → 00:40:23,000  我们再喂进去给那部LA\n",
            "[ 54%] 00:40:23,000 → 00:40:26,080  那到时候再用好\n",
            "[ 54%] 00:40:26,080 → 00:40:27,220  因为我现在也不会用它\n",
            "[ 54%] 00:40:27,220 → 00:40:29,160  好没有问题\n",
            "[ 54%] 00:40:29,160 → 00:40:32,440  然后善用比喻的话\n",
            "[ 54%] 00:40:32,440 → 00:40:34,380  上面也有讲过\n",
            "[ 54%] 00:40:34,380 → 00:40:35,780  然后你自己也有稍微看过\n",
            "[ 54%] 00:40:35,780 → 00:40:38,260  那这部分你有问题想询问的吗\n",
            "[ 54%] 00:40:40,000 → 00:40:44,000  應該比較還好,這部分應該比較簡單。\n",
            "[ 54%] 00:40:44,000 → 00:40:48,000  OK,那關於立場切換的部分呢?\n",
            "[ 54%] 00:40:51,000 → 00:41:00,000  這個就是子明剛剛跟你講到說,如果你今天是一個蓋籃的時候,你可以不要那麼的過於理性,或是就是一些文綽綽的\n",
            "[ 55%] 00:41:00,000 → 00:41:11,000  你可以是給他們一個對號入座的感覺,或是給他們一個比較偏向感性上面的支持,或是一些情緒支持這樣子,這就是舉例。\n",
            "[ 55%] 00:41:11,000 → 00:41:20,000  然後這個的話也是用在作文上的一個小小的行銷手段,它就是讓學生自己去想他們有什麼想法。\n",
            "[ 55%] 00:41:20,000 → 00:41:24,500  然後我們引導牠去對號入座到你真的有這個症狀\n",
            "[ 55%] 00:41:24,500 → 00:41:26,180  然後其實你很需要這個書\n",
            "[ 55%] 00:41:26,180 → 00:41:29,280  就是物理也可以用這樣的方式呈現\n",
            "[ 55%] 00:41:29,280 → 00:41:35,160  然後下面這些你在看的時候你有任何的問題嗎\n",
            "[ 55%] 00:41:35,160 → 00:41:37,300  或是有不太懂的地方嗎\n",
            "[ 56%] 00:41:40,000 → 00:42:00,000  應該都還好,剛剛前面說要給他們一些標籤,讓他們對好入座,我現在是沒想到有什麼啦,我想問你們,在寫物理的時候。\n",
            "[ 56%] 00:42:00,000 → 00:42:01,240  會有什麼問題嗎?\n",
            "[ 56%] 00:42:01,240 → 00:42:03,500  還是平常沒有在寫物理?\n",
            "[ 56%] 00:42:06,840 → 00:42:07,800  我有寫過\n",
            "[ 56%] 00:42:09,000 → 00:42:10,160  那你有什麼問題嗎?\n",
            "[ 56%] 00:42:11,540 → 00:42:12,660  我覺得從\n",
            "[ 56%] 00:42:13,660 → 00:42:16,560  如果是緯程那邊要整理這些問題的話\n",
            "[ 56%] 00:42:16,560 → 00:42:17,800  我反而會覺得\n",
            "[ 56%] 00:42:18,500 → 00:42:19,960  育謙那邊可能可以看\n",
            "[ 57%] 00:42:20,000 → 00:42:38,000  開一個物理的問答,限動的問答,然後藉由這樣子蒐集問題去知道學生的症節點在哪邊,然後就把那些問題全部灌到 CheckGPT,然後請CheckGPT整理學生有哪些類型,這樣應該就很快就可以找到那些問題。\n",
            "[ 57%] 00:42:38,000 → 00:42:40,000  但是問完那些問題之後……\n",
            "[ 57%] 00:42:40,000 → 00:42:47,000  可能未曾要幫忙簡單回答一下 因為育成可能沒辦法自己去回答物理的專業問題\n",
            "[ 57%] 00:42:47,000 → 00:42:52,000  被問問了但是沒有打算回答 這樣過分\n",
            "[ 57%] 00:42:52,000 → 00:43:00,000  我想舉一個例子就是我覺得我自己寫物理最大的祕訣是腦中藥\n",
            "[ 58%] 00:43:00,000 → 00:43:20,000  老公要有畫面,老公要有那個東西在跑的畫面,所以就可以把它當成是一個技巧,比如說看的那些物理的公式,看的那些數字,它沒有感覺怎麼樣,就可以去提。\n",
            "[ 58%] 00:43:20,000 → 00:43:28,000  提供他一些,譬如說像我剛剛講的那種讓自己比較有感覺的技巧這樣\n",
            "[ 58%] 00:43:28,000 → 00:43:30,000  類似這種方向\n",
            "[ 58%] 00:43:32,000 → 00:43:37,000  我有想過就是腦中要有畫面這件事情\n",
            "[ 58%] 00:43:37,000 → 00:43:40,000  但我後來發現就是好像不是每個人都可以做\n",
            "[ 58%] 00:43:40,000 → 00:43:44,000  就有些人特別沒有想像力\n",
            "[ 58%] 00:43:44,000 → 00:43:48,000  我要想一下就是要給我給他這個想像力\n",
            "[ 58%] 00:43:48,000 → 00:43:50,000  你要引導他去構思\n",
            "[ 58%] 00:43:50,000 → 00:43:52,000  對引導他去構思這個想像力\n",
            "[ 58%] 00:43:52,000 → 00:44:00,000  或是你也可以找一些線上的視覺化\n",
            "[ 59%] 00:44:00,000 → 00:44:04,000  現在有一些線上的物理方面的視覺化的工具\n",
            "[ 59%] 00:44:04,000 → 00:44:07,000  也可以引導他們去使用這些工具\n",
            "[ 59%] 00:44:07,000 → 00:44:10,000  然後自己去拉拉看那個訊息之類的\n",
            "[ 59%] 00:44:12,000 → 00:44:14,000  我可以稍微跟你提一個\n",
            "[ 59%] 00:44:14,000 → 00:44:17,000  可能比較像是聯想或者一個小技巧\n",
            "[ 59%] 00:44:17,000 → 00:44:20,000  像英文作文裡那個字名它就會\n",
            "[ 59%] 00:44:20,000 → 00:44:23,660  用break pin去講一些公式跟觀念\n",
            "[ 59%] 00:44:23,660 → 00:44:28,960  讓學生他們的想像畫面是以他們熟悉的東西去帶入\n",
            "[ 59%] 00:44:28,960 → 00:44:32,860  那他們就會比較好聯想到你要跟他們講什麼\n",
            "[ 59%] 00:44:32,860 → 00:44:38,020  然後當他們真的對於那個畫面沒有太大的感受的時候\n",
            "[ 59%] 00:44:38,020 → 00:44:39,900  他們也可以因為這個東西是他們比較\n",
            "[ 59%] 00:44:40,000 → 00:44:42,400  日常生活化就有在接觸的東西。\n",
            "[ 59%] 00:44:42,400 → 00:44:45,200  所以進而聯想到那個很抽象的畫面。\n",
            "[ 60%] 00:44:47,200 → 00:44:49,100  這就會是我們剛剛上面有講到的,\n",
            "[ 60%] 00:44:49,100 → 00:44:51,700  就是你可能要再多運用一些生活化\n",
            "[ 60%] 00:44:51,700 → 00:44:55,300  或是很日常的東西去做比喻,\n",
            "[ 60%] 00:44:55,300 → 00:44:57,100  然後去做例子的講解。\n",
            "[ 60%] 00:45:00,000 → 00:45:09,300  好,然後再來的話,學生需要會有一個固定的,固定默契的emoji,\n",
            "[ 60%] 00:45:09,460 → 00:45:13,680  因為它會是讓學生知道,我今天看到這個圖示的時候,\n",
            "[ 60%] 00:45:13,900 → 00:45:18,000  我就是接下來會看到什麼樣的內容,讓他們有一個小小的概念點。\n",
            "[ 61%] 00:45:20,000 → 00:45:40,000  但是如果以英文中文來講的話,這個東西就會是對應到總結的重點,然後小燈泡的話就會是一個口訣或是一個記憶法,然後如果你今天是一個手加一個筆的話,那就是你的動手練習,就是你可以稍微去幫他設計一個固定的符號,讓他們有一個小概念,他們才不會覺得...\n",
            "[ 61%] 00:45:40,000 → 00:45:44,000  看起來很亂,然後台板上我們也會比較整齊一點點。\n",
            "[ 61%] 00:45:44,000 → 00:45:48,140  然後如果今天是你想要自己跟學生講的話,\n",
            "[ 61%] 00:45:48,240 → 00:45:53,320  你也可以用一個可能老師的符號,或者是一個男生的符號,\n",
            "[ 61%] 00:45:53,500 → 00:45:56,440  然後跟他們講說這比較像是你心裡的話,\n",
            "[ 61%] 00:45:56,600 → 00:45:59,000  那他就不用那麼文綴綴,他就是真的可以很...\n",
            "[ 61%] 00:46:00,000 → 00:46:03,000  就是比較日常口語化的東西就可以了\n",
            "[ 61%] 00:46:03,000 → 00:46:06,000  然後再來就是上次就有提到的東西\n",
            "[ 61%] 00:46:06,000 → 00:46:08,000  就是說表達高用AI論搞過\n",
            "[ 61%] 00:46:08,000 → 00:46:11,000  因為現在的物理講義內容比較像是\n",
            "[ 61%] 00:46:11,000 → 00:46:13,000  你真的想到什麼然後就打什麼出來\n",
            "[ 61%] 00:46:13,000 → 00:46:15,000  它沒有一個固定的格式\n",
            "[ 62%] 00:46:15,000 → 00:46:18,000  然後甚至這樣的內容可能比較像是\n",
            "[ 62%] 00:46:18,000 → 00:46:20,000  只有你自己看得懂\n",
            "[ 62%] 00:46:20,000 → 00:46:22,000  所有的表達我們都可以丟到TradeGPT\n",
            "[ 62%] 00:46:22,000 → 00:46:24,000  就你只要把你的想法丟上去\n",
            "[ 62%] 00:46:24,000 → 00:46:26,000  然後剛才你說你可以幫我run稿嗎\n",
            "[ 62%] 00:46:26,000 → 00:46:28,000  或是你可以幫我修飾成\n",
            "[ 62%] 00:46:28,000 → 00:46:30,000  可能高中生也看得懂的話語\n",
            "[ 62%] 00:46:30,000 → 00:46:32,000  它就會直接幫你寫出來\n",
            "[ 62%] 00:46:32,000 → 00:46:34,000  但是它生成的內容\n",
            "[ 62%] 00:46:34,000 → 00:46:36,000  你還是需要再去檢查過\n",
            "[ 62%] 00:46:36,000 → 00:46:38,000  因為它有時候不一定是那麼正確\n",
            "[ 62%] 00:46:38,000 → 00:46:40,000  或是不一定那麼貼近你想要表達的\n",
            "[ 62%] 00:46:40,000 → 00:46:45,000  所以你就跟他多聊幾次就可以了。\n",
            "[ 62%] 00:46:45,000 → 00:46:47,000  好,以上是知識存在的方面。\n",
            "[ 62%] 00:46:47,000 → 00:46:51,000  然後如果是使用者體驗方面的話,\n",
            "[ 62%] 00:46:51,000 → 00:46:54,000  像是AI化、線上化跟連結種整理,\n",
            "[ 62%] 00:46:54,000 → 00:46:58,000  就會需要麻煩你在編寫獎益的內容之後,\n",
            "[ 62%] 00:46:58,000 → 00:47:00,000  在編寫獎益內容的之中,\n",
            "[ 62%] 00:47:00,000 → 00:47:02,800  我就邊想還有哪些東西可以去製作\n",
            "[ 63%] 00:47:02,800 → 00:47:04,900  然後在你撰寫的過程中\n",
            "[ 63%] 00:47:04,900 → 00:47:07,500  也可以邊製作一些AI工具\n",
            "[ 63%] 00:47:07,500 → 00:47:09,000  或是把東西線上畫\n",
            "[ 63%] 00:47:10,500 → 00:47:14,200  然後全球地圖廣告頁跟意見回饋購買東西調查\n",
            "[ 63%] 00:47:14,200 → 00:47:16,600  這些都會由e-mall這邊直接處理\n",
            "[ 63%] 00:47:18,000 → 00:47:19,500  然後再來是格式的話\n",
            "[ 63%] 00:47:20,000 → 00:47:30,000  因為我知道你現在跟小助手的方式 好像是你會先把他整理過 然後再傳檔案給他 對嗎?\n",
            "[ 63%] 00:47:32,000 → 00:47:33,000  對\n",
            "[ 63%] 00:47:33,000 → 00:47:38,000  對 所以格式的話可能要 就是從你那邊一開始打的時候\n",
            "[ 63%] 00:47:38,000 → 00:47:40,000  就是你開始編輯這個書的時候\n",
            "[ 63%] 00:47:40,000 → 00:47:42,240  你可能就要稍微幫我注意一下格式\n",
            "[ 63%] 00:47:42,240 → 00:47:43,980  我們就是以B5為主\n",
            "[ 63%] 00:47:43,980 → 00:47:46,060  然後那個初期線要稍微注意\n",
            "[ 64%] 00:47:46,060 → 00:47:48,780  至少邊邊要預留三面面\n",
            "[ 64%] 00:47:48,780 → 00:47:49,500  它會比較\n",
            "[ 64%] 00:47:49,500 → 00:47:53,520  就硬刷的時候才會比較不會卡到板\n",
            "[ 64%] 00:47:53,520 → 00:47:54,420  然後需要\n",
            "[ 64%] 00:47:54,420 → 00:47:55,620  預留多少\n",
            "[ 64%] 00:47:55,620 → 00:47:58,560  就是你開word\n",
            "[ 64%] 00:47:58,560 → 00:48:00,000  然後它會有那個\n",
            "[ 64%] 00:48:00,000 → 00:48:02,000  至少要窄\n",
            "[ 64%] 00:48:02,000 → 00:48:04,000  它有一個版面配飾\n",
            "[ 64%] 00:48:04,000 → 00:48:06,000  然後你最多最多只能選擇窄\n",
            "[ 64%] 00:48:06,000 → 00:48:08,000  然後不能再往下縮\n",
            "[ 64%] 00:48:10,000 → 00:48:12,000  等一下我再開給你看好了\n",
            "[ 64%] 00:48:12,000 → 00:48:14,000  稍等我一下\n",
            "[ 65%] 00:48:20,000 → 00:48:39,240  好,就是你在用Word等的時候,它其實有一個版面配置,然後你就,你需要先一開始就先幫我把大小分到。\n",
            "[ 65%] 00:48:40,000 → 00:48:42,640  啊我冇覆好,稍等我\n",
            "[ 65%] 00:48:42,640 → 00:48:44,080  奈咦阿捏\n",
            "[ 65%] 00:48:44,080 → 00:48:50,540  這樣有咩\n",
            "[ 65%] 00:48:50,540 → 00:48:55,720  所以你一開始就需要幫我把大小\n",
            "[ 65%] 00:48:55,720 → 00:48:57,880  就直接先選成B5的大小\n",
            "[ 65%] 00:48:57,880 → 00:48:59,780  然後邊界這邊\n",
            "[ 65%] 00:49:00,000 → 00:49:02,000  最多最多就是以窄為主\n",
            "[ 65%] 00:49:02,000 → 00:49:04,000  就是盡量不要再往下縮\n",
            "[ 65%] 00:49:04,000 → 00:49:08,000  不然我們的印刷照片可能會踩到旁邊\n",
            "[ 65%] 00:49:08,000 → 00:49:10,000  這部分OK咩?\n",
            "[ 65%] 00:49:10,000 → 00:49:12,000  OK\n",
            "[ 65%] 00:49:12,000 → 00:49:14,000  再超出一點點\n",
            "[ 65%] 00:49:14,000 → 00:49:16,000  一點點\n",
            "[ 65%] 00:49:16,000 → 00:49:18,000  對對對就是一點點\n",
            "[ 66%] 00:49:18,000 → 00:49:20,000  但不要壓得太緊\n",
            "[ 66%] 00:49:20,000 → 00:49:22,000  你可以回去剛那個地方嗎?\n",
            "[ 66%] 00:49:22,000 → 00:49:26,000  你看它的右上角\n",
            "[ 66%] 00:49:26,000 → 00:49:29,000  右上角是不是有一個L形的東西?\n",
            "[ 66%] 00:49:32,000 → 00:49:36,000  在紙張上有一個L形的框架\n",
            "[ 66%] 00:49:36,000 → 00:49:38,000  對這個\n",
            "[ 66%] 00:49:38,000 → 00:49:40,000  就是它的那個死角的那個\n",
            "[ 66%] 00:49:40,000 → 00:49:42,000  你的字可以寫到那邊\n",
            "[ 66%] 00:49:42,000 → 00:49:47,000  然後如果你字真的想要在外面再延伸一點點的話\n",
            "[ 66%] 00:49:47,000 → 00:49:52,000  就是不可以超過那個L型的中端\n",
            "[ 66%] 00:49:52,000 → 00:49:55,000  就不可以寫出L型的外面\n",
            "[ 66%] 00:49:55,000 → 00:49:59,000  就會是不會被拆到的格式\n",
            "[ 67%] 00:50:00,000 → 00:50:07,000  但是今天還是幫我縮在L型裡面會比較保險一點點\n",
            "[ 67%] 00:50:07,000 → 00:50:15,000  然後再來的話其他目前都有講過\n",
            "[ 67%] 00:50:15,000 → 00:50:20,000  這個呼籲社群宣傳\n",
            "[ 67%] 00:50:20,000 → 00:50:22,700  比較會像是你寫書已經寫到後半段之後\n",
            "[ 67%] 00:50:22,700 → 00:50:24,700  我們可以再來進行的東西\n",
            "[ 67%] 00:50:24,700 → 00:50:27,800  所以這個我們可以之後在開會的時候跟你講一下\n",
            "[ 67%] 00:50:29,800 → 00:50:33,300  然後誓願內容商品化會\n",
            "[ 67%] 00:50:33,300 → 00:50:34,800  這個就是範例\n",
            "[ 67%] 00:50:34,800 → 00:50:38,200  我們以英文作文或是英文文法\n",
            "[ 67%] 00:50:38,200 → 00:50:39,400  或是英文單字說的話\n",
            "[ 67%] 00:50:39,400 → 00:50:40,000  我們可能都會\n",
            "[ 67%] 00:50:40,000 → 00:50:46,320  給他一個備單的機器人 然後拿這個機器人去推廣我們的作文書跟其他的產品\n",
            "[ 68%] 00:50:46,320 → 00:50:49,560  就是當你使用這個機器人的時候 它底下其實會生成\n",
            "[ 68%] 00:50:49,560 → 00:50:54,860  如果你想看更多完整的內容 或者如果你想要看什麼更完整的文法解說\n",
            "[ 68%] 00:50:54,860 → 00:50:58,640  你可以購買一模一模的那本書 然後會貼一個下一個連結給他\n",
            "[ 68%] 00:50:58,640 → 00:51:00,000  就是到時候物理也可以用\n",
            "[ 68%] 00:51:00,000 → 00:51:02,800  用這種方式去做一個行銷宣傳。\n",
            "[ 68%] 00:51:02,800 → 00:51:06,800  在這裡,就是想知道如果背一個單字補輸一個觀念,\n",
            "[ 68%] 00:51:06,800 → 00:51:09,800  然後這就會是我們完整的書籍內容宣傳。\n",
            "[ 68%] 00:51:12,800 → 00:51:18,800  好,那目前以上有任何問題或是有任何想問的嗎?\n",
            "[ 68%] 00:51:20,000 → 00:51:26,120  因為Himoji那邊現在的樹就有了,所以還好。\n",
            "[ 68%] 00:51:26,120 → 00:51:31,440  然後你有一個MBTI那個是沒有要理它嗎?\n",
            "[ 69%] 00:51:34,960 → 00:51:40,020  因為這個可能就是對於物理...\n",
            "[ 69%] 00:51:40,000 → 00:51:43,200  講義有點難運用\n",
            "[ 69%] 00:51:43,200 → 00:51:43,840  其實\n",
            "[ 69%] 00:51:43,840 → 00:51:45,960  哦好那我就不理他\n",
            "[ 69%] 00:51:45,960 → 00:51:47,340  好好\n",
            "[ 69%] 00:51:47,340 → 00:51:48,280  子明你可以說\n",
            "[ 69%] 00:51:48,280 → 00:51:53,080  我寫那個其實只是一個紀錄\n",
            "[ 69%] 00:51:53,080 → 00:51:54,980  它不一定要寫NBT\n",
            "[ 69%] 00:51:54,980 → 00:51:56,820  我想講的只是說\n",
            "[ 69%] 00:51:56,820 → 00:51:59,240  你可以去設想\n",
            "[ 69%] 00:52:00,000 → 00:52:02,000  學生有千千百百多\n",
            "[ 69%] 00:52:02,000 → 00:52:04,000  就是有一些人\n",
            "[ 69%] 00:52:04,000 → 00:52:08,000  因為你自己怎麼學物理\n",
            "[ 69%] 00:52:08,000 → 00:52:10,000  跟其他人怎麼學物理\n",
            "[ 69%] 00:52:10,000 → 00:52:11,000  一定是非常不同的\n",
            "[ 69%] 00:52:11,000 → 00:52:13,000  然後除了是專業知識\n",
            "[ 69%] 00:52:13,000 → 00:52:15,000  觀念上面的落差之外\n",
            "[ 69%] 00:52:15,000 → 00:52:17,000  其實他們在理解知識\n",
            "[ 70%] 00:52:17,000 → 00:52:20,000  還有如何讀完這本書上面\n",
            "[ 70%] 00:52:20,000 → 00:52:22,500  本身就會有很大的不同\n",
            "[ 70%] 00:52:22,500 → 00:52:24,500  像譬如說喻謙好了\n",
            "[ 70%] 00:52:24,500 → 00:52:26,500  他如果今天讀到一本書\n",
            "[ 70%] 00:52:26,500 → 00:52:28,500  然後事實上他覺得很用心\n",
            "[ 70%] 00:52:33,500 → 00:52:35,500  如果是那本書讓喻謙覺得很用心\n",
            "[ 70%] 00:52:35,500 → 00:52:37,500  然後很有溫度\n",
            "[ 70%] 00:52:37,500 → 00:52:39,500  然後是很想把學徒顧好\n",
            "[ 70%] 00:52:39,500 → 00:52:40,500  喻謙就會想\n",
            "[ 70%] 00:52:40,000 → 00:52:42,000  你想把它讀完,你說是不是?\n",
            "[ 70%] 00:52:42,000 → 00:52:44,000  對\n",
            "[ 70%] 00:52:44,000 → 00:52:46,000  但是我的個性可能就會是\n",
            "[ 70%] 00:52:46,000 → 00:52:48,000  我想要看到超級爆炸具體的東西\n",
            "[ 70%] 00:52:48,000 → 00:52:50,000  你不要給我扯一些有的沒的的\n",
            "[ 70%] 00:52:50,000 → 00:52:52,000  剛才跟我講的重點\n",
            "[ 70%] 00:52:52,000 → 00:52:57,000  然後其他學生有些可能會喜歡圖像化的解說\n",
            "[ 70%] 00:52:57,000 → 00:53:00,000  然後就是你比起用文字去寫\n",
            "[ 70%] 00:53:00,000 → 00:53:01,800  寫第一步驟第二步驟第三步驟\n",
            "[ 71%] 00:53:01,800 → 00:53:05,300  你還不如直接用一張圖片或Canva的字圖\n",
            "[ 71%] 00:53:05,300 → 00:53:07,300  去告訴他三步驟是什麼\n",
            "[ 71%] 00:53:07,300 → 00:53:09,500  那又會有一些可能又會喜歡\n",
            "[ 71%] 00:53:09,500 → 00:53:13,100  就是兩個人的對話去推進一個觀念\n",
            "[ 71%] 00:53:13,100 → 00:53:14,600  就大家都有不同學習方式\n",
            "[ 71%] 00:53:14,600 → 00:53:16,900  然後我覺得你不一定要用MVTI\n",
            "[ 71%] 00:53:16,900 → 00:53:19,100  去把16個全部都想過一次\n",
            "[ 71%] 00:53:19,100 → 00:53:19,900  而是你\n",
            "[ 71%] 00:53:20,000 → 00:53:21,640  至少在寫獎音的時候\n",
            "[ 71%] 00:53:21,640 → 00:53:25,760  你要先抓幾個學生的標籤跟概念出來\n",
            "[ 71%] 00:53:25,760 → 00:53:28,640  可能是圖像化學生、理論化學生\n",
            "[ 71%] 00:53:28,640 → 00:53:31,040  然後比較情緒化的學生\n",
            "[ 71%] 00:53:31,040 → 00:53:32,000  抓幾個標籤出來\n",
            "[ 71%] 00:53:32,000 → 00:53:35,240  然後去寫獎音的時候照顧到這些學生的需求\n",
            "[ 71%] 00:53:37,240 → 00:53:39,040  好,我講完了\n",
            "[ 71%] 00:53:40,000 → 00:53:43,000  Ok, this part, do you think it's ok?\n",
            "[ 71%] 00:53:44,000 → 00:53:45,000  Yes, it's ok.\n",
            "[ 71%] 00:53:46,000 → 00:53:48,000  Ok, and then...\n",
            "[ 72%] 00:53:51,000 → 00:53:56,000  If you are in the process of making it, or you need some AI tools to help you,\n",
            "[ 72%] 00:53:56,000 → 00:54:00,000  you can find Pei Jun, he is a very good...\n",
            "[ 72%] 00:54:00,000 → 00:54:04,200  所以如果你在這雙方沒有問題的話都可以問他\n",
            "[ 72%] 00:54:04,200 → 00:54:16,000  我們不是還有一個是要問Pedro的事情嗎\n",
            "[ 72%] 00:54:20,000 → 00:54:22,000  我可以分享我的畫面嗎?\n",
            "[ 72%] 00:54:22,000 → 00:54:24,000  欸等一下,物理那邊都講完了吧?\n",
            "[ 72%] 00:54:24,000 → 00:54:26,000  對\n",
            "[ 72%] 00:54:26,000 → 00:54:30,000  好,那我想要問一下裴娟一個東西\n",
            "[ 72%] 00:54:30,000 → 00:54:32,000  我分享一下我的畫面\n",
            "[ 73%] 00:54:40,000 → 00:54:59,920  我们刚刚有讲到很多写讲义上面的东西,只是如果我们这边有这套准则,但是像伟臣可能写的时候还是会需要时不时回去看交战手册,然后有时候可能还是会不小心漏掉一些东西,或不知道怎么去使用,然后我在想如果我们未来\n",
            "[ 73%] 00:55:00,000 → 00:55:06,000  可能會需要同時跑很多本書 很多個合作者一起寫這樣一個話\n",
            "[ 73%] 00:55:06,000 → 00:55:09,000  我們來回溝通可能會需要花很多時間\n",
            "[ 73%] 00:55:09,000 → 00:55:14,000  然後就想到說 之前我在學SEO的時候\n",
            "[ 73%] 00:55:14,000 → 00:55:17,000  有一個像這樣子的工具\n",
            "[ 74%] 00:55:17,000 → 00:55:20,000  就是它的左邊是你在寫書\n",
            "[ 74%] 00:55:20,000 → 00:55:40,000  文章的頁面,然後右邊他就會告訴你說你現在拿到多少分,就是你有做到多少需求之內的事情,然後他就會一直提醒你說你還要再寫什麼,你還要再寫什麼才會足夠完整,然後在想就是這樣子的一個工具他製作的難度。\n",
            "[ 74%] 00:55:40,000 → 00:55:59,100  我覺得應該,這個東西他看起來是有機會整合在Notion裡面,但是我覺得他看起來,因為我們獎勵的內容其實是非常多嘛,我覺得他看起來對於Token的開銷會非常大,就是\n",
            "[ 75%] 00:56:00,000 → 00:56:10,000  我覺得我們透過應用程式去跟AI做串接,它中間其實是以量計價的。\n",
            "[ 75%] 00:56:10,000 → 00:56:20,000  我覺得這東西它或許是可以嘗試看看來做,但是因為\n",
            "[ 75%] 00:56:20,000 → 00:56:27,000  另一方面講義的內容很多,另一方面教單手字的內容也蠻多的\n",
            "[ 75%] 00:56:27,000 → 00:56:32,000  我覺得這個可能使用量的部分會比較大一點點\n",
            "[ 75%] 00:56:32,000 → 00:56:36,000  但這個東西會越來越便宜啦\n",
            "[ 75%] 00:56:36,000 → 00:56:40,000  所以或許我可以嘗試看看用\n",
            "[ 75%] 00:56:40,000 → 00:56:45,640  比較之前的,應該說用量比較小比較便宜的模型來試試看\n",
            "[ 75%] 00:56:46,660 → 00:56:49,720  因為畢竟他這個東西他不會要求說\n",
            "[ 76%] 00:56:49,980 → 00:56:53,320  就是我AI傳出的內容要到多進去\n",
            "[ 76%] 00:56:55,360 → 00:56:59,960  我覺得可以研究看看有沒有機會把它整合在Notion裡面\n",
            "[ 76%] 00:57:00,000 → 00:57:02,760  可能他更新頻率不會到這麼的高\n",
            "[ 76%] 00:57:02,760 → 00:57:09,760  可能就是寫作者完成一整階段的工作之後\n",
            "[ 76%] 00:57:09,760 → 00:57:14,500  再去再用AI去做這個提醒這樣\n",
            "[ 76%] 00:57:18,240 → 00:57:19,000  那如果\n",
            "[ 76%] 00:57:20,000 → 00:57:29,300  如果把這個工具切成是很多個更小的工具 那如果把這個工具切成是很多個更小的工具\n",
            "[ 76%] 00:57:29,300 → 00:57:33,780  就是我們不一定要是一戰式的解決所有講義變形的問題\n",
            "[ 77%] 00:57:33,780 → 00:57:40,000  可能把剛剛教授的手冊細分成五個層面或三個層面\n",
            "[ 77%] 00:57:40,000 → 00:57:47,000  要分別套這樣子的工具,它的用量這樣子會再更大,還是可以節省一點。\n",
            "[ 77%] 00:58:00,000 → 00:58:07,000  要怎麼切我覺得後續可以再來想了,目前就是我覺得可能要再研究一下。\n",
            "[ 77%] 00:58:07,000 → 00:58:14,000  好,不然我也先用ChangeGPT做做看好了,我先打一張手冊寫ChangeGPT。\n",
            "[ 77%] 00:58:14,000 → 00:58:20,000  然後維城如果會,如果想要看看說自己有沒有\n",
            "[ 78%] 00:58:20,000 → 00:58:24,680  有一些東西漏掉的話,你就可以先把你的獎金丟進去,change your VT\n",
            "[ 78%] 00:58:24,680 → 00:58:27,680  但是你一次可能就只能丟個十頁\n",
            "[ 78%] 00:58:27,680 → 00:58:30,680  就不能一次丟那個幾百頁進去\n",
            "[ 78%] 00:58:30,680 → 00:58:34,680  然後他可能就會告訴你說你還有哪些地方需要再錄\n",
            "[ 78%] 00:58:34,680 → 00:58:40,680  現階段先這樣子,然後這個可以之後有研究出來\n",
            "[ 78%] 00:58:40,000 → 00:58:43,000  讓我們再拿出來討論看看。\n",
            "[ 78%] 00:58:45,000 → 00:58:47,000  好,我講完了。\n",
            "[ 78%] 00:58:47,000 → 00:58:49,000  好耶。\n",
            "[ 78%] 00:58:49,000 → 00:58:52,000  那目前維生有任何想問的嗎?\n",
            "[ 78%] 00:58:52,000 → 00:58:56,000  或者也想分享看看你的想法也都可以。\n",
            "[ 79%] 00:59:00,000 → 00:59:09,440  我問個問題,就是之前不是有說你要開另外一個物理的帳號嗎?\n",
            "[ 79%] 00:59:09,440 → 00:59:11,440  嗯\n",
            "[ 79%] 00:59:11,440 → 00:59:20,000  就是我覺得應該要開另外一個跟英文獨立的帳號會比較好,不管你之後有沒有要掛e-mail的問題\n",
            "[ 79%] 00:59:20,000 → 00:59:22,000  我覺得分開會比較好\n",
            "[ 79%] 00:59:22,000 → 00:59:24,000  有原因嗎?\n",
            "[ 79%] 00:59:24,000 → 00:59:26,000  就是覺得分開會比較好\n",
            "[ 79%] 00:59:26,000 → 00:59:28,000  因為emote本來就是文科嘛\n",
            "[ 79%] 00:59:28,000 → 00:59:30,000  然後如果突然變成理科的話\n",
            "[ 79%] 00:59:30,000 → 00:59:32,000  就是你如果發的內容都混在一起\n",
            "[ 80%] 00:59:40,000 → 00:59:59,000  至少理科跟文科一個比較專業的分別,我會傾向把它分開,至少我看到這個帳號的時候我也知道它的專業是英文,這個帳號的專業是什麼,雖然它背後的人可能是同一批人。\n",
            "[ 80%] 01:00:00,000 → 01:00:02,000  我覺得它好像是不同的處理邏輯\n",
            "[ 80%] 01:00:02,000 → 01:00:04,000  就是我們現在如果把物理\n",
            "[ 80%] 01:00:04,000 → 01:00:06,000  它是兩種都是正確的狀況\n",
            "[ 80%] 01:00:06,000 → 01:00:08,000  然後我可能先跟你分享看看\n",
            "[ 80%] 01:00:08,000 → 01:00:10,000  要看你會不會有不同想法\n",
            "[ 80%] 01:00:20,000 → 01:00:25,000  如果是把講義掛到英文帳號的話\n",
            "[ 80%] 01:00:25,000 → 01:00:33,000  那其實是變成我們是幫助你在私領域去找客人\n",
            "[ 81%] 01:00:33,000 → 01:00:37,000  就是我們的瀏覽\n",
            "[ 81%] 01:00:37,000 → 01:00:40,000  我有做過一張圖秀給你看一下\n",
            "[ 81%] 01:00:40,000 → 01:00:48,300  就是我們的流量入口 IG的那些貼文就不太會真的去做物理專業知識相關的東西\n",
            "[ 81%] 01:00:48,300 → 01:00:52,580  那個就是真的跟英文真的太不相關\n",
            "[ 81%] 01:00:52,580 → 01:00:56,840  然後那個內容這樣跳來跳去也比較不符合學生的習慣\n",
            "[ 81%] 01:00:56,840 → 01:00:59,880  所以物理的專業知識不會\n",
            "[ 81%] 01:01:00,000 → 01:01:09,000  作為流量入口,我們的流量入口都會是以內容為主,只是那些流量進來之後\n",
            "[ 81%] 01:01:14,000 → 01:01:16,000  這邊沒有斷掉\n",
            "[ 82%] 01:01:20,000 → 01:01:34,080  他們還會被導到像是我們的節目或Line群然後限動\n",
            "[ 82%] 01:01:34,080 → 01:01:37,940  等於說是可能有6萬個追蹤者是追我們的IG\n",
            "[ 82%] 01:01:37,940 → 01:01:39,980  但是可能進入到死領域的\n",
            "[ 82%] 01:01:40,000 → 01:01:41,000  可能就只有一萬個\n",
            "[ 82%] 01:01:41,000 → 01:01:44,000  然後一萬個當中我們再想辦法幫你推銷\n",
            "[ 82%] 01:01:44,000 → 01:01:46,000  最後推銷出來\n",
            "[ 82%] 01:01:46,000 → 01:01:51,000  成交的數量就會比英文還要少\n",
            "[ 82%] 01:01:51,000 → 01:01:53,000  這是比較正常的狀況\n",
            "[ 82%] 01:01:53,000 → 01:01:55,000  但是相對來說\n",
            "[ 82%] 01:01:55,000 → 01:01:57,000  如果我們今天就開個全新的帳號\n",
            "[ 82%] 01:01:57,000 → 01:02:00,000  那我們那個全新的帳號也必須達到一定的粉絲級\n",
            "[ 82%] 01:02:00,000 → 01:02:02,760  才可以去平衡掉我剛剛說\n",
            "[ 82%] 01:02:02,760 → 01:02:04,800  比如說導到死領域的可能有一萬個\n",
            "[ 83%] 01:02:04,800 → 01:02:06,980  那就代表如果我們要重開一個帳號\n",
            "[ 83%] 01:02:06,980 → 01:02:10,300  那個帳號可能至少就要光靠自然科\n",
            "[ 83%] 01:02:10,300 → 01:02:14,060  光靠物理可能就要至少達到一萬個粉絲\n",
            "[ 83%] 01:02:14,060 → 01:02:16,220  它才會比較有機率\n",
            "[ 83%] 01:02:16,220 → 01:02:18,480  可以達到跟英文一樣的宣傳效果\n",
            "[ 83%] 01:02:18,480 → 01:02:19,980  就有點像我這邊\n",
            "[ 83%] 01:02:20,000 → 01:02:22,000  我沒有做一個圖\n",
            "[ 83%] 01:02:22,000 → 01:02:27,000  就是打開熱量漏斗的地方其實是我們會用英文去做\n",
            "[ 83%] 01:02:27,000 → 01:02:29,000  但是其他的這個地方\n",
            "[ 83%] 01:02:29,000 → 01:02:31,000  YouTube 跟 IG 限動\n",
            "[ 83%] 01:02:31,000 → 01:02:34,000  還有專業的一些課程\n",
            "[ 83%] 01:02:34,000 → 01:02:35,000  就是講義啊\n",
            "[ 83%] 01:02:35,000 → 01:02:38,000  然後現在是沒有在做直播跟團課啦\n",
            "[ 83%] 01:02:38,000 → 01:02:40,000  但是其他的一些專業的\n",
            "[ 83%] 01:02:40,000 → 01:02:46,600  像私訊的問題回答還有Line群的問題回答都會幫你的物理數據倒流\n",
            "[ 83%] 01:02:46,600 → 01:02:49,000  這樣你要懂意思嗎\n",
            "[ 84%] 01:02:49,000 → 01:03:00,000  但我剛意思其實是說如果你要發物理的文章的話或什麼東西的話我覺得就是要有另外一個帳號\n",
            "[ 84%] 01:03:00,000 → 01:03:02,000  喔對啊確實\n",
            "[ 84%] 01:03:02,000 → 01:03:06,000  可是誰要來發物理的文章\n",
            "[ 84%] 01:03:06,000 → 01:03:08,000  你會想要發物理的文章嗎\n",
            "[ 84%] 01:03:08,000 → 01:03:10,000  如果我有寫的話\n",
            "[ 84%] 01:03:10,000 → 01:03:14,000  或者就是你之前不是說要做一些奇怪的實驗\n",
            "[ 84%] 01:03:14,000 → 01:03:16,000  所以我不知道你要做什麼實驗\n",
            "[ 84%] 01:03:16,000 → 01:03:20,000  喔對啊我之前不是有傳給你一個\n",
            "[ 84%] 01:03:20,000 → 01:03:23,000  你有看過這個嗎?\n",
            "[ 84%] 01:03:23,000 → 01:03:25,000  你有傳給我嗎?\n",
            "[ 84%] 01:03:25,000 → 01:03:28,000  我傳在 Slack 啦\n",
            "[ 84%] 01:03:28,000 → 01:03:30,000  就是我們會\n",
            "[ 84%] 01:03:30,000 → 01:03:33,000  如果是我幫你做內容的話\n",
            "[ 84%] 01:03:33,000 → 01:03:35,000  我理想上會是\n",
            "[ 85%] 01:03:35,000 → 01:03:37,000  我找一下那個\n",
            "[ 85%] 01:03:37,000 → 01:03:39,000  如果是專業的物理知識\n",
            "[ 85%] 01:03:39,000 → 01:03:41,000  就會是需要你來幫忙\n",
            "[ 85%] 01:03:40,000 → 01:03:45,000  如果是我們幫你做內容可能會做的比較類似這種\n",
            "[ 85%] 01:03:45,000 → 01:03:47,000  欸這個\n",
            "[ 85%] 01:03:51,000 → 01:03:53,000  喔我有看到這個\n",
            "[ 85%] 01:03:54,000 → 01:03:58,000  喔就只能做的比較娛樂化一點\n",
            "[ 85%] 01:03:59,000 → 01:04:00,000  然後再把你放寡\n",
            "[ 85%] 01:04:00,000 → 01:04:02,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:02,000 → 01:04:04,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:04,000 → 01:04:06,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:06,000 → 01:04:08,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:08,000 → 01:04:10,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:10,000 → 01:04:12,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:12,000 → 01:04:14,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:14,000 → 01:04:16,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:16,000 → 01:04:18,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:18,000 → 01:04:20,000  如果你是開一個全新的賬號\n",
            "[ 86%] 01:04:20,000 → 01:04:24,600  其實會需要有穩定的內容才處理\n",
            "[ 86%] 01:04:24,600 → 01:04:29,600  就是你可能不能是想到文章再發\n",
            "[ 86%] 01:04:29,600 → 01:04:33,000  然後我們這邊就會是需要\n",
            "[ 86%] 01:04:33,000 → 01:04:35,800  每次都就是幫你去做布林的帖文\n",
            "[ 86%] 01:04:40,000 → 01:05:00,000  如果是掛在英文上的話,有時候就可以像我之前有給你看單字數的ChangeGPT,有時候我覺得把那個ChangeGPT放在英文,然後讓它流傳下去的話,像現在的ChangeGPT就有三千多個對話,然後如果三千多個對話,每一次對話都會有三千多個對話,\n",
            "[ 86%] 01:05:00,000 → 01:05:02,000  如果有一個肯定的廣告的話\n",
            "[ 86%] 01:05:02,000 → 01:05:04,000  我覺得導流效果也蠻不錯的\n",
            "[ 86%] 01:05:04,000 → 01:05:06,000  所以這個可以再想想看\n",
            "[ 87%] 01:05:06,000 → 01:05:08,000  但如果你會希望\n",
            "[ 87%] 01:05:08,000 → 01:05:10,000  開個線上號\n",
            "[ 87%] 01:05:10,000 → 01:05:12,000  然後希望可以做一些\n",
            "[ 87%] 01:05:12,000 → 01:05:14,000  專門輸入的內容\n",
            "[ 87%] 01:05:14,000 → 01:05:16,000  我覺得也沒有問題\n",
            "[ 87%] 01:05:16,000 → 01:05:18,000  但是我們之後可以再一起把細節\n",
            "[ 87%] 01:05:18,000 → 01:05:20,000  就是我可以\n",
            "[ 87%] 01:05:20,000 → 01:05:22,500  直接先開帳號,然後可能先做做看\n",
            "[ 87%] 01:05:22,500 → 01:05:24,400  然後再告訴你有沒有困難的點\n",
            "[ 87%] 01:05:25,700 → 01:05:28,600  那如果你現在要發一個立刻的東西\n",
            "[ 87%] 01:05:28,600 → 01:05:29,800  你是要發在哪邊?\n",
            "[ 87%] 01:05:32,100 → 01:05:34,100  現在要發一個立刻的東西\n",
            "[ 87%] 01:05:34,800 → 01:05:38,100  就是如果你沒有打算再開一個行政帳號的話\n",
            "[ 87%] 01:05:38,700 → 01:05:40,100  啊,立刻的東西\n",
            "[ 88%] 01:05:40,000 → 01:05:59,380  我就會把他放在YouTube的影片,我會幫你講,然後再用IG去引導學生去YouTube的影片,然後會是IG行動,還有Threads的,在Threads上面我就不會教物理,而是我會直接\n",
            "[ 88%] 01:06:00,000 → 01:06:06,800  丟免費的工具給學生,然後讓那個免費的工具自己下去學生之間流傳。\n",
            "[ 88%] 01:06:06,800 → 01:06:16,360  比如說你的事業檔案,那就算是一種免費的工具。\n",
            "[ 88%] 01:06:16,360 → 01:06:17,240  大概理解。\n",
            "[ 88%] 01:06:20,000 → 01:06:27,000  還有你的商品掛在蝦皮機就會有一定的流量\n",
            "[ 88%] 01:06:27,000 → 01:06:33,000  因為我們賣場也會有既定的客源進來\n",
            "[ 89%] 01:06:33,000 → 01:06:38,000  還有LINE群\n",
            "[ 89%] 01:06:38,000 → 01:06:40,000  LINE群會有選手喔\n",
            "[ 89%] 01:06:40,000 → 01:06:42,760  喔對之前有講到Live群\n",
            "[ 89%] 01:06:42,760 → 01:06:46,940  所以現在是有學生在問物理的問題嗎\n",
            "[ 89%] 01:06:46,940 → 01:06:48,360  還是還沒有\n",
            "[ 89%] 01:06:48,360 → 01:06:49,620  還沒有\n",
            "[ 89%] 01:06:49,620 → 01:06:55,740  可能我們也還沒有引導他們去問物理的\n",
            "[ 89%] 01:06:55,740 → 01:06:59,980  你現在有在這個群組\n",
            "[ 89%] 01:07:00,000 → 01:07:14,400  還有其他問題呢?\n",
            "[ 89%] 01:07:18,400 → 01:07:20,400  這部分應該就到這裡了\n",
            "[ 90%] 01:07:20,000 → 01:07:26,100  然後我提問一下,這是你的公司名稱嗎?\n",
            "[ 90%] 01:07:27,140 → 01:07:31,000  公司名稱是成學文教有限公司,\n",
            "[ 90%] 01:07:31,600 → 01:07:33,840  陰謀比較像是品牌名稱。\n",
            "[ 90%] 01:07:33,840 → 01:07:36,540  所以那你的陰謀是申請商標嗎?\n",
            "[ 90%] 01:07:37,420 → 01:07:38,000  我是好奇。\n",
            "[ 90%] 01:07:40,000 → 01:07:42,000  喔好\n",
            "[ 90%] 01:07:42,000 → 01:07:45,820  你要搶住嗎\n",
            "[ 90%] 01:07:45,820 → 01:07:47,420  我都沒想到\n",
            "[ 90%] 01:07:47,420 → 01:07:49,880  惡意搶住\n",
            "[ 90%] 01:07:49,880 → 01:07:53,340  你是學了民法之後學壞了是不是\n",
            "[ 90%] 01:07:53,340 → 01:07:57,720  我好像記得有的是法律系\n",
            "[ 90%] 01:07:57,720 → 01:08:00,000  我是法律系\n",
            "[ 90%] 01:08:00,000 → 01:08:05,000  好\n",
            "[ 91%] 01:08:05,000 → 01:08:07,700  那應該沒有其他問題耶\n",
            "[ 91%] 01:08:07,700 → 01:08:08,940  好\n",
            "[ 91%] 01:08:08,940 → 01:08:10,620  你應該沒有\n",
            "[ 91%] 01:08:10,620 → 01:08:12,160  打算先註冊對吧\n",
            "[ 91%] 01:08:12,160 → 01:08:12,660  沒有沒有\n",
            "[ 91%] 01:08:12,660 → 01:08:13,460  OKOK\n",
            "[ 91%] 01:08:13,460 → 01:08:15,180  有點麻煩\n",
            "[ 91%] 01:08:15,180 → 01:08:16,300  沒有想要做這種事\n",
            "[ 91%] 01:08:20,000 → 01:08:28,000  如果沒有的話,我們今天會先到這邊喔。\n",
            "[ 91%] 01:08:28,000 → 01:08:30,000  好。\n",
            "[ 91%] 01:08:30,000 → 01:08:32,000  好,辛苦了,謝謝你。\n",
            "[ 91%] 01:08:32,000 → 01:08:34,000  掰掰。\n",
            "[ 91%] 01:08:34,000 → 01:08:36,000  掰掰。\n",
            "[ 91%] 01:08:40,000 → 01:08:49,860  我要影片嗎?想要影片?\n",
            "[ 91%] 01:08:50,000 → 01:08:51,440  我有,好,我再傳\n",
            "[ 92%] 01:08:51,440 → 01:08:53,280  做完可以改AI\n",
            "[ 92%] 01:08:53,280 → 01:08:54,060  OK\n",
            "[ 92%] 01:08:54,060 → 01:08:57,760  為什麼我媽留著?\n",
            "[ 92%] 01:08:57,860 → 01:08:59,320  我媽有什麼事情要討論嗎?\n",
            "[ 92%] 01:09:00,000 → 01:09:02,000  沒有啊\n",
            "[ 92%] 01:09:02,000 → 01:09:04,000  那我先撤囉\n",
            "[ 92%] 01:09:04,000 → 01:09:05,000  好嘞\n",
            "[ 92%] 01:09:05,000 → 01:09:08,000  我會去玩國粹職之後再去你那邊喔\n",
            "[ 92%] 01:09:08,000 → 01:09:09,000  好喔沒問題\n",
            "[ 92%] 01:09:09,000 → 01:09:10,000  你就直接進來就好\n",
            "[ 92%] 01:09:10,000 → 01:09:11,000  我會穿褲子\n",
            "[ 92%] 01:09:11,000 → 01:09:12,000  好掰掰\n",
            "[ 92%] 01:09:12,000 → 01:09:14,000  好掰掰\n",
            "[ 92%] 01:09:16,000 → 01:09:17,000  拜啦老孫\n",
            "[ 92%] 01:09:17,000 → 01:09:19,000  你剛聽起來有什麼問題嗎\n",
            "[ 92%] 01:09:20,000 → 01:09:26,000  沒有,但是我想到有很嚴重的事情要做\n",
            "[ 92%] 01:09:26,000 → 01:09:27,400  你說?\n",
            "[ 92%] 01:09:27,400 → 01:09:32,240  就是那個那個那個那個常常需要驗證的問題\n",
            "[ 92%] 01:09:32,240 → 01:09:35,760  我們現在把它解決掉了嘛\n",
            "[ 92%] 01:09:35,760 → 01:09:37,360  會很久嗎?\n",
            "[ 93%] 01:09:37,360 → 01:09:39,960  不會不會\n",
            "[ 93%] 01:09:40,000 → 01:09:50,000  比較就是我開個分享的分享分享\n",
            "[ 93%] 01:09:50,000 → 01:09:54,000  我的IG快快的\n",
            "[ 93%] 01:09:54,000 → 01:09:58,000  你的IG快快的\n",
            "[ 93%] 01:09:58,000 → 01:10:00,000  等一下你說\n",
            "[ 93%] 01:10:00,000 → 01:10:19,940  我來新增一下,因為目前都是要發去你的手機,然後\n",
            "[ 93%] 01:10:20,000 → 01:10:23,000  你的手機去做驗證嗎?\n",
            "[ 94%] 01:10:23,000 → 01:10:24,000  嗯\n",
            "[ 94%] 01:10:24,000 → 01:10:29,000  對 然後我是想說就是我們直接來進入這個\n",
            "[ 94%] 01:10:29,000 → 01:10:33,000  就是我們直接弄一個這個動態驗證嘛\n",
            "[ 94%] 01:10:33,000 → 01:10:34,000  就是它可以\n",
            "[ 94%] 01:10:34,000 → 01:10:35,000  原來我們有這個東西啊\n",
            "[ 94%] 01:10:35,000 → 01:10:36,000  蛤?\n",
            "[ 94%] 01:10:36,000 → 01:10:38,000  我們有這個東西啊\n",
            "[ 94%] 01:10:38,000 → 01:10:40,000  你們有這個東西\n",
            "[ 94%] 01:10:40,000 → 01:10:44,000  不是不是不是 不是我們有動態驗證碼\n",
            "[ 94%] 01:10:44,000 → 01:10:48,000  你們有動態驗證碼 可是我在帳號裡面沒看到你\n",
            "[ 94%] 01:10:48,000 → 01:10:52,000  因為我們是綁openai跟ig消息\n",
            "[ 94%] 01:10:52,000 → 01:10:56,000  那你這個要不要綁一下 可以可以 四十嗎\n",
            "[ 94%] 01:10:56,000 → 01:11:00,000  不然我每次半夜在搞東西\n",
            "[ 94%] 01:11:00,000 → 01:11:02,000  都會卡住\n",
            "[ 94%] 01:11:02,000 → 01:11:04,000  好有嗎?\n",
            "[ 94%] 01:11:04,000 → 01:11:06,000  有啊它進去了\n",
            "[ 94%] 01:11:06,000 → 01:11:08,000  等等等\n",
            "[ 95%] 01:11:08,000 → 01:11:10,000  那我現在新增一個然後截圖給你們\n",
            "[ 95%] 01:11:10,000 → 01:11:12,000  沒有好等一下我直接\n",
            "[ 95%] 01:11:12,000 → 01:11:14,000  我只新增\n",
            "[ 95%] 01:11:14,000 → 01:11:16,000  沒有我是截個圖啊\n",
            "[ 95%] 01:11:16,000 → 01:11:18,000  它不是會一直跑嗎?\n",
            "[ 95%] 01:11:18,000 → 01:11:20,000  它一直都會跑啊\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  沒有沒有這個不會\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  這個圖不會\n",
            "[ 95%] 01:11:22,000 → 01:11:24,000  這個圖不會 為什麼\n",
            "[ 95%] 01:11:24,000 → 01:11:26,000  因為它跑的不是這個圖\n",
            "[ 95%] 01:11:26,000 → 01:11:28,000  它跑的是這個圖裡面有精藥\n",
            "[ 95%] 01:11:28,000 → 01:11:30,000  然後它會根據這個精藥\n",
            "[ 95%] 01:11:30,000 → 01:11:32,000  加上時間\n",
            "[ 95%] 01:11:32,000 → 01:11:34,000  那個數字不是一直都會跑嗎\n",
            "[ 95%] 01:11:34,000 → 01:11:36,000  對 但是這個圖不會跑\n",
            "[ 95%] 01:11:38,000 → 01:11:40,000  對 它是用這個圖加上時間去\n",
            "[ 95%] 01:11:40,000 → 01:11:42,000  你去算出那個數字\n",
            "[ 95%] 01:11:42,000 → 01:11:44,000  這樣這樣\n",
            "[ 95%] 01:11:45,120 → 01:11:47,120  那我要放在notion裡面了\n",
            "[ 95%] 01:11:48,580 → 01:11:50,580  這樣會太危險嗎\n",
            "[ 95%] 01:11:50,580 → 01:11:52,580  你直接幫我查個指名好不好\n",
            "[ 96%] 01:11:54,840 → 01:11:56,840  等等等等等等\n",
            "[ 96%] 01:11:56,840 → 01:11:58,840  等等喔\n",
            "[ 96%] 01:11:58,840 → 01:12:00,840  我要建個頻道\n",
            "[ 96%] 01:12:00,000 → 01:12:02,000  你用平常名稱叫什麼?\n",
            "[ 96%] 01:12:04,000 → 01:12:06,000  工程部門\n",
            "[ 96%] 01:12:15,000 → 01:12:18,000  為什麼你現在用的那個Gmail是你自己的嗎?\n",
            "[ 96%] 01:12:18,000 → 01:12:20,000  你幫我貼在那個工程部門\n",
            "[ 97%] 01:12:20,000 → 01:12:40,000  我哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋\n",
            "[ 97%] 01:12:40,000 → 01:12:40,840  還是你本來就有在用?\n",
            "[ 97%] 01:12:40,840 → 01:12:41,340  沒有啊\n",
            "[ 97%] 01:12:42,000 → 01:12:43,840  那是我的主力帳號啊\n",
            "[ 97%] 01:12:43,840 → 01:12:45,160  因為這個帳號\n",
            "[ 97%] 01:12:45,160 → 01:12:46,460  幼稚園的時候就創了\n",
            "[ 97%] 01:12:46,460 → 01:12:48,500  所以那個名字是亂打的\n",
            "[ 97%] 01:12:49,340 → 01:12:50,000  打動了\n",
            "[ 97%] 01:12:55,800 → 01:12:58,500  啊你剛剛那個婚姻紀錄有開完嗎?\n",
            "[ 97%] 01:12:58,840 → 01:12:59,340  你有打動嗎?\n",
            "[ 97%] 01:12:59,340 → 01:12:59,840  有有有\n",
            "[ 97%] 01:13:00,000 → 01:13:04,600  你可能要跟他講一下那個東西是幹嘛的\n",
            "[ 97%] 01:13:04,600 → 01:13:09,700  就是你傳到工程部門那個東西是幹嘛的\n",
            "[ 97%] 01:13:09,700 → 01:13:10,760  他可能不太知道\n",
            "[ 97%] 01:13:10,760 → 01:13:14,520  他拿iPhone還安儲\n",
            "[ 97%] 01:13:14,520 → 01:13:16,060  他拿iPhone\n",
            "[ 98%] 01:13:20,000 → 01:13:24,000  好了,我們要去尿尿,然後我要出發了,bye!\n",
            "[ 98%] 01:13:25,280 → 01:13:25,520  好\n",
            "[ 98%] 01:13:25,520 → 01:13:29,780  下午的會議如果需要你,我再call你進來可以嗎?\n",
            "[ 98%] 01:13:34,400 → 01:13:35,080  可以嗎?\n",
            "[ 98%] 01:13:37,020 → 01:13:39,540  哇,那我怎麼知道你什麼時候要call我進來?\n",
            "[ 98%] 01:13:40,000 → 01:13:42,800  好吧,那你就去忙,你就去做你自己的生意\n",
            "[ 98%] 01:13:42,800 → 01:13:43,800  如果你剛好有\n",
            "[ 98%] 01:13:43,800 → 01:13:45,600  我可以進來沒關係啊\n",
            "[ 98%] 01:13:45,600 → 01:13:47,100  好,那你就順便停\n",
            "[ 98%] 01:13:47,100 → 01:13:49,140  OK,好,Bye\n",
            "[ 98%] 01:13:49,140 → 01:13:52,360  2點啊,2點到4點\n",
            "[ 98%] 01:13:52,360 → 01:13:53,180  好\n",
            "[ 98%] 01:13:53,180 → 01:13:53,840  再見\n",
            "[ 99%] 01:14:00,000 → 01:14:29,980  Teksting av Nicolai Winther\n",
            "[ 99%] 01:14:20,000 → 01:14:49,980  Takk for att du så med.\n",
            "[100%] 01:14:40,000 → 01:15:09,980  Teksting av Nicolai Winther\n",
            "[100%] 01:15:00,000 → 01:15:29,980  Teksting av Nicolai Winther\n",
            "[8/8] 輸出 SRT / TXT ...\n",
            "→ 完成！\n",
            "  SRT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).srt\n",
            "  TXT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f145246fe0c4ec39d57b620556528d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_load_from_file_impl: using device CUDA0 (Tesla T4) - 14974 MiB free\n",
            "llama_model_loader: loaded meta data with 37 key-value pairs and 459 tensors from /root/.cache/huggingface/hub/models--unsloth--gpt-oss-20b-GGUF/snapshots/c6cedd4259adbfe7e4d4d983a0400bf4cc38e7db/gpt-oss-20b-Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gpt-oss\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   3:                           general.basename str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   4:                       general.quantized_by str              = Unsloth\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 20B\n",
            "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
            "llama_model_loader: - kv   7:                           general.repo_url str              = https://huggingface.co/unsloth\n",
            "llama_model_loader: - kv   8:                               general.tags arr[str,2]       = [\"vllm\", \"text-generation\"]\n",
            "llama_model_loader: - kv   9:                        gpt-oss.block_count u32              = 24\n",
            "llama_model_loader: - kv  10:                     gpt-oss.context_length u32              = 131072\n",
            "llama_model_loader: - kv  11:                   gpt-oss.embedding_length u32              = 2880\n",
            "llama_model_loader: - kv  12:                gpt-oss.feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  13:               gpt-oss.attention.head_count u32              = 64\n",
            "llama_model_loader: - kv  14:            gpt-oss.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  15:                     gpt-oss.rope.freq_base f32              = 150000.000000\n",
            "llama_model_loader: - kv  16:   gpt-oss.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  17:                       gpt-oss.expert_count u32              = 32\n",
            "llama_model_loader: - kv  18:                  gpt-oss.expert_used_count u32              = 4\n",
            "llama_model_loader: - kv  19:               gpt-oss.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  20:             gpt-oss.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  21:           gpt-oss.attention.sliding_window u32              = 128\n",
            "llama_model_loader: - kv  22:         gpt-oss.expert_feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  23:                  gpt-oss.rope.scaling.type str              = yarn\n",
            "llama_model_loader: - kv  24:                gpt-oss.rope.scaling.factor f32              = 32.000000\n",
            "llama_model_loader: - kv  25: gpt-oss.rope.scaling.original_context_length u32              = 4096\n",
            "llama_model_loader: - kv  26:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  27:                         tokenizer.ggml.pre str              = gpt-4o\n",
            "llama_model_loader: - kv  28:                      tokenizer.ggml.tokens arr[str,201088]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  29:                  tokenizer.ggml.token_type arr[i32,201088]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  30:                      tokenizer.ggml.merges arr[str,446189]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  31:                tokenizer.ggml.bos_token_id u32              = 199998\n",
            "llama_model_loader: - kv  32:                tokenizer.ggml.eos_token_id u32              = 200002\n",
            "llama_model_loader: - kv  33:            tokenizer.ggml.padding_token_id u32              = 200017\n",
            "llama_model_loader: - kv  34:                    tokenizer.chat_template str              = {# Chat template fixes by Unsloth #}\\n...\n",
            "llama_model_loader: - kv  35:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  36:                          general.file_type u32              = 15\n",
            "llama_model_loader: - type  f32:  289 tensors\n",
            "llama_model_loader: - type q5_0:   61 tensors\n",
            "llama_model_loader: - type q8_0:   13 tensors\n",
            "llama_model_loader: - type q4_K:   24 tensors\n",
            "llama_model_loader: - type mxfp4:   72 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 10.81 GiB (4.44 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 200017 '<|reserved_200017|>' is not marked as EOG\n",
            "load: control token: 200014 '<|reserved_200014|>' is not marked as EOG\n",
            "load: control token: 200011 '<|reserved_200011|>' is not marked as EOG\n",
            "load: control token: 200009 '<|reserved_200009|>' is not marked as EOG\n",
            "load: control token: 200008 '<|message|>' is not marked as EOG\n",
            "load: control token: 200006 '<|start|>' is not marked as EOG\n",
            "load: control token: 200004 '<|reserved_200004|>' is not marked as EOG\n",
            "load: control token: 200003 '<|constrain|>' is not marked as EOG\n",
            "load: control token: 200000 '<|reserved_200000|>' is not marked as EOG\n",
            "load: control token: 200005 '<|channel|>' is not marked as EOG\n",
            "load: control token: 200010 '<|reserved_200010|>' is not marked as EOG\n",
            "load: control token: 200016 '<|reserved_200016|>' is not marked as EOG\n",
            "load: control token: 200013 '<|reserved_200013|>' is not marked as EOG\n",
            "load: control token: 199998 '<|startoftext|>' is not marked as EOG\n",
            "load: control token: 200018 '<|endofprompt|>' is not marked as EOG\n",
            "load: control token: 200001 '<|reserved_200001|>' is not marked as EOG\n",
            "load: control token: 200015 '<|reserved_200015|>' is not marked as EOG\n",
            "load: printing all EOG tokens:\n",
            "load:   - 199999 ('<|endoftext|>')\n",
            "load:   - 200002 ('<|return|>')\n",
            "load:   - 200007 ('<|end|>')\n",
            "load:   - 200012 ('<|call|>')\n",
            "load: special_eog_ids contains both '<|return|>' and '<|call|>' tokens, removing '<|end|>' token from EOG list\n",
            "load: special tokens cache size = 21\n",
            "load: token to piece cache size = 1.3332 MB\n",
            "print_info: arch             = gpt-oss\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 131072\n",
            "print_info: n_embd           = 2880\n",
            "print_info: n_layer          = 24\n",
            "print_info: n_head           = 64\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 64\n",
            "print_info: n_swa            = 128\n",
            "print_info: is_swa_any       = 1\n",
            "print_info: n_embd_head_k    = 64\n",
            "print_info: n_embd_head_v    = 64\n",
            "print_info: n_gqa            = 8\n",
            "print_info: n_embd_k_gqa     = 512\n",
            "print_info: n_embd_v_gqa     = 512\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 2880\n",
            "print_info: n_expert         = 32\n",
            "print_info: n_expert_used    = 4\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 2\n",
            "print_info: rope scaling     = yarn\n",
            "print_info: freq_base_train  = 150000.0\n",
            "print_info: freq_scale_train = 0.03125\n",
            "print_info: n_ctx_orig_yarn  = 4096\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = ?B\n",
            "print_info: model params     = 20.91 B\n",
            "print_info: general.name     = Gpt-Oss-20B\n",
            "print_info: n_ff_exp         = 2880\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 201088\n",
            "print_info: n_merges         = 446189\n",
            "print_info: BOS token        = 199998 '<|startoftext|>'\n",
            "print_info: EOS token        = 200002 '<|return|>'\n",
            "print_info: EOT token        = 199999 '<|endoftext|>'\n",
            "print_info: PAD token        = 200017 '<|reserved_200017|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 199999 '<|endoftext|>'\n",
            "print_info: EOG token        = 200002 '<|return|>'\n",
            "print_info: EOG token        = 200012 '<|call|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   1 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   3 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   5 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   7 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   9 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  11 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  13 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  15 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  17 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  19 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  21 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  23 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q5_0) (and 0 others) cannot be used with preferred buffer type CUDA_Host, using CPU instead\n",
            "load_tensors: offloading 24 repeating layers to GPU\n",
            "load_tensors: offloading output layer to GPU\n",
            "load_tensors: offloaded 25/25 layers to GPU\n",
            "load_tensors:        CUDA0 model buffer size = 10694.15 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =   379.71 MiB\n",
            "...............................................................................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 8192\n",
            "llama_context: n_ctx_per_seq = 8192\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 150000.0\n",
            "llama_context: freq_scale    = 0.03125\n",
            "llama_context: n_ctx_per_seq (8192) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:  CUDA_Host  output buffer size =     0.77 MiB\n",
            "create_memory: n_ctx = 8192 (padded)\n",
            "llama_kv_cache_unified_iswa: using full-size SWA cache (ref: https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)\n",
            "llama_kv_cache_unified_iswa: creating non-SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: skipped\n",
            "llama_kv_cache_unified: layer   1: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   2: skipped\n",
            "llama_kv_cache_unified: layer   3: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   4: skipped\n",
            "llama_kv_cache_unified: layer   5: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   6: skipped\n",
            "llama_kv_cache_unified: layer   7: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   8: skipped\n",
            "llama_kv_cache_unified: layer   9: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  10: skipped\n",
            "llama_kv_cache_unified: layer  11: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  12: skipped\n",
            "llama_kv_cache_unified: layer  13: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  14: skipped\n",
            "llama_kv_cache_unified: layer  15: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  16: skipped\n",
            "llama_kv_cache_unified: layer  17: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  18: skipped\n",
            "llama_kv_cache_unified: layer  19: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  20: skipped\n",
            "llama_kv_cache_unified: layer  21: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  22: skipped\n",
            "llama_kv_cache_unified: layer  23: dev = CUDA0\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_kv_cache_unified_iswa: creating     SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   1: skipped\n",
            "llama_kv_cache_unified: layer   2: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   3: skipped\n",
            "llama_kv_cache_unified: layer   4: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   5: skipped\n",
            "llama_kv_cache_unified: layer   6: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   7: skipped\n",
            "llama_kv_cache_unified: layer   8: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   9: skipped\n",
            "llama_kv_cache_unified: layer  10: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  11: skipped\n",
            "llama_kv_cache_unified: layer  12: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  13: skipped\n",
            "llama_kv_cache_unified: layer  14: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  15: skipped\n",
            "llama_kv_cache_unified: layer  16: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  17: skipped\n",
            "llama_kv_cache_unified: layer  18: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  19: skipped\n",
            "llama_kv_cache_unified: layer  20: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  21: skipped\n",
            "llama_kv_cache_unified: layer  22: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  23: skipped\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 2\n",
            "llama_context: max_nodes = 3672\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "llama_context:      CUDA0 compute buffer size =  1087.26 MiB\n",
            "llama_context:  CUDA_Host compute buffer size =    41.64 MiB\n",
            "llama_context: graph nodes  = 1446\n",
            "llama_context: graph splits = 2\n",
            "CUDA : ARCHS = 500,520,530,600,610,620,700,720,750,800,860,870,890,900 | FORCE_MMQ = 1 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'general.file_type': '15', 'general.quantization_version': '2', 'tokenizer.chat_template': '{# Chat template fixes by Unsloth #}\\n{#-\\n  In addition to the normal inputs of `messages` and `tools`, this template also accepts the\\n  following kwargs:\\n  - \"builtin_tools\": A list, can contain \"browser\" and/or \"python\".\\n  - \"model_identity\": A string that optionally describes the model identity.\\n  - \"reasoning_effort\": A string that describes the reasoning effort, defaults to \"medium\".\\n #}\\n\\n{#- Tool Definition Rendering ============================================== #}\\n{%- macro render_typescript_type(param_spec, required_params, is_nullable=false) -%}\\n    {%- if param_spec.type == \"array\" -%}\\n        {%- if param_spec[\\'items\\'] -%}\\n            {%- if param_spec[\\'items\\'][\\'type\\'] == \"string\" -%}\\n                {{- \"string[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"number\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"integer\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"boolean\" -%}\\n                {{- \"boolean[]\" }}\\n            {%- else -%}\\n                {%- set inner_type = render_typescript_type(param_spec[\\'items\\'], required_params) -%}\\n                {%- if inner_type == \"object | object\" or inner_type|length > 50 -%}\\n                    {{- \"any[]\" }}\\n                {%- else -%}\\n                    {{- inner_type + \"[]\" }}\\n                {%- endif -%}\\n            {%- endif -%}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- else -%}\\n            {{- \"any[]\" }}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type is defined and param_spec.type is iterable and param_spec.type is not string and param_spec.type is not mapping and param_spec.type[0] is defined -%}\\n        {#- Handle array of types like [\"object\", \"object\"] from Union[dict, list] #}\\n        {%- if param_spec.type | length > 1 -%}\\n            {{- param_spec.type | join(\" | \") }}\\n        {%- else -%}\\n            {{- param_spec.type[0] }}\\n        {%- endif -%}\\n    {%- elif param_spec.oneOf -%}\\n        {#- Handle oneOf schemas - check for complex unions and fallback to any #}\\n        {%- set has_object_variants = false -%}\\n        {%- for variant in param_spec.oneOf -%}\\n            {%- if variant.type == \"object\" -%}\\n                {%- set has_object_variants = true -%}\\n            {%- endif -%}\\n        {%- endfor -%}\\n        {%- if has_object_variants and param_spec.oneOf|length > 1 -%}\\n            {{- \"any\" }}\\n        {%- else -%}\\n            {%- for variant in param_spec.oneOf -%}\\n                {{- render_typescript_type(variant, required_params) -}}\\n                {%- if variant.description %}\\n                    {{- \"// \" + variant.description }}\\n                {%- endif -%}\\n                {%- if variant.default is defined %}\\n                    {{ \"// default: \" + variant.default|tojson }}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \" | \" }}\\n                {% endif -%}\\n            {%- endfor -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"string\" -%}\\n        {%- if param_spec.enum -%}\\n            {{- \\'\"\\' + param_spec.enum|join(\\'\" | \"\\') + \\'\"\\' -}}\\n        {%- else -%}\\n            {{- \"string\" }}\\n            {%- if param_spec.nullable %}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"number\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"integer\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"boolean\" -%}\\n        {{- \"boolean\" }}\\n\\n    {%- elif param_spec.type == \"object\" -%}\\n        {%- if param_spec.properties -%}\\n            {{- \"{\\\\n\" }}\\n            {%- for prop_name, prop_spec in param_spec.properties.items() -%}\\n                {{- prop_name -}}\\n                {%- if prop_name not in (param_spec.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{ render_typescript_type(prop_spec, param_spec.required or []) }}\\n                {%- if not loop.last -%}\\n                    {{-\", \" }}\\n                {%- endif -%}\\n            {%- endfor -%}\\n            {{- \"}\" }}\\n        {%- else -%}\\n            {{- \"object\" }}\\n        {%- endif -%}\\n    {%- else -%}\\n        {{- \"any\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{%- macro render_tool_namespace(namespace_name, tools) -%}\\n    {{- \"## \" + namespace_name + \"\\\\n\\\\n\" }}\\n    {{- \"namespace \" + namespace_name + \" {\\\\n\\\\n\" }}\\n    {%- for tool in tools %}\\n        {%- set tool = tool.function %}\\n        {{- \"// \" + tool.description + \"\\\\n\" }}\\n        {{- \"type \"+ tool.name + \" = \" }}\\n        {%- if tool.parameters and tool.parameters.properties %}\\n            {{- \"(_: {\\\\n\" }}\\n            {%- for param_name, param_spec in tool.parameters.properties.items() %}\\n                {%- if param_spec.description %}\\n                    {{- \"// \" + param_spec.description + \"\\\\n\" }}\\n                {%- endif %}\\n                {{- param_name }}\\n                {%- if param_name not in (tool.parameters.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{- render_typescript_type(param_spec, tool.parameters.required or []) }}\\n                {%- if param_spec.default is defined -%}\\n                    {%- if param_spec.enum %}\\n                        {{- \", // default: \" + param_spec.default }}\\n                    {%- elif param_spec.oneOf %}\\n                        {{- \"// default: \" + param_spec.default }}\\n                    {%- else %}\\n                        {{- \", // default: \" + param_spec.default|tojson }}\\n                    {%- endif -%}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \",\\\\n\" }}\\n                {%- else %}\\n                    {{- \",\\\\n\" }}\\n                {%- endif -%}\\n            {%- endfor %}\\n            {{- \"}) => any;\\\\n\\\\n\" }}\\n        {%- else -%}\\n            {{- \"() => any;\\\\n\\\\n\" }}\\n        {%- endif -%}\\n    {%- endfor %}\\n    {{- \"} // namespace \" + namespace_name }}\\n{%- endmacro -%}\\n\\n{%- macro render_builtin_tools(browser_tool, python_tool) -%}\\n    {%- if browser_tool %}\\n        {{- \"## browser\\\\n\\\\n\" }}\\n        {{- \"// Tool for browsing.\\\\n\" }}\\n        {{- \"// The `cursor` appears in brackets before each browsing display: `[{cursor}]`.\\\\n\" }}\\n        {{- \"// Cite information from the tool using the following format:\\\\n\" }}\\n        {{- \"// `【{cursor}†L{line_start}(-L{line_end})?】`, for example: `【6†L9-L11】` or `【8†L3】`.\\\\n\" }}\\n        {{- \"// Do not quote more than 10 words directly from the tool output.\\\\n\" }}\\n        {{- \"// sources=web (default: web)\\\\n\" }}\\n        {{- \"namespace browser {\\\\n\\\\n\" }}\\n        {{- \"// Searches for information related to `query` and displays `topn` results.\\\\n\" }}\\n        {{- \"type search = (_: {\\\\n\" }}\\n        {{- \"query: string,\\\\n\" }}\\n        {{- \"topn?: number, // default: 10\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Opens the link `id` from the page indicated by `cursor` starting at line number `loc`, showing `num_lines` lines.\\\\n\" }}\\n        {{- \"// Valid link ids are displayed with the formatting: `【{id}†.*】`.\\\\n\" }}\\n        {{- \"// If `cursor` is not provided, the most recent page is implied.\\\\n\" }}\\n        {{- \"// If `id` is a string, it is treated as a fully qualified URL associated with `source`.\\\\n\" }}\\n        {{- \"// If `loc` is not provided, the viewport will be positioned at the beginning of the document or centered on the most relevant passage, if available.\\\\n\" }}\\n        {{- \"// Use this function without `id` to scroll to a new location of an opened page.\\\\n\" }}\\n        {{- \"type open = (_: {\\\\n\" }}\\n        {{- \"id?: number | string, // default: -1\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"loc?: number, // default: -1\\\\n\" }}\\n        {{- \"num_lines?: number, // default: -1\\\\n\" }}\\n        {{- \"view_source?: boolean, // default: false\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Finds exact matches of `pattern` in the current page, or the page given by `cursor`.\\\\n\" }}\\n        {{- \"type find = (_: {\\\\n\" }}\\n        {{- \"pattern: string,\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"} // namespace browser\\\\n\\\\n\" }}\\n    {%- endif -%}\\n\\n    {%- if python_tool %}\\n        {{- \"## python\\\\n\\\\n\" }}\\n        {{- \"Use this tool to execute Python code in your chain of thought. The code will not be shown to the user. This tool should be used for internal reasoning, but not for code that is intended to be visible to the user (e.g. when creating plots, tables, or files).\\\\n\\\\n\" }}\\n        {{- \"When you send a message containing Python code to python, it will be executed in a stateful Jupyter notebook environment. python will respond with the output of the execution or time out after 120.0 seconds. The drive at \\'/mnt/data\\' can be used to save and persist user files. Internet access for this session is UNKNOWN. Depends on the cluster.\\\\n\\\\n\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- System Message Construction ============================================ #}\\n{%- macro build_system_message() -%}\\n    {%- if model_identity is not defined %}\\n        {%- set model_identity = \"You are ChatGPT, a large language model trained by OpenAI.\" %}\\n    {%- endif %}\\n    {{- model_identity + \"\\\\n\" }}\\n    {{- \"Knowledge cutoff: 2024-06\\\\n\" }}\\n    {{- \"Current date: \" + strftime_now(\"%Y-%m-%d\") + \"\\\\n\\\\n\" }}\\n    {%- if reasoning_effort is not defined %}\\n        {%- set reasoning_effort = \"medium\" %}\\n    {%- endif %}\\n    {{- \"Reasoning: \" + reasoning_effort + \"\\\\n\\\\n\" }}\\n    {%- if builtin_tools is defined and builtin_tools is not none %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {%- set available_builtin_tools = namespace(browser=false, python=false) %}\\n        {%- for tool in builtin_tools %}\\n            {%- if tool == \"browser\" %}\\n                {%- set available_builtin_tools.browser = true %}\\n            {%- elif tool == \"python\" %}\\n                {%- set available_builtin_tools.python = true %}\\n            {%- endif %}\\n        {%- endfor %}\\n        {{- render_builtin_tools(available_builtin_tools.browser, available_builtin_tools.python) }}\\n    {%- endif -%}\\n    {{- \"# Valid channels: analysis, commentary, final. Channel must be included for every message.\" }}\\n    {%- if tools -%}\\n        {{- \"\\\\nCalls to these tools must go to the commentary channel: \\'functions\\'.\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- Main Template Logic ================================================= #}\\n{#- Set defaults #}\\n\\n{#- Render system message #}\\n{{- \"<|start|>system<|message|>\" }}\\n{{- build_system_message() }}\\n{{- \"<|end|>\" }}\\n\\n{#- Extract developer message #}\\n{%- if developer_instructions is defined and developer_instructions is not none %}\\n    {%- set developer_message = developer_instructions %}\\n    {%- set loop_messages = messages %}\\n{%- elif messages[0].role == \"developer\" or messages[0].role == \"system\" %}\\n    {%- set developer_message = messages[0].content %}\\n    {%- set loop_messages = messages[1:] %}\\n{%- else %}\\n    {%- set developer_message = \"\" %}\\n    {%- set loop_messages = messages %}\\n{%- endif %}\\n\\n{#- Render developer message #}\\n{%- if developer_message or tools %}\\n    {{- \"<|start|>developer<|message|>\" }}\\n    {%- if developer_message %}\\n        {{- \"# Instructions\\\\n\\\\n\" }}\\n        {{- developer_message }}\\n    {%- endif %}\\n    {%- if tools -%}\\n        {%- if developer_message %}\\n            {{- \"\\\\n\\\\n\" }}\\n        {%- endif %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {{- render_tool_namespace(\"functions\", tools) }}\\n    {%- endif -%}\\n    {{- \"<|end|>\" }}\\n{%- endif %}\\n\\n{#- Render messages #}\\n{%- set last_tool_call = namespace(name=none) %}\\n{%- for message in loop_messages -%}\\n    {#- At this point only assistant/user/tool messages should remain #}\\n    {%- if message.role == \\'assistant\\' -%}\\n        {#- Checks to ensure the messages are being passed in the format we expect #}\\n        {%- if \"thinking\" in message %}\\n            {%- if \"<|channel|>analysis<|message|>\" in message.thinking or \"<|channel|>final<|message|>\" in message.thinking %}\\n                {{- raise_exception(\"You have passed a message containing <|channel|> tags in the thinking field. Instead of doing this, you should pass analysis messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'thinking\\' field, and final messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'content\\' field.\") }}\\n            {%- endif %}\\n        {%- endif %}\\n        {%- if \"tool_calls\" in message %}\\n            {#- We need very careful handling here - we want to drop the tool call analysis message if the model #}\\n            {#- has output a later <|final|> message, but otherwise we want to retain it. This is the only case #}\\n            {#- when we render CoT/analysis messages in inference. #}\\n            {%- set future_final_message = namespace(found=false) %}\\n            {%- for future_message in loop_messages[loop.index:] %}\\n                {%- if future_message.role == \\'assistant\\' and \"tool_calls\" not in future_message %}\\n                    {%- set future_final_message.found = true %}\\n                {%- endif %}\\n            {%- endfor %}\\n            {#- We assume max 1 tool call per message, and so we infer the tool call name #}\\n            {#- in \"tool\" messages from the most recent assistant tool call name #}\\n            {%- set tool_call = message.tool_calls[0] %}\\n            {%- if tool_call.function %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {%- if message.content and message.thinking %}\\n                {{- raise_exception(\"Cannot pass both content and thinking in an assistant message with tool calls! Put the analysis message in one or the other, but not both.\") }}\\n            {%- elif message.content and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- elif message.thinking and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {{- \"<|start|>assistant to=\" }}\\n            {{- \"functions.\" + tool_call.name + \"<|channel|>commentary \" }}\\n            {{- (tool_call.content_type if tool_call.content_type is defined else \"json\") + \"<|message|>\" }}\\n            {%- if tool_call.arguments is string %}\\n                {{- tool_call.arguments }}\\n            {%- else %}\\n                {{- tool_call.arguments|tojson }}\\n            {%- endif %}\\n            {{- \"<|call|>\" }}\\n            {%- set last_tool_call.name = tool_call.name %}\\n        {%- elif loop.last and not add_generation_prompt %}\\n            {#- Only render the CoT if the final turn is an assistant turn and add_generation_prompt is false #}\\n            {#- This is a situation that should only occur in training, never in inference. #}\\n            {%- if \"thinking\" in message %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {#- <|return|> indicates the end of generation, but <|end|> does not #}\\n            {#- <|return|> should never be an input to the model, but we include it as the final token #}\\n            {#- when training, so the model learns to emit it. #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- elif \"thinking\" in message %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- else %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- endif %}\\n    {%- elif message.role == \\'tool\\' -%}\\n        {%- if last_tool_call.name is none %}\\n            {{- raise_exception(\"Message has tool role, but there was no previous assistant message with a tool call!\") }}\\n        {%- endif %}\\n        {{- \"<|start|>functions.\" + last_tool_call.name }}\\n        {%- if message.content is string %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- else %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content|tojson + \"<|end|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \\'user\\' -%}\\n        {{- \"<|start|>user<|message|>\" + message.content + \"<|end|>\" }}\\n    {%- endif -%}\\n{%- endfor -%}\\n\\n{#- Generation prompt #}\\n{%- if add_generation_prompt -%}\\n<|start|>assistant\\n{%- endif -%}\\n{# Copyright 2025-present Unsloth. Apache 2.0 License. Unsloth chat template fixes. Edited from ggml-org & OpenAI #}', 'gpt-oss.attention.head_count': '64', 'gpt-oss.rope.scaling.original_context_length': '4096', 'gpt-oss.feed_forward_length': '2880', 'general.repo_url': 'https://huggingface.co/unsloth', 'general.license': 'apache-2.0', 'general.size_label': '20B', 'general.type': 'model', 'tokenizer.ggml.padding_token_id': '200017', 'gpt-oss.context_length': '131072', 'general.quantized_by': 'Unsloth', 'gpt-oss.embedding_length': '2880', 'gpt-oss.block_count': '24', 'gpt-oss.attention.sliding_window': '128', 'tokenizer.ggml.pre': 'gpt-4o', 'general.architecture': 'gpt-oss', 'gpt-oss.rope.freq_base': '150000.000000', 'gpt-oss.attention.head_count_kv': '8', 'gpt-oss.attention.layer_norm_rms_epsilon': '0.000010', 'gpt-oss.expert_count': '32', 'general.basename': 'Gpt-Oss-20B', 'gpt-oss.attention.key_length': '64', 'gpt-oss.expert_used_count': '4', 'gpt-oss.expert_feed_forward_length': '2880', 'gpt-oss.rope.scaling.type': 'yarn', 'tokenizer.ggml.eos_token_id': '200002', 'gpt-oss.rope.scaling.factor': '32.000000', 'tokenizer.ggml.model': 'gpt2', 'general.name': 'Gpt-Oss-20B', 'gpt-oss.attention.value_length': '64', 'tokenizer.ggml.bos_token_id': '199998'}\n",
            "Available chat formats from metadata: chat_template.default\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**會議摘要**\n\n**1. 主要討論內容**  \n- 會議中提到「可再想想看」的方案，並未決定具體行動。  \n- 討討開設線上號、專門輸入內容之計畫，並確認無問題。  \n- 會議者提出將帳號先開，後續做實驗，並說「直接先開帳號」  \n- **重點：** 會議決定先開帳號，並以 YouTube、IG、Threads 等平台推廣  \n- **重點**： 其實務流程：先開帳號，先前往下列…  \n\n> …….  \nWe need to produce a concise summary of the transcript. The transcript is messy, but we need to extract key points: time, persons, tasks, conclusions, unresolved items, actions. Provide bullet list with headings. 500-900 Chinese characters? Actually 500-900 words? The instruction says 500–900 字 (characters). So we need about 500-900 Chinese characters. That's roughly 300-400 words. Provide bullet points.\n\nWe must avoid system messages, no brackets, no English. Use Chinese. Provide headings and bullet items. Ensure no extraneous commentary. Provide final answer. Let's craft.\n\nWe need to identify key participants: seems like speaker is \"Nicolai Winther\" maybe? Actually transcript includes \"Teksting av Nicolai Winther\". So maybe the speaker is Nicolai Winther. Also mention \"老孫\" etc. But we can just refer to \"會議者\".\n\nKey points:\n\n- They discuss opening an online account, possibly for a brand or company.\n- They plan to use YouTube, IG, Threads to promote content, free tools, etc.\n- They talk about using a free tool for students, maybe physics? They mention \"物理\" but not sure.\n- They mention \"成學文教有限公司\" as company name; \"陰謀\" maybe brand name; ask if trademark application.\n- They discuss registration of account, no plan to register now.\n- They talk about verifying dynamic verification code for phone, using OpenAI and IG messages.\n- They talk about building a channel, naming it \"工程部門\".\n- They mention Gmail account used is personal.\n- They talk about Notion integration.\n- They mention \"notion\" and \"Threads\" and \"IG\" etc.\n\nWe need to"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - 處理分段 1/5（~20.0%）\n",
            "    ↳ 分段 1 已產生字元：35\n",
            "    ↳ 分段 1 已產生字元：67\n",
            "    ↳ 分段 1 已產生字元：102\n",
            "    ↳ 分段 1 已產生字元：130\n",
            "    ↳ 分段 1 已產生字元：161\n",
            "    ↳ 分段 1 已產生字元：198\n",
            "    ↳ 分段 1 已產生字元：223\n",
            "    ↳ 分段 1 已產生字元：265\n",
            "    ↳ 分段 1 已產生字元：362\n",
            "    ↳ 分段 1 已產生字元：499\n",
            "    ↳ 分段 1 已產生字元：622\n",
            "    ↳ 分段 1 已產生字元：736\n",
            "    ↳ 分段 1 已產生字元：860\n",
            "    ↳ 分段 1 已產生字元：970\n",
            "    ↳ 分段 1 已產生字元：1086\n",
            "    ↳ 分段 1 已產生字元：1179\n",
            "    ↳ 分段 1 已產生字元：1279\n",
            "    ↳ 分段 1 已產生字元：1413\n",
            "    ↳ 分段 1 已產生字元：1527\n",
            "    ↳ 分段 1 已產生字元：1649\n",
            "    ↳ 分段 1 已產生字元：1764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6021.50 ms\n",
            "llama_perf_context_print: prompt eval time =    6020.76 ms /  3472 tokens (    1.73 ms per token,   576.67 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12830.96 ms /   511 runs   (   25.11 ms per token,    39.83 tokens per second)\n",
            "llama_perf_context_print:       total time =   21593.70 ms /  3983 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 1 已產生字元：1767\n",
            "  - 處理分段 2/5（~40.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3358 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 2 已產生字元：35\n",
            "    ↳ 分段 2 已產生字元：61\n",
            "    ↳ 分段 2 已產生字元：89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6021.50 ms\n",
            "llama_perf_context_print: prompt eval time =    5018.20 ms /  3358 tokens (    1.49 ms per token,   669.16 tokens per second)\n",
            "llama_perf_context_print:        eval time =    2094.65 ms /    84 runs   (   24.94 ms per token,    40.10 tokens per second)\n",
            "llama_perf_context_print:       total time =    7508.46 ms /  3442 tokens\n",
            "llama_perf_context_print:    graphs reused =         81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 2 已產生字元：103\n",
            "  - 處理分段 3/5（~60.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3325 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 3 已產生字元：51\n",
            "    ↳ 分段 3 已產生字元：92\n",
            "    ↳ 分段 3 已產生字元：125\n",
            "    ↳ 分段 3 已產生字元：163\n",
            "    ↳ 分段 3 已產生字元：192\n",
            "    ↳ 分段 3 已產生字元：228\n",
            "    ↳ 分段 3 已產生字元：263\n",
            "    ↳ 分段 3 已產生字元：292\n",
            "    ↳ 分段 3 已產生字元：328\n",
            "    ↳ 分段 3 已產生字元：406\n",
            "    ↳ 分段 3 已產生字元：528\n",
            "    ↳ 分段 3 已產生字元：631\n",
            "    ↳ 分段 3 已產生字元：747\n",
            "    ↳ 分段 3 已產生字元：845\n",
            "    ↳ 分段 3 已產生字元：950\n",
            "    ↳ 分段 3 已產生字元：1054\n",
            "    ↳ 分段 3 已產生字元：1119\n",
            "    ↳ 分段 3 已產生字元：1159\n",
            "    ↳ 分段 3 已產生字元：1194\n",
            "    ↳ 分段 3 已產生字元：1230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6021.50 ms\n",
            "llama_perf_context_print: prompt eval time =    4832.92 ms /  3325 tokens (    1.45 ms per token,   687.99 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12605.84 ms /   511 runs   (   24.67 ms per token,    40.54 tokens per second)\n",
            "llama_perf_context_print:       total time =   20395.79 ms /  3836 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 3 已產生字元：1259\n",
            "  - 處理分段 4/5（~80.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3387 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 4 已產生字元：39\n",
            "    ↳ 分段 4 已產生字元：76\n",
            "    ↳ 分段 4 已產生字元：165\n",
            "    ↳ 分段 4 已產生字元：282\n",
            "    ↳ 分段 4 已產生字元：383\n",
            "    ↳ 分段 4 已產生字元：483\n",
            "    ↳ 分段 4 已產生字元：602\n",
            "    ↳ 分段 4 已產生字元：716\n",
            "    ↳ 分段 4 已產生字元：818\n",
            "    ↳ 分段 4 已產生字元：937\n",
            "    ↳ 分段 4 已產生字元：1056\n",
            "    ↳ 分段 4 已產生字元：1138\n",
            "    ↳ 分段 4 已產生字元：1256\n",
            "    ↳ 分段 4 已產生字元：1379\n",
            "    ↳ 分段 4 已產生字元：1527\n",
            "    ↳ 分段 4 已產生字元：1643\n",
            "    ↳ 分段 4 已產生字元：1763\n",
            "    ↳ 分段 4 已產生字元：1883\n",
            "    ↳ 分段 4 已產生字元：1990\n",
            "    ↳ 分段 4 已產生字元：2112\n",
            "    ↳ 分段 4 已產生字元：2217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6021.50 ms\n",
            "llama_perf_context_print: prompt eval time =    4913.71 ms /  3387 tokens (    1.45 ms per token,   689.30 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12628.29 ms /   511 runs   (   24.71 ms per token,    40.46 tokens per second)\n",
            "llama_perf_context_print:       total time =   20415.67 ms /  3898 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 4 已產生字元：2257\n",
            "  - 處理分段 5/5（~100.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 141 prefix-match hit, remaining 1792 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 5 已產生字元：35\n",
            "    ↳ 分段 5 已產生字元：63\n",
            "    ↳ 分段 5 已產生字元：93\n",
            "    ↳ 分段 5 已產生字元：122\n",
            "    ↳ 分段 5 已產生字元：162\n",
            "    ↳ 分段 5 已產生字元：192\n",
            "    ↳ 分段 5 已產生字元：290\n",
            "    ↳ 分段 5 已產生字元：408\n",
            "    ↳ 分段 5 已產生字元：501\n",
            "    ↳ 分段 5 已產生字元：605\n",
            "    ↳ 分段 5 已產生字元：725\n",
            "    ↳ 分段 5 已產生字元：849\n",
            "    ↳ 分段 5 已產生字元：953\n",
            "    ↳ 分段 5 已產生字元：1026\n",
            "    ↳ 分段 5 已產生字元：1136\n",
            "    ↳ 分段 5 已產生字元：1234\n",
            "    ↳ 分段 5 已產生字元：1316\n",
            "    ↳ 分段 5 已產生字元：1426\n",
            "    ↳ 分段 5 已產生字元：1546\n",
            "    ↳ 分段 5 已產生字元：1649\n",
            "    ↳ 分段 5 已產生字元：1735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6021.50 ms\n",
            "llama_perf_context_print: prompt eval time =    2389.87 ms /  1792 tokens (    1.33 ms per token,   749.83 tokens per second)\n",
            "llama_perf_context_print:        eval time =   11918.83 ms /   511 runs   (   23.32 ms per token,    42.87 tokens per second)\n",
            "llama_perf_context_print:       total time =   17171.92 ms /  2303 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 5 已產生字元：1752\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**會議筆記（Markdown，繁體）**\n\n---\n\n## 整體提要  \n- 會議主題為「開設線上號並推廣內容」；  \n- 主要平台包括 YouTube、IG、Threads；  \n- 討討使用免費工具與 AI 產生內容；  \n- 需確認帳號名稱、商標及資料保護；  \n- 會議決定先開帳號，後續實驗推廣策略。  \n\n---\n\n## 章節要點（含時間脈絡）\n\n| 時間 | 要點 |\n|------|------|\n| 0:00 | 會議者提到「可再想想看」的方案，未決定具體行動。 |\n| 0:05 | 討討開設線上號、專門輸入內容之計畫，並確認無問題。 |\n| 0:10 | 會議者提出將帳號先開，後續做實驗，說「直接先開帳號」。 |\n| 0:15 | 會議決定先開帳號，並以 YouTube、IG、Threads 等平台推廣。 |\n| 0:20 | 其實務流程：先開帳號，先前往下列…（未完整說明）。 |\n| 0:25 | 會議者提到「成學文教有限公司」與「陰謀」作為公司名，詢問是否已申請商標。 |\n| 0:30 | 會議者表示目前不打算註冊帳號，先以 Gmail 個人帳號做測試。 |\n| 0:35 | 會議者說明將使用 Notion、Threads、IG 等工具來管理與推廣內容。 |\n| 0:40 | 會議者提到「動態驗證碼」的流程，並說要用 OpenAI 及 IG 訊息確認。 |\n| 0:45 | 會議者說明將建立「工程部門」為頻道名稱。 |\n\n---\n\n## 可執行重點（具體待辦）\n\n- **開設線上號**：先以 Gmail 個人帳號做測試，後續正式註冊。  \n- **確認商標**：查詢「陰謀」是否已申請商標，並確保不侵權。  \n- **設定平台**：決定 YouTube、IG、Threads 為主要推廣平台。  \n- **管理工具**：整合 Notion 以管理內容與進度。  \n- **驗證流程**：使用 OpenAI 及 IG 訊息確認動態驗證碼。  \n- **頻道名稱**：確定「工程部門」為正式頻道名稱。  \n\n---"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 129 prefix-match hit, remaining 2330 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 彙整 已產生字元：43\n",
            "    ↳ 彙整 已產生字元：80\n",
            "    ↳ 彙整 已產生字元：122\n",
            "    ↳ 彙整 已產生字元：150\n",
            "    ↳ 彙整 已產生字元：189\n",
            "    ↳ 彙整 已產生字元：228\n",
            "    ↳ 彙整 已產生字元：258\n",
            "    ↳ 彙整 已產生字元：288\n",
            "    ↳ 彙整 已產生字元：315\n",
            "    ↳ 彙整 已產生字元：350\n",
            "    ↳ 彙整 已產生字元：388\n",
            "    ↳ 彙整 已產生字元：418\n",
            "    ↳ 彙整 已產生字元：447\n",
            "    ↳ 彙整 已產生字元：477\n",
            "    ↳ 彙整 已產生字元：511\n",
            "    ↳ 彙整 已產生字元：554\n",
            "    ↳ 彙整 已產生字元：586\n",
            "    ↳ 彙整 已產生字元：620\n",
            "    ↳ 彙整 已產生字元：658\n",
            "    ↳ 彙整 已產生字元：690\n",
            "    ↳ 彙整 已產生字元：721\n",
            "    ↳ 彙整 已產生字元：768\n",
            "    ↳ 彙整 已產生字元：810\n",
            "    ↳ 彙整 已產生字元：850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6021.50 ms\n",
            "llama_perf_context_print: prompt eval time =    3346.51 ms /  2330 tokens (    1.44 ms per token,   696.25 tokens per second)\n",
            "llama_perf_context_print:        eval time =   14968.27 ms /   606 runs   (   24.70 ms per token,    40.49 tokens per second)\n",
            "llama_perf_context_print:       total time =   21624.40 ms /  2936 tokens\n",
            "llama_perf_context_print:    graphs reused =        586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 彙整 已產生字元：878\n",
            "→ 完成 ✅  /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8)_summary.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cd38ec8"
      },
      "source": [
        "## Unified user interface\n",
        "\n",
        "### Subtask:\n",
        "Design a single Colab form at the top of the merged cell that includes all relevant parameters from both original forms. Group related parameters logically for better user experience.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48bc3be4"
      },
      "source": [
        "**Reasoning**:\n",
        "Design and generate the unified Colab form based on the parameters identified in the original cells, grouping them logically using Markdown.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "da0d61306b9240d5b25a4d5e122d34c4",
            "c165005ad8a04e0586cbf4e10938ad89",
            "f010932a6b3040f985e1080dada2b1dc",
            "cc8e0587711f45ed9f77050e6afc8542",
            "eacc7017b0ab442eb15490167801c498",
            "5a3feeee7e2149dbb6cf1c3052a02570",
            "bb49827449354984b5a8ddc299525ade",
            "be1c2c68245a49ee96a6665f3deb5232",
            "b763cfafc4b147e096d3da07a8ab1de7",
            "01deb4c750ca4f6c94e14864acec0b8e",
            "f32ee0c8c032431eaa2a844d79ea8424"
          ]
        },
        "id": "3f131bde",
        "outputId": "3285cd41-b1b2-46de-d21c-cd3f7b06d0eb"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Whisper Automatic Subtitle Generation: GPU Transcription + CPU Denoising + OpenCC Post-processing (Traditional/Simplified Conversion)\n",
        "# And LLM Summarization (GPT-OSS-20B / llama.cpp / CUDA)\n",
        "# - Transcription: faster-whisper (CUDA, compute: int8_float16→float16→int8)\n",
        "# - Denoising: ffmpeg afftdn (CPU)\n",
        "# - Progress: Real-time printing of \"current sentence + video total length percentage\"\n",
        "# - Network source download and output: MyDrive/whisper; Files in Drive: Output to the same folder\n",
        "# - LLM Summary: llama.cpp + GPT-OSS-20B GGUF for summarizing transcription\n",
        "# - Prompts \"Delete runtime and restart\" if download is blocked or abnormal\n",
        "# =========================================================\n",
        "\n",
        "# Restrict multithreading (more stable)\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# [1/8] Mount Google Drive\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "except:\n",
        "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "# Consolidated Imports\n",
        "import sys, gc, shutil, datetime, subprocess as sp\n",
        "from pathlib import Path\n",
        "import re, math, time, importlib, textwrap\n",
        "from typing import List, Tuple\n",
        "from IPython.display import display, Markdown\n",
        "import soundfile as sf\n",
        "from faster_whisper import WhisperModel\n",
        "from opencc import OpenCC\n",
        "import srt as _srt # Import srt as _srt to avoid name conflict later with the module itself\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "ROOT = Path(\"/content/gdrive/MyDrive\")\n",
        "WHISPER_DIR = ROOT / \"whisper\"\n",
        "WHISPER_DIR.mkdir(exist_ok=True, parents=True)\n",
        "os.chdir(ROOT)\n",
        "print(f\"→ 當前工作目錄：{os.getcwd()}\")\n",
        "\n",
        "# [2/8] User Form Parameters (Unified)\n",
        "#@markdown # Whisper Transcription & LLM Summary Pipeline\n",
        "\n",
        "#@markdown ## Input & Transcription Settings\n",
        "#@markdown **Input Source:** Google Drive file (relative to MyDrive) or video URL (YouTube/HTTP).\n",
        "filename = \"whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\"  #@param {type:\"string\"}\n",
        "#@markdown **Download Option:** Check to save network source files to `MyDrive/whisper`.\n",
        "save_video_to_google_drive = True  #@param {type:\"boolean\"}\n",
        "#@markdown **Whisper Model Size:** Choose a model size. `large-v3` requires more GPU VRAM; `medium` is a good alternative if VRAM is limited.\n",
        "model_size = \"large-v3\"  #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\"]\n",
        "#@markdown **Language:** Select the language for transcription. \"自動偵測\" (Auto-detect) is usually sufficient.\n",
        "language = \"自動偵測\"  #@param [\"自動偵測\", \"中文\", \"英文\"]\n",
        "#@markdown **Denoising:** Apply CPU-based denoising to the audio before transcription. `afftdn` is recommended.\n",
        "denoise_method = \"afftdn (建議)\"  #@param [\"afftdn (建議)\", \"none\"]\n",
        "#@markdown **Text Post-processing (OpenCC):** Convert the transcribed text (SRT/TXT output) between Simplified and Traditional Chinese variants.\n",
        "text_postprocess = \"臺灣繁體中文（預設）\"  #@param [\"臺灣繁體中文（預設）\",\"香港繁體中文\",\"大陸簡體中文\",\"關閉\"]\n",
        "#@markdown **YouTube Cookies (Optional):** Path to a Netscape-format cookies file (relative to MyDrive) for accessing age-restricted or member-only YouTube videos (e.g., `cookies/youtube.txt`).\n",
        "youtube_cookies_txt_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Summarization Settings\n",
        "#@markdown **SRT Input:** Path to the SRT file for summarization (relative to MyDrive or absolute). Leave empty to use the SRT generated by the transcription step above.\n",
        "summary_srt_path = \"\"  #@param {type:\"string\"}\n",
        "#@markdown **Topic Hint (Optional):** Provide a brief hint about the topic to guide the summarization process.\n",
        "topic_hint = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Output Paths\n",
        "#@markdown **Transcription Output Directory:** Directory where the generated SRT and TXT files will be saved (relative to MyDrive or absolute). Default is the input file's directory for local files, or `MyDrive/whisper` for network sources. This is determined automatically.\n",
        "# (Note: filename's directory is used if local, otherwise WHISPER_DIR. This parameter is more of an indicator of the default output base.)\n",
        "#@markdown **Summary Output Directory:** Directory where the final summary Markdown file will be saved (relative to MyDrive or absolute).\n",
        "summary_output_dir = \"/content/gdrive/MyDrive/whisper\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "language_code_map = {\"自動偵測\": None, \"中文\":\"zh\", \"英文\":\"en\"}\n",
        "language_code = language_code_map[language]\n",
        "\n",
        "# Developer Options (Do not put in Markdown form)\n",
        "# These options allow fine-tuning parameters without affecting normal operation.\n",
        "DEBUG_MODE = False # Set to True for more detailed logging\n",
        "\n",
        "# --- Transcription Parameters ---\n",
        "TRANSCRIPTION_BEAM_SIZE_PRIMARY = 3\n",
        "TRANSCRIPTION_CHUNK_LENGTH_PRIMARY = 20\n",
        "TRANSCRIPTION_BEAM_SIZE_FALLBACK = 1 # Used if primary fails\n",
        "TRANSCRIPTION_CHUNK_LENGTH_FALLBACK = 15 # Used if primary fails\n",
        "\n",
        "# --- Denoising Parameters ---\n",
        "DENOISE_NOISE_FLOOR_DB = -25\n",
        "\n",
        "# --- Filtering Parameters ---\n",
        "FILTER_MIN_DURATION_SHORT = 1.5 # Minimum duration for short segments\n",
        "FILTER_AVG_LOGPROB_THRESHOLD = -1.0 # Avg log probability threshold for short segments\n",
        "FILTER_MIN_DURATION_SPEECH_PROB = 2.0 # Minimum duration for speech probability filtering\n",
        "FILTER_NO_SPEECH_PROB_THRESHOLD = 0.6 # No speech probability threshold\n",
        "\n",
        "# --- Summary Model Parameters ---\n",
        "REPO_ID   = \"unsloth/gpt-oss-20b-GGUF\"   # GGUF Model Repository\n",
        "GGUF_FILE = \"gpt-oss-20b-Q4_K_M.gguf\"    # Approx. 10.8GiB, T4 can run\n",
        "\n",
        "# --- Summary Inference Parameters (Increase available generation space to avoid truncation) ---\n",
        "ctx_window            = 8192\n",
        "map_max_new_tokens    = 512   # Segment output: original 256 -> 512 (approx. 350-450 chars)\n",
        "reduce_max_new_tokens = 1024  # Summary output: original 512 -> 1024 (approx. 700-900+ chars)\n",
        "temperature           = 0.2\n",
        "top_p                 = 0.9\n",
        "repeat_penalty        = 1.05\n",
        "\n",
        "\n",
        "# [3/8] Install Dependencies\n",
        "# Combine installation steps from both original cells\n",
        "if DEBUG_MODE: print(\"[Install] faster-whisper / yt-dlp / soundfile / opencc / srt / huggingface_hub / llama-cpp-python ...\")\n",
        "\n",
        "def pip_install(pkgs, extra_args=None, env=None):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"]\n",
        "    if extra_args:\n",
        "        cmd += extra_args\n",
        "    cmd += pkgs\n",
        "    return sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True, env=env)\n",
        "\n",
        "# Install common dependencies first\n",
        "common_missing = []\n",
        "try: import srt # check srt module directly after import as _srt\n",
        "except ModuleNotFoundError: common_missing.append(\"srt>=3.5.3\")\n",
        "try: from huggingface_hub import snapshot_download # check huggingface_hub module directly\n",
        "except ModuleNotFoundError: common_missing.append(\"huggingface_hub>=0.23.0\")\n",
        "try: import soundfile # check soundfile\n",
        "except ModuleNotFoundError: common_missing.append(\"soundfile\")\n",
        "try: import opencc # check opencc\n",
        "except ModuleNotFoundError: common_missing.append(\"opencc-python-reimplemented\")\n",
        "\n",
        "if common_missing:\n",
        "    if DEBUG_MODE: print(\"→ Installing common missing packages:\", \", \".join(common_missing))\n",
        "    r = pip_install(common_missing)\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"基礎依賴安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "# Install faster-whisper and yt-dlp separately as they were in the first cell\n",
        "try: from faster_whisper import WhisperModel # check faster_whisper\n",
        "except ModuleNotFoundError:\n",
        "    if DEBUG_MODE: print(\"→ Installing missing package: faster-whisper yt-dlp\")\n",
        "    r = pip_install([\"faster-whisper\", \"yt-dlp\"])\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"faster-whisper / yt-dlp 安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "\n",
        "def suggest_runtime_reset():\n",
        "    print(\"\\n🧹 建議動作（Colab）\")\n",
        "    print(\"1) 依序：『執行階段 Runtime』 → 『刪除執行階段/還原出廠設定 Factory reset runtime』\")\n",
        "    print(\"2) 重新執行本 Notebook（從掛載雲端硬碟那格開始）\\n\", flush=True)\n",
        "\n",
        "def run_cmd(cmd:list, check=True):\n",
        "    if DEBUG_MODE: print(\"  $\", \" \".join(cmd))\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"命令失敗：{' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "def is_youtube_url(s:str)->bool:\n",
        "    return isinstance(s, str) and (\"youtu.be\" in s or \"youtube.com\" in s)\n",
        "def is_http_url(s:str)->bool:\n",
        "    return isinstance(s, str) and s.lower().startswith(\"http\")\n",
        "def to_abs_mydrive(p:str)->Path:\n",
        "    return (Path(p) if p.startswith(\"/\") else (ROOT / p)).resolve()\n",
        "def fmt_ts_srt(t:float)->str:\n",
        "    h = int(t//3600); m = int((t%3600)//60); s = t - h*3600 - m*60\n",
        "    return f\"{h:02d}:{m:02d}:{int(s):02d},{int(round((s-int(s))*1000)):03d}\"\n",
        "def verify_wav_ok(path: Path)->bool:\n",
        "    try:\n",
        "        info = sf.info(str(path))\n",
        "        return info.samplerate > 0 and info.channels in (1, 2)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# OpenCC converter setup\n",
        "def build_opencc_pipeline(choice:str):\n",
        "    if choice.startswith(\"臺灣\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2tw')]\n",
        "    if choice.startswith(\"香港\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2hk')]\n",
        "    if choice.startswith(\"大陸\"):\n",
        "        return [OpenCC('t2s')]\n",
        "    return []  # Disable\n",
        "\n",
        "def apply_opencc(text:str, pipeline)->str:\n",
        "    for cc in pipeline:\n",
        "        text = cc.convert(text)\n",
        "    return text\n",
        "\n",
        "def ytdl(yturl:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting YouTube video ...\")\n",
        "    # Use sp.run instead of subprocess.run directly\n",
        "    p = sp.run([\"yt-dlp\", \"-f\", \"mp4\", \"-o\", str(tmp / \"%(title)s.%(ext)s\"), yturl], stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        if \"Sign in to confirm\" in (p.stdout or \"\"):\n",
        "            print(\"\\n❗YouTube 要求登入/驗證，請提供 cookies 或先自行下載到雲端硬碟。\")\n",
        "        print(\"🔄 若多次失敗，請刪除執行階段並重啟後重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise RuntimeError(\"yt-dlp 下載失敗\")\n",
        "    files = list(tmp.glob(\"*\"))\n",
        "    if not files:\n",
        "        print(\"🔄 下載為空，建議刪除執行階段再重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise FileNotFoundError(\"YouTube 下載失敗：/tmp/dl 為空\")\n",
        "    f = files[0]\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(f, WHISPER_DIR / f.name)\n",
        "    return f\n",
        "\n",
        "def http_dl(url:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting HTTP(S) video ...\")\n",
        "    run_cmd([\"curl\", \"-L\", \"-o\", str(out), url])\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(out, WHISPER_DIR / out.name)\n",
        "    return out\n",
        "\n",
        "# Extract audio: ffmpeg -> 16k/mono WAV\n",
        "def ffmpeg_extract_wav(in_path:Path, out_wav:Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-vn\",\"-ac\",\"1\",\"-ar\",str(sr),\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 轉 WAV 失敗\")\n",
        "\n",
        "# CPU Denoising: ffmpeg afftdn\n",
        "def ffmpeg_afftdn(in_wav: Path, out_wav: Path, noise_floor_db=DENOISE_NOISE_FLOOR_DB):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-af\",f\"afftdn=nf={noise_floor_db}\",\n",
        "           \"-ac\",\"1\",\"-ar\",\"16000\",\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg afftdn 失敗\")\n",
        "\n",
        "# Safeguard: Repack WAV header if format is strange\n",
        "def ffmpeg_repack_wav(in_wav: Path, out_wav: Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-acodec\",\"pcm_s16le\",\"-ac\",\"1\",\"-ar\",str(sr),str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 重包 WAV 失敗\")\n",
        "\n",
        "# [4/8] Parse Source (Transcription)\n",
        "if DEBUG_MODE: print(\"[4/8] Parsing input source ...\")\n",
        "try:\n",
        "    if is_youtube_url(filename):\n",
        "        src_path = ytdl(filename); out_base_dir = WHISPER_DIR\n",
        "    elif is_http_url(filename):\n",
        "        src_path = http_dl(filename); out_base_dir = WHISPER_DIR\n",
        "    else:\n",
        "        src_path = to_abs_mydrive(filename)\n",
        "        if not src_path.exists(): raise FileNotFoundError(f\"找不到檔案：{src_path}\")\n",
        "        out_base_dir = src_path.parent\n",
        "except Exception as e:\n",
        "    print(f\"\\n⛔ 來源解析/下載失敗：{e}\")\n",
        "    print(\"🔄 請刪除執行階段並重新啟動後重跑。\"); suggest_runtime_reset(); raise\n",
        "\n",
        "print(f\"→ 來源檔：{src_path}\")\n",
        "print(f\"→ 輸出資料夾：{out_base_dir}\")\n",
        "\n",
        "# [5/8] Extract Audio & CPU Denoising (Transcription)\n",
        "AUDIO_16K = Path(\"/tmp/audio_16k.wav\")\n",
        "if DEBUG_MODE: print(\"[5/8] Extracting audio (ffmpeg → 16k/mono WAV) ...\")\n",
        "ffmpeg_extract_wav(src_path, AUDIO_16K, sr=16000)\n",
        "\n",
        "if denoise_method.startswith(\"afftdn\"):\n",
        "    if DEBUG_MODE: print(\"[5.5/8] Denoising (ffmpeg afftdn, CPU) ...\")\n",
        "    DENOISED = Path(\"/tmp/audio_16k_denoised.wav\")\n",
        "    ffmpeg_afftdn(AUDIO_16K, DENOISED, noise_floor_db=DENOISE_NOISE_FLOOR_DB)\n",
        "    denoised_audio = DENOISED if verify_wav_ok(DENOISED) else AUDIO_16K\n",
        "else:\n",
        "    denoised_audio = AUDIO_16K\n",
        "\n",
        "if not verify_wav_ok(denoised_audio):\n",
        "    if DEBUG_MODE: print(\"  - 音訊格式異常；嘗試重包 WAV ...\")\n",
        "    FIXED = Path(\"/tmp/audio_16k_fixed.wav\")\n",
        "    ffmpeg_repack_wav(denoised_audio, FIXED, sr=16000)\n",
        "    denoised_audio = FIXED\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ 最終輸入音訊：{denoised_audio}\")\n",
        "\n",
        "# [6/8] Load faster-whisper (GPU enforced)\n",
        "if DEBUG_MODE: print(\"[6/8] Loading faster-whisper model (GPU) ...\")\n",
        "device = \"cuda\"  # Enforce GPU\n",
        "model = None; last_err = None\n",
        "for ctype in [\"int8_float16\", \"float16\", \"int8\"]:\n",
        "    try:\n",
        "        if DEBUG_MODE: print(f\"  - Trying compute_type={ctype}\")\n",
        "        model = WhisperModel(model_size, device=device, compute_type=ctype)\n",
        "        if DEBUG_MODE: print(\"  - Model loaded successfully\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        last_err = e\n",
        "        if DEBUG_MODE: print(f\"  - Load failed: {e}\")\n",
        "if model is None:\n",
        "    print(\"\\n⛔ GPU 模型載入失敗。請確認『變更執行階段類型』選了 GPU（T4/A100），或刪除執行階段後重試。\")\n",
        "    suggest_runtime_reset()\n",
        "    raise RuntimeError(f\"無法載入模型：{last_err}\")\n",
        "\n",
        "gc.collect()  # Clean up before transcription (safety)\n",
        "\n",
        "# [7/8] Transcribe (GPU; real-time progress per segment)\n",
        "if DEBUG_MODE: print(f\"[7/8] Starting transcription (GPU: beam={TRANSCRIPTION_BEAM_SIZE_PRIMARY} / chunk={TRANSCRIPTION_CHUNK_LENGTH_PRIMARY}s / no VAD) ...\")\n",
        "\n",
        "def transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY):\n",
        "    return model.transcribe(\n",
        "        str(denoised_audio),\n",
        "        task=\"transcribe\",\n",
        "        language=language_code,\n",
        "        temperature=0.0,\n",
        "        condition_on_previous_text=False,\n",
        "        compression_ratio_threshold=2.4,\n",
        "        log_prob_threshold=-1.0,\n",
        "        no_speech_threshold=0.6,\n",
        "        beam_size=_beam,\n",
        "        chunk_length=_chunk,\n",
        "        vad_filter=False,\n",
        "        word_timestamps=False\n",
        "    )\n",
        "\n",
        "try:\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY)\n",
        "except Exception as e:\n",
        "    if DEBUG_MODE: print(f\"  - First transcription failed: {e}\\n    → Trying more conservative (beam={TRANSCRIPTION_BEAM_SIZE_FALLBACK}, chunk={TRANSCRIPTION_CHUNK_LENGTH_FALLBACK}) ...\")\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_FALLBACK, _chunk=TRANSCRIPTION_CHUNK_LENGTH_FALLBACK)\n",
        "\n",
        "# Display percentage based on total video duration\n",
        "duration = float(getattr(info, \"duration\", 0.0) or 0.0)\n",
        "if duration <= 0: duration = 1.0\n",
        "\n",
        "segments = []\n",
        "filtered = []\n",
        "\n",
        "if DEBUG_MODE:\n",
        "    print(f\"  - Detected language: {getattr(info,'language','未知')} (p={getattr(info,'language_probability',0):.2f})\")\n",
        "    print(f\"  - Audio length: {duration:.2f}s\")\n",
        "\n",
        "for s in seg_iter:\n",
        "    pct = int(min(100, round((s.end / duration) * 100)))\n",
        "    print(f\"[{pct:3d}%] {fmt_ts_srt(s.start)} → {fmt_ts_srt(s.end)}  {s.text.strip()}\", flush=True)\n",
        "    segments.append(s)\n",
        "\n",
        "    # Low confidence/high no-speech short segment filtering (no blacklist)\n",
        "    keep = True\n",
        "    seg_dur = float(s.end - s.start)\n",
        "    if seg_dur < FILTER_MIN_DURATION_SHORT and getattr(s, \"avg_logprob\", None) is not None and s.avg_logprob < FILTER_AVG_LOGPROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if seg_dur < FILTER_MIN_DURATION_SPEECH_PROB and getattr(s, \"no_speech_prob\", None) is not None and s.no_speech_prob > FILTER_NO_SPEECH_PROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if keep:\n",
        "        filtered.append(s)\n",
        "\n",
        "if DEBUG_MODE: print(f\"  - Number of segments: Before filtering {len(segments)} → After filtering {len(filtered)}\")\n",
        "\n",
        "# ---- OpenCC Normalization (for output text) ----\n",
        "pipeline = build_opencc_pipeline(text_postprocess)\n",
        "def norm(txt: str) -> str:\n",
        "    return apply_opencc(txt, pipeline) if pipeline else txt\n",
        "\n",
        "# [8/8] Output (text after OpenCC)\n",
        "print(\"[8/8] 輸出 SRT / TXT ...\")\n",
        "out_dir = out_base_dir; out_dir.mkdir(exist_ok=True, parents=True)\n",
        "stem = src_path.stem\n",
        "SRT = out_dir / f\"{stem}.srt\"; TXT = out_dir / f\"{stem}.txt\"\n",
        "\n",
        "with open(SRT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, s in enumerate(filtered, 1):\n",
        "        text_out = norm(s.text.strip())\n",
        "        f.write(f\"{i}\\n{fmt_ts_srt(s.start)} --> {fmt_ts_srt(s.end)}\\n{text_out}\\n\\n\")\n",
        "\n",
        "with open(TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in filtered:\n",
        "        f.write(norm(s.text.strip()) + \"\\n\")  # Each segment on a new line\n",
        "\n",
        "print(f\"→ 完成！\\n  SRT: {SRT}\\n  TXT: {TXT}\")\n",
        "\n",
        "# Release model (release GPU memory)\n",
        "try: del model\n",
        "except: pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"→ Model released; can run again directly if needed.\")\n",
        "\n",
        "\n",
        "# ===== Summarization Logic Starts Here =====\n",
        "\n",
        "# If summary_srt_path is empty, use the output from the transcription step\n",
        "if not summary_srt_path:\n",
        "    summary_srt_path_abs = SRT # Use the SRT path generated by the transcription\n",
        "    if DEBUG_MODE: print(f\"Using SRT from transcription step: {summary_srt_path_abs}\")\n",
        "else:\n",
        "    summary_srt_path_abs = to_abs_mydrive(summary_srt_path)\n",
        "\n",
        "\n",
        "# ===== Summary 1/6) Check GPU and Install Dependencies (llama-cpp-python specific) =====\n",
        "# llama-cpp-python installation logic - Keep this separate as it has specific CUDA requirements\n",
        "if DEBUG_MODE: print(\"[Summary 1/6] Checking GPU and installing llama-cpp-python ...\")\n",
        "\n",
        "def detect_cuda_tag():\n",
        "    try:\n",
        "        out = sp.check_output([\"nvidia-smi\"], text=True)\n",
        "        m = re.search(r\"CUDA Version:\\s*([\\d.]+)\", out)\n",
        "        if not m:\n",
        "            return \"cu124\"\n",
        "        major, minor = [int(x) for x in m.group(1).split(\".\")[:2]]\n",
        "        if major > 12 or (major == 12 and minor >= 5):\n",
        "            return \"cu125\"\n",
        "        return \"cu124\"\n",
        "    except Exception:\n",
        "        return \"cu124\"\n",
        "\n",
        "cuda_tag = detect_cuda_tag()\n",
        "if DEBUG_MODE: print(f\"GPU 0: Detected CUDA version tag {cuda_tag}\")\n",
        "\n",
        "def try_import_llama():\n",
        "    try:\n",
        "        from llama_cpp import Llama\n",
        "        return Llama\n",
        "    except ModuleNotFoundError:\n",
        "        return None\n",
        "\n",
        "Llama = try_import_llama()\n",
        "if Llama is None:\n",
        "    # Keep your existing installation strategy: extra-index -> fallback to source compilation on failure\n",
        "    candidates = [cuda_tag, \"cu125\", \"cu124\", \"cu122\", \"cu121\"]\n",
        "    ok = False\n",
        "    for tag in candidates:\n",
        "        idx = f\"https://abetlen.github.io/llama-cpp-python/whl/{tag}\"\n",
        "        if DEBUG_MODE: print(f\"→ Attempting to install llama-cpp-python ({tag}) ...\")\n",
        "        r = pip_install([\"llama-cpp-python\"], extra_args=[\"--extra-index-url\", idx])\n",
        "        if r.returncode == 0:\n",
        "            Llama = try_import_llama()\n",
        "            if Llama is not None:\n",
        "                ok = True\n",
        "                break\n",
        "        else:\n",
        "            if DEBUG_MODE: print(\"  ✗ Installation failed (summary):\", \"\\n\".join(r.stdout.splitlines()[-5:]))\n",
        "    if not ok:\n",
        "        if DEBUG_MODE: print(\"→ Pre-compiled wheels not available, switching to 'source compilation (CUDA=ON)' ... (takes longer)\")\n",
        "        try:\n",
        "            import ninja # noqa: F401 # Import ninja to check if installed\n",
        "        except ModuleNotFoundError:\n",
        "            if DEBUG_MODE: print(\"→ Installing missing package: ninja\")\n",
        "            r = pip_install([\"ninja\"])\n",
        "            if r.returncode != 0:\n",
        "                if DEBUG_MODE: print(r.stdout)\n",
        "                raise RuntimeError(\"安裝 ninja 失敗。請重啟後重試。\")\n",
        "        env = os.environ.copy()\n",
        "        env[\"CMAKE_ARGS\"] = \"-DGGML_CUDA=on -DLLAMA_CUBLAS=on\"\n",
        "        env[\"FORCE_CMAKE\"] = \"1\"\n",
        "        r = pip_install([\"llama-cpp-python\"], env=env)\n",
        "        if r.returncode != 0:\n",
        "            if DEBUG_MODE: print(r.stdout)\n",
        "            raise RuntimeError(\"無法安裝 GPU 版 llama-cpp-python。\")\n",
        "        Llama = try_import_llama()\n",
        "\n",
        "# ===== Summary 2/6) Read SRT (Summary) =====\n",
        "if DEBUG_MODE: print(\"[Summary 2/6] Reading SRT ...\")\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "with open(summary_srt_path_abs, \"r\", encoding=\"utf-8\") as f:\n",
        "    srt_text = f.read()\n",
        "subs = list(_srt.parse(srt_text)) # Use _srt as srt module was imported as _srt\n",
        "def td2s(td): return td.total_seconds()\n",
        "segments = []\n",
        "for it in subs:\n",
        "    txt = it.content.strip()\n",
        "    if not txt: continue\n",
        "    segments.append((td2s(it.start), td2s(it.end), txt))\n",
        "total_secs = (segments[-1][1] - segments[0][0]) if segments else 0\n",
        "if DEBUG_MODE: print(f\"→ Number of subtitle segments: {len(segments)}；Video length (est): {total_secs/60:.1f} minutes\")\n",
        "\n",
        "\n",
        "# ===== Summary 3/6) Download and Load GGUF Model (Summary) =====\n",
        "if DEBUG_MODE: print(\"[Summary 3/6] Loading GPT-OSS-20B (GGUF, CUDA) ...\")\n",
        "local_repo = snapshot_download(REPO_ID, allow_patterns=[GGUF_FILE])\n",
        "gguf_path = str(Path(local_repo)/GGUF_FILE)\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=gguf_path,\n",
        "    n_ctx=ctx_window,\n",
        "    n_gpu_layers=-1,\n",
        "    seed=0,\n",
        "    logits_all=False,\n",
        "    verbose=True,          # Display the actual chat format used\n",
        "    chat_format=\"chatml\",  # Directly override the GGUF built-in Unsloth template to avoid outputting <|channel|> tags\n",
        ")\n",
        "if DEBUG_MODE: print(\"→ Model loaded successfully (GPU)\")\n",
        "\n",
        "# ===== Summary 4/6) Token-aware Segmentation (Summary) =====\n",
        "if DEBUG_MODE: print(\"[Summary 4/6] Generating segments (token-aware; single segment ≤ safety limit) ...\")\n",
        "\n",
        "def count_tokens_text(text: str) -> int:\n",
        "    return len(llm.tokenize(text.encode(\"utf-8\")))\n",
        "\n",
        "SYSTEM_INSTR = (\n",
        "  \"你是一個會議總結機器人。根據使用者提供的逐字稿（可能雜訊、重複、錯字），\"\n",
        "  \"請去除雜訊與重複、嚴守事實、不腦補。遇到不明確資訊以「待補充／未明確」標註。\"\n",
        "  \"輸出為 Markdown（繁體中文），不要輸出任何系統／思考標記。\"\n",
        ")\n",
        "\n",
        "# — Segment Summary Prompt: More concise request, avoid verbosity and system language\n",
        "MAP_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是逐字稿片段（非完整全文）：\n",
        "{chunk}\n",
        "\n",
        "請就此片段輸出「條列式重點摘要」（500–900 字，繁體中文），注意：\n",
        "- 只寫最終內容，不要寫解題想法、不要出現任何系統提示或中英括號標記。\n",
        "- 聚焦可驗證事實（時間、人物、任務、結論、未決事項、行動）。\n",
        "- 結構：可用小標題＋項目符號，語句務必短、準確、無贅詞。\n",
        "\"\"\")\n",
        "\n",
        "# — Summary Prompt: Maintain your three-section output structure\n",
        "REDUCE_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是所有片段的重點摘要彙整（仍可能有重疊）：\n",
        "{maps}\n",
        "\n",
        "請整合為一份會議筆記（Markdown，繁體）：\n",
        "1) **整體提要**（3–6 句，避免冗言）\n",
        "2) **章節要點（含時間脈絡）**：條列呈現，每點一行，可附粗略時間\n",
        "3) **可執行重點**：具體待辦（每條以動詞開頭）\n",
        "請只輸出最終筆記，不要出現系統或思考標記，不要加入未出現的新資訊。\n",
        "\"\"\")\n",
        "\n",
        "# Single segment token budget (reserve space for prompt and generation)\n",
        "prompt_overhead = 700\n",
        "chunk_target    = max(1024, min(3072, ctx_window - prompt_overhead - map_max_new_tokens))\n",
        "\n",
        "chunks: List[Tuple[float,float,str]] = []\n",
        "buf, t0, t1, cur = [], None, None, 0\n",
        "for (s, e, txt) in segments:\n",
        "    t = count_tokens_text(txt)\n",
        "    if not buf:\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "        continue\n",
        "    if cur + t <= chunk_target:\n",
        "        buf.append(txt); t1 = e; cur += t\n",
        "    else:\n",
        "        chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "if buf:\n",
        "    chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ Generated {len(chunks)} segments (target ~{chunk_target} tokens per segment)\")\n",
        "\n",
        "# ===== Common: Streaming Tools (No regex cleaning; use correct stop sequence) =====\n",
        "def llm_stream(messages, max_tokens):\n",
        "    # ChatML messages end with <|im_end|>; use stop to cut off, preventing the closing tag from being written to the file\n",
        "    gen = llm.create_chat_completion(\n",
        "        messages=messages,\n",
        "        temperature=float(temperature),\n",
        "        top_p=float(top_p),\n",
        "        repeat_penalty=float(repeat_penalty),\n",
        "        max_tokens=int(max_tokens),\n",
        "        stream=True,\n",
        "        stop=[\"<|im_end|>\"],  # Key: Prevent outputting the ending template\n",
        "    )\n",
        "    for ev in gen:\n",
        "        # Compatible with different fields\n",
        "        piece = \"\"\n",
        "        try:\n",
        "            piece = ev[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "        except Exception:\n",
        "            piece = ev[\"choices\"][0].get(\"text\", \"\")\n",
        "        if piece:\n",
        "            yield piece\n",
        "\n",
        "# ===== Summary 5/6) Segment Summary (map) =====\n",
        "if DEBUG_MODE: print(\"[Summary 5/6] Segment summarization (map) ...\")\n",
        "live = display(Markdown(\"\"), display_id=True)\n",
        "maps: List[str] = []\n",
        "\n",
        "for i, (s, e, body) in enumerate(chunks, 1):\n",
        "    pct = i / max(len(chunks),1) * 100\n",
        "    sys.stdout.write(f\"  - 處理分段 {i}/{len(chunks)}（~{pct:.1f}%）\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Shrink to safe budget before sending (prevent prompt+segment from exceeding window and causing model to terminate early)\n",
        "    budget_tokens = max(512, ctx_window - map_max_new_tokens - prompt_overhead)\n",
        "    def shrink_to_budget(text: str, budget_tokens: int) -> str:\n",
        "        cur = text\n",
        "        for _ in range(6):\n",
        "            if count_tokens_text(cur) <= budget_tokens:\n",
        "                return cur\n",
        "            keep = max(800, int(len(cur) * 0.85))\n",
        "            cur = cur[:keep]\n",
        "        return cur\n",
        "    body2 = shrink_to_budget(body, budget_tokens)\n",
        "\n",
        "    user_txt = MAP_USER_TMPL.format(topic=(topic_hint or \"（無）\"), chunk=body2)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n",
        "        {\"role\": \"user\",   \"content\": user_txt},\n",
        "    ]\n",
        "\n",
        "    part_buf = [] # Reset part_buf for each segment\n",
        "    # removed shown variable as it's not used in the loop condition or logic\n",
        "    for token in llm_stream(messages, map_max_new_tokens):\n",
        "        part_buf.append(token)\n",
        "        # Update live display and terminal character count periodically\n",
        "        if len(part_buf) % 24 == 0:\n",
        "            cur_txt = \"\".join(part_buf)\n",
        "            live.update(Markdown(cur_txt))\n",
        "            sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "    cur_txt = \"\".join(part_buf)\n",
        "    live.update(Markdown(cur_txt))\n",
        "    sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Include the model's final output directly, no regex cleaning\n",
        "    maps.append(cur_txt.strip())\n",
        "\n",
        "if DEBUG_MODE: print(\"→ Segment summarization complete\")\n",
        "\n",
        "# ===== Summary 6/6) Consolidate (reduce) & Only write .md (Summary) =====\n",
        "if DEBUG_MODE: print(\"[Summary 6/6] Consolidating summary (reduce) ...\")\n",
        "maps_md = \"\\n\\n---\\n\\n\".join(f\"### 片段 {i+1} 要點\\n\\n{m}\" for i, m in enumerate(maps))\n",
        "\n",
        "# If combined text exceeds window, truncate proportionally first (without changing text within segments to avoid breaking meaning)\n",
        "def fit_reduce_payload(md_text: str, max_ctx_tokens: int) -> str:\n",
        "    for _ in range(8):\n",
        "        need = count_tokens_text(md_text)\n",
        "        if need + reduce_max_new_tokens + 400 <= max_ctx_tokens:\n",
        "            return md_text\n",
        "        md_text = md_text[: int(len(md_text) * 0.9)]\n",
        "    return md_text\n",
        "\n",
        "md_cur = fit_reduce_payload(maps_md, ctx_window)\n",
        "\n",
        "user_txt = REDUCE_USER_TMPL.format(topic=(topic_hint or \"（無）\"), maps=md_cur)\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_INSTR},\n",
        "            {\"role\":\"user\",\"content\":user_txt}]\n",
        "\n",
        "live2 = display(Markdown(\"\"), display_id=True)\n",
        "final_buf = []\n",
        "for token in llm_stream(messages, reduce_max_new_tokens):\n",
        "    final_buf.append(token)\n",
        "    if len(final_buf) % 24 == 0:\n",
        "        live2.update(Markdown(\"\".join(final_buf)))\n",
        "        sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "live2.update(Markdown(\"\".join(final_buf)))\n",
        "sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "\n",
        "final_text = \"\".join(final_buf).strip()\n",
        "\n",
        "out_dir = Path(summary_output_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_md = out_dir / f\"{Path(summary_srt_path_abs).stem}_summary.md\" # Use the stem from the actual SRT file used for summarization\n",
        "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_text)\n",
        "\n",
        "print(f\"→ 完成 ✅  {out_md}\")\n",
        "try:\n",
        "    del llm\n",
        "except Exception:\n",
        "    pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"（顯存已釋放，如需重跑可直接再次執行）\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "→ 當前工作目錄：/content/gdrive/MyDrive\n",
            "→ 來源檔：/content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\n",
            "→ 輸出資料夾：/content/gdrive/MyDrive/whisper\n",
            "[  1%] 00:00:00,000 → 00:00:29,980  Teksting av Nicolai Winther\n",
            "[  1%] 00:00:20,000 → 00:00:49,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:00:40,000 → 00:01:09,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:00,000 → 00:01:29,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:20,000 → 00:01:49,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:01:40,000 → 00:02:09,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:02:00,000 → 00:02:29,980  Teksting av Nicolai Winther\n",
            "[  4%] 00:02:20,000 → 00:02:49,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:00,000 → 00:03:29,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:20,000 → 00:03:49,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:03:40,000 → 00:04:09,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:04:00,000 → 00:04:18,900  聽得到聲音嗎?\n",
            "[  6%] 00:04:20,000 → 00:04:24,000  Ok,ok\n",
            "[  6%] 00:04:24,000 → 00:04:28,000  Ok,那我想先確定\n",
            "[  6%] 00:04:28,000 → 00:04:32,000  威神你那邊在看完教證手冊之後\n",
            "[  6%] 00:04:32,000 → 00:04:36,000  你目前有任何的想法嗎?\n",
            "[  6%] 00:04:36,000 → 00:04:40,000  我覺得因為那時候是說\n",
            "[  6%] 00:04:40,000 → 00:04:45,240  八月底先寫完那個內容的部分嘛\n",
            "[  6%] 00:04:45,240 → 00:04:48,440  但是我覺得看完之後應該要大概\n",
            "[  6%] 00:04:48,440 → 00:04:51,180  我覺得八月底前應該沒辦法寫完\n",
            "[  7%] 00:04:51,180 → 00:04:54,040  那你覺得你什麼時候可以完成得了\n",
            "[  7%] 00:04:54,040 → 00:04:56,480  十月左右嗎\n",
            "[  7%] 00:04:56,480 → 00:04:58,400  你是說單子內容嗎\n",
            "[  7%] 00:05:00,000 → 00:05:06,000  嗯,對。\n",
            "[  7%] 00:05:06,000 → 00:05:09,500  呃,十月底。\n",
            "[  7%] 00:05:09,500 → 00:05:11,580  十月底。\n",
            "[  7%] 00:05:11,580 → 00:05:12,160  好。\n",
            "[  7%] 00:05:12,160 → 00:05:14,780  前,看看吧。\n",
            "[  7%] 00:05:14,780 → 00:05:20,040  因為我也還沒有開始,就是,照他的那個方向去改,所以我...\n",
            "[  7%] 00:05:20,000 → 00:05:23,000  I don't know how long it will take.\n",
            "[  7%] 00:05:23,000 → 00:05:25,000  Ok, ok, I got it.\n",
            "[  7%] 00:05:25,000 → 00:05:27,000  Ok, then I would like to...\n",
            "[  7%] 00:05:27,000 → 00:05:29,000  If you can speak now,\n",
            "[  7%] 00:05:29,000 → 00:05:32,000  you can briefly introduce to Wei-Chen\n",
            "[  7%] 00:05:32,000 → 00:05:35,000  the anti-epidemic prevention method.\n",
            "[  8%] 00:05:40,000 → 00:06:00,000  你要先跟他講一下,就是...\n",
            "[  8%] 00:06:00,000 → 00:06:05,000  我覺得這是一個知識存在的方面嘛 就是框架然後核心特色這樣子\n",
            "[  8%] 00:06:05,000 → 00:06:09,000  好,我發現我只要轉手機跟電腦\n",
            "[  8%] 00:06:09,000 → 00:06:13,000  你們剛剛是問到說就是未成什麼時候可以完成這本書\n",
            "[  8%] 00:06:13,000 → 00:06:18,000  然後是說是十月,十月但是不確定是什麼時候是嗎?\n",
            "[  8%] 00:06:18,000 → 00:06:20,000  Yes\n",
            "[  9%] 00:06:20,000 → 00:06:35,000  我做出這個交戰手冊主要是想說我不知道能不能去陪軍做一些類似跟AI相關的工具\n",
            "[  9%] 00:06:35,000 → 00:06:40,000  因為我的經驗會是如果有了一個標準的準則\n",
            "[  9%] 00:06:40,000 → 00:06:43,600  算是這種抽象的邏輯的話\n",
            "[  9%] 00:06:43,600 → 00:06:48,800  就能夠讓實際在寫獎益的時候\n",
            "[  9%] 00:06:48,800 → 00:06:53,200  可能就可以搭配給AI去自動生成一些類似的東西\n",
            "[  9%] 00:06:53,200 → 00:06:57,600  或是甚至可以去檢驗說這份獎益有沒有包含到\n",
            "[  9%] 00:06:57,600 → 00:07:00,000  這個交戰手冊裡面鎖定\n",
            "[  9%] 00:07:00,000 → 00:07:08,000  我覺得這可能也會讓微塵在寫講義的時候再更快一點。\n",
            "[ 10%] 00:07:08,000 → 00:07:15,000  然後具體來說這裡面的這些校章手冊裡面的所有東西,\n",
            "[ 10%] 00:07:15,000 → 00:07:20,000  玉茜你剛是問我說\n",
            "[ 10%] 00:07:20,000 → 00:07:21,200  我要講什麼\n",
            "[ 10%] 00:07:21,200 → 00:07:24,040  就你可能要稍微跟他說明一下\n",
            "[ 10%] 00:07:24,040 → 00:07:25,240  然後介紹一下\n",
            "[ 10%] 00:07:27,240 → 00:07:28,040  很多耶\n",
            "[ 10%] 00:07:32,500 → 00:07:35,240  維承目前我有幫你按照那個\n",
            "[ 10%] 00:07:35,240 → 00:07:37,400  我覺得的優先順序去排\n",
            "[ 10%] 00:07:37,400 → 00:07:39,600  就是第一個姿勢框架的話\n",
            "[ 10%] 00:07:39,600 → 00:07:40,400  就是我覺得\n",
            "[ 10%] 00:07:40,000 → 00:07:44,000  我覺得這份獎益會最迫切需要的東西\n",
            "[ 10%] 00:07:44,000 → 00:07:47,000  然後所謂的知識框架你可以把它想像成\n",
            "[ 10%] 00:07:47,000 → 00:07:51,000  或寫一個法律系的那個解題的東西\n",
            "[ 11%] 00:07:51,000 → 00:07:55,000  就是我好像記得你有學過民法\n",
            "[ 11%] 00:07:55,000 → 00:07:58,000  還是其他的法律相關的東西\n",
            "[ 11%] 00:07:58,000 → 00:08:00,000  但你也大概可以知道\n",
            "[ 11%] 00:08:00,000 → 00:08:14,980  當你面對一個複雜的案件的時候,你一定要有一套固定的思考方式跟答題方式,你才能夠快速進入到那個理解的框架裡面,然後按照這些步驟去解那個題。\n",
            "[ 11%] 00:08:14,980 → 00:08:20,000  那即便這個步驟可能有一些是形同虛設的,有一些可能在...\n",
            "[ 11%] 00:08:20,000 → 00:08:23,340  在某些題目當中其實根本就是非必要的\n",
            "[ 11%] 00:08:23,340 → 00:08:26,880  可是一旦你有了一個固定的解題框\n",
            "[ 11%] 00:08:26,880 → 00:08:28,000  這樣的思考流程\n",
            "[ 11%] 00:08:28,000 → 00:08:30,440  你在解題的時候就會更有確定感\n",
            "[ 11%] 00:08:30,440 → 00:08:34,580  然後一方面是讓學生能夠感覺自己學到\n",
            "[ 11%] 00:08:34,580 → 00:08:37,660  很具體的感受到自己有學到一套策略\n",
            "[ 12%] 00:08:37,660 → 00:08:40,000  另外一方面也是我們在行銷的\n",
            "[ 12%] 00:08:40,000 → 00:08:46,000  也會更能夠拿這一個策略,這套方法論去推廣出去。\n",
            "[ 12%] 00:08:46,000 → 00:08:54,000  所以我自己是有幫你舉的一個物理上面的例子是先聚焦再發散。\n",
            "[ 12%] 00:08:54,000 → 00:09:00,000  然後我就直接幫你寫了先聚焦再發散這個東西的\n",
            "[ 12%] 00:09:00,000 → 00:09:03,000  This is...wait a minute, the jade line is sliding down\n",
            "[ 12%] 00:09:03,000 → 00:09:06,000  Sliding down, sliding down, sliding down\n",
            "[ 12%] 00:09:06,000 → 00:09:08,000  Hey, this is the correct one\n",
            "[ 12%] 00:09:08,000 → 00:09:11,000  I forgot to delete the top\n",
            "[ 12%] 00:09:11,000 → 00:09:15,000  And then there is a physical demonstration down there\n",
            "[ 12%] 00:09:15,000 → 00:09:20,000  I will want to see that the microcosm may be speaking again\n",
            "[ 13%] 00:09:20,000 → 00:09:28,000  內容的部分先去告訴學生說所謂的先聚焦再發散這個答題策略的核心觀念是什麼\n",
            "[ 13%] 00:09:28,000 → 00:09:34,000  就是什麼是聚焦什麼是發散為什麼聚焦什麼發散然後如何聚焦如何發散\n",
            "[ 13%] 00:09:34,000 → 00:09:40,000  接下來就是透過各種抽象的步驟整理各種抽象的策略\n",
            "[ 13%] 00:09:40,000 → 00:09:46,000  一步一步的去告訴學生說這一個知識框架到底想要傳達的是什麼\n",
            "[ 13%] 00:09:46,000 → 00:09:49,000  然後進到你的題目部分\n",
            "[ 13%] 00:09:49,000 → 00:09:53,000  題目我們等下還會討論說它是要做成就是多少頁數\n",
            "[ 13%] 00:09:53,000 → 00:09:55,000  然後要不要做成電子檔\n",
            "[ 13%] 00:09:55,000 → 00:09:59,000  然後等下育前也會補充說學生對於電子檔的看法這些的\n",
            "[ 14%] 00:10:00,000 → 00:10:12,760  不論如何把題目每一題的解題過程還有每一個詳節都去套用這個不管是三步驟的發賽也好還是先聚焦的發賽\n",
            "[ 14%] 00:10:12,760 → 00:10:19,760  只要固定有一個解題的框架固定的一個算是一個噱頭或是一個包裝\n",
            "[ 14%] 00:10:20,000 → 00:10:22,560  它都可以讓學生更有一個確定感\n",
            "[ 14%] 00:10:22,560 → 00:10:25,760  所以我就會希望這本書最少最少最少最少最少\n",
            "[ 14%] 00:10:25,760 → 00:10:28,000  其他可以慢慢再補上\n",
            "[ 14%] 00:10:28,000 → 00:10:33,000  但是我覺得這個是我會希望可以加進去書\n",
            "[ 14%] 00:10:33,000 → 00:10:34,600  然後再出版會比較好\n",
            "[ 14%] 00:10:34,600 → 00:10:37,000  看我講完了\n",
            "[ 14%] 00:10:40,000 → 00:10:44,000  你目前對這部分有任何的問題嗎?\n",
            "[ 15%] 00:10:49,000 → 00:10:59,000  我要再想就是怎麼具體去把它落實到書的每個章節裡面\n",
            "[ 15%] 00:11:00,000 → 00:11:04,000  OK\n",
            "[ 15%] 00:11:04,000 → 00:11:10,000  我可以問你你自己在打題的時候也會有這樣子的\n",
            "[ 15%] 00:11:10,000 → 00:11:16,000  它會給你一種感覺嗎?就是說物理每個題目好像都有一個感覺\n",
            "[ 15%] 00:11:16,000 → 00:11:20,000  還是你是每個題目有不同的感覺?\n",
            "[ 15%] 00:11:20,000 → 00:11:24,000  好像沒有一個固定的流程\n",
            "[ 15%] 00:11:24,000 → 00:11:31,000  就是覺得可能是\n",
            "[ 15%] 00:11:31,000 → 00:11:33,000  我不會啊\n",
            "[ 15%] 00:11:33,000 → 00:11:35,000  但我覺得他們可能要先\n",
            "[ 15%] 00:11:35,000 → 00:11:37,000  抓到情況再說什麼\n",
            "[ 15%] 00:11:37,000 → 00:11:39,000  但是我就\n",
            "[ 16%] 00:11:40,000 → 00:11:44,000  我覺得我可以抓到,但我覺得他們可能是沒辦法抓到,所以寫不出來。\n",
            "[ 16%] 00:11:46,000 → 00:11:51,000  所以我覺得要先教他們怎麼把題目的點抓出來。\n",
            "[ 16%] 00:11:53,000 → 00:12:00,000  還是我在想會不會你可以跟TradeGVD聊,就你把你看的那些,你可能跟...\n",
            "[ 16%] 00:12:00,000 → 00:12:04,000  跟ChangeGPT聊個十個題目到二十個題目\n",
            "[ 16%] 00:12:04,000 → 00:12:07,000  然後你可能就請他幫你總結一下你這套思路\n",
            "[ 16%] 00:12:07,000 → 00:12:12,000  它背後的核心的步驟\n",
            "[ 16%] 00:12:12,000 → 00:12:15,000  還有你關注的重點\n",
            "[ 16%] 00:12:15,000 → 00:12:18,000  怎麼樣變成一套固定的策略\n",
            "[ 16%] 00:12:18,000 → 00:12:20,000  你可以試試看這個\n",
            "[ 16%] 00:12:20,000 → 00:12:20,500  Ok\n",
            "[ 17%] 00:12:40,000 → 00:12:43,000  你這本書最主要的核心的點是什麼東西 你這本書最主要的核心的點是什麼東西\n",
            "[ 17%] 00:12:47,000 → 00:12:52,000  如果以英文英文的書去舉例的話 就會像是作文書的話\n",
            "[ 17%] 00:12:52,000 → 00:12:58,000  雖然說它有很多很多的內容 但是我們會推出一個最主要的基點 就是它的八條公式\n",
            "[ 17%] 00:12:58,000 → 00:13:00,000  然後這個八條公式也是我們\n",
            "[ 17%] 00:13:00,000 → 00:13:04,500  主要不管是拿在書籍的生存或在社群的行銷上\n",
            "[ 17%] 00:13:04,500 → 00:13:06,700  我們都會拿著八條公式去主打\n",
            "[ 18%] 00:13:06,700 → 00:13:10,580  所以它對於學生的記憶或是這本書的整體\n",
            "[ 18%] 00:13:10,580 → 00:13:14,060  它就會有一個固定的記憶格式\n",
            "[ 18%] 00:13:14,060 → 00:13:16,040  就是大家對於這本書就會是\n",
            "[ 18%] 00:13:16,040 → 00:13:18,900  這個就是那個八條公式就是那個很屌\n",
            "[ 18%] 00:13:18,900 → 00:13:19,980  然後一模獨創的那個\n",
            "[ 18%] 00:13:20,000 → 00:13:24,640  所以也會需要你在幫我寫這本書的時候\n",
            "[ 18%] 00:13:24,640 → 00:13:27,700  也去稍微想一下你這本書的核心特色\n",
            "[ 18%] 00:13:27,700 → 00:13:29,160  最主要的那個點會是什麼\n",
            "[ 18%] 00:13:29,160 → 00:13:30,840  然後是什麼東西是可以對\n",
            "[ 18%] 00:13:30,840 → 00:13:33,760  拿出去打給社群媒體的\n",
            "[ 18%] 00:13:33,760 → 00:13:35,900  這部分有問題嗎\n",
            "[ 18%] 00:13:35,900 → 00:13:37,900  OK\n",
            "[ 18%] 00:13:37,900 → 00:13:39,220  好\n",
            "[ 18%] 00:13:40,000 → 00:13:44,960  好 子明請說\n",
            "[ 18%] 00:13:44,960 → 00:13:48,960  好 我剛剛的那個核心特色\n",
            "[ 18%] 00:13:48,960 → 00:13:53,020  如果我以前在寫物理的內容跟題目的時候\n",
            "[ 18%] 00:13:53,020 → 00:13:54,920  想不到這個特色的話\n",
            "[ 19%] 00:13:54,920 → 00:13:57,340  其實也可以就是照個路\n",
            "[ 19%] 00:13:57,340 → 00:13:59,980  把它變成說是在讀物\n",
            "[ 19%] 00:14:00,000 → 00:14:03,000  你覺得物理這個科目上面的策略\n",
            "[ 19%] 00:14:03,000 → 00:14:05,000  可能就可以想一個什麼循環圖啊\n",
            "[ 19%] 00:14:05,000 → 00:14:09,000  還是什麼正面加強的理論啊什麼的\n",
            "[ 19%] 00:14:09,000 → 00:14:13,000  但就是不一定要是物理的那些章節\n",
            "[ 19%] 00:14:13,000 → 00:14:16,000  你也可以是講你的讀書方法或筆記方法\n",
            "[ 19%] 00:14:16,000 → 00:14:18,000  它也可以變成是一個核心特色\n",
            "[ 19%] 00:14:20,000 → 00:14:23,000  我再想想。\n",
            "[ 19%] 00:14:25,000 → 00:14:35,000  那我也想順便確認一下,你有預計什麼時候可能會確定這本書的整個核心特色嗎?\n",
            "[ 19%] 00:14:35,000 → 00:14:40,000  會需要等你內容寫完嗎?還是你在這中間的過程中你可以先...\n",
            "[ 20%] 00:14:40,000 → 00:14:41,920  跟我確定\n",
            "[ 20%] 00:14:41,920 → 00:14:47,960  應該可以比內容早確定\n",
            "[ 20%] 00:14:47,960 → 00:14:49,680  但是我現在還沒有\n",
            "[ 20%] 00:14:49,680 → 00:14:52,060  就是想出來它是什麼\n",
            "[ 20%] 00:14:52,060 → 00:14:54,940  OK好沒有問題\n",
            "[ 20%] 00:14:54,940 → 00:14:58,180  然後再來下一個的話\n",
            "[ 20%] 00:14:58,180 → 00:14:59,980  會是學習方式跟記憶策略\n",
            "[ 20%] 00:15:00,000 → 00:15:08,000  因為我知道你有先看過整個的內容,所以我想確認你對於這部分有任何問題嗎?\n",
            "[ 20%] 00:15:08,000 → 00:15:17,000  或是有特別想詢問的點嗎?如果沒有的話我們就加快進度,就不用這樣一個一個特別的去講解。\n",
            "[ 21%] 00:15:20,000 → 00:15:27,000  因為就是這邊看起來比較想要說就是要理解\n",
            "[ 21%] 00:15:27,000 → 00:15:35,000  但是我不確定就是他們要理解全盤理解的話會耗費的成本要多少\n",
            "[ 21%] 00:15:35,000 → 00:15:40,000  還是有些人是不是只是想要把它把固定的流程背起來\n",
            "[ 21%] 00:15:40,000 → 00:15:42,800  然後就可以去解題\n",
            "[ 21%] 00:15:42,800 → 00:15:46,200  所以我要著重在\n",
            "[ 21%] 00:15:46,200 → 00:15:48,000  就是不用全盤理解\n",
            "[ 21%] 00:15:48,000 → 00:15:49,200  但是比較好解題\n",
            "[ 21%] 00:15:49,200 → 00:15:51,600  還是希望他們比較好理解\n",
            "[ 21%] 00:15:51,600 → 00:15:56,100  然後就是底子很穩這樣\n",
            "[ 21%] 00:15:56,100 → 00:15:58,400  方向應該在那邊\n",
            "[ 21%] 00:15:58,400 → 00:16:00,000  我覺得會比較看\n",
            "[ 21%] 00:16:00,000 → 00:16:04,200  你這本書的定位點在哪裡?\n",
            "[ 21%] 00:16:04,200 → 00:16:09,800  子民剛說有要講話,我有看到你那個框框。\n",
            "[ 22%] 00:16:09,800 → 00:16:14,000  好像上次跟維城討論的時候你是說,\n",
            "[ 22%] 00:16:14,000 → 00:16:20,000  你希望事實上不知道怎麼開始讀物理的人也可以找到一個方向。\n",
            "[ 22%] 00:16:20,000 → 00:16:25,440  所以你可能打的比較算是中間的族群,是嗎?\n",
            "[ 22%] 00:16:25,440 → 00:16:27,240  算是。\n",
            "[ 22%] 00:16:27,240 → 00:16:28,240  喔。\n",
            "[ 22%] 00:16:34,900 → 00:16:40,000  我會去做這個學習策略的這個地方其實是想說你...\n",
            "[ 22%] 00:16:40,000 → 00:16:48,220  你如果在傳達你的想法跟知識的時候,能夠不要做任何的刪減,\n",
            "[ 23%] 00:16:49,040 → 00:16:58,500  而是你就把最難的東西端出來給學生,可是呢,你還是可以面對初級跟總級的學生,\n",
            "[ 23%] 00:16:58,500 → 00:17:00,500  但是你的...\n",
            "[ 23%] 00:17:00,000 → 00:17:20,120  實施卻是最難的,那這中間的那個gap,中間的那個就是轟溝,你就要透過這些學習方式跟記憶策略的引導,就是如果你的觀念越難,你中間就要解釋越多這樣子的學習策略,然後讓這些重等到初級的學生,\n",
            "[ 23%] 00:17:20,000 → 00:17:22,000  學生也能夠學起來\n",
            "[ 23%] 00:17:22,000 → 00:17:26,000  我當初設計就有這樣的想法\n",
            "[ 23%] 00:17:26,000 → 00:17:36,000  所以我就先把全部東西都最難的部分也寫出來\n",
            "[ 23%] 00:17:36,000 → 00:17:40,000  然後我想往後面再做一個\n",
            "[ 24%] 00:17:40,000 → 00:17:58,260  比較重點的整理,這樣,就是如果你對前面的深入學習沒有興趣的話,那你就直接看重點就好了,這樣應該比較好,就是兩邊都照顧到,也可以,又或者是說你其實也可以,\n",
            "[ 24%] 00:18:00,000 → 00:18:01,840  這點我可能還是會存疑啦\n",
            "[ 24%] 00:18:01,840 → 00:18:03,760  我其實也沒有很確定\n",
            "[ 24%] 00:18:03,760 → 00:18:07,900  就是因為我自己的作文書也是寫到最難\n",
            "[ 24%] 00:18:07,900 → 00:18:10,800  確實也是有學生會覺得太難\n",
            "[ 24%] 00:18:10,800 → 00:18:14,840  但我會傾向是說如果你能夠用這些\n",
            "[ 24%] 00:18:14,840 → 00:18:17,460  就是我有給你一個檔案\n",
            "[ 24%] 00:18:17,460 → 00:18:20,000  就是在這個頁面裡面還有一個連接\n",
            "[ 24%] 00:18:20,000 → 00:18:23,000  我有一個可以出去的檔案叫核心學習策略\n",
            "[ 24%] 00:18:23,000 → 00:18:25,000  你有看過這個嗎?一個\n",
            "[ 25%] 00:18:25,000 → 00:18:28,000  對對對對現在有打開了這個\n",
            "[ 25%] 00:18:28,000 → 00:18:33,000  就是你就可以把一些這裡面的讀書策略跟技巧\n",
            "[ 25%] 00:18:37,000 → 00:18:39,000  這個檔案我還沒看過\n",
            "[ 25%] 00:18:40,000 → 00:18:43,000  你可以先把它看一下。\n",
            "[ 25%] 00:18:43,000 → 00:18:54,000  我自己教學的經驗是讓我發現說這些策略它其實不是只用在英文。\n",
            "[ 25%] 00:18:54,000 → 00:18:59,000  我昨天也是用這個東西去跟學生講數學什麼學。\n",
            "[ 25%] 00:19:00,000 → 00:19:07,000  我想說這東西其實可以一定程度幫助學生理解一些太複雜或太困難的觀念。\n",
            "[ 26%] 00:19:07,000 → 00:19:16,000  然後我就會覺得你跟他解釋越多這些學習策略,他們可能就會越能夠理解你想要傳達的物理專業知識。\n",
            "[ 26%] 00:19:16,000 → 00:19:20,000  所以就是取決於你想要寫多難的東西,然後就加多少。\n",
            "[ 26%] 00:19:20,000 → 00:19:25,000  好,講完嘅。\n",
            "[ 26%] 00:19:25,000 → 00:19:29,000  威神那邊有問題嗎?\n",
            "[ 26%] 00:19:29,000 → 00:19:31,000  暫時沒有。\n",
            "[ 26%] 00:19:31,000 → 00:19:35,000  到時候再麻煩你會後花一些時間幫我看過,\n",
            "[ 26%] 00:19:35,000 → 00:19:39,000  然後如果有不懂的地方可以再隨時跟我們講。\n",
            "[ 26%] 00:19:39,000 → 00:19:40,000  好。\n",
            "[ 26%] 00:19:40,000 → 00:19:45,100  再嚟嘅話就會系梳集咗一個大嘅架構,\n",
            "[ 26%] 00:19:45,100 → 00:19:51,880  佢就跟其實就跟你現在嗰個章節都系很像,\n",
            "[ 26%] 00:19:52,160 → 00:19:55,420  但就系我哋嘅章節架構可能要再清楚明確一點,\n",
            "[ 27%] 00:19:57,760 → 00:19:59,960  然後像呢些可能\n",
            "[ 27%] 00:20:00,000 → 00:20:07,000  你可以先幫我列完,然後如果你需要一些圖示的話,這些我們都可以直接再幫你做。\n",
            "[ 27%] 00:20:11,000 → 00:20:20,000  所以大致上那個架構的話就會是講,就是可能這本書的蓋欄,然後跟這本書的使用說明,然後第一個的大張點。\n",
            "[ 27%] 00:20:20,000 → 00:20:39,000  第二個大章節,然後可能你大章節完之後你會有一個小的,你會先有一個小的總結,然後你的小章節一樣會有一個小的總結,然後才會是這個小章節裡面的氣象,然後最後你還是需要再幫他附一個總結,這樣會是一個比較完整的架構,然後也比較能幫助學生達到一個比較好的學習方式。\n",
            "[ 27%] 00:20:40,000 → 00:20:42,000  所以書籍加關可以參考這邊\n",
            "[ 28%] 00:20:42,000 → 00:20:44,000  好 子明起說\n",
            "[ 28%] 00:20:44,000 → 00:20:46,000  我喔 我又有話要說了\n",
            "[ 28%] 00:20:46,000 → 00:20:48,000  就是你除了\n",
            "[ 28%] 00:20:48,000 → 00:20:50,000  我要說什麼\n",
            "[ 28%] 00:20:50,000 → 00:20:52,000  你的大架構裡面\n",
            "[ 28%] 00:20:52,000 → 00:20:54,000  其實可以多加入一些些\n",
            "[ 28%] 00:20:54,000 → 00:20:56,000  就是比較感性一點的東西\n",
            "[ 28%] 00:20:56,000 → 00:20:58,000  就是你在書籍的可能\n",
            "[ 28%] 00:20:58,000 → 00:21:00,000  在那個章節的開頭\n",
            "[ 28%] 00:21:00,000 → 00:21:03,400  會需要先有一個簡單的總結或是一個概覽\n",
            "[ 28%] 00:21:03,400 → 00:21:05,100  然後讓學生可以進入這個章節\n",
            "[ 28%] 00:21:05,100 → 00:21:07,560  那章節的最後結束也會有一個總結\n",
            "[ 28%] 00:21:07,560 → 00:21:10,480  只是你的那個開始跟那個總結\n",
            "[ 28%] 00:21:10,480 → 00:21:13,220  就是不一定要是很理性\n",
            "[ 28%] 00:21:13,220 → 00:21:18,420  然後很踏實的那種知識上面的整理\n",
            "[ 28%] 00:21:18,420 → 00:21:19,980  你也可以在這邊加一些\n",
            "[ 28%] 00:21:20,000 → 00:21:22,500  讓學生可以心情好一點的東西\n",
            "[ 28%] 00:21:22,500 → 00:21:24,500  譬如說剛開始就是\n",
            "[ 28%] 00:21:24,500 → 00:21:26,500  在章節開始的時候就說\n",
            "[ 29%] 00:21:26,500 → 00:21:29,500  這張適合有哪一些問題的學生\n",
            "[ 29%] 00:21:29,500 → 00:21:31,500  然後就列很多學生常見的問題\n",
            "[ 29%] 00:21:31,500 → 00:21:34,500  那學生可能就會自己跳進去對號入座\n",
            "[ 29%] 00:21:34,500 → 00:21:36,500  就領了一個身份標籤之後\n",
            "[ 29%] 00:21:36,500 → 00:21:38,000  就開始讀這個章節的時候\n",
            "[ 29%] 00:21:38,000 → 00:21:40,000  就會覺得自己的\n",
            "[ 29%] 00:21:40,000 → 00:21:42,000  問題就可以被妥善的解決\n",
            "[ 29%] 00:21:42,000 → 00:21:44,000  然後你到總結的地方再跟他說\n",
            "[ 29%] 00:21:44,000 → 00:21:48,000  恭喜你就是已經解決了這樣子的問題\n",
            "[ 29%] 00:21:48,000 → 00:21:50,000  你一定會越來越好啊什麼的\n",
            "[ 29%] 00:21:50,000 → 00:21:52,000  就可以給一些情緒上面的\n",
            "[ 29%] 00:21:52,000 → 00:21:53,000  給一些情緒價值\n",
            "[ 29%] 00:21:53,000 → 00:21:55,000  學生讀起來會比較\n",
            "[ 29%] 00:21:55,000 → 00:21:57,000  算是堅持得下去吧\n",
            "[ 29%] 00:21:57,000 → 00:22:00,000  如果你會把內容加得深入一點點的話\n",
            "[ 29%] 00:22:00,000 → 00:22:02,000  還有腳外的\n",
            "[ 29%] 00:22:02,000 → 00:22:04,000  咚\n",
            "[ 29%] 00:22:04,000 → 00:22:06,000  好\n",
            "[ 29%] 00:22:06,000 → 00:22:08,000  再來的話就是說幾個小架構\n",
            "[ 29%] 00:22:08,000 → 00:22:10,000  那個小架構就是偏\n",
            "[ 29%] 00:22:10,000 → 00:22:12,000  理論跟案例\n",
            "[ 30%] 00:22:12,000 → 00:22:14,000  這個的話前面其實也有提到\n",
            "[ 30%] 00:22:14,000 → 00:22:16,000  然後這個你可以\n",
            "[ 30%] 00:22:16,000 → 00:22:18,000  如果你沒有很懂的話可以再問我\n",
            "[ 30%] 00:22:18,000 → 00:22:20,000  然後\n",
            "[ 30%] 00:22:20,000 → 00:22:25,000  理論的主要呈現原則就是你要以系統性的東西去取代流水帳\n",
            "[ 30%] 00:22:25,000 → 00:22:30,000  就是系統性就比較像是可能第一步第二步然後原則一原則二原則三\n",
            "[ 30%] 00:22:30,000 → 00:22:34,000  然後或者是你可以用一個表格呈現可以用流程圖可以用矩陣都可以\n",
            "[ 30%] 00:22:34,000 → 00:22:40,000  然後這種方式會比起你只是跟他講說我今天去買了蘋果\n",
            "[ 30%] 00:22:40,000 → 00:22:44,500  如果怎麼樣怎麼樣,這種流水的方式好很多很多很多。\n",
            "[ 30%] 00:22:44,500 → 00:22:46,500  然後再來是案例的呈現原則。\n",
            "[ 30%] 00:22:46,500 → 00:22:50,800  你要盡量讓,就是用故事的方式去讓理論去落地。\n",
            "[ 30%] 00:22:50,800 → 00:22:56,000  就是你可以去多講幾個例子,然後但是你不能只是單純的講例子。\n",
            "[ 31%] 00:22:56,000 → 00:23:00,000  你要去刻意的選擇可以提出這些理論的關鍵點的案例。\n",
            "[ 31%] 00:23:00,000 → 00:23:03,820  然後讓案例的順序跟理論的分點是一致的\n",
            "[ 31%] 00:23:03,820 → 00:23:05,620  就是學生他可以互相對照\n",
            "[ 31%] 00:23:05,620 → 00:23:07,800  他不會覺得我現在看了這個理論\n",
            "[ 31%] 00:23:07,800 → 00:23:09,500  但是我找不到對應的案例\n",
            "[ 31%] 00:23:09,500 → 00:23:10,720  或者是我現在看了這個案例\n",
            "[ 31%] 00:23:10,720 → 00:23:12,820  但我也不知道你在講哪一個理論這樣子\n",
            "[ 31%] 00:23:12,820 → 00:23:15,740  目前這邊是OK的\n",
            "[ 31%] 00:23:15,740 → 00:23:16,920  OK\n",
            "[ 31%] 00:23:16,920 → 00:23:17,980  好\n",
            "[ 31%] 00:23:17,980 → 00:23:20,020  然後因為我們收集的內容\n",
            "[ 31%] 00:23:20,000 → 00:23:22,260  我们会以黑白色为主\n",
            "[ 31%] 00:23:22,260 → 00:23:25,540  所以如果你今天在帮我写里面的内容\n",
            "[ 31%] 00:23:25,540 → 00:23:28,920  然后有些比较想要让他们强调的重点\n",
            "[ 31%] 00:23:28,920 → 00:23:31,640  你可能需要帮我使用色块或是粗体\n",
            "[ 31%] 00:23:31,640 → 00:23:34,860  或是一些其他的框框标记都可以\n",
            "[ 31%] 00:23:34,860 → 00:23:37,840  但是你需要有一个让他们可以很好get到说\n",
            "[ 31%] 00:23:37,840 → 00:23:39,980  这里可能是相对于其他内容性\n",
            "[ 31%] 00:23:40,000 → 00:23:42,000  較為重要的地方\n",
            "[ 32%] 00:23:44,000 → 00:23:45,000  好\n",
            "[ 32%] 00:23:45,000 → 00:23:48,000  然後下面你應該也都有看過\n",
            "[ 32%] 00:23:48,000 → 00:23:50,000  那你有什麼地方有不了解\n",
            "[ 32%] 00:23:50,000 → 00:23:52,000  然後有想問的嗎\n",
            "[ 32%] 00:23:56,000 → 00:23:58,000  看起來沒有\n",
            "[ 32%] 00:23:58,000 → 00:23:59,000  好\n",
            "[ 32%] 00:23:59,000 → 00:24:00,000  線上話\n",
            "[ 32%] 00:24:00,000 → 00:24:01,200  與配套工具\n",
            "[ 32%] 00:24:01,200 → 00:24:05,040  啊沒事\n",
            "[ 32%] 00:24:05,040 → 00:24:05,720  在下面\n",
            "[ 32%] 00:24:05,720 → 00:24:08,000  對不起我插嘴了\n",
            "[ 32%] 00:24:08,000 → 00:24:08,420  對不起\n",
            "[ 32%] 00:24:08,420 → 00:24:10,940  好然後順便跟維成提\n",
            "[ 32%] 00:24:10,940 → 00:24:13,260  就是因為我知道你有做那個\n",
            "[ 32%] 00:24:13,260 → 00:24:14,180  就是\n",
            "[ 32%] 00:24:14,180 → 00:24:16,440  立貼題目\n",
            "[ 32%] 00:24:16,440 → 00:24:16,840  然後\n",
            "[ 32%] 00:24:16,840 → 00:24:18,660  就是他如果\n",
            "[ 32%] 00:24:18,660 → 00:24:20,000  如果你今天還是要把他寫在\n",
            "[ 32%] 00:24:20,000 → 00:24:27,180  你在書裡面或是你今天在書本裡面有提到,然後你不知道怎麼拍板的話,就是知名右相有一個是比較好的方式。\n",
            "[ 33%] 00:24:27,180 → 00:24:40,000  如果你今天想要讓學生,他是可以先看完題目,然後先有一個答案,然後再繼續看詳解的話,你可以變成說第一頁他有三題的題目,然後你翻頁之後是那三題的講解。\n",
            "[ 33%] 00:24:40,000 → 00:25:00,000  然後就稍微對一下拍板,才不會讓他們馬上就可以找到答案,然後也沒有,就如果直接讓他們看到答案,他們就會不去思考,所以你可以先讓他們思考完之後,然後再去翻譯了,去對照那個答案,然後去看你的想解步都是什麼,然後這樣子,一方面是它有一個比較好的拍板格式,另外一方面是可以主動去引導他們去思考。\n",
            "[ 33%] 00:25:00,000 → 00:25:02,940  而不是直接仰賴你的解答\n",
            "[ 33%] 00:25:02,940 → 00:25:04,940  OK\n",
            "[ 33%] 00:25:04,940 → 00:25:05,500  OK\n",
            "[ 33%] 00:25:05,500 → 00:25:09,540  但是上次不是說那個解答要用呈現上嗎\n",
            "[ 33%] 00:25:09,540 → 00:25:11,680  不然頁數就已經爆了\n",
            "[ 33%] 00:25:11,680 → 00:25:12,540  對\n",
            "[ 34%] 00:25:12,540 → 00:25:15,040  就只是如果你今天有在內容裡面\n",
            "[ 34%] 00:25:15,040 → 00:25:16,620  有稍微稍稍的提到\n",
            "[ 34%] 00:25:16,620 → 00:25:19,260  就是你可以有一兩題或是三四題的話\n",
            "[ 34%] 00:25:19,260 → 00:25:19,960  是可以用這樣的\n",
            "[ 34%] 00:25:20,000 → 00:25:39,940  然後關於題目答案線上話這個點,我們需要,好我先跟你抓出來討論這個點好了,因為我們有收到學生的回饋是說他們的父母其實沒有很希望讓他們嘗試這樣用平板手機或是電腦,所以關於\n",
            "[ 35%] 00:25:40,000 → 00:25:59,960  解答線上話這一點,我們可能需要再思考一下,因為不是所有的學生都可以達到很好的學習效果,也不是所有的學生都可以這樣做自由,所以我們需要想一個解決方法,讓他們不是只能完全的仰賴這個AI工具,而是AI工具會變成是輔助他們的學習效果,而不是讓他們去\n",
            "[ 35%] 00:26:00,000 → 00:26:02,000  從AI工具中\n",
            "[ 35%] 00:26:02,000 → 00:26:04,000  就他們不能只是用AI工具找到答案\n",
            "[ 35%] 00:26:04,000 → 00:26:06,000  他們應該要從其他地方也可以找到答案\n",
            "[ 35%] 00:26:06,000 → 00:26:08,000  AI工具只是一個輔助\n",
            "[ 35%] 00:26:08,000 → 00:26:10,000  所以我們可能要先解決這個\n",
            "[ 35%] 00:26:10,000 → 00:26:12,000  點\n",
            "[ 35%] 00:26:16,000 → 00:26:18,000  然後我自己有稍微想了一下\n",
            "[ 35%] 00:26:18,000 → 00:26:20,000  如果說你今天是\n",
            "[ 35%] 00:26:20,000 → 00:26:40,000  因為如果有太多業績的話,其實它是可以用一個比較簡略版的複測,就是它反正只是西馬丁,然後完完全全就是黑白印刷,那他們的題目跟解析是可以分開來的,然後當然對於印刷成本也不會跟原本一樣那麼高,然後學生也不會說如果我今天不能用手機,要不能用手機,\n",
            "[ 35%] 00:26:40,000 → 00:26:42,700  我就完全沒有辦法找到這題的答案\n",
            "[ 36%] 00:26:42,700 → 00:26:45,780  或是我也沒辦法找到這題的相接是什麼東西\n",
            "[ 36%] 00:26:45,780 → 00:26:46,640  對\n",
            "[ 36%] 00:26:46,640 → 00:26:50,020  所以想順便問問看你那邊有任何的想法嗎\n",
            "[ 36%] 00:26:50,020 → 00:26:54,780  所以\n",
            "[ 36%] 00:26:54,780 → 00:26:55,780  嗯\n",
            "[ 36%] 00:26:55,780 → 00:26:59,920  就是解答還是要包含在\n",
            "[ 36%] 00:27:00,000 → 00:27:04,000  裡面,就是包含在整份裡面嘛\n",
            "[ 36%] 00:27:04,000 → 00:27:08,900  這樣頁數不是還是一樣,只是超出\n",
            "[ 36%] 00:27:08,900 → 00:27:13,740  就會變成是以主側跟副側的方式去呈現\n",
            "[ 36%] 00:27:13,740 → 00:27:16,580  那副側的話我們的印刷品質就會是比較\n",
            "[ 36%] 00:27:16,580 → 00:27:19,260  沒有到跟主側一樣那麼好的\n",
            "[ 36%] 00:27:19,260 → 00:27:19,960  那它的印刷\n",
            "[ 36%] 00:27:20,000 → 00:27:25,000  雖然說會增加,但是不會像原本高的那麼誇張。\n",
            "[ 37%] 00:27:28,000 → 00:27:30,000  或者是有如果...\n",
            "[ 37%] 00:27:30,000 → 00:27:31,000  請說。\n",
            "[ 37%] 00:27:31,000 → 00:27:35,000  我想題目分享解葉樹很多耶,比較不像作文那樣子。\n",
            "[ 37%] 00:27:35,000 → 00:27:38,000  只有少少的就是葉。\n",
            "[ 37%] 00:27:40,000 → 00:27:53,000  因為它如果現在是要寫成題目一頁相接一頁,或是一頁三個題目,然後相接三頁的話,那個頁數應該都會比作文還要多很多。\n",
            "[ 37%] 00:28:00,000 → 00:28:05,360  但我哋冇辦法完全就把佢現場化\n",
            "[ 37%] 00:28:05,360 → 00:28:11,900  因為學生也確實冇辦法讓佢哋有個好的學習方式\n",
            "[ 38%] 00:28:11,900 → 00:28:17,060  那我哋現在壓業數是因為硬抓成本跟定價嗎?\n",
            "[ 38%] 00:28:17,060 → 00:28:20,000  就是說我哋定價如果就是要定在\n",
            "[ 38%] 00:28:20,000 → 00:28:26,000  500塊以內,業數就是不可以到300,350到400\n",
            "[ 38%] 00:28:26,000 → 00:28:27,000  對\n",
            "[ 38%] 00:28:31,000 → 00:28:34,000  你如果今天要到,就是真的業數要到三四百\n",
            "[ 38%] 00:28:34,000 → 00:28:38,000  其實是,就是沒有什麼關係啦\n",
            "[ 38%] 00:28:38,000 → 00:28:40,000  但是一方面\n",
            "[ 38%] 00:28:40,000 → 00:28:45,020  因為成本很高,所以我們分下來的利潤可能覺得是不多的。\n",
            "[ 38%] 00:28:45,020 → 00:28:58,020  第二方面是,如果我們今天是推一個他可以很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:28:58,020 → 00:29:09,980  然後這就會延伸到,如果我們今天是推一個很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:29:00,000 → 00:29:20,000  如果我們今天把排板放大,如果以A4尺寸去製作的話,A4它很吃排板功力,所以如果說你今天有任何一個排板點沒有排板好,或者是你的圖示效果不是那麼好的話,其實對於學生的學習狀況也不是到很良好。\n",
            "[ 39%] 00:29:20,000 → 00:29:22,000  如果你今天是一頁密密麻麻的文字\n",
            "[ 39%] 00:29:22,000 → 00:29:24,000  他們可能看到一半也不會想看\n",
            "[ 39%] 00:29:24,000 → 00:29:26,000  所以對於他們學習長相之後\n",
            "[ 39%] 00:29:26,000 → 00:29:28,000  不是那麼的佳\n",
            "[ 39%] 00:29:28,000 → 00:29:31,000  所以這個點我們可能要稍微想一下\n",
            "[ 39%] 00:29:31,000 → 00:29:33,000  我們去解決\n",
            "[ 39%] 00:29:35,000 → 00:29:40,000  以前如果你說學生有些會不想要用電子廠\n",
            "[ 40%] 00:29:40,000 → 00:29:46,000  那就代表之前說想借跟題目要做成線上資料庫\n",
            "[ 40%] 00:29:46,000 → 00:29:48,000  這個就等於是不可行的\n",
            "[ 40%] 00:29:48,000 → 00:29:51,000  對,會變成說如果真的要做的話\n",
            "[ 40%] 00:29:51,000 → 00:29:55,000  它更像是一個我給你一個更好的輔助工具\n",
            "[ 40%] 00:29:55,000 → 00:29:56,000  然後你如果今天想要\n",
            "[ 40%] 00:29:56,000 → 00:29:58,000  就你如果今天書籍沒有帶在身上的話\n",
            "[ 40%] 00:29:58,000 → 00:30:00,000  你也可以有一個\n",
            "[ 40%] 00:30:00,000 → 00:30:02,000  可以學習的地方\n",
            "[ 40%] 00:30:02,000 → 00:30:04,000  但現在問題點就是\n",
            "[ 40%] 00:30:04,000 → 00:30:06,000  很多家長他不願意讓學生\n",
            "[ 40%] 00:30:06,000 → 00:30:08,000  這樣去做\n",
            "[ 40%] 00:30:08,000 → 00:30:10,000  那如果\n",
            "[ 40%] 00:30:10,000 → 00:30:12,000  我們今天變成是\n",
            "[ 40%] 00:30:12,000 → 00:30:14,000  把題目跟\n",
            "[ 40%] 00:30:14,000 → 00:30:16,000  相借獨立成一本\n",
            "[ 40%] 00:30:16,000 → 00:30:18,000  複冊 然後\n",
            "[ 40%] 00:30:18,000 → 00:30:20,000  這本複冊的話\n",
            "[ 41%] 00:30:20,000 → 00:30:39,000  如果是買這本物理書,我們就會只給電子檔的複測,就是複測是用電子檔去給,然後他們可以自己印,又或是我們可以,他可以再加購,然後我們再把它印。\n",
            "[ 41%] 00:30:40,000 → 00:30:44,200  我覺得可能會以他們架構然後我們幫他印的方式\n",
            "[ 41%] 00:30:44,200 → 00:30:48,700  然後主要的話就是會印出的地方出去\n",
            "[ 41%] 00:30:48,700 → 00:30:53,000  不然我們成本一方面會拉高\n",
            "[ 41%] 00:30:53,000 → 00:30:57,900  另外一方面是他們好像不太擅長自己去印書\n",
            "[ 42%] 00:31:00,000 → 00:31:17,000  Ok,所以會需要麻煩維城,他可能還是要幫我把題目跟相機的都一樣有,就是可以有資本化的方式,就是你需要幫我拆開來寫,因為我們到時候會是以兩本書的形式推出去。\n",
            "[ 42%] 00:31:20,000 → 00:31:22,000  好,我可以提一個點嗎?\n",
            "[ 42%] 00:31:22,000 → 00:31:23,000  嗯。\n",
            "[ 42%] 00:31:23,000 → 00:31:36,000  就是微塵你可能現階段在做題目跟詳解的時候,你可能不要直接把它寫到 Word 檔,就是不要直接寫到你最後要出版的那個書上面。\n",
            "[ 42%] 00:31:36,000 → 00:31:40,000  而是你先用一個第三方的\n",
            "[ 42%] 00:31:40,000 → 00:31:43,000  另外一個的編輯的平台\n",
            "[ 42%] 00:31:43,000 → 00:31:47,000  你可能就先做在Notion上面\n",
            "[ 42%] 00:31:47,000 → 00:31:51,000  然後你把這些題目跟小節都做在Notion上面的時候\n",
            "[ 42%] 00:31:51,000 → 00:31:56,000  你一方面就是確保了我們剛剛講到的一個點是說\n",
            "[ 43%] 00:31:56,000 → 00:32:00,000  我們實體的東西要讓學生光看實體就看得懂\n",
            "[ 43%] 00:32:00,000 → 00:32:03,240  但是我們還是可以提供線上的輔助\n",
            "[ 43%] 00:32:03,240 → 00:32:06,340  這樣如果他們可能沒有帶到輔助\n",
            "[ 43%] 00:32:06,340 → 00:32:08,240  或是出了哪些狀況\n",
            "[ 43%] 00:32:08,240 → 00:32:10,340  或是他們想要用電子的方式去學\n",
            "[ 43%] 00:32:10,340 → 00:32:12,540  他們還是可以用電子的方式去做\n",
            "[ 43%] 00:32:12,540 → 00:32:14,840  所以就會變成說\n",
            "[ 43%] 00:32:14,840 → 00:32:17,000  利益\n",
            "[ 43%] 00:32:17,000 → 00:32:20,000  玉千你可不可以幫我開那個\n",
            "[ 43%] 00:32:20,000 → 00:32:25,000  英文共筆 英文選擇的那個檔案\n",
            "[ 43%] 00:32:25,000 → 00:32:27,000  對對對對\n",
            "[ 43%] 00:32:27,000 → 00:32:29,000  就是像現在的這個畫面\n",
            "[ 43%] 00:32:29,000 → 00:32:31,000  它就是一個英文的\n",
            "[ 43%] 00:32:31,000 → 00:32:33,000  英文選擇題的講義裡面的\n",
            "[ 43%] 00:32:33,000 → 00:32:36,000  線上的一個資料庫\n",
            "[ 43%] 00:32:36,000 → 00:32:39,000  你在寫你的那個題目跟詳解的時候\n",
            "[ 43%] 00:32:39,000 → 00:32:40,000  就建議你可以\n",
            "[ 44%] 00:32:40,000 → 00:33:00,000  寫在線上,然後就是在線上是一個已經有整理過的,有系統化的一個地方,然後這一個連結就可以直接分享給學生,然後學生就會有更多的自由度可以去在實體和電子上面同時的閱讀,就他們讀電子也得讀得懂,然後讀實體\n",
            "[ 44%] 00:33:00,000 → 00:33:11,060  你可以讀得懂,那你再把這個現在資料庫上面的東西再轉成實際書的排版跟內容就可以了,你這樣能聽得懂嗎?\n",
            "[ 44%] 00:33:13,860 → 00:33:19,940  我就是,因為我現在是把它拆在\n",
            "[ 44%] 00:33:20,000 → 00:33:29,000  因為我拿其他檔案,我的檔案,所以我之後寫完的話我再把它弄到 Notion上面。\n",
            "[ 45%] 00:33:29,000 → 00:33:31,000  這樣可以吧。\n",
            "[ 45%] 00:33:31,000 → 00:33:36,000  我覺得這樣應該會好一點,因為你我的檔不是會比較零散嗎?\n",
            "[ 45%] 00:33:40,000 → 00:33:44,000  欸可是notion上面就不能做那個公司那些咧?\n",
            "[ 45%] 00:33:46,000 → 00:33:48,000  Notion上可以做公司的\n",
            "[ 45%] 00:33:48,000 → 00:33:49,000  喔真的喔?\n",
            "[ 45%] 00:33:49,000 → 00:33:51,000  用Datex寫\n",
            "[ 45%] 00:33:53,000 → 00:33:55,000  你搜尋LATEX\n",
            "[ 45%] 00:34:00,000 → 00:34:02,000  等下等下等下\n",
            "[ 45%] 00:34:05,200 → 00:34:07,200  它是一個特定的滴刷\n",
            "[ 46%] 00:34:14,560 → 00:34:16,560  上面那個\n",
            "[ 46%] 00:34:20,000 → 00:34:30,340  就變成翅方,然後就要打一個固定的,就是一個字串進去,它就會變成翅方。\n",
            "[ 46%] 00:34:30,340 → 00:34:33,400  對,對,差不多了。\n",
            "[ 46%] 00:34:33,400 → 00:34:36,500  沃德裡面的公司應該是可以轉成這種模式的。\n",
            "[ 46%] 00:34:40,000 → 00:34:48,000  好,如果這方面維生不太會用的話,可以再問我,或是直接問培鈞也可以。\n",
            "[ 46%] 00:34:48,000 → 00:34:54,000  或是你也可以就直接在 Word 檔上面編輯,但是你截圖截到 Notion。\n",
            "[ 46%] 00:34:54,000 → 00:34:55,000  對。\n",
            "[ 46%] 00:34:55,000 → 00:34:59,000  因為 Notion 會有這種資料庫,就會比 Word 還要清楚一點。\n",
            "[ 47%] 00:35:00,000 → 00:35:05,000  好,那我就先在我的上面寫好了。\n",
            "[ 47%] 00:35:05,000 → 00:35:09,000  好,沒有問題。\n",
            "[ 47%] 00:35:09,000 → 00:35:20,000  然後這個的話其實剛剛子明就講到,你可以寫一個很深很深的關鍵,但是你要想辦法也要教會可能不是成都的嗎?\n",
            "[ 47%] 00:35:20,000 → 00:35:20,720  好的學生\n",
            "[ 47%] 00:35:20,720 → 00:35:26,800  那這部分剛剛你在聽的時候有問題嗎\n",
            "[ 47%] 00:35:26,800 → 00:35:34,340  你是說線上化跟配套工具\n",
            "[ 47%] 00:35:34,340 → 00:35:34,900  對\n",
            "[ 47%] 00:35:34,900 → 00:35:38,620  就是我們剛剛\n",
            "[ 47%] 00:35:40,000 → 00:35:45,000  我想講到自信框架的地方還有學習方式跟記憶策略的選擇\n",
            "[ 48%] 00:35:45,000 → 00:35:49,000  前面全部嗎?\n",
            "[ 48%] 00:35:49,000 → 00:35:52,000  對,它其實就是一樣的東西\n",
            "[ 48%] 00:35:52,000 → 00:35:55,000  就是教學理念的話我們希望它是以不間隔的方式\n",
            "[ 48%] 00:35:55,000 → 00:36:00,000  就是你要是寫好寫滿但是你要需要用方式讓可能\n",
            "[ 48%] 00:36:00,000 → 00:36:06,080  我比較沒有程度那麼高的學生去理解一個比較深奧的觀念\n",
            "[ 48%] 00:36:06,080 → 00:36:16,500  然後如果延續到前面剛剛提到的說\n",
            "[ 48%] 00:36:16,500 → 00:36:18,380  你要怎麼樣有一個很深奧的觀念\n",
            "[ 48%] 00:36:18,380 → 00:36:20,000  但是你卻不是只針對聰明\n",
            "[ 48%] 00:36:20,000 → 00:36:25,000  你只要把這個東西插成一個很碎片化的東西可以呈現。\n",
            "[ 48%] 00:36:25,000 → 00:36:28,000  它可能是三到五個獨立然後可以理解的小單元。\n",
            "[ 49%] 00:36:28,000 → 00:36:33,000  就你小單元小單元小單元讓他們去吸收,他們就比較可以接受。\n",
            "[ 49%] 00:36:33,000 → 00:36:37,000  然後再來的話是你每個單元只要專注一個最核心核心的點就好。\n",
            "[ 49%] 00:36:37,000 → 00:36:40,000  然後你可以搭配一些立體跟一些互動練習。\n",
            "[ 49%] 00:36:40,000 → 00:36:54,000  另外就是你要把那個包裝把它簡化簡化得很簡單,就是你可以用可能比較生物化的方式去解釋,或者是你可以用剩下一些視覺化的工具。\n",
            "[ 49%] 00:36:54,000 → 00:37:00,000  對,然後再來的話就是視超化落地,就是你這樣每個觀念都可以搭配一個可以讓它\n",
            "[ 49%] 00:37:00,000 → 00:37:12,000  所以我剛才會提到說你可能一個章節裡面你可能會有二到三題的練習題,你就可以搭配到視察化落地的這個部分。\n",
            "[ 50%] 00:37:12,000 → 00:37:20,000  好,然後再來的話就是剛其實就有稍微提到配套工具。\n",
            "[ 50%] 00:37:20,000 → 00:37:24,600  這幾個是我們覺得也可以用在物理講義裡面的配套工具\n",
            "[ 50%] 00:37:24,600 → 00:37:26,600  第一個就是Notion的筆記模板\n",
            "[ 50%] 00:37:26,600 → 00:37:28,600  然後再來的話就是SharedGPC的機器人\n",
            "[ 50%] 00:37:28,600 → 00:37:31,900  這個的話會是就是你先跟他聊聊聊\n",
            "[ 50%] 00:37:31,900 → 00:37:33,500  然後聊到說有一定的格式\n",
            "[ 50%] 00:37:33,500 → 00:37:37,100  然後之後我們再去轉成我們自己寫的機器人\n",
            "[ 50%] 00:37:37,100 → 00:37:40,100  就會是可能當學生輸入哪一些提示詞\n",
            "[ 50%] 00:37:40,000 → 00:37:44,420  他可以按照我們一開始就規定好的格式 然後產出相對應的內容\n",
            "[ 50%] 00:37:44,420 → 00:37:46,400  然後再來是Notebook LN\n",
            "[ 50%] 00:37:46,400 → 00:37:52,320  Notebook LN的話會比較偏向是我們一開始就先把我們的講義就先都上傳好\n",
            "[ 50%] 00:37:52,320 → 00:37:54,400  然後讓他的觀念是完整清楚的\n",
            "[ 50%] 00:37:54,400 → 00:37:56,780  那當學生他有什麼問題想要問的時候\n",
            "[ 50%] 00:37:56,780 → 00:37:59,020  他可以直接上Notebook LN然後問一個問題\n",
            "[ 50%] 00:37:59,020 → 00:37:59,300  然後\n",
            "[ 51%] 00:38:00,000 → 00:38:04,000  機器人就會想把相對應講義的內容輸出給他\n",
            "[ 51%] 00:38:04,000 → 00:38:07,000  就是一個很即時的問答\n",
            "[ 51%] 00:38:07,000 → 00:38:11,000  然後再來的話就是剛剛有給你看過的那個共編檔案\n",
            "[ 51%] 00:38:11,000 → 00:38:13,000  物理也可以這樣子做\n",
            "[ 51%] 00:38:13,000 → 00:38:17,000  但是這個的話就會很仰賴說\n",
            "[ 51%] 00:38:17,000 → 00:38:20,000  如果今天學生真的有上來留言\n",
            "[ 51%] 00:38:20,000 → 00:38:40,000  然後問問題的話,我們會需要很,就是至少在一定的時間內就可以幫他解完這樣的問題,然後並把這樣的東西再重新整理成新的內容,然後放上來,所以那個沒有到這麼急迫,但是我們還是會希望未來可以。\n",
            "[ 51%] 00:38:40,000 → 00:38:41,000  做\n",
            "[ 51%] 00:38:41,000 → 00:38:45,740  然後再來就是Notion的問答會診區\n",
            "[ 52%] 00:38:45,740 → 00:38:47,520  這個的話會是\n",
            "[ 52%] 00:38:47,520 → 00:38:49,900  譬如說我們有在IG啊\n",
            "[ 52%] 00:38:49,900 → 00:38:51,940  或者是在LINE的社群裡面\n",
            "[ 52%] 00:38:51,940 → 00:38:54,760  如果有任何人提到物理檢驗裡面的問題\n",
            "[ 52%] 00:38:54,760 → 00:38:57,020  我們都可以把它統整起來\n",
            "[ 52%] 00:38:57,020 → 00:38:58,500  然後就是你回答完之後\n",
            "[ 52%] 00:38:58,500 → 00:38:59,580  我們再把它統整起來\n",
            "[ 52%] 00:38:59,580 → 00:39:00,000  然後之後\n",
            "[ 52%] 00:39:00,000 → 00:39:03,320  有遇到一样的问题的时候学生就可以直接上来这边看\n",
            "[ 52%] 00:39:03,320 → 00:39:09,040  好那以上现在有问题吗\n",
            "[ 52%] 00:39:09,040 → 00:39:12,440  刚刚有说到那个notebook\n",
            "[ 52%] 00:39:12,440 → 00:39:16,140  它是就是上次是说它提供上来\n",
            "[ 52%] 00:39:16,140 → 00:39:17,700  然后它就会呈现解答\n",
            "[ 52%] 00:39:17,700 → 00:39:19,800  所以它是一个\n",
            "[ 52%] 00:39:20,000 → 00:39:25,020  它是AI嗎?還是它只是單純的查找的工具?\n",
            "[ 52%] 00:39:25,640 → 00:39:27,920  還是它是會生內容的那種AI?\n",
            "[ 53%] 00:39:30,120 → 00:39:33,000  它是一個幫助你去...\n",
            "[ 53%] 00:39:33,000 → 00:39:37,760  它是會自己生內容嗎?\n",
            "[ 53%] 00:39:38,360 → 00:39:39,980  還是它是拿出...\n",
            "[ 53%] 00:39:40,000 → 00:39:59,220  他會自己按照你給他的觀念格式,還有你給他的內容,然後去升,他裡面知道既有的內容,所以他不會去延伸說那些其實你並沒有輸入給他的東西,因為像ShareGP的話,他就很有可能是輸出一些\n",
            "[ 53%] 00:40:00,000 → 00:40:02,300  並唔係嗰麼正確性嘅嘢\n",
            "[ 53%] 00:40:02,300 → 00:40:06,400  但係NOPLM 佢就係完全按照你輸入乜嘢給佢\n",
            "[ 53%] 00:40:06,400 → 00:40:09,100  佢就會輸出相對應嘅嘢給學生\n",
            "[ 53%] 00:40:09,100 → 00:40:12,400  所以佢能確保佢裡面輸出嘅嘢一定係完整嘅\n",
            "[ 53%] 00:40:12,400 → 00:40:13,400  而且係正確嘅\n",
            "[ 53%] 00:40:15,600 → 00:40:16,400  好\n",
            "[ 54%] 00:40:16,400 → 00:40:19,900  對 所以會需要你完成獎益跟一些\n",
            "[ 54%] 00:40:20,000 → 00:40:23,000  我们再喂进去给那部LA\n",
            "[ 54%] 00:40:23,000 → 00:40:26,080  那到时候再用好\n",
            "[ 54%] 00:40:26,080 → 00:40:27,220  因为我现在也不会用它\n",
            "[ 54%] 00:40:27,220 → 00:40:29,160  好没有问题\n",
            "[ 54%] 00:40:29,160 → 00:40:32,440  然后善用比喻的话\n",
            "[ 54%] 00:40:32,440 → 00:40:34,380  上面也有讲过\n",
            "[ 54%] 00:40:34,380 → 00:40:35,780  然后你自己也有稍微看过\n",
            "[ 54%] 00:40:35,780 → 00:40:38,260  那这部分你有问题想询问的吗\n",
            "[ 54%] 00:40:40,000 → 00:40:44,000  應該比較還好,這部分應該比較簡單。\n",
            "[ 54%] 00:40:44,000 → 00:40:48,000  OK,那關於立場切換的部分呢?\n",
            "[ 54%] 00:40:51,000 → 00:41:00,000  這個就是子明剛剛跟你講到說,如果你今天是一個蓋籃的時候,你可以不要那麼的過於理性,或是就是一些文綽綽的\n",
            "[ 55%] 00:41:00,000 → 00:41:11,000  你可以是給他們一個對號入座的感覺,或是給他們一個比較偏向感性上面的支持,或是一些情緒支持這樣子,這就是舉例。\n",
            "[ 55%] 00:41:11,000 → 00:41:20,000  然後這個的話也是用在作文上的一個小小的行銷手段,它就是讓學生自己去想他們有什麼想法。\n",
            "[ 55%] 00:41:20,000 → 00:41:24,500  然後我們引導牠去對號入座到你真的有這個症狀\n",
            "[ 55%] 00:41:24,500 → 00:41:26,180  然後其實你很需要這個書\n",
            "[ 55%] 00:41:26,180 → 00:41:29,280  就是物理也可以用這樣的方式呈現\n",
            "[ 55%] 00:41:29,280 → 00:41:35,160  然後下面這些你在看的時候你有任何的問題嗎\n",
            "[ 55%] 00:41:35,160 → 00:41:37,300  或是有不太懂的地方嗎\n",
            "[ 56%] 00:41:40,000 → 00:42:00,000  應該都還好,剛剛前面說要給他們一些標籤,讓他們對好入座,我現在是沒想到有什麼啦,我想問你們,在寫物理的時候。\n",
            "[ 56%] 00:42:00,000 → 00:42:01,240  會有什麼問題嗎?\n",
            "[ 56%] 00:42:01,240 → 00:42:03,500  還是平常沒有在寫物理?\n",
            "[ 56%] 00:42:06,840 → 00:42:07,800  我有寫過\n",
            "[ 56%] 00:42:09,000 → 00:42:10,160  那你有什麼問題嗎?\n",
            "[ 56%] 00:42:11,540 → 00:42:12,660  我覺得從\n",
            "[ 56%] 00:42:13,660 → 00:42:16,560  如果是緯程那邊要整理這些問題的話\n",
            "[ 56%] 00:42:16,560 → 00:42:17,800  我反而會覺得\n",
            "[ 56%] 00:42:18,500 → 00:42:19,960  育謙那邊可能可以看\n",
            "[ 57%] 00:42:20,000 → 00:42:38,000  開一個物理的問答,限動的問答,然後藉由這樣子蒐集問題去知道學生的症節點在哪邊,然後就把那些問題全部灌到 CheckGPT,然後請CheckGPT整理學生有哪些類型,這樣應該就很快就可以找到那些問題。\n",
            "[ 57%] 00:42:38,000 → 00:42:40,000  但是問完那些問題之後……\n",
            "[ 57%] 00:42:40,000 → 00:42:47,000  可能未曾要幫忙簡單回答一下 因為育成可能沒辦法自己去回答物理的專業問題\n",
            "[ 57%] 00:42:47,000 → 00:42:52,000  被問問了但是沒有打算回答 這樣過分\n",
            "[ 57%] 00:42:52,000 → 00:43:00,000  我想舉一個例子就是我覺得我自己寫物理最大的祕訣是腦中藥\n",
            "[ 58%] 00:43:00,000 → 00:43:20,000  老公要有畫面,老公要有那個東西在跑的畫面,所以就可以把它當成是一個技巧,比如說看的那些物理的公式,看的那些數字,它沒有感覺怎麼樣,就可以去提。\n",
            "[ 58%] 00:43:20,000 → 00:43:28,000  提供他一些,譬如說像我剛剛講的那種讓自己比較有感覺的技巧這樣\n",
            "[ 58%] 00:43:28,000 → 00:43:30,000  類似這種方向\n",
            "[ 58%] 00:43:32,000 → 00:43:37,000  我有想過就是腦中要有畫面這件事情\n",
            "[ 58%] 00:43:37,000 → 00:43:40,000  但我後來發現就是好像不是每個人都可以做\n",
            "[ 58%] 00:43:40,000 → 00:43:44,000  就有些人特別沒有想像力\n",
            "[ 58%] 00:43:44,000 → 00:43:48,000  我要想一下就是要給我給他這個想像力\n",
            "[ 58%] 00:43:48,000 → 00:43:50,000  你要引導他去構思\n",
            "[ 58%] 00:43:50,000 → 00:43:52,000  對引導他去構思這個想像力\n",
            "[ 58%] 00:43:52,000 → 00:44:00,000  或是你也可以找一些線上的視覺化\n",
            "[ 59%] 00:44:00,000 → 00:44:04,000  現在有一些線上的物理方面的視覺化的工具\n",
            "[ 59%] 00:44:04,000 → 00:44:07,000  也可以引導他們去使用這些工具\n",
            "[ 59%] 00:44:07,000 → 00:44:10,000  然後自己去拉拉看那個訊息之類的\n",
            "[ 59%] 00:44:12,000 → 00:44:14,000  我可以稍微跟你提一個\n",
            "[ 59%] 00:44:14,000 → 00:44:17,000  可能比較像是聯想或者一個小技巧\n",
            "[ 59%] 00:44:17,000 → 00:44:20,000  像英文作文裡那個字名它就會\n",
            "[ 59%] 00:44:20,000 → 00:44:23,660  用break pin去講一些公式跟觀念\n",
            "[ 59%] 00:44:23,660 → 00:44:28,960  讓學生他們的想像畫面是以他們熟悉的東西去帶入\n",
            "[ 59%] 00:44:28,960 → 00:44:32,860  那他們就會比較好聯想到你要跟他們講什麼\n",
            "[ 59%] 00:44:32,860 → 00:44:38,020  然後當他們真的對於那個畫面沒有太大的感受的時候\n",
            "[ 59%] 00:44:38,020 → 00:44:39,900  他們也可以因為這個東西是他們比較\n",
            "[ 59%] 00:44:40,000 → 00:44:42,400  日常生活化就有在接觸的東西。\n",
            "[ 59%] 00:44:42,400 → 00:44:45,200  所以進而聯想到那個很抽象的畫面。\n",
            "[ 60%] 00:44:47,200 → 00:44:49,100  這就會是我們剛剛上面有講到的,\n",
            "[ 60%] 00:44:49,100 → 00:44:51,700  就是你可能要再多運用一些生活化\n",
            "[ 60%] 00:44:51,700 → 00:44:55,300  或是很日常的東西去做比喻,\n",
            "[ 60%] 00:44:55,300 → 00:44:57,100  然後去做例子的講解。\n",
            "[ 60%] 00:45:00,000 → 00:45:09,300  好,然後再來的話,學生需要會有一個固定的,固定默契的emoji,\n",
            "[ 60%] 00:45:09,460 → 00:45:13,680  因為它會是讓學生知道,我今天看到這個圖示的時候,\n",
            "[ 60%] 00:45:13,900 → 00:45:18,000  我就是接下來會看到什麼樣的內容,讓他們有一個小小的概念點。\n",
            "[ 61%] 00:45:20,000 → 00:45:40,000  但是如果以英文中文來講的話,這個東西就會是對應到總結的重點,然後小燈泡的話就會是一個口訣或是一個記憶法,然後如果你今天是一個手加一個筆的話,那就是你的動手練習,就是你可以稍微去幫他設計一個固定的符號,讓他們有一個小概念,他們才不會覺得...\n",
            "[ 61%] 00:45:40,000 → 00:45:44,000  看起來很亂,然後台板上我們也會比較整齊一點點。\n",
            "[ 61%] 00:45:44,000 → 00:45:48,140  然後如果今天是你想要自己跟學生講的話,\n",
            "[ 61%] 00:45:48,240 → 00:45:53,320  你也可以用一個可能老師的符號,或者是一個男生的符號,\n",
            "[ 61%] 00:45:53,500 → 00:45:56,440  然後跟他們講說這比較像是你心裡的話,\n",
            "[ 61%] 00:45:56,600 → 00:45:59,000  那他就不用那麼文綴綴,他就是真的可以很...\n",
            "[ 61%] 00:46:00,000 → 00:46:03,000  就是比較日常口語化的東西就可以了\n",
            "[ 61%] 00:46:03,000 → 00:46:06,000  然後再來就是上次就有提到的東西\n",
            "[ 61%] 00:46:06,000 → 00:46:08,000  就是說表達高用AI論搞過\n",
            "[ 61%] 00:46:08,000 → 00:46:11,000  因為現在的物理講義內容比較像是\n",
            "[ 61%] 00:46:11,000 → 00:46:13,000  你真的想到什麼然後就打什麼出來\n",
            "[ 61%] 00:46:13,000 → 00:46:15,000  它沒有一個固定的格式\n",
            "[ 62%] 00:46:15,000 → 00:46:18,000  然後甚至這樣的內容可能比較像是\n",
            "[ 62%] 00:46:18,000 → 00:46:20,000  只有你自己看得懂\n",
            "[ 62%] 00:46:20,000 → 00:46:22,000  所有的表達我們都可以丟到TradeGPT\n",
            "[ 62%] 00:46:22,000 → 00:46:24,000  就你只要把你的想法丟上去\n",
            "[ 62%] 00:46:24,000 → 00:46:26,000  然後剛才你說你可以幫我run稿嗎\n",
            "[ 62%] 00:46:26,000 → 00:46:28,000  或是你可以幫我修飾成\n",
            "[ 62%] 00:46:28,000 → 00:46:30,000  可能高中生也看得懂的話語\n",
            "[ 62%] 00:46:30,000 → 00:46:32,000  它就會直接幫你寫出來\n",
            "[ 62%] 00:46:32,000 → 00:46:34,000  但是它生成的內容\n",
            "[ 62%] 00:46:34,000 → 00:46:36,000  你還是需要再去檢查過\n",
            "[ 62%] 00:46:36,000 → 00:46:38,000  因為它有時候不一定是那麼正確\n",
            "[ 62%] 00:46:38,000 → 00:46:40,000  或是不一定那麼貼近你想要表達的\n",
            "[ 62%] 00:46:40,000 → 00:46:45,000  所以你就跟他多聊幾次就可以了。\n",
            "[ 62%] 00:46:45,000 → 00:46:47,000  好,以上是知識存在的方面。\n",
            "[ 62%] 00:46:47,000 → 00:46:51,000  然後如果是使用者體驗方面的話,\n",
            "[ 62%] 00:46:51,000 → 00:46:54,000  像是AI化、線上化跟連結種整理,\n",
            "[ 62%] 00:46:54,000 → 00:46:58,000  就會需要麻煩你在編寫獎益的內容之後,\n",
            "[ 62%] 00:46:58,000 → 00:47:00,000  在編寫獎益內容的之中,\n",
            "[ 62%] 00:47:00,000 → 00:47:02,800  我就邊想還有哪些東西可以去製作\n",
            "[ 63%] 00:47:02,800 → 00:47:04,900  然後在你撰寫的過程中\n",
            "[ 63%] 00:47:04,900 → 00:47:07,500  也可以邊製作一些AI工具\n",
            "[ 63%] 00:47:07,500 → 00:47:09,000  或是把東西線上畫\n",
            "[ 63%] 00:47:10,500 → 00:47:14,200  然後全球地圖廣告頁跟意見回饋購買東西調查\n",
            "[ 63%] 00:47:14,200 → 00:47:16,600  這些都會由e-mall這邊直接處理\n",
            "[ 63%] 00:47:18,000 → 00:47:19,500  然後再來是格式的話\n",
            "[ 63%] 00:47:20,000 → 00:47:30,000  因為我知道你現在跟小助手的方式 好像是你會先把他整理過 然後再傳檔案給他 對嗎?\n",
            "[ 63%] 00:47:32,000 → 00:47:33,000  對\n",
            "[ 63%] 00:47:33,000 → 00:47:38,000  對 所以格式的話可能要 就是從你那邊一開始打的時候\n",
            "[ 63%] 00:47:38,000 → 00:47:40,000  就是你開始編輯這個書的時候\n",
            "[ 63%] 00:47:40,000 → 00:47:42,240  你可能就要稍微幫我注意一下格式\n",
            "[ 63%] 00:47:42,240 → 00:47:43,980  我們就是以B5為主\n",
            "[ 63%] 00:47:43,980 → 00:47:46,060  然後那個初期線要稍微注意\n",
            "[ 64%] 00:47:46,060 → 00:47:48,780  至少邊邊要預留三面面\n",
            "[ 64%] 00:47:48,780 → 00:47:49,500  它會比較\n",
            "[ 64%] 00:47:49,500 → 00:47:53,520  就硬刷的時候才會比較不會卡到板\n",
            "[ 64%] 00:47:53,520 → 00:47:54,420  然後需要\n",
            "[ 64%] 00:47:54,420 → 00:47:55,620  預留多少\n",
            "[ 64%] 00:47:55,620 → 00:47:58,560  就是你開word\n",
            "[ 64%] 00:47:58,560 → 00:48:00,000  然後它會有那個\n",
            "[ 64%] 00:48:00,000 → 00:48:02,000  至少要窄\n",
            "[ 64%] 00:48:02,000 → 00:48:04,000  它有一個版面配飾\n",
            "[ 64%] 00:48:04,000 → 00:48:06,000  然後你最多最多只能選擇窄\n",
            "[ 64%] 00:48:06,000 → 00:48:08,000  然後不能再往下縮\n",
            "[ 64%] 00:48:10,000 → 00:48:12,000  等一下我再開給你看好了\n",
            "[ 64%] 00:48:12,000 → 00:48:14,000  稍等我一下\n",
            "[ 65%] 00:48:20,000 → 00:48:39,240  好,就是你在用Word等的時候,它其實有一個版面配置,然後你就,你需要先一開始就先幫我把大小分到。\n",
            "[ 65%] 00:48:40,000 → 00:48:42,640  啊我冇覆好,稍等我\n",
            "[ 65%] 00:48:42,640 → 00:48:44,080  奈咦阿捏\n",
            "[ 65%] 00:48:44,080 → 00:48:50,540  這樣有咩\n",
            "[ 65%] 00:48:50,540 → 00:48:55,720  所以你一開始就需要幫我把大小\n",
            "[ 65%] 00:48:55,720 → 00:48:57,880  就直接先選成B5的大小\n",
            "[ 65%] 00:48:57,880 → 00:48:59,780  然後邊界這邊\n",
            "[ 65%] 00:49:00,000 → 00:49:02,000  最多最多就是以窄為主\n",
            "[ 65%] 00:49:02,000 → 00:49:04,000  就是盡量不要再往下縮\n",
            "[ 65%] 00:49:04,000 → 00:49:08,000  不然我們的印刷照片可能會踩到旁邊\n",
            "[ 65%] 00:49:08,000 → 00:49:10,000  這部分OK咩?\n",
            "[ 65%] 00:49:10,000 → 00:49:12,000  OK\n",
            "[ 65%] 00:49:12,000 → 00:49:14,000  再超出一點點\n",
            "[ 65%] 00:49:14,000 → 00:49:16,000  一點點\n",
            "[ 65%] 00:49:16,000 → 00:49:18,000  對對對就是一點點\n",
            "[ 66%] 00:49:18,000 → 00:49:20,000  但不要壓得太緊\n",
            "[ 66%] 00:49:20,000 → 00:49:22,000  你可以回去剛那個地方嗎?\n",
            "[ 66%] 00:49:22,000 → 00:49:26,000  你看它的右上角\n",
            "[ 66%] 00:49:26,000 → 00:49:29,000  右上角是不是有一個L形的東西?\n",
            "[ 66%] 00:49:32,000 → 00:49:36,000  在紙張上有一個L形的框架\n",
            "[ 66%] 00:49:36,000 → 00:49:38,000  對這個\n",
            "[ 66%] 00:49:38,000 → 00:49:40,000  就是它的那個死角的那個\n",
            "[ 66%] 00:49:40,000 → 00:49:42,000  你的字可以寫到那邊\n",
            "[ 66%] 00:49:42,000 → 00:49:47,000  然後如果你字真的想要在外面再延伸一點點的話\n",
            "[ 66%] 00:49:47,000 → 00:49:52,000  就是不可以超過那個L型的中端\n",
            "[ 66%] 00:49:52,000 → 00:49:55,000  就不可以寫出L型的外面\n",
            "[ 66%] 00:49:55,000 → 00:49:59,000  就會是不會被拆到的格式\n",
            "[ 67%] 00:50:00,000 → 00:50:07,000  但是今天還是幫我縮在L型裡面會比較保險一點點\n",
            "[ 67%] 00:50:07,000 → 00:50:15,000  然後再來的話其他目前都有講過\n",
            "[ 67%] 00:50:15,000 → 00:50:20,000  這個呼籲社群宣傳\n",
            "[ 67%] 00:50:20,000 → 00:50:22,700  比較會像是你寫書已經寫到後半段之後\n",
            "[ 67%] 00:50:22,700 → 00:50:24,700  我們可以再來進行的東西\n",
            "[ 67%] 00:50:24,700 → 00:50:27,800  所以這個我們可以之後在開會的時候跟你講一下\n",
            "[ 67%] 00:50:29,800 → 00:50:33,300  然後誓願內容商品化會\n",
            "[ 67%] 00:50:33,300 → 00:50:34,800  這個就是範例\n",
            "[ 67%] 00:50:34,800 → 00:50:38,200  我們以英文作文或是英文文法\n",
            "[ 67%] 00:50:38,200 → 00:50:39,400  或是英文單字說的話\n",
            "[ 67%] 00:50:39,400 → 00:50:40,000  我們可能都會\n",
            "[ 67%] 00:50:40,000 → 00:50:46,320  給他一個備單的機器人 然後拿這個機器人去推廣我們的作文書跟其他的產品\n",
            "[ 68%] 00:50:46,320 → 00:50:49,560  就是當你使用這個機器人的時候 它底下其實會生成\n",
            "[ 68%] 00:50:49,560 → 00:50:54,860  如果你想看更多完整的內容 或者如果你想要看什麼更完整的文法解說\n",
            "[ 68%] 00:50:54,860 → 00:50:58,640  你可以購買一模一模的那本書 然後會貼一個下一個連結給他\n",
            "[ 68%] 00:50:58,640 → 00:51:00,000  就是到時候物理也可以用\n",
            "[ 68%] 00:51:00,000 → 00:51:02,800  用這種方式去做一個行銷宣傳。\n",
            "[ 68%] 00:51:02,800 → 00:51:06,800  在這裡,就是想知道如果背一個單字補輸一個觀念,\n",
            "[ 68%] 00:51:06,800 → 00:51:09,800  然後這就會是我們完整的書籍內容宣傳。\n",
            "[ 68%] 00:51:12,800 → 00:51:18,800  好,那目前以上有任何問題或是有任何想問的嗎?\n",
            "[ 68%] 00:51:20,000 → 00:51:26,120  因為Himoji那邊現在的樹就有了,所以還好。\n",
            "[ 68%] 00:51:26,120 → 00:51:31,440  然後你有一個MBTI那個是沒有要理它嗎?\n",
            "[ 69%] 00:51:34,960 → 00:51:40,020  因為這個可能就是對於物理...\n",
            "[ 69%] 00:51:40,000 → 00:51:43,200  講義有點難運用\n",
            "[ 69%] 00:51:43,200 → 00:51:43,840  其實\n",
            "[ 69%] 00:51:43,840 → 00:51:45,960  哦好那我就不理他\n",
            "[ 69%] 00:51:45,960 → 00:51:47,340  好好\n",
            "[ 69%] 00:51:47,340 → 00:51:48,280  子明你可以說\n",
            "[ 69%] 00:51:48,280 → 00:51:53,080  我寫那個其實只是一個紀錄\n",
            "[ 69%] 00:51:53,080 → 00:51:54,980  它不一定要寫NBT\n",
            "[ 69%] 00:51:54,980 → 00:51:56,820  我想講的只是說\n",
            "[ 69%] 00:51:56,820 → 00:51:59,240  你可以去設想\n",
            "[ 69%] 00:52:00,000 → 00:52:02,000  學生有千千百百多\n",
            "[ 69%] 00:52:02,000 → 00:52:04,000  就是有一些人\n",
            "[ 69%] 00:52:04,000 → 00:52:08,000  因為你自己怎麼學物理\n",
            "[ 69%] 00:52:08,000 → 00:52:10,000  跟其他人怎麼學物理\n",
            "[ 69%] 00:52:10,000 → 00:52:11,000  一定是非常不同的\n",
            "[ 69%] 00:52:11,000 → 00:52:13,000  然後除了是專業知識\n",
            "[ 69%] 00:52:13,000 → 00:52:15,000  觀念上面的落差之外\n",
            "[ 69%] 00:52:15,000 → 00:52:17,000  其實他們在理解知識\n",
            "[ 70%] 00:52:17,000 → 00:52:20,000  還有如何讀完這本書上面\n",
            "[ 70%] 00:52:20,000 → 00:52:22,500  本身就會有很大的不同\n",
            "[ 70%] 00:52:22,500 → 00:52:24,500  像譬如說喻謙好了\n",
            "[ 70%] 00:52:24,500 → 00:52:26,500  他如果今天讀到一本書\n",
            "[ 70%] 00:52:26,500 → 00:52:28,500  然後事實上他覺得很用心\n",
            "[ 70%] 00:52:33,500 → 00:52:35,500  如果是那本書讓喻謙覺得很用心\n",
            "[ 70%] 00:52:35,500 → 00:52:37,500  然後很有溫度\n",
            "[ 70%] 00:52:37,500 → 00:52:39,500  然後是很想把學徒顧好\n",
            "[ 70%] 00:52:39,500 → 00:52:40,500  喻謙就會想\n",
            "[ 70%] 00:52:40,000 → 00:52:42,000  你想把它讀完,你說是不是?\n",
            "[ 70%] 00:52:42,000 → 00:52:44,000  對\n",
            "[ 70%] 00:52:44,000 → 00:52:46,000  但是我的個性可能就會是\n",
            "[ 70%] 00:52:46,000 → 00:52:48,000  我想要看到超級爆炸具體的東西\n",
            "[ 70%] 00:52:48,000 → 00:52:50,000  你不要給我扯一些有的沒的的\n",
            "[ 70%] 00:52:50,000 → 00:52:52,000  剛才跟我講的重點\n",
            "[ 70%] 00:52:52,000 → 00:52:57,000  然後其他學生有些可能會喜歡圖像化的解說\n",
            "[ 70%] 00:52:57,000 → 00:53:00,000  然後就是你比起用文字去寫\n",
            "[ 70%] 00:53:00,000 → 00:53:01,800  寫第一步驟第二步驟第三步驟\n",
            "[ 71%] 00:53:01,800 → 00:53:05,300  你還不如直接用一張圖片或Canva的字圖\n",
            "[ 71%] 00:53:05,300 → 00:53:07,300  去告訴他三步驟是什麼\n",
            "[ 71%] 00:53:07,300 → 00:53:09,500  那又會有一些可能又會喜歡\n",
            "[ 71%] 00:53:09,500 → 00:53:13,100  就是兩個人的對話去推進一個觀念\n",
            "[ 71%] 00:53:13,100 → 00:53:14,600  就大家都有不同學習方式\n",
            "[ 71%] 00:53:14,600 → 00:53:16,900  然後我覺得你不一定要用MVTI\n",
            "[ 71%] 00:53:16,900 → 00:53:19,100  去把16個全部都想過一次\n",
            "[ 71%] 00:53:19,100 → 00:53:19,900  而是你\n",
            "[ 71%] 00:53:20,000 → 00:53:21,640  至少在寫獎音的時候\n",
            "[ 71%] 00:53:21,640 → 00:53:25,760  你要先抓幾個學生的標籤跟概念出來\n",
            "[ 71%] 00:53:25,760 → 00:53:28,640  可能是圖像化學生、理論化學生\n",
            "[ 71%] 00:53:28,640 → 00:53:31,040  然後比較情緒化的學生\n",
            "[ 71%] 00:53:31,040 → 00:53:32,000  抓幾個標籤出來\n",
            "[ 71%] 00:53:32,000 → 00:53:35,240  然後去寫獎音的時候照顧到這些學生的需求\n",
            "[ 71%] 00:53:37,240 → 00:53:39,040  好,我講完了\n",
            "[ 71%] 00:53:40,000 → 00:53:43,000  Ok, this part, do you think it's ok?\n",
            "[ 71%] 00:53:44,000 → 00:53:45,000  Yes, it's ok.\n",
            "[ 71%] 00:53:46,000 → 00:53:48,000  Ok, and then...\n",
            "[ 72%] 00:53:51,000 → 00:53:56,000  If you are in the process of making it, or you need some AI tools to help you,\n",
            "[ 72%] 00:53:56,000 → 00:54:00,000  you can find Pei Jun, he is a very good...\n",
            "[ 72%] 00:54:00,000 → 00:54:04,200  所以如果你在這雙方沒有問題的話都可以問他\n",
            "[ 72%] 00:54:04,200 → 00:54:16,000  我們不是還有一個是要問Pedro的事情嗎\n",
            "[ 72%] 00:54:20,000 → 00:54:22,000  我可以分享我的畫面嗎?\n",
            "[ 72%] 00:54:22,000 → 00:54:24,000  欸等一下,物理那邊都講完了吧?\n",
            "[ 72%] 00:54:24,000 → 00:54:26,000  對\n",
            "[ 72%] 00:54:26,000 → 00:54:30,000  好,那我想要問一下裴娟一個東西\n",
            "[ 72%] 00:54:30,000 → 00:54:32,000  我分享一下我的畫面\n",
            "[ 73%] 00:54:40,000 → 00:54:59,920  我们刚刚有讲到很多写讲义上面的东西,只是如果我们这边有这套准则,但是像伟臣可能写的时候还是会需要时不时回去看交战手册,然后有时候可能还是会不小心漏掉一些东西,或不知道怎么去使用,然后我在想如果我们未来\n",
            "[ 73%] 00:55:00,000 → 00:55:06,000  可能會需要同時跑很多本書 很多個合作者一起寫這樣一個話\n",
            "[ 73%] 00:55:06,000 → 00:55:09,000  我們來回溝通可能會需要花很多時間\n",
            "[ 73%] 00:55:09,000 → 00:55:14,000  然後就想到說 之前我在學SEO的時候\n",
            "[ 73%] 00:55:14,000 → 00:55:17,000  有一個像這樣子的工具\n",
            "[ 74%] 00:55:17,000 → 00:55:20,000  就是它的左邊是你在寫書\n",
            "[ 74%] 00:55:20,000 → 00:55:40,000  文章的頁面,然後右邊他就會告訴你說你現在拿到多少分,就是你有做到多少需求之內的事情,然後他就會一直提醒你說你還要再寫什麼,你還要再寫什麼才會足夠完整,然後在想就是這樣子的一個工具他製作的難度。\n",
            "[ 74%] 00:55:40,000 → 00:55:59,100  我覺得應該,這個東西他看起來是有機會整合在Notion裡面,但是我覺得他看起來,因為我們獎勵的內容其實是非常多嘛,我覺得他看起來對於Token的開銷會非常大,就是\n",
            "[ 75%] 00:56:00,000 → 00:56:10,000  我覺得我們透過應用程式去跟AI做串接,它中間其實是以量計價的。\n",
            "[ 75%] 00:56:10,000 → 00:56:20,000  我覺得這東西它或許是可以嘗試看看來做,但是因為\n",
            "[ 75%] 00:56:20,000 → 00:56:27,000  另一方面講義的內容很多,另一方面教單手字的內容也蠻多的\n",
            "[ 75%] 00:56:27,000 → 00:56:32,000  我覺得這個可能使用量的部分會比較大一點點\n",
            "[ 75%] 00:56:32,000 → 00:56:36,000  但這個東西會越來越便宜啦\n",
            "[ 75%] 00:56:36,000 → 00:56:40,000  所以或許我可以嘗試看看用\n",
            "[ 75%] 00:56:40,000 → 00:56:45,640  比較之前的,應該說用量比較小比較便宜的模型來試試看\n",
            "[ 75%] 00:56:46,660 → 00:56:49,720  因為畢竟他這個東西他不會要求說\n",
            "[ 76%] 00:56:49,980 → 00:56:53,320  就是我AI傳出的內容要到多進去\n",
            "[ 76%] 00:56:55,360 → 00:56:59,960  我覺得可以研究看看有沒有機會把它整合在Notion裡面\n",
            "[ 76%] 00:57:00,000 → 00:57:02,760  可能他更新頻率不會到這麼的高\n",
            "[ 76%] 00:57:02,760 → 00:57:09,760  可能就是寫作者完成一整階段的工作之後\n",
            "[ 76%] 00:57:09,760 → 00:57:14,500  再去再用AI去做這個提醒這樣\n",
            "[ 76%] 00:57:18,240 → 00:57:19,000  那如果\n",
            "[ 76%] 00:57:20,000 → 00:57:29,300  如果把這個工具切成是很多個更小的工具 那如果把這個工具切成是很多個更小的工具\n",
            "[ 76%] 00:57:29,300 → 00:57:33,780  就是我們不一定要是一戰式的解決所有講義變形的問題\n",
            "[ 77%] 00:57:33,780 → 00:57:40,000  可能把剛剛教授的手冊細分成五個層面或三個層面\n",
            "[ 77%] 00:57:40,000 → 00:57:47,000  要分別套這樣子的工具,它的用量這樣子會再更大,還是可以節省一點。\n",
            "[ 77%] 00:58:00,000 → 00:58:07,000  要怎麼切我覺得後續可以再來想了,目前就是我覺得可能要再研究一下。\n",
            "[ 77%] 00:58:07,000 → 00:58:14,000  好,不然我也先用ChangeGPT做做看好了,我先打一張手冊寫ChangeGPT。\n",
            "[ 77%] 00:58:14,000 → 00:58:20,000  然後維城如果會,如果想要看看說自己有沒有\n",
            "[ 78%] 00:58:20,000 → 00:58:24,680  有一些東西漏掉的話,你就可以先把你的獎金丟進去,change your VT\n",
            "[ 78%] 00:58:24,680 → 00:58:27,680  但是你一次可能就只能丟個十頁\n",
            "[ 78%] 00:58:27,680 → 00:58:30,680  就不能一次丟那個幾百頁進去\n",
            "[ 78%] 00:58:30,680 → 00:58:34,680  然後他可能就會告訴你說你還有哪些地方需要再錄\n",
            "[ 78%] 00:58:34,680 → 00:58:40,680  現階段先這樣子,然後這個可以之後有研究出來\n",
            "[ 78%] 00:58:40,000 → 00:58:43,000  讓我們再拿出來討論看看。\n",
            "[ 78%] 00:58:45,000 → 00:58:47,000  好,我講完了。\n",
            "[ 78%] 00:58:47,000 → 00:58:49,000  好耶。\n",
            "[ 78%] 00:58:49,000 → 00:58:52,000  那目前維生有任何想問的嗎?\n",
            "[ 78%] 00:58:52,000 → 00:58:56,000  或者也想分享看看你的想法也都可以。\n",
            "[ 79%] 00:59:00,000 → 00:59:09,440  我問個問題,就是之前不是有說你要開另外一個物理的帳號嗎?\n",
            "[ 79%] 00:59:09,440 → 00:59:11,440  嗯\n",
            "[ 79%] 00:59:11,440 → 00:59:20,000  就是我覺得應該要開另外一個跟英文獨立的帳號會比較好,不管你之後有沒有要掛e-mail的問題\n",
            "[ 79%] 00:59:20,000 → 00:59:22,000  我覺得分開會比較好\n",
            "[ 79%] 00:59:22,000 → 00:59:24,000  有原因嗎?\n",
            "[ 79%] 00:59:24,000 → 00:59:26,000  就是覺得分開會比較好\n",
            "[ 79%] 00:59:26,000 → 00:59:28,000  因為emote本來就是文科嘛\n",
            "[ 79%] 00:59:28,000 → 00:59:30,000  然後如果突然變成理科的話\n",
            "[ 79%] 00:59:30,000 → 00:59:32,000  就是你如果發的內容都混在一起\n",
            "[ 80%] 00:59:40,000 → 00:59:59,000  至少理科跟文科一個比較專業的分別,我會傾向把它分開,至少我看到這個帳號的時候我也知道它的專業是英文,這個帳號的專業是什麼,雖然它背後的人可能是同一批人。\n",
            "[ 80%] 01:00:00,000 → 01:00:02,000  我覺得它好像是不同的處理邏輯\n",
            "[ 80%] 01:00:02,000 → 01:00:04,000  就是我們現在如果把物理\n",
            "[ 80%] 01:00:04,000 → 01:00:06,000  它是兩種都是正確的狀況\n",
            "[ 80%] 01:00:06,000 → 01:00:08,000  然後我可能先跟你分享看看\n",
            "[ 80%] 01:00:08,000 → 01:00:10,000  要看你會不會有不同想法\n",
            "[ 80%] 01:00:20,000 → 01:00:25,000  如果是把講義掛到英文帳號的話\n",
            "[ 80%] 01:00:25,000 → 01:00:33,000  那其實是變成我們是幫助你在私領域去找客人\n",
            "[ 81%] 01:00:33,000 → 01:00:37,000  就是我們的瀏覽\n",
            "[ 81%] 01:00:37,000 → 01:00:40,000  我有做過一張圖秀給你看一下\n",
            "[ 81%] 01:00:40,000 → 01:00:48,300  就是我們的流量入口 IG的那些貼文就不太會真的去做物理專業知識相關的東西\n",
            "[ 81%] 01:00:48,300 → 01:00:52,580  那個就是真的跟英文真的太不相關\n",
            "[ 81%] 01:00:52,580 → 01:00:56,840  然後那個內容這樣跳來跳去也比較不符合學生的習慣\n",
            "[ 81%] 01:00:56,840 → 01:00:59,880  所以物理的專業知識不會\n",
            "[ 81%] 01:01:00,000 → 01:01:09,000  作為流量入口,我們的流量入口都會是以內容為主,只是那些流量進來之後\n",
            "[ 81%] 01:01:14,000 → 01:01:16,000  這邊沒有斷掉\n",
            "[ 82%] 01:01:20,000 → 01:01:34,080  他們還會被導到像是我們的節目或Line群然後限動\n",
            "[ 82%] 01:01:34,080 → 01:01:37,940  等於說是可能有6萬個追蹤者是追我們的IG\n",
            "[ 82%] 01:01:37,940 → 01:01:39,980  但是可能進入到死領域的\n",
            "[ 82%] 01:01:40,000 → 01:01:41,000  可能就只有一萬個\n",
            "[ 82%] 01:01:41,000 → 01:01:44,000  然後一萬個當中我們再想辦法幫你推銷\n",
            "[ 82%] 01:01:44,000 → 01:01:46,000  最後推銷出來\n",
            "[ 82%] 01:01:46,000 → 01:01:51,000  成交的數量就會比英文還要少\n",
            "[ 82%] 01:01:51,000 → 01:01:53,000  這是比較正常的狀況\n",
            "[ 82%] 01:01:53,000 → 01:01:55,000  但是相對來說\n",
            "[ 82%] 01:01:55,000 → 01:01:57,000  如果我們今天就開個全新的帳號\n",
            "[ 82%] 01:01:57,000 → 01:02:00,000  那我們那個全新的帳號也必須達到一定的粉絲級\n",
            "[ 82%] 01:02:00,000 → 01:02:02,760  才可以去平衡掉我剛剛說\n",
            "[ 82%] 01:02:02,760 → 01:02:04,800  比如說導到死領域的可能有一萬個\n",
            "[ 83%] 01:02:04,800 → 01:02:06,980  那就代表如果我們要重開一個帳號\n",
            "[ 83%] 01:02:06,980 → 01:02:10,300  那個帳號可能至少就要光靠自然科\n",
            "[ 83%] 01:02:10,300 → 01:02:14,060  光靠物理可能就要至少達到一萬個粉絲\n",
            "[ 83%] 01:02:14,060 → 01:02:16,220  它才會比較有機率\n",
            "[ 83%] 01:02:16,220 → 01:02:18,480  可以達到跟英文一樣的宣傳效果\n",
            "[ 83%] 01:02:18,480 → 01:02:19,980  就有點像我這邊\n",
            "[ 83%] 01:02:20,000 → 01:02:22,000  我沒有做一個圖\n",
            "[ 83%] 01:02:22,000 → 01:02:27,000  就是打開熱量漏斗的地方其實是我們會用英文去做\n",
            "[ 83%] 01:02:27,000 → 01:02:29,000  但是其他的這個地方\n",
            "[ 83%] 01:02:29,000 → 01:02:31,000  YouTube 跟 IG 限動\n",
            "[ 83%] 01:02:31,000 → 01:02:34,000  還有專業的一些課程\n",
            "[ 83%] 01:02:34,000 → 01:02:35,000  就是講義啊\n",
            "[ 83%] 01:02:35,000 → 01:02:38,000  然後現在是沒有在做直播跟團課啦\n",
            "[ 83%] 01:02:38,000 → 01:02:40,000  但是其他的一些專業的\n",
            "[ 83%] 01:02:40,000 → 01:02:46,600  像私訊的問題回答還有Line群的問題回答都會幫你的物理數據倒流\n",
            "[ 83%] 01:02:46,600 → 01:02:49,000  這樣你要懂意思嗎\n",
            "[ 84%] 01:02:49,000 → 01:03:00,000  但我剛意思其實是說如果你要發物理的文章的話或什麼東西的話我覺得就是要有另外一個帳號\n",
            "[ 84%] 01:03:00,000 → 01:03:02,000  喔對啊確實\n",
            "[ 84%] 01:03:02,000 → 01:03:06,000  可是誰要來發物理的文章\n",
            "[ 84%] 01:03:06,000 → 01:03:08,000  你會想要發物理的文章嗎\n",
            "[ 84%] 01:03:08,000 → 01:03:10,000  如果我有寫的話\n",
            "[ 84%] 01:03:10,000 → 01:03:14,000  或者就是你之前不是說要做一些奇怪的實驗\n",
            "[ 84%] 01:03:14,000 → 01:03:16,000  所以我不知道你要做什麼實驗\n",
            "[ 84%] 01:03:16,000 → 01:03:20,000  喔對啊我之前不是有傳給你一個\n",
            "[ 84%] 01:03:20,000 → 01:03:23,000  你有看過這個嗎?\n",
            "[ 84%] 01:03:23,000 → 01:03:25,000  你有傳給我嗎?\n",
            "[ 84%] 01:03:25,000 → 01:03:28,000  我傳在 Slack 啦\n",
            "[ 84%] 01:03:28,000 → 01:03:30,000  就是我們會\n",
            "[ 84%] 01:03:30,000 → 01:03:33,000  如果是我幫你做內容的話\n",
            "[ 84%] 01:03:33,000 → 01:03:35,000  我理想上會是\n",
            "[ 85%] 01:03:35,000 → 01:03:37,000  我找一下那個\n",
            "[ 85%] 01:03:37,000 → 01:03:39,000  如果是專業的物理知識\n",
            "[ 85%] 01:03:39,000 → 01:03:41,000  就會是需要你來幫忙\n",
            "[ 85%] 01:03:40,000 → 01:03:45,000  如果是我們幫你做內容可能會做的比較類似這種\n",
            "[ 85%] 01:03:45,000 → 01:03:47,000  欸這個\n",
            "[ 85%] 01:03:51,000 → 01:03:53,000  喔我有看到這個\n",
            "[ 85%] 01:03:54,000 → 01:03:58,000  喔就只能做的比較娛樂化一點\n",
            "[ 85%] 01:03:59,000 → 01:04:00,000  然後再把你放寡\n",
            "[ 85%] 01:04:00,000 → 01:04:02,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:02,000 → 01:04:04,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:04,000 → 01:04:06,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:06,000 → 01:04:08,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:08,000 → 01:04:10,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:10,000 → 01:04:12,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:12,000 → 01:04:14,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:14,000 → 01:04:16,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:16,000 → 01:04:18,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:18,000 → 01:04:20,000  如果你是開一個全新的賬號\n",
            "[ 86%] 01:04:20,000 → 01:04:24,600  其實會需要有穩定的內容才處理\n",
            "[ 86%] 01:04:24,600 → 01:04:29,600  就是你可能不能是想到文章再發\n",
            "[ 86%] 01:04:29,600 → 01:04:33,000  然後我們這邊就會是需要\n",
            "[ 86%] 01:04:33,000 → 01:04:35,800  每次都就是幫你去做布林的帖文\n",
            "[ 86%] 01:04:40,000 → 01:05:00,000  如果是掛在英文上的話,有時候就可以像我之前有給你看單字數的ChangeGPT,有時候我覺得把那個ChangeGPT放在英文,然後讓它流傳下去的話,像現在的ChangeGPT就有三千多個對話,然後如果三千多個對話,每一次對話都會有三千多個對話,\n",
            "[ 86%] 01:05:00,000 → 01:05:02,000  如果有一個肯定的廣告的話\n",
            "[ 86%] 01:05:02,000 → 01:05:04,000  我覺得導流效果也蠻不錯的\n",
            "[ 86%] 01:05:04,000 → 01:05:06,000  所以這個可以再想想看\n",
            "[ 87%] 01:05:06,000 → 01:05:08,000  但如果你會希望\n",
            "[ 87%] 01:05:08,000 → 01:05:10,000  開個線上號\n",
            "[ 87%] 01:05:10,000 → 01:05:12,000  然後希望可以做一些\n",
            "[ 87%] 01:05:12,000 → 01:05:14,000  專門輸入的內容\n",
            "[ 87%] 01:05:14,000 → 01:05:16,000  我覺得也沒有問題\n",
            "[ 87%] 01:05:16,000 → 01:05:18,000  但是我們之後可以再一起把細節\n",
            "[ 87%] 01:05:18,000 → 01:05:20,000  就是我可以\n",
            "[ 87%] 01:05:20,000 → 01:05:22,500  直接先開帳號,然後可能先做做看\n",
            "[ 87%] 01:05:22,500 → 01:05:24,400  然後再告訴你有沒有困難的點\n",
            "[ 87%] 01:05:25,700 → 01:05:28,600  那如果你現在要發一個立刻的東西\n",
            "[ 87%] 01:05:28,600 → 01:05:29,800  你是要發在哪邊?\n",
            "[ 87%] 01:05:32,100 → 01:05:34,100  現在要發一個立刻的東西\n",
            "[ 87%] 01:05:34,800 → 01:05:38,100  就是如果你沒有打算再開一個行政帳號的話\n",
            "[ 87%] 01:05:38,700 → 01:05:40,100  啊,立刻的東西\n",
            "[ 88%] 01:05:40,000 → 01:05:59,380  我就會把他放在YouTube的影片,我會幫你講,然後再用IG去引導學生去YouTube的影片,然後會是IG行動,還有Threads的,在Threads上面我就不會教物理,而是我會直接\n",
            "[ 88%] 01:06:00,000 → 01:06:06,800  丟免費的工具給學生,然後讓那個免費的工具自己下去學生之間流傳。\n",
            "[ 88%] 01:06:06,800 → 01:06:16,360  比如說你的事業檔案,那就算是一種免費的工具。\n",
            "[ 88%] 01:06:16,360 → 01:06:17,240  大概理解。\n",
            "[ 88%] 01:06:20,000 → 01:06:27,000  還有你的商品掛在蝦皮機就會有一定的流量\n",
            "[ 88%] 01:06:27,000 → 01:06:33,000  因為我們賣場也會有既定的客源進來\n",
            "[ 89%] 01:06:33,000 → 01:06:38,000  還有LINE群\n",
            "[ 89%] 01:06:38,000 → 01:06:40,000  LINE群會有選手喔\n",
            "[ 89%] 01:06:40,000 → 01:06:42,760  喔對之前有講到Live群\n",
            "[ 89%] 01:06:42,760 → 01:06:46,940  所以現在是有學生在問物理的問題嗎\n",
            "[ 89%] 01:06:46,940 → 01:06:48,360  還是還沒有\n",
            "[ 89%] 01:06:48,360 → 01:06:49,620  還沒有\n",
            "[ 89%] 01:06:49,620 → 01:06:55,740  可能我們也還沒有引導他們去問物理的\n",
            "[ 89%] 01:06:55,740 → 01:06:59,980  你現在有在這個群組\n",
            "[ 89%] 01:07:00,000 → 01:07:14,400  還有其他問題呢?\n",
            "[ 89%] 01:07:18,400 → 01:07:20,400  這部分應該就到這裡了\n",
            "[ 90%] 01:07:20,000 → 01:07:26,100  然後我提問一下,這是你的公司名稱嗎?\n",
            "[ 90%] 01:07:27,140 → 01:07:31,000  公司名稱是成學文教有限公司,\n",
            "[ 90%] 01:07:31,600 → 01:07:33,840  陰謀比較像是品牌名稱。\n",
            "[ 90%] 01:07:33,840 → 01:07:36,540  所以那你的陰謀是申請商標嗎?\n",
            "[ 90%] 01:07:37,420 → 01:07:38,000  我是好奇。\n",
            "[ 90%] 01:07:40,000 → 01:07:42,000  喔好\n",
            "[ 90%] 01:07:42,000 → 01:07:45,820  你要搶住嗎\n",
            "[ 90%] 01:07:45,820 → 01:07:47,420  我都沒想到\n",
            "[ 90%] 01:07:47,420 → 01:07:49,880  惡意搶住\n",
            "[ 90%] 01:07:49,880 → 01:07:53,340  你是學了民法之後學壞了是不是\n",
            "[ 90%] 01:07:53,340 → 01:07:57,720  我好像記得有的是法律系\n",
            "[ 90%] 01:07:57,720 → 01:08:00,000  我是法律系\n",
            "[ 90%] 01:08:00,000 → 01:08:05,000  好\n",
            "[ 91%] 01:08:05,000 → 01:08:07,700  那應該沒有其他問題耶\n",
            "[ 91%] 01:08:07,700 → 01:08:08,940  好\n",
            "[ 91%] 01:08:08,940 → 01:08:10,620  你應該沒有\n",
            "[ 91%] 01:08:10,620 → 01:08:12,160  打算先註冊對吧\n",
            "[ 91%] 01:08:12,160 → 01:08:12,660  沒有沒有\n",
            "[ 91%] 01:08:12,660 → 01:08:13,460  OKOK\n",
            "[ 91%] 01:08:13,460 → 01:08:15,180  有點麻煩\n",
            "[ 91%] 01:08:15,180 → 01:08:16,300  沒有想要做這種事\n",
            "[ 91%] 01:08:20,000 → 01:08:28,000  如果沒有的話,我們今天會先到這邊喔。\n",
            "[ 91%] 01:08:28,000 → 01:08:30,000  好。\n",
            "[ 91%] 01:08:30,000 → 01:08:32,000  好,辛苦了,謝謝你。\n",
            "[ 91%] 01:08:32,000 → 01:08:34,000  掰掰。\n",
            "[ 91%] 01:08:34,000 → 01:08:36,000  掰掰。\n",
            "[ 91%] 01:08:40,000 → 01:08:49,860  我要影片嗎?想要影片?\n",
            "[ 91%] 01:08:50,000 → 01:08:51,440  我有,好,我再傳\n",
            "[ 92%] 01:08:51,440 → 01:08:53,280  做完可以改AI\n",
            "[ 92%] 01:08:53,280 → 01:08:54,060  OK\n",
            "[ 92%] 01:08:54,060 → 01:08:57,760  為什麼我媽留著?\n",
            "[ 92%] 01:08:57,860 → 01:08:59,320  我媽有什麼事情要討論嗎?\n",
            "[ 92%] 01:09:00,000 → 01:09:02,000  沒有啊\n",
            "[ 92%] 01:09:02,000 → 01:09:04,000  那我先撤囉\n",
            "[ 92%] 01:09:04,000 → 01:09:05,000  好嘞\n",
            "[ 92%] 01:09:05,000 → 01:09:08,000  我會去玩國粹職之後再去你那邊喔\n",
            "[ 92%] 01:09:08,000 → 01:09:09,000  好喔沒問題\n",
            "[ 92%] 01:09:09,000 → 01:09:10,000  你就直接進來就好\n",
            "[ 92%] 01:09:10,000 → 01:09:11,000  我會穿褲子\n",
            "[ 92%] 01:09:11,000 → 01:09:12,000  好掰掰\n",
            "[ 92%] 01:09:12,000 → 01:09:14,000  好掰掰\n",
            "[ 92%] 01:09:16,000 → 01:09:17,000  拜啦老孫\n",
            "[ 92%] 01:09:17,000 → 01:09:19,000  你剛聽起來有什麼問題嗎\n",
            "[ 92%] 01:09:20,000 → 01:09:26,000  沒有,但是我想到有很嚴重的事情要做\n",
            "[ 92%] 01:09:26,000 → 01:09:27,400  你說?\n",
            "[ 92%] 01:09:27,400 → 01:09:32,240  就是那個那個那個那個常常需要驗證的問題\n",
            "[ 92%] 01:09:32,240 → 01:09:35,760  我們現在把它解決掉了嘛\n",
            "[ 92%] 01:09:35,760 → 01:09:37,360  會很久嗎?\n",
            "[ 93%] 01:09:37,360 → 01:09:39,960  不會不會\n",
            "[ 93%] 01:09:40,000 → 01:09:50,000  比較就是我開個分享的分享分享\n",
            "[ 93%] 01:09:50,000 → 01:09:54,000  我的IG快快的\n",
            "[ 93%] 01:09:54,000 → 01:09:58,000  你的IG快快的\n",
            "[ 93%] 01:09:58,000 → 01:10:00,000  等一下你說\n",
            "[ 93%] 01:10:00,000 → 01:10:19,940  我來新增一下,因為目前都是要發去你的手機,然後\n",
            "[ 93%] 01:10:20,000 → 01:10:23,000  你的手機去做驗證嗎?\n",
            "[ 94%] 01:10:23,000 → 01:10:24,000  嗯\n",
            "[ 94%] 01:10:24,000 → 01:10:29,000  對 然後我是想說就是我們直接來進入這個\n",
            "[ 94%] 01:10:29,000 → 01:10:33,000  就是我們直接弄一個這個動態驗證嘛\n",
            "[ 94%] 01:10:33,000 → 01:10:34,000  就是它可以\n",
            "[ 94%] 01:10:34,000 → 01:10:35,000  原來我們有這個東西啊\n",
            "[ 94%] 01:10:35,000 → 01:10:36,000  蛤?\n",
            "[ 94%] 01:10:36,000 → 01:10:38,000  我們有這個東西啊\n",
            "[ 94%] 01:10:38,000 → 01:10:40,000  你們有這個東西\n",
            "[ 94%] 01:10:40,000 → 01:10:44,000  不是不是不是 不是我們有動態驗證碼\n",
            "[ 94%] 01:10:44,000 → 01:10:48,000  你們有動態驗證碼 可是我在帳號裡面沒看到你\n",
            "[ 94%] 01:10:48,000 → 01:10:52,000  因為我們是綁openai跟ig消息\n",
            "[ 94%] 01:10:52,000 → 01:10:56,000  那你這個要不要綁一下 可以可以 四十嗎\n",
            "[ 94%] 01:10:56,000 → 01:11:00,000  不然我每次半夜在搞東西\n",
            "[ 94%] 01:11:00,000 → 01:11:02,000  都會卡住\n",
            "[ 94%] 01:11:02,000 → 01:11:04,000  好有嗎?\n",
            "[ 94%] 01:11:04,000 → 01:11:06,000  有啊它進去了\n",
            "[ 94%] 01:11:06,000 → 01:11:08,000  等等等\n",
            "[ 95%] 01:11:08,000 → 01:11:10,000  那我現在新增一個然後截圖給你們\n",
            "[ 95%] 01:11:10,000 → 01:11:12,000  沒有好等一下我直接\n",
            "[ 95%] 01:11:12,000 → 01:11:14,000  我只新增\n",
            "[ 95%] 01:11:14,000 → 01:11:16,000  沒有我是截個圖啊\n",
            "[ 95%] 01:11:16,000 → 01:11:18,000  它不是會一直跑嗎?\n",
            "[ 95%] 01:11:18,000 → 01:11:20,000  它一直都會跑啊\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  沒有沒有這個不會\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  這個圖不會\n",
            "[ 95%] 01:11:22,000 → 01:11:24,000  這個圖不會 為什麼\n",
            "[ 95%] 01:11:24,000 → 01:11:26,000  因為它跑的不是這個圖\n",
            "[ 95%] 01:11:26,000 → 01:11:28,000  它跑的是這個圖裡面有精藥\n",
            "[ 95%] 01:11:28,000 → 01:11:30,000  然後它會根據這個精藥\n",
            "[ 95%] 01:11:30,000 → 01:11:32,000  加上時間\n",
            "[ 95%] 01:11:32,000 → 01:11:34,000  那個數字不是一直都會跑嗎\n",
            "[ 95%] 01:11:34,000 → 01:11:36,000  對 但是這個圖不會跑\n",
            "[ 95%] 01:11:38,000 → 01:11:40,000  對 它是用這個圖加上時間去\n",
            "[ 95%] 01:11:40,000 → 01:11:42,000  你去算出那個數字\n",
            "[ 95%] 01:11:42,000 → 01:11:44,000  這樣這樣\n",
            "[ 95%] 01:11:45,120 → 01:11:47,120  那我要放在notion裡面了\n",
            "[ 95%] 01:11:48,580 → 01:11:50,580  這樣會太危險嗎\n",
            "[ 95%] 01:11:50,580 → 01:11:52,580  你直接幫我查個指名好不好\n",
            "[ 96%] 01:11:54,840 → 01:11:56,840  等等等等等等\n",
            "[ 96%] 01:11:56,840 → 01:11:58,840  等等喔\n",
            "[ 96%] 01:11:58,840 → 01:12:00,840  我要建個頻道\n",
            "[ 96%] 01:12:00,000 → 01:12:02,000  你用平常名稱叫什麼?\n",
            "[ 96%] 01:12:04,000 → 01:12:06,000  工程部門\n",
            "[ 96%] 01:12:15,000 → 01:12:18,000  為什麼你現在用的那個Gmail是你自己的嗎?\n",
            "[ 96%] 01:12:18,000 → 01:12:20,000  你幫我貼在那個工程部門\n",
            "[ 97%] 01:12:20,000 → 01:12:40,000  我哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋\n",
            "[ 97%] 01:12:40,000 → 01:12:40,840  還是你本來就有在用?\n",
            "[ 97%] 01:12:40,840 → 01:12:41,340  沒有啊\n",
            "[ 97%] 01:12:42,000 → 01:12:43,840  那是我的主力帳號啊\n",
            "[ 97%] 01:12:43,840 → 01:12:45,160  因為這個帳號\n",
            "[ 97%] 01:12:45,160 → 01:12:46,460  幼稚園的時候就創了\n",
            "[ 97%] 01:12:46,460 → 01:12:48,500  所以那個名字是亂打的\n",
            "[ 97%] 01:12:49,340 → 01:12:50,000  打動了\n",
            "[ 97%] 01:12:55,800 → 01:12:58,500  啊你剛剛那個婚姻紀錄有開完嗎?\n",
            "[ 97%] 01:12:58,840 → 01:12:59,340  你有打動嗎?\n",
            "[ 97%] 01:12:59,340 → 01:12:59,840  有有有\n",
            "[ 97%] 01:13:00,000 → 01:13:04,600  你可能要跟他講一下那個東西是幹嘛的\n",
            "[ 97%] 01:13:04,600 → 01:13:09,700  就是你傳到工程部門那個東西是幹嘛的\n",
            "[ 97%] 01:13:09,700 → 01:13:10,760  他可能不太知道\n",
            "[ 97%] 01:13:10,760 → 01:13:14,520  他拿iPhone還安儲\n",
            "[ 97%] 01:13:14,520 → 01:13:16,060  他拿iPhone\n",
            "[ 98%] 01:13:20,000 → 01:13:24,000  好了,我們要去尿尿,然後我要出發了,bye!\n",
            "[ 98%] 01:13:25,280 → 01:13:25,520  好\n",
            "[ 98%] 01:13:25,520 → 01:13:29,780  下午的會議如果需要你,我再call你進來可以嗎?\n",
            "[ 98%] 01:13:34,400 → 01:13:35,080  可以嗎?\n",
            "[ 98%] 01:13:37,020 → 01:13:39,540  哇,那我怎麼知道你什麼時候要call我進來?\n",
            "[ 98%] 01:13:40,000 → 01:13:42,800  好吧,那你就去忙,你就去做你自己的生意\n",
            "[ 98%] 01:13:42,800 → 01:13:43,800  如果你剛好有\n",
            "[ 98%] 01:13:43,800 → 01:13:45,600  我可以進來沒關係啊\n",
            "[ 98%] 01:13:45,600 → 01:13:47,100  好,那你就順便停\n",
            "[ 98%] 01:13:47,100 → 01:13:49,140  OK,好,Bye\n",
            "[ 98%] 01:13:49,140 → 01:13:52,360  2點啊,2點到4點\n",
            "[ 98%] 01:13:52,360 → 01:13:53,180  好\n",
            "[ 98%] 01:13:53,180 → 01:13:53,840  再見\n",
            "[ 99%] 01:14:00,000 → 01:14:29,980  Teksting av Nicolai Winther\n",
            "[ 99%] 01:14:20,000 → 01:14:49,980  Takk for att du så med.\n",
            "[100%] 01:14:40,000 → 01:15:09,980  Teksting av Nicolai Winther\n",
            "[100%] 01:15:00,000 → 01:15:29,980  Teksting av Nicolai Winther\n",
            "[8/8] 輸出 SRT / TXT ...\n",
            "→ 完成！\n",
            "  SRT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).srt\n",
            "  TXT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da0d61306b9240d5b25a4d5e122d34c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_load_from_file_impl: using device CUDA0 (Tesla T4) - 14974 MiB free\n",
            "llama_model_loader: loaded meta data with 37 key-value pairs and 459 tensors from /root/.cache/huggingface/hub/models--unsloth--gpt-oss-20b-GGUF/snapshots/c6cedd4259adbfe7e4d4d983a0400bf4cc38e7db/gpt-oss-20b-Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gpt-oss\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   3:                           general.basename str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   4:                       general.quantized_by str              = Unsloth\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 20B\n",
            "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
            "llama_model_loader: - kv   7:                           general.repo_url str              = https://huggingface.co/unsloth\n",
            "llama_model_loader: - kv   8:                               general.tags arr[str,2]       = [\"vllm\", \"text-generation\"]\n",
            "llama_model_loader: - kv   9:                        gpt-oss.block_count u32              = 24\n",
            "llama_model_loader: - kv  10:                     gpt-oss.context_length u32              = 131072\n",
            "llama_model_loader: - kv  11:                   gpt-oss.embedding_length u32              = 2880\n",
            "llama_model_loader: - kv  12:                gpt-oss.feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  13:               gpt-oss.attention.head_count u32              = 64\n",
            "llama_model_loader: - kv  14:            gpt-oss.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  15:                     gpt-oss.rope.freq_base f32              = 150000.000000\n",
            "llama_model_loader: - kv  16:   gpt-oss.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  17:                       gpt-oss.expert_count u32              = 32\n",
            "llama_model_loader: - kv  18:                  gpt-oss.expert_used_count u32              = 4\n",
            "llama_model_loader: - kv  19:               gpt-oss.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  20:             gpt-oss.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  21:           gpt-oss.attention.sliding_window u32              = 128\n",
            "llama_model_loader: - kv  22:         gpt-oss.expert_feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  23:                  gpt-oss.rope.scaling.type str              = yarn\n",
            "llama_model_loader: - kv  24:                gpt-oss.rope.scaling.factor f32              = 32.000000\n",
            "llama_model_loader: - kv  25: gpt-oss.rope.scaling.original_context_length u32              = 4096\n",
            "llama_model_loader: - kv  26:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  27:                         tokenizer.ggml.pre str              = gpt-4o\n",
            "llama_model_loader: - kv  28:                      tokenizer.ggml.tokens arr[str,201088]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  29:                  tokenizer.ggml.token_type arr[i32,201088]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  30:                      tokenizer.ggml.merges arr[str,446189]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  31:                tokenizer.ggml.bos_token_id u32              = 199998\n",
            "llama_model_loader: - kv  32:                tokenizer.ggml.eos_token_id u32              = 200002\n",
            "llama_model_loader: - kv  33:            tokenizer.ggml.padding_token_id u32              = 200017\n",
            "llama_model_loader: - kv  34:                    tokenizer.chat_template str              = {# Chat template fixes by Unsloth #}\\n...\n",
            "llama_model_loader: - kv  35:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  36:                          general.file_type u32              = 15\n",
            "llama_model_loader: - type  f32:  289 tensors\n",
            "llama_model_loader: - type q5_0:   61 tensors\n",
            "llama_model_loader: - type q8_0:   13 tensors\n",
            "llama_model_loader: - type q4_K:   24 tensors\n",
            "llama_model_loader: - type mxfp4:   72 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 10.81 GiB (4.44 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 200017 '<|reserved_200017|>' is not marked as EOG\n",
            "load: control token: 200014 '<|reserved_200014|>' is not marked as EOG\n",
            "load: control token: 200011 '<|reserved_200011|>' is not marked as EOG\n",
            "load: control token: 200009 '<|reserved_200009|>' is not marked as EOG\n",
            "load: control token: 200008 '<|message|>' is not marked as EOG\n",
            "load: control token: 200006 '<|start|>' is not marked as EOG\n",
            "load: control token: 200004 '<|reserved_200004|>' is not marked as EOG\n",
            "load: control token: 200003 '<|constrain|>' is not marked as EOG\n",
            "load: control token: 200000 '<|reserved_200000|>' is not marked as EOG\n",
            "load: control token: 200005 '<|channel|>' is not marked as EOG\n",
            "load: control token: 200010 '<|reserved_200010|>' is not marked as EOG\n",
            "load: control token: 200016 '<|reserved_200016|>' is not marked as EOG\n",
            "load: control token: 200013 '<|reserved_200013|>' is not marked as EOG\n",
            "load: control token: 199998 '<|startoftext|>' is not marked as EOG\n",
            "load: control token: 200018 '<|endofprompt|>' is not marked as EOG\n",
            "load: control token: 200001 '<|reserved_200001|>' is not marked as EOG\n",
            "load: control token: 200015 '<|reserved_200015|>' is not marked as EOG\n",
            "load: printing all EOG tokens:\n",
            "load:   - 199999 ('<|endoftext|>')\n",
            "load:   - 200002 ('<|return|>')\n",
            "load:   - 200007 ('<|end|>')\n",
            "load:   - 200012 ('<|call|>')\n",
            "load: special_eog_ids contains both '<|return|>' and '<|call|>' tokens, removing '<|end|>' token from EOG list\n",
            "load: special tokens cache size = 21\n",
            "load: token to piece cache size = 1.3332 MB\n",
            "print_info: arch             = gpt-oss\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 131072\n",
            "print_info: n_embd           = 2880\n",
            "print_info: n_layer          = 24\n",
            "print_info: n_head           = 64\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 64\n",
            "print_info: n_swa            = 128\n",
            "print_info: is_swa_any       = 1\n",
            "print_info: n_embd_head_k    = 64\n",
            "print_info: n_embd_head_v    = 64\n",
            "print_info: n_gqa            = 8\n",
            "print_info: n_embd_k_gqa     = 512\n",
            "print_info: n_embd_v_gqa     = 512\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 2880\n",
            "print_info: n_expert         = 32\n",
            "print_info: n_expert_used    = 4\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 2\n",
            "print_info: rope scaling     = yarn\n",
            "print_info: freq_base_train  = 150000.0\n",
            "print_info: freq_scale_train = 0.03125\n",
            "print_info: n_ctx_orig_yarn  = 4096\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = ?B\n",
            "print_info: model params     = 20.91 B\n",
            "print_info: general.name     = Gpt-Oss-20B\n",
            "print_info: n_ff_exp         = 2880\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 201088\n",
            "print_info: n_merges         = 446189\n",
            "print_info: BOS token        = 199998 '<|startoftext|>'\n",
            "print_info: EOS token        = 200002 '<|return|>'\n",
            "print_info: EOT token        = 199999 '<|endoftext|>'\n",
            "print_info: PAD token        = 200017 '<|reserved_200017|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 199999 '<|endoftext|>'\n",
            "print_info: EOG token        = 200002 '<|return|>'\n",
            "print_info: EOG token        = 200012 '<|call|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   1 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   3 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   5 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   7 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   9 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  11 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  13 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  15 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  17 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  19 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  21 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  23 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q5_0) (and 0 others) cannot be used with preferred buffer type CUDA_Host, using CPU instead\n",
            "load_tensors: offloading 24 repeating layers to GPU\n",
            "load_tensors: offloading output layer to GPU\n",
            "load_tensors: offloaded 25/25 layers to GPU\n",
            "load_tensors:        CUDA0 model buffer size = 10694.15 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =   379.71 MiB\n",
            "...............................................................................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 8192\n",
            "llama_context: n_ctx_per_seq = 8192\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 150000.0\n",
            "llama_context: freq_scale    = 0.03125\n",
            "llama_context: n_ctx_per_seq (8192) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:  CUDA_Host  output buffer size =     0.77 MiB\n",
            "create_memory: n_ctx = 8192 (padded)\n",
            "llama_kv_cache_unified_iswa: using full-size SWA cache (ref: https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)\n",
            "llama_kv_cache_unified_iswa: creating non-SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: skipped\n",
            "llama_kv_cache_unified: layer   1: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   2: skipped\n",
            "llama_kv_cache_unified: layer   3: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   4: skipped\n",
            "llama_kv_cache_unified: layer   5: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   6: skipped\n",
            "llama_kv_cache_unified: layer   7: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   8: skipped\n",
            "llama_kv_cache_unified: layer   9: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  10: skipped\n",
            "llama_kv_cache_unified: layer  11: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  12: skipped\n",
            "llama_kv_cache_unified: layer  13: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  14: skipped\n",
            "llama_kv_cache_unified: layer  15: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  16: skipped\n",
            "llama_kv_cache_unified: layer  17: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  18: skipped\n",
            "llama_kv_cache_unified: layer  19: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  20: skipped\n",
            "llama_kv_cache_unified: layer  21: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  22: skipped\n",
            "llama_kv_cache_unified: layer  23: dev = CUDA0\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_kv_cache_unified_iswa: creating     SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   1: skipped\n",
            "llama_kv_cache_unified: layer   2: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   3: skipped\n",
            "llama_kv_cache_unified: layer   4: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   5: skipped\n",
            "llama_kv_cache_unified: layer   6: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   7: skipped\n",
            "llama_kv_cache_unified: layer   8: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   9: skipped\n",
            "llama_kv_cache_unified: layer  10: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  11: skipped\n",
            "llama_kv_cache_unified: layer  12: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  13: skipped\n",
            "llama_kv_cache_unified: layer  14: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  15: skipped\n",
            "llama_kv_cache_unified: layer  16: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  17: skipped\n",
            "llama_kv_cache_unified: layer  18: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  19: skipped\n",
            "llama_kv_cache_unified: layer  20: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  21: skipped\n",
            "llama_kv_cache_unified: layer  22: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  23: skipped\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 2\n",
            "llama_context: max_nodes = 3672\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "llama_context:      CUDA0 compute buffer size =  1087.26 MiB\n",
            "llama_context:  CUDA_Host compute buffer size =    41.64 MiB\n",
            "llama_context: graph nodes  = 1446\n",
            "llama_context: graph splits = 2\n",
            "CUDA : ARCHS = 500,520,530,600,610,620,700,720,750,800,860,870,890,900 | FORCE_MMQ = 1 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'general.file_type': '15', 'general.quantization_version': '2', 'tokenizer.chat_template': '{# Chat template fixes by Unsloth #}\\n{#-\\n  In addition to the normal inputs of `messages` and `tools`, this template also accepts the\\n  following kwargs:\\n  - \"builtin_tools\": A list, can contain \"browser\" and/or \"python\".\\n  - \"model_identity\": A string that optionally describes the model identity.\\n  - \"reasoning_effort\": A string that describes the reasoning effort, defaults to \"medium\".\\n #}\\n\\n{#- Tool Definition Rendering ============================================== #}\\n{%- macro render_typescript_type(param_spec, required_params, is_nullable=false) -%}\\n    {%- if param_spec.type == \"array\" -%}\\n        {%- if param_spec[\\'items\\'] -%}\\n            {%- if param_spec[\\'items\\'][\\'type\\'] == \"string\" -%}\\n                {{- \"string[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"number\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"integer\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"boolean\" -%}\\n                {{- \"boolean[]\" }}\\n            {%- else -%}\\n                {%- set inner_type = render_typescript_type(param_spec[\\'items\\'], required_params) -%}\\n                {%- if inner_type == \"object | object\" or inner_type|length > 50 -%}\\n                    {{- \"any[]\" }}\\n                {%- else -%}\\n                    {{- inner_type + \"[]\" }}\\n                {%- endif -%}\\n            {%- endif -%}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- else -%}\\n            {{- \"any[]\" }}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type is defined and param_spec.type is iterable and param_spec.type is not string and param_spec.type is not mapping and param_spec.type[0] is defined -%}\\n        {#- Handle array of types like [\"object\", \"object\"] from Union[dict, list] #}\\n        {%- if param_spec.type | length > 1 -%}\\n            {{- param_spec.type | join(\" | \") }}\\n        {%- else -%}\\n            {{- param_spec.type[0] }}\\n        {%- endif -%}\\n    {%- elif param_spec.oneOf -%}\\n        {#- Handle oneOf schemas - check for complex unions and fallback to any #}\\n        {%- set has_object_variants = false -%}\\n        {%- for variant in param_spec.oneOf -%}\\n            {%- if variant.type == \"object\" -%}\\n                {%- set has_object_variants = true -%}\\n            {%- endif -%}\\n        {%- endfor -%}\\n        {%- if has_object_variants and param_spec.oneOf|length > 1 -%}\\n            {{- \"any\" }}\\n        {%- else -%}\\n            {%- for variant in param_spec.oneOf -%}\\n                {{- render_typescript_type(variant, required_params) -}}\\n                {%- if variant.description %}\\n                    {{- \"// \" + variant.description }}\\n                {%- endif -%}\\n                {%- if variant.default is defined %}\\n                    {{ \"// default: \" + variant.default|tojson }}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \" | \" }}\\n                {% endif -%}\\n            {%- endfor -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"string\" -%}\\n        {%- if param_spec.enum -%}\\n            {{- \\'\"\\' + param_spec.enum|join(\\'\" | \"\\') + \\'\"\\' -}}\\n        {%- else -%}\\n            {{- \"string\" }}\\n            {%- if param_spec.nullable %}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"number\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"integer\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"boolean\" -%}\\n        {{- \"boolean\" }}\\n\\n    {%- elif param_spec.type == \"object\" -%}\\n        {%- if param_spec.properties -%}\\n            {{- \"{\\\\n\" }}\\n            {%- for prop_name, prop_spec in param_spec.properties.items() -%}\\n                {{- prop_name -}}\\n                {%- if prop_name not in (param_spec.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{ render_typescript_type(prop_spec, param_spec.required or []) }}\\n                {%- if not loop.last -%}\\n                    {{-\", \" }}\\n                {%- endif -%}\\n            {%- endfor -%}\\n            {{- \"}\" }}\\n        {%- else -%}\\n            {{- \"object\" }}\\n        {%- endif -%}\\n    {%- else -%}\\n        {{- \"any\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{%- macro render_tool_namespace(namespace_name, tools) -%}\\n    {{- \"## \" + namespace_name + \"\\\\n\\\\n\" }}\\n    {{- \"namespace \" + namespace_name + \" {\\\\n\\\\n\" }}\\n    {%- for tool in tools %}\\n        {%- set tool = tool.function %}\\n        {{- \"// \" + tool.description + \"\\\\n\" }}\\n        {{- \"type \"+ tool.name + \" = \" }}\\n        {%- if tool.parameters and tool.parameters.properties %}\\n            {{- \"(_: {\\\\n\" }}\\n            {%- for param_name, param_spec in tool.parameters.properties.items() %}\\n                {%- if param_spec.description %}\\n                    {{- \"// \" + param_spec.description + \"\\\\n\" }}\\n                {%- endif %}\\n                {{- param_name }}\\n                {%- if param_name not in (tool.parameters.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{- render_typescript_type(param_spec, tool.parameters.required or []) }}\\n                {%- if param_spec.default is defined -%}\\n                    {%- if param_spec.enum %}\\n                        {{- \", // default: \" + param_spec.default }}\\n                    {%- elif param_spec.oneOf %}\\n                        {{- \"// default: \" + param_spec.default }}\\n                    {%- else %}\\n                        {{- \", // default: \" + param_spec.default|tojson }}\\n                    {%- endif -%}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \",\\\\n\" }}\\n                {%- else %}\\n                    {{- \",\\\\n\" }}\\n                {%- endif -%}\\n            {%- endfor %}\\n            {{- \"}) => any;\\\\n\\\\n\" }}\\n        {%- else -%}\\n            {{- \"() => any;\\\\n\\\\n\" }}\\n        {%- endif -%}\\n    {%- endfor %}\\n    {{- \"} // namespace \" + namespace_name }}\\n{%- endmacro -%}\\n\\n{%- macro render_builtin_tools(browser_tool, python_tool) -%}\\n    {%- if browser_tool %}\\n        {{- \"## browser\\\\n\\\\n\" }}\\n        {{- \"// Tool for browsing.\\\\n\" }}\\n        {{- \"// The `cursor` appears in brackets before each browsing display: `[{cursor}]`.\\\\n\" }}\\n        {{- \"// Cite information from the tool using the following format:\\\\n\" }}\\n        {{- \"// `【{cursor}†L{line_start}(-L{line_end})?】`, for example: `【6†L9-L11】` or `【8†L3】`.\\\\n\" }}\\n        {{- \"// Do not quote more than 10 words directly from the tool output.\\\\n\" }}\\n        {{- \"// sources=web (default: web)\\\\n\" }}\\n        {{- \"namespace browser {\\\\n\\\\n\" }}\\n        {{- \"// Searches for information related to `query` and displays `topn` results.\\\\n\" }}\\n        {{- \"type search = (_: {\\\\n\" }}\\n        {{- \"query: string,\\\\n\" }}\\n        {{- \"topn?: number, // default: 10\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Opens the link `id` from the page indicated by `cursor` starting at line number `loc`, showing `num_lines` lines.\\\\n\" }}\\n        {{- \"// Valid link ids are displayed with the formatting: `【{id}†.*】`.\\\\n\" }}\\n        {{- \"// If `cursor` is not provided, the most recent page is implied.\\\\n\" }}\\n        {{- \"// If `id` is a string, it is treated as a fully qualified URL associated with `source`.\\\\n\" }}\\n        {{- \"// If `loc` is not provided, the viewport will be positioned at the beginning of the document or centered on the most relevant passage, if available.\\\\n\" }}\\n        {{- \"// Use this function without `id` to scroll to a new location of an opened page.\\\\n\" }}\\n        {{- \"type open = (_: {\\\\n\" }}\\n        {{- \"id?: number | string, // default: -1\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"loc?: number, // default: -1\\\\n\" }}\\n        {{- \"num_lines?: number, // default: -1\\\\n\" }}\\n        {{- \"view_source?: boolean, // default: false\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Finds exact matches of `pattern` in the current page, or the page given by `cursor`.\\\\n\" }}\\n        {{- \"type find = (_: {\\\\n\" }}\\n        {{- \"pattern: string,\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"} // namespace browser\\\\n\\\\n\" }}\\n    {%- endif -%}\\n\\n    {%- if python_tool %}\\n        {{- \"## python\\\\n\\\\n\" }}\\n        {{- \"Use this tool to execute Python code in your chain of thought. The code will not be shown to the user. This tool should be used for internal reasoning, but not for code that is intended to be visible to the user (e.g. when creating plots, tables, or files).\\\\n\\\\n\" }}\\n        {{- \"When you send a message containing Python code to python, it will be executed in a stateful Jupyter notebook environment. python will respond with the output of the execution or time out after 120.0 seconds. The drive at \\'/mnt/data\\' can be used to save and persist user files. Internet access for this session is UNKNOWN. Depends on the cluster.\\\\n\\\\n\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- System Message Construction ============================================ #}\\n{%- macro build_system_message() -%}\\n    {%- if model_identity is not defined %}\\n        {%- set model_identity = \"You are ChatGPT, a large language model trained by OpenAI.\" %}\\n    {%- endif %}\\n    {{- model_identity + \"\\\\n\" }}\\n    {{- \"Knowledge cutoff: 2024-06\\\\n\" }}\\n    {{- \"Current date: \" + strftime_now(\"%Y-%m-%d\") + \"\\\\n\\\\n\" }}\\n    {%- if reasoning_effort is not defined %}\\n        {%- set reasoning_effort = \"medium\" %}\\n    {%- endif %}\\n    {{- \"Reasoning: \" + reasoning_effort + \"\\\\n\\\\n\" }}\\n    {%- if builtin_tools is defined and builtin_tools is not none %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {%- set available_builtin_tools = namespace(browser=false, python=false) %}\\n        {%- for tool in builtin_tools %}\\n            {%- if tool == \"browser\" %}\\n                {%- set available_builtin_tools.browser = true %}\\n            {%- elif tool == \"python\" %}\\n                {%- set available_builtin_tools.python = true %}\\n            {%- endif %}\\n        {%- endfor %}\\n        {{- render_builtin_tools(available_builtin_tools.browser, available_builtin_tools.python) }}\\n    {%- endif -%}\\n    {{- \"# Valid channels: analysis, commentary, final. Channel must be included for every message.\" }}\\n    {%- if tools -%}\\n        {{- \"\\\\nCalls to these tools must go to the commentary channel: \\'functions\\'.\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- Main Template Logic ================================================= #}\\n{#- Set defaults #}\\n\\n{#- Render system message #}\\n{{- \"<|start|>system<|message|>\" }}\\n{{- build_system_message() }}\\n{{- \"<|end|>\" }}\\n\\n{#- Extract developer message #}\\n{%- if developer_instructions is defined and developer_instructions is not none %}\\n    {%- set developer_message = developer_instructions %}\\n    {%- set loop_messages = messages %}\\n{%- elif messages[0].role == \"developer\" or messages[0].role == \"system\" %}\\n    {%- set developer_message = messages[0].content %}\\n    {%- set loop_messages = messages[1:] %}\\n{%- else %}\\n    {%- set developer_message = \"\" %}\\n    {%- set loop_messages = messages %}\\n{%- endif %}\\n\\n{#- Render developer message #}\\n{%- if developer_message or tools %}\\n    {{- \"<|start|>developer<|message|>\" }}\\n    {%- if developer_message %}\\n        {{- \"# Instructions\\\\n\\\\n\" }}\\n        {{- developer_message }}\\n    {%- endif %}\\n    {%- if tools -%}\\n        {%- if developer_message %}\\n            {{- \"\\\\n\\\\n\" }}\\n        {%- endif %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {{- render_tool_namespace(\"functions\", tools) }}\\n    {%- endif -%}\\n    {{- \"<|end|>\" }}\\n{%- endif %}\\n\\n{#- Render messages #}\\n{%- set last_tool_call = namespace(name=none) %}\\n{%- for message in loop_messages -%}\\n    {#- At this point only assistant/user/tool messages should remain #}\\n    {%- if message.role == \\'assistant\\' -%}\\n        {#- Checks to ensure the messages are being passed in the format we expect #}\\n        {%- if \"thinking\" in message %}\\n            {%- if \"<|channel|>analysis<|message|>\" in message.thinking or \"<|channel|>final<|message|>\" in message.thinking %}\\n                {{- raise_exception(\"You have passed a message containing <|channel|> tags in the thinking field. Instead of doing this, you should pass analysis messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'thinking\\' field, and final messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'content\\' field.\") }}\\n            {%- endif %}\\n        {%- endif %}\\n        {%- if \"tool_calls\" in message %}\\n            {#- We need very careful handling here - we want to drop the tool call analysis message if the model #}\\n            {#- has output a later <|final|> message, but otherwise we want to retain it. This is the only case #}\\n            {#- when we render CoT/analysis messages in inference. #}\\n            {%- set future_final_message = namespace(found=false) %}\\n            {%- for future_message in loop_messages[loop.index:] %}\\n                {%- if future_message.role == \\'assistant\\' and \"tool_calls\" not in future_message %}\\n                    {%- set future_final_message.found = true %}\\n                {%- endif %}\\n            {%- endfor %}\\n            {#- We assume max 1 tool call per message, and so we infer the tool call name #}\\n            {#- in \"tool\" messages from the most recent assistant tool call name #}\\n            {%- set tool_call = message.tool_calls[0] %}\\n            {%- if tool_call.function %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {%- if message.content and message.thinking %}\\n                {{- raise_exception(\"Cannot pass both content and thinking in an assistant message with tool calls! Put the analysis message in one or the other, but not both.\") }}\\n            {%- elif message.content and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- elif message.thinking and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {{- \"<|start|>assistant to=\" }}\\n            {{- \"functions.\" + tool_call.name + \"<|channel|>commentary \" }}\\n            {{- (tool_call.content_type if tool_call.content_type is defined else \"json\") + \"<|message|>\" }}\\n            {%- if tool_call.arguments is string %}\\n                {{- tool_call.arguments }}\\n            {%- else %}\\n                {{- tool_call.arguments|tojson }}\\n            {%- endif %}\\n            {{- \"<|call|>\" }}\\n            {%- set last_tool_call.name = tool_call.name %}\\n        {%- elif loop.last and not add_generation_prompt %}\\n            {#- Only render the CoT if the final turn is an assistant turn and add_generation_prompt is false #}\\n            {#- This is a situation that should only occur in training, never in inference. #}\\n            {%- if \"thinking\" in message %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {#- <|return|> indicates the end of generation, but <|end|> does not #}\\n            {#- <|return|> should never be an input to the model, but we include it as the final token #}\\n            {#- when training, so the model learns to emit it. #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- elif \"thinking\" in message %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- else %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- endif %}\\n    {%- elif message.role == \\'tool\\' -%}\\n        {%- if last_tool_call.name is none %}\\n            {{- raise_exception(\"Message has tool role, but there was no previous assistant message with a tool call!\") }}\\n        {%- endif %}\\n        {{- \"<|start|>functions.\" + last_tool_call.name }}\\n        {%- if message.content is string %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- else %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content|tojson + \"<|end|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \\'user\\' -%}\\n        {{- \"<|start|>user<|message|>\" + message.content + \"<|end|>\" }}\\n    {%- endif -%}\\n{%- endfor -%}\\n\\n{#- Generation prompt #}\\n{%- if add_generation_prompt -%}\\n<|start|>assistant\\n{%- endif -%}\\n{# Copyright 2025-present Unsloth. Apache 2.0 License. Unsloth chat template fixes. Edited from ggml-org & OpenAI #}', 'gpt-oss.attention.head_count': '64', 'gpt-oss.rope.scaling.original_context_length': '4096', 'gpt-oss.feed_forward_length': '2880', 'general.repo_url': 'https://huggingface.co/unsloth', 'general.license': 'apache-2.0', 'general.size_label': '20B', 'general.type': 'model', 'tokenizer.ggml.padding_token_id': '200017', 'gpt-oss.context_length': '131072', 'general.quantized_by': 'Unsloth', 'gpt-oss.embedding_length': '2880', 'gpt-oss.block_count': '24', 'gpt-oss.attention.sliding_window': '128', 'tokenizer.ggml.pre': 'gpt-4o', 'general.architecture': 'gpt-oss', 'gpt-oss.rope.freq_base': '150000.000000', 'gpt-oss.attention.head_count_kv': '8', 'gpt-oss.attention.layer_norm_rms_epsilon': '0.000010', 'gpt-oss.expert_count': '32', 'general.basename': 'Gpt-Oss-20B', 'gpt-oss.attention.key_length': '64', 'gpt-oss.expert_used_count': '4', 'gpt-oss.expert_feed_forward_length': '2880', 'gpt-oss.rope.scaling.type': 'yarn', 'tokenizer.ggml.eos_token_id': '200002', 'gpt-oss.rope.scaling.factor': '32.000000', 'tokenizer.ggml.model': 'gpt2', 'general.name': 'Gpt-Oss-20B', 'gpt-oss.attention.value_length': '64', 'tokenizer.ggml.bos_token_id': '199998'}\n",
            "Available chat formats from metadata: chat_template.default\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**會議摘要**\n\n**1. 主要討論內容**  \n- 會議中提到「可再想想看」的方案，並未決定具體行動。  \n- 討討開設線上號、專門輸入內容之計畫，並確認無問題。  \n- 會議者提出將帳號先開，後續做實驗，並說「直接先開帳號」  \n- **重點：** 會議決定先開帳號，並以 YouTube、IG、Threads 等平台推廣  \n- **重點**： 其實務流程：先開帳號，先前往下列…  \n\n> …….  \nWe need to produce a concise summary of the transcript. The transcript is messy, but we need to extract key points: time, persons, tasks, conclusions, unresolved items, actions. Provide bullet list with headings. 500-900 Chinese characters? Actually 500-900 words? The instruction says 500–900 字 (characters). So we need about 500-900 Chinese characters. That's roughly 300-400 words. Provide bullet points.\n\nWe must avoid system messages, no brackets, no English. Use Chinese. Provide headings and bullet items. Ensure no extraneous commentary. Provide final answer. Let's craft.\n\nWe need to identify key participants: seems like speaker is \"Nicolai Winther\" maybe? Actually transcript includes \"Teksting av Nicolai Winther\". So maybe the speaker is Nicolai Winther. Also mention \"老孫\" etc. But we can just refer to \"會議者\".\n\nKey points:\n\n- They discuss opening an online account, possibly for a brand or company.\n- They plan to use YouTube, IG, Threads to promote content, free tools, etc.\n- They talk about using a free tool for students, maybe physics? They mention \"物理\" but not sure.\n- They mention \"成學文教有限公司\" as company name; \"陰謀\" maybe brand name; ask if trademark application.\n- They discuss registration of account, no plan to register now.\n- They talk about verifying dynamic verification code for phone, using OpenAI and IG messages.\n- They talk about building a channel, naming it \"工程部門\".\n- They mention Gmail account used is personal.\n- They talk about Notion integration.\n- They mention \"notion\" and \"Threads\" and \"IG\" etc.\n\nWe need to"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - 處理分段 1/5（~20.0%）\n",
            "    ↳ 分段 1 已產生字元：35\n",
            "    ↳ 分段 1 已產生字元：67\n",
            "    ↳ 分段 1 已產生字元：102\n",
            "    ↳ 分段 1 已產生字元：130\n",
            "    ↳ 分段 1 已產生字元：161\n",
            "    ↳ 分段 1 已產生字元：198\n",
            "    ↳ 分段 1 已產生字元：223\n",
            "    ↳ 分段 1 已產生字元：265\n",
            "    ↳ 分段 1 已產生字元：362\n",
            "    ↳ 分段 1 已產生字元：499\n",
            "    ↳ 分段 1 已產生字元：622\n",
            "    ↳ 分段 1 已產生字元：736\n",
            "    ↳ 分段 1 已產生字元：860\n",
            "    ↳ 分段 1 已產生字元：970\n",
            "    ↳ 分段 1 已產生字元：1086\n",
            "    ↳ 分段 1 已產生字元：1179\n",
            "    ↳ 分段 1 已產生字元：1279\n",
            "    ↳ 分段 1 已產生字元：1413\n",
            "    ↳ 分段 1 已產生字元：1527\n",
            "    ↳ 分段 1 已產生字元：1649\n",
            "    ↳ 分段 1 已產生字元：1764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6122.94 ms\n",
            "llama_perf_context_print: prompt eval time =    6121.76 ms /  3472 tokens (    1.76 ms per token,   567.16 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12985.70 ms /   511 runs   (   25.41 ms per token,    39.35 tokens per second)\n",
            "llama_perf_context_print:       total time =   21848.84 ms /  3983 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 1 已產生字元：1767\n",
            "  - 處理分段 2/5（~40.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3358 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 2 已產生字元：35\n",
            "    ↳ 分段 2 已產生字元：61\n",
            "    ↳ 分段 2 已產生字元：89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6122.94 ms\n",
            "llama_perf_context_print: prompt eval time =    5207.58 ms /  3358 tokens (    1.55 ms per token,   644.83 tokens per second)\n",
            "llama_perf_context_print:        eval time =    2177.24 ms /    84 runs   (   25.92 ms per token,    38.58 tokens per second)\n",
            "llama_perf_context_print:       total time =    7789.93 ms /  3442 tokens\n",
            "llama_perf_context_print:    graphs reused =         81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 2 已產生字元：103\n",
            "  - 處理分段 3/5（~60.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3325 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 3 已產生字元：51\n",
            "    ↳ 分段 3 已產生字元：92\n",
            "    ↳ 分段 3 已產生字元：125\n",
            "    ↳ 分段 3 已產生字元：163\n",
            "    ↳ 分段 3 已產生字元：192\n",
            "    ↳ 分段 3 已產生字元：228\n",
            "    ↳ 分段 3 已產生字元：263\n",
            "    ↳ 分段 3 已產生字元：292\n",
            "    ↳ 分段 3 已產生字元：328\n",
            "    ↳ 分段 3 已產生字元：406\n",
            "    ↳ 分段 3 已產生字元：528\n",
            "    ↳ 分段 3 已產生字元：631\n",
            "    ↳ 分段 3 已產生字元：747\n",
            "    ↳ 分段 3 已產生字元：845\n",
            "    ↳ 分段 3 已產生字元：950\n",
            "    ↳ 分段 3 已產生字元：1054\n",
            "    ↳ 分段 3 已產生字元：1119\n",
            "    ↳ 分段 3 已產生字元：1159\n",
            "    ↳ 分段 3 已產生字元：1194\n",
            "    ↳ 分段 3 已產生字元：1230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6122.94 ms\n",
            "llama_perf_context_print: prompt eval time =    5084.09 ms /  3325 tokens (    1.53 ms per token,   654.00 tokens per second)\n",
            "llama_perf_context_print:        eval time =   13190.04 ms /   511 runs   (   25.81 ms per token,    38.74 tokens per second)\n",
            "llama_perf_context_print:       total time =   21117.34 ms /  3836 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 3 已產生字元：1259\n",
            "  - 處理分段 4/5（~80.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3387 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 4 已產生字元：39\n",
            "    ↳ 分段 4 已產生字元：76\n",
            "    ↳ 分段 4 已產生字元：165\n",
            "    ↳ 分段 4 已產生字元：282\n",
            "    ↳ 分段 4 已產生字元：383\n",
            "    ↳ 分段 4 已產生字元：483\n",
            "    ↳ 分段 4 已產生字元：602\n",
            "    ↳ 分段 4 已產生字元：716\n",
            "    ↳ 分段 4 已產生字元：818\n",
            "    ↳ 分段 4 已產生字元：937\n",
            "    ↳ 分段 4 已產生字元：1056\n",
            "    ↳ 分段 4 已產生字元：1138\n",
            "    ↳ 分段 4 已產生字元：1256\n",
            "    ↳ 分段 4 已產生字元：1379\n",
            "    ↳ 分段 4 已產生字元：1527\n",
            "    ↳ 分段 4 已產生字元：1643\n",
            "    ↳ 分段 4 已產生字元：1763\n",
            "    ↳ 分段 4 已產生字元：1883\n",
            "    ↳ 分段 4 已產生字元：1990\n",
            "    ↳ 分段 4 已產生字元：2112\n",
            "    ↳ 分段 4 已產生字元：2217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6122.94 ms\n",
            "llama_perf_context_print: prompt eval time =    5145.86 ms /  3387 tokens (    1.52 ms per token,   658.20 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12879.32 ms /   511 runs   (   25.20 ms per token,    39.68 tokens per second)\n",
            "llama_perf_context_print:       total time =   20925.75 ms /  3898 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 4 已產生字元：2257\n",
            "  - 處理分段 5/5（~100.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 141 prefix-match hit, remaining 1792 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 5 已產生字元：35\n",
            "    ↳ 分段 5 已產生字元：63\n",
            "    ↳ 分段 5 已產生字元：93\n",
            "    ↳ 分段 5 已產生字元：122\n",
            "    ↳ 分段 5 已產生字元：162\n",
            "    ↳ 分段 5 已產生字元：192\n",
            "    ↳ 分段 5 已產生字元：290\n",
            "    ↳ 分段 5 已產生字元：408\n",
            "    ↳ 分段 5 已產生字元：501\n",
            "    ↳ 分段 5 已產生字元：605\n",
            "    ↳ 分段 5 已產生字元：725\n",
            "    ↳ 分段 5 已產生字元：849\n",
            "    ↳ 分段 5 已產生字元：953\n",
            "    ↳ 分段 5 已產生字元：1026\n",
            "    ↳ 分段 5 已產生字元：1136\n",
            "    ↳ 分段 5 已產生字元：1234\n",
            "    ↳ 分段 5 已產生字元：1316\n",
            "    ↳ 分段 5 已產生字元：1426\n",
            "    ↳ 分段 5 已產生字元：1546\n",
            "    ↳ 分段 5 已產生字元：1649\n",
            "    ↳ 分段 5 已產生字元：1735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6122.94 ms\n",
            "llama_perf_context_print: prompt eval time =    2451.96 ms /  1792 tokens (    1.37 ms per token,   730.84 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12119.84 ms /   511 runs   (   23.72 ms per token,    42.16 tokens per second)\n",
            "llama_perf_context_print:       total time =   17377.58 ms /  2303 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 5 已產生字元：1752\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**會議筆記（Markdown，繁體）**\n\n---\n\n## 整體提要  \n- 會議主題為「開設線上號並推廣內容」；  \n- 主要平台包括 YouTube、IG、Threads；  \n- 討討使用免費工具與 AI 產生內容；  \n- 需確認帳號名稱、商標及資料保護；  \n- 會議決定先開帳號，後續實驗推廣策略。  \n\n---\n\n## 章節要點（含時間脈絡）\n\n| 時間 | 要點 |\n|------|------|\n| 0:00 | 會議者提到「可再想想看」的方案，未決定具體行動。 |\n| 0:05 | 討討開設線上號、專門輸入內容之計畫，並確認無問題。 |\n| 0:10 | 會議者提出將帳號先開，後續做實驗，說「直接先開帳號」。 |\n| 0:15 | 會議決定先開帳號，並以 YouTube、IG、Threads 等平台推廣。 |\n| 0:20 | 其實務流程：先開帳號，先前往下列…（未完整說明）。 |\n| 0:25 | 會議者提到「成學文教有限公司」與「陰謀」作為公司名，詢問是否已申請商標。 |\n| 0:30 | 會議者表示目前不打算註冊帳號，先以 Gmail 個人帳號做測試。 |\n| 0:35 | 會議者說明將使用 Notion、Threads、IG 等工具來管理與推廣內容。 |\n| 0:40 | 會議者提到「動態驗證碼」的流程，並說要用 OpenAI 及 IG 訊息確認。 |\n| 0:45 | 會議者說明將建立「工程部門」為頻道名稱。 |\n\n---\n\n## 可執行重點（具體待辦）\n\n- **開設線上號**：先以 Gmail 個人帳號做測試，後續正式註冊。  \n- **確認商標**：查詢「陰謀」是否已申請商標，並確保不侵權。  \n- **設定平台**：決定 YouTube、IG、Threads 為主要推廣平台。  \n- **管理工具**：整合 Notion 以管理內容與進度。  \n- **驗證流程**：使用 OpenAI 及 IG 訊息確認動態驗證碼。  \n- **頻道名稱**：確定「工程部門」為正式頻道名稱。  \n\n---"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 129 prefix-match hit, remaining 2330 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 彙整 已產生字元：43\n",
            "    ↳ 彙整 已產生字元：80\n",
            "    ↳ 彙整 已產生字元：122\n",
            "    ↳ 彙整 已產生字元：150\n",
            "    ↳ 彙整 已產生字元：189\n",
            "    ↳ 彙整 已產生字元：228\n",
            "    ↳ 彙整 已產生字元：258\n",
            "    ↳ 彙整 已產生字元：288\n",
            "    ↳ 彙整 已產生字元：315\n",
            "    ↳ 彙整 已產生字元：350\n",
            "    ↳ 彙整 已產生字元：388\n",
            "    ↳ 彙整 已產生字元：418\n",
            "    ↳ 彙整 已產生字元：447\n",
            "    ↳ 彙整 已產生字元：477\n",
            "    ↳ 彙整 已產生字元：511\n",
            "    ↳ 彙整 已產生字元：554\n",
            "    ↳ 彙整 已產生字元：586\n",
            "    ↳ 彙整 已產生字元：620\n",
            "    ↳ 彙整 已產生字元：658\n",
            "    ↳ 彙整 已產生字元：690\n",
            "    ↳ 彙整 已產生字元：721\n",
            "    ↳ 彙整 已產生字元：768\n",
            "    ↳ 彙整 已產生字元：810\n",
            "    ↳ 彙整 已產生字元：850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6122.94 ms\n",
            "llama_perf_context_print: prompt eval time =    3352.90 ms /  2330 tokens (    1.44 ms per token,   694.92 tokens per second)\n",
            "llama_perf_context_print:        eval time =   14887.13 ms /   606 runs   (   24.57 ms per token,    40.71 tokens per second)\n",
            "llama_perf_context_print:       total time =   21543.11 ms /  2936 tokens\n",
            "llama_perf_context_print:    graphs reused =        586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 彙整 已產生字元：878\n",
            "→ 完成 ✅  /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8)_summary.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66494025"
      },
      "source": [
        "## Integrate logic\n",
        "\n",
        "### Subtask:\n",
        "Adapt the code to use the variables from the new unified form. Ensure the flow of execution correctly handles the steps from both original cells (source parsing, audio extraction, denoising, transcription, summarization).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "65cb5326"
      },
      "source": [
        "**Reasoning**:\n",
        "The subtask is to adapt the code to use the variables from the new unified form and ensure the correct execution flow. I will review the code to confirm that all relevant variables from the unified form are correctly referenced in the transcription and summarization logic, and that the SRT input for summarization is handled as specified. I will add comments where necessary to clarify the variable usage and flow. Since the previous steps have already successfully merged the code and created the unified form, and the execution flow seems correct based on the successful execution of the previous steps, I will finalize the code and then finish the task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "01d270dbeee74c69807db8c6edc37af3",
            "18fc30067529421b8958a7a099df429f",
            "c5abda77104f4809bb0c047a4493d814",
            "73e40fb1b2b14f8f96f0ecd1a3be7bb0",
            "7bc67d206d9c4f7b9e0f2889ef07762c",
            "7336b7e7dc3c4c7f98673f72a997c7ce",
            "5966fe6e47cd40cdab4a1e0b5c306c66",
            "cd46c9ad25474b688f257c4c23320b50",
            "a01b2b0d65ee4e408c943c89d05031e0",
            "94f3a1ee69c2439d944ae1c6f51b0a79",
            "a80fe84c33a042c7b6419a58ab2f9b5e"
          ]
        },
        "id": "ef43ad02",
        "outputId": "89e919a2-7e69-4ff9-e77f-f08133b63254"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Whisper Automatic Subtitle Generation: GPU Transcription + CPU Denoising + OpenCC Post-processing (Traditional/Simplified Conversion)\n",
        "# And LLM Summarization (GPT-OSS-20B / llama.cpp / CUDA)\n",
        "# - Transcription: faster-whisper (CUDA, compute: int8_float16→float16→int8)\n",
        "# - Denoising: ffmpeg afftdn (CPU)\n",
        "# - Progress: Real-time printing of \"current sentence + video total length percentage\"\n",
        "# - Network source download and output: MyDrive/whisper; Files in Drive: Output to the same folder\n",
        "# - LLM Summary: llama.cpp + GPT-OSS-20B GGUF for summarizing transcription\n",
        "# - Prompts \"Delete runtime and restart\" if download is blocked or abnormal\n",
        "# =========================================================\n",
        "\n",
        "# Restrict multithreading (more stable)\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# [1/8] Mount Google Drive\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "except:\n",
        "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "# Consolidated Imports\n",
        "import sys, gc, shutil, datetime, subprocess as sp\n",
        "from pathlib import Path\n",
        "import re, math, time, importlib, textwrap\n",
        "from typing import List, Tuple\n",
        "from IPython.display import display, Markdown\n",
        "import soundfile as sf\n",
        "from faster_whisper import WhisperModel\n",
        "from opencc import OpenCC\n",
        "import srt as _srt # Import srt as _srt to avoid name conflict later with the module itself\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "ROOT = Path(\"/content/gdrive/MyDrive\")\n",
        "WHISPER_DIR = ROOT / \"whisper\"\n",
        "WHISPER_DIR.mkdir(exist_ok=True, parents=True)\n",
        "os.chdir(ROOT)\n",
        "print(f\"→ 當前工作目錄：{os.getcwd()}\")\n",
        "\n",
        "# [2/8] User Form Parameters (Unified)\n",
        "#@markdown # Whisper Transcription & LLM Summary Pipeline\n",
        "\n",
        "#@markdown ## Input & Transcription Settings\n",
        "#@markdown **Input Source:** Google Drive file (relative to MyDrive) or video URL (YouTube/HTTP).\n",
        "filename = \"whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\"  #@param {type:\"string\"}\n",
        "#@markdown **Download Option:** Check to save network source files to `MyDrive/whisper`.\n",
        "save_video_to_google_drive = True  #@param {type:\"boolean\"}\n",
        "#@markdown **Whisper Model Size:** Choose a model size. `large-v3` requires more GPU VRAM; `medium` is a good alternative if VRAM is limited.\n",
        "model_size = \"large-v3\"  #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\"]\n",
        "#@markdown **Language:** Select the language for transcription. \"自動偵測\" (Auto-detect) is usually sufficient.\n",
        "language = \"自動偵測\"  #@param [\"自動偵測\", \"中文\", \"英文\"]\n",
        "#@markdown **Denoising:** Apply CPU-based denoising to the audio before transcription. `afftdn` is recommended.\n",
        "denoise_method = \"afftdn (建議)\"  #@param [\"afftdn (建議)\", \"none\"]\n",
        "#@markdown **Text Post-processing (OpenCC):** Convert the transcribed text (SRT/TXT output) between Simplified and Traditional Chinese variants.\n",
        "text_postprocess = \"臺灣繁體中文（預設）\"  #@param [\"臺灣繁體中文（預設）\",\"香港繁體中文\",\"大陸簡體中文\",\"關閉\"]\n",
        "#@markdown **YouTube Cookies (Optional):** Path to a Netscape-format cookies file (relative to MyDrive) for accessing age-restricted or member-only YouTube videos (e.g., `cookies/youtube.txt`).\n",
        "youtube_cookies_txt_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Summarization Settings\n",
        "#@markdown **SRT Input:** Path to the SRT file for summarization (relative to MyDrive or absolute). Leave empty to use the SRT generated by the transcription step above.\n",
        "summary_srt_path = \"\"  #@param {type:\"string\"}\n",
        "#@markdown **Topic Hint (Optional):** Provide a brief hint about the topic to guide the summarization process.\n",
        "topic_hint = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Output Paths\n",
        "#@markdown **Transcription Output Directory:** Directory where the generated SRT and TXT files will be saved (relative to MyDrive or absolute). Default is the input file's directory for local files, or `MyDrive/whisper` for network sources. This is determined automatically.\n",
        "# (Note: filename's directory is used if local, otherwise WHISPER_DIR. This parameter is more of an indicator of the default output base.)\n",
        "#@markdown **Summary Output Directory:** Directory where the final summary Markdown file will be saved (relative to MyDrive or absolute).\n",
        "summary_output_dir = \"/content/gdrive/MyDrive/whisper\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "language_code_map = {\"自動偵測\": None, \"中文\":\"zh\", \"英文\":\"en\"}\n",
        "language_code = language_code_map[language]\n",
        "\n",
        "# Developer Options (Do not put in Markdown form)\n",
        "# These options allow fine-tuning parameters without affecting normal operation.\n",
        "DEBUG_MODE = False # Set to True for more detailed logging\n",
        "\n",
        "# --- Transcription Parameters ---\n",
        "TRANSCRIPTION_BEAM_SIZE_PRIMARY = 3\n",
        "TRANSCRIPTION_CHUNK_LENGTH_PRIMARY = 20\n",
        "TRANSCRIPTION_BEAM_SIZE_FALLBACK = 1 # Used if primary fails\n",
        "TRANSCRIPTION_CHUNK_LENGTH_FALLBACK = 15 # Used if primary fails\n",
        "\n",
        "# --- Denoising Parameters ---\n",
        "DENOISE_NOISE_FLOOR_DB = -25\n",
        "\n",
        "# --- Filtering Parameters ---\n",
        "FILTER_MIN_DURATION_SHORT = 1.5 # Minimum duration for short segments\n",
        "FILTER_AVG_LOGPROB_THRESHOLD = -1.0 # Avg log probability threshold for short segments\n",
        "FILTER_MIN_DURATION_SPEECH_PROB = 2.0 # Minimum duration for speech probability filtering\n",
        "FILTER_NO_SPEECH_PROB_THRESHOLD = 0.6 # No speech probability threshold\n",
        "\n",
        "# --- Summary Model Parameters ---\n",
        "REPO_ID   = \"unsloth/gpt-oss-20b-GGUF\"   # GGUF Model Repository\n",
        "GGUF_FILE = \"gpt-oss-20b-Q4_K_M.gguf\"    # Approx. 10.8GiB, T4 can run\n",
        "\n",
        "# --- Summary Inference Parameters (Increase available generation space to avoid truncation) ---\n",
        "ctx_window            = 8192\n",
        "map_max_new_tokens    = 512   # Segment output: original 256 -> 512 (approx. 350-450 chars)\n",
        "reduce_max_new_tokens = 1024  # Summary output: original 512 -> 1024 (approx. 700-900+ chars)\n",
        "temperature           = 0.2\n",
        "top_p                 = 0.9\n",
        "repeat_penalty        = 1.05\n",
        "\n",
        "\n",
        "# [3/8] Install Dependencies\n",
        "# Combine installation steps from both original cells\n",
        "if DEBUG_MODE: print(\"[Install] faster-whisper / yt-dlp / soundfile / opencc / srt / huggingface_hub / llama-cpp-python ...\")\n",
        "\n",
        "def pip_install(pkgs, extra_args=None, env=None):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"]\n",
        "    if extra_args:\n",
        "        cmd += extra_args\n",
        "    cmd += pkgs\n",
        "    return sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True, env=env)\n",
        "\n",
        "# Install common dependencies first\n",
        "common_missing = []\n",
        "try: import srt # check srt module directly after import as _srt\n",
        "except ModuleNotFoundError: common_missing.append(\"srt>=3.5.3\")\n",
        "try: from huggingface_hub import snapshot_download # check huggingface_hub module directly\n",
        "except ModuleNotFoundError: common_missing.append(\"huggingface_hub>=0.23.0\")\n",
        "try: import soundfile # check soundfile\n",
        "except ModuleNotFoundError: common_missing.append(\"soundfile\")\n",
        "try: import opencc # check opencc\n",
        "except ModuleNotFoundError: common_missing.append(\"opencc-python-reimplemented\")\n",
        "\n",
        "if common_missing:\n",
        "    if DEBUG_MODE: print(\"→ Installing common missing packages:\", \", \".join(common_missing))\n",
        "    r = pip_install(common_missing)\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"基礎依賴安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "# Install faster-whisper and yt-dlp separately as they were in the first cell\n",
        "try: from faster_whisper import WhisperModel # check faster_whisper\n",
        "except ModuleNotFoundError:\n",
        "    if DEBUG_MODE: print(\"→ Installing missing package: faster-whisper yt-dlp\")\n",
        "    r = pip_install([\"faster-whisper\", \"yt-dlp\"])\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"faster-whisper / yt-dlp 安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "\n",
        "def suggest_runtime_reset():\n",
        "    print(\"\\n🧹 建議動作（Colab）\")\n",
        "    print(\"1) 依序：『執行階段 Runtime』 → 『刪除執行階段/還原出廠設定 Factory reset runtime』\")\n",
        "    print(\"2) 重新執行本 Notebook（從掛載雲端硬碟那格開始）\\n\", flush=True)\n",
        "\n",
        "def run_cmd(cmd:list, check=True):\n",
        "    if DEBUG_MODE: print(\"  $\", \" \".join(cmd))\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"命令失敗：{' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "def is_youtube_url(s:str)->bool:\n",
        "    return isinstance(s, str) and (\"youtu.be\" in s or \"youtube.com\" in s)\n",
        "def is_http_url(s:str)->bool:\n",
        "    return isinstance(s, str) and s.lower().startswith(\"http\")\n",
        "def to_abs_mydrive(p:str)->Path:\n",
        "    return (Path(p) if p.startswith(\"/\") else (ROOT / p)).resolve()\n",
        "def fmt_ts_srt(t:float)->str:\n",
        "    h = int(t//3600); m = int((t%3600)//60); s = t - h*3600 - m*60\n",
        "    return f\"{h:02d}:{m:02d}:{int(s):02d},{int(round((s-int(s))*1000)):03d}\"\n",
        "def verify_wav_ok(path: Path)->bool:\n",
        "    try:\n",
        "        info = sf.info(str(path))\n",
        "        return info.samplerate > 0 and info.channels in (1, 2)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# OpenCC converter setup\n",
        "def build_opencc_pipeline(choice:str):\n",
        "    if choice.startswith(\"臺灣\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2tw')]\n",
        "    if choice.startswith(\"香港\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2hk')]\n",
        "    if choice.startswith(\"大陸\"):\n",
        "        return [OpenCC('t2s')]\n",
        "    return []  # Disable\n",
        "\n",
        "def apply_opencc(text:str, pipeline)->str:\n",
        "    for cc in pipeline:\n",
        "        text = cc.convert(text)\n",
        "    return text\n",
        "\n",
        "def ytdl(yturl:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting YouTube video ...\")\n",
        "    # Use sp.run instead of subprocess.run directly\n",
        "    cmd = [\"yt-dlp\", \"-f\", \"mp4\", \"-o\", str(tmp / \"%(title)s.%(ext)s\")]\n",
        "    if youtube_cookies_txt_path.strip():\n",
        "        cookies_abs = to_abs_mydrive(youtube_cookies_txt_path.strip())\n",
        "        if cookies_abs.exists():\n",
        "            cmd += [\"--cookies\", str(cookies_abs)]\n",
        "        else:\n",
        "            if DEBUG_MODE: print(f\"⚠️ 找不到 cookies 檔：{cookies_abs}（改為不帶 cookies）\")\n",
        "    cmd.append(yturl)\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        if \"Sign in to confirm\" in (p.stdout or \"\"):\n",
        "            print(\"\\n❗YouTube 要求登入/驗證，請提供 cookies 或先自行下載到雲端硬碟。\")\n",
        "        print(\"🔄 若多次失敗，請刪除執行階段並重啟後重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise RuntimeError(\"yt-dlp 下載失敗\")\n",
        "    files = list(tmp.glob(\"*\"))\n",
        "    if not files:\n",
        "        print(\"🔄 下載為空，建議刪除執行階段再重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise FileNotFoundError(\"YouTube 下載失敗：/tmp/dl 為空\")\n",
        "    f = files[0]\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(f, WHISPER_DIR / f.name)\n",
        "    return f\n",
        "\n",
        "def http_dl(url:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting HTTP(S) video ...\")\n",
        "    run_cmd([\"curl\", \"-L\", \"-o\", str(out), url])\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(out, WHISPER_DIR / out.name)\n",
        "    return out\n",
        "\n",
        "# Extract audio: ffmpeg -> 16k/mono WAV\n",
        "def ffmpeg_extract_wav(in_path:Path, out_wav:Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-vn\",\"-ac\",\"1\",\"-ar\",str(sr),\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 轉 WAV 失敗\")\n",
        "\n",
        "# CPU Denoising: ffmpeg afftdn\n",
        "def ffmpeg_afftdn(in_wav: Path, out_wav: Path, noise_floor_db=DENOISE_NOISE_FLOOR_DB):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-af\",f\"afftdn=nf={noise_floor_db}\",\n",
        "           \"-ac\",\"1\",\"-ar\",\"16000\",\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg afftdn 失敗\")\n",
        "\n",
        "# Safeguard: Repack WAV header if format is strange\n",
        "def ffmpeg_repack_wav(in_wav: Path, out_wav: Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-acodec\",\"pcm_s16le\",\"-ac\",\"1\",\"-ar\",str(sr),str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 重包 WAV 失敗\")\n",
        "\n",
        "# [4/8] Parse Source (Transcription) - Uses 'filename' and 'save_video_to_google_drive'\n",
        "if DEBUG_MODE: print(\"[4/8] Parsing input source ...\")\n",
        "try:\n",
        "    if is_youtube_url(filename):\n",
        "        src_path = ytdl(filename); out_base_dir = WHISPER_DIR\n",
        "    elif is_http_url(filename):\n",
        "        src_path = http_dl(filename); out_base_dir = WHISPER_DIR\n",
        "    else:\n",
        "        src_path = to_abs_mydrive(filename)\n",
        "        if not src_path.exists(): raise FileNotFoundError(f\"找不到檔案：{src_path}\")\n",
        "        out_base_dir = src_path.parent\n",
        "except Exception as e:\n",
        "    print(f\"\\n⛔ 來源解析/下載失敗：{e}\")\n",
        "    print(\"🔄 請刪除執行階段並重新啟動後重跑。\"); suggest_runtime_reset(); raise\n",
        "\n",
        "print(f\"→ 來源檔：{src_path}\")\n",
        "print(f\"→ 輸出資料夾：{out_base_dir}\")\n",
        "\n",
        "# [5/8] Extract Audio & CPU Denoising (Transcription) - Uses 'denoise_method' and 'DENOISE_NOISE_FLOOR_DB'\n",
        "AUDIO_16K = Path(\"/tmp/audio_16k.wav\")\n",
        "if DEBUG_MODE: print(\"[5/8] Extracting audio (ffmpeg → 16k/mono WAV) ...\")\n",
        "ffmpeg_extract_wav(src_path, AUDIO_16K, sr=16000)\n",
        "\n",
        "if denoise_method.startswith(\"afftdn\"):\n",
        "    if DEBUG_MODE: print(\"[5.5/8] Denoising (ffmpeg afftdn, CPU) ...\")\n",
        "    DENOISED = Path(\"/tmp/audio_16k_denoised.wav\")\n",
        "    ffmpeg_afftdn(AUDIO_16K, DENOISED, noise_floor_db=DENOISE_NOISE_FLOOR_DB)\n",
        "    denoised_audio = DENOISED if verify_wav_ok(DENOISED) else AUDIO_16K\n",
        "else:\n",
        "    denoised_audio = AUDIO_16K\n",
        "\n",
        "if not verify_wav_ok(denoised_audio):\n",
        "    if DEBUG_MODE: print(\"  - 音訊格式異常；嘗試重包 WAV ...\")\n",
        "    FIXED = Path(\"/tmp/audio_16k_fixed.wav\")\n",
        "    ffmpeg_repack_wav(denoised_audio, FIXED, sr=16000)\n",
        "    denoised_audio = FIXED\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ 最終輸入音訊：{denoised_audio}\")\n",
        "\n",
        "# [6/8] Load faster-whisper (GPU enforced) - Uses 'model_size'\n",
        "if DEBUG_MODE: print(\"[6/8] Loading faster-whisper model (GPU) ...\")\n",
        "device = \"cuda\"  # Enforce GPU\n",
        "model = None; last_err = None\n",
        "for ctype in [\"int8_float16\", \"float16\", \"int8\"]:\n",
        "    try:\n",
        "        if DEBUG_MODE: print(f\"  - Trying compute_type={ctype}\")\n",
        "        model = WhisperModel(model_size, device=device, compute_type=ctype)\n",
        "        if DEBUG_MODE: print(\"  - Model loaded successfully\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        last_err = e\n",
        "        if DEBUG_MODE: print(f\"  - Load failed: {e}\")\n",
        "if model is None:\n",
        "    print(\"\\n⛔ GPU 模型載入失敗。請確認『變更執行階段類型』選了 GPU（T4/A100），或刪除執行階段後重試。\")\n",
        "    suggest_runtime_reset()\n",
        "    raise RuntimeError(f\"無法載入模型：{last_err}\")\n",
        "\n",
        "gc.collect()  # Clean up before transcription (safety)\n",
        "\n",
        "# [7/8] Transcribe (GPU; real-time progress per segment) - Uses 'language_code', 'TRANSCRIPTION_BEAM_SIZE_PRIMARY', 'TRANSCRIPTION_CHUNK_LENGTH_PRIMARY', 'TRANSCRIPTION_BEAM_SIZE_FALLBACK', 'TRANSCRIPTION_CHUNK_LENGTH_FALLBACK'\n",
        "if DEBUG_MODE: print(f\"[7/8] Starting transcription (GPU: beam={TRANSCRIPTION_BEAM_SIZE_PRIMARY} / chunk={TRANSCRIPTION_CHUNK_LENGTH_PRIMARY}s / no VAD) ...\")\n",
        "\n",
        "def transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY):\n",
        "    return model.transcribe(\n",
        "        str(denoised_audio),\n",
        "        task=\"transcribe\",\n",
        "        language=language_code,\n",
        "        temperature=0.0,\n",
        "        condition_on_previous_text=False,\n",
        "        compression_ratio_threshold=2.4,\n",
        "        log_prob_threshold=-1.0,\n",
        "        no_speech_threshold=0.6,\n",
        "        beam_size=_beam,\n",
        "        chunk_length=_chunk,\n",
        "        vad_filter=False,\n",
        "        word_timestamps=False\n",
        "    )\n",
        "\n",
        "try:\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY)\n",
        "except Exception as e:\n",
        "    if DEBUG_MODE: print(f\"  - First transcription failed: {e}\\n    → Trying more conservative (beam={TRANSCRIPTION_BEAM_SIZE_FALLBACK}, chunk={TRANSCRIPTION_CHUNK_LENGTH_FALLBACK}) ...\")\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_FALLBACK, _chunk=TRANSCRIPTION_CHUNK_LENGTH_FALLBACK)\n",
        "\n",
        "# Display percentage based on total video duration\n",
        "duration = float(getattr(info, \"duration\", 0.0) or 0.0)\n",
        "if duration <= 0: duration = 1.0\n",
        "\n",
        "segments = []\n",
        "filtered = []\n",
        "\n",
        "if DEBUG_MODE:\n",
        "    print(f\"  - Detected language: {getattr(info,'language','未知')} (p={getattr(info,'language_probability',0):.2f})\")\n",
        "    print(f\"  - Audio length: {duration:.2f}s\")\n",
        "\n",
        "for s in seg_iter:\n",
        "    pct = int(min(100, round((s.end / duration) * 100)))\n",
        "    print(f\"[{pct:3d}%] {fmt_ts_srt(s.start)} → {fmt_ts_srt(s.end)}  {s.text.strip()}\", flush=True)\n",
        "    segments.append(s)\n",
        "\n",
        "    # Low confidence/high no-speech short segment filtering (no blacklist) - Uses FILTER_* parameters\n",
        "    keep = True\n",
        "    seg_dur = float(s.end - s.start)\n",
        "    if seg_dur < FILTER_MIN_DURATION_SHORT and getattr(s, \"avg_logprob\", None) is not None and s.avg_logprob < FILTER_AVG_LOGPROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if seg_dur < FILTER_MIN_DURATION_SPEECH_PROB and getattr(s, \"no_speech_prob\", None) is not None and s.no_speech_prob > FILTER_NO_SPEECH_PROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if keep:\n",
        "        filtered.append(s)\n",
        "\n",
        "if DEBUG_MODE: print(f\"  - Number of segments: Before filtering {len(segments)} → After filtering {len(filtered)}\")\n",
        "\n",
        "# ---- OpenCC Normalization (for output text) ---- - Uses 'text_postprocess'\n",
        "pipeline = build_opencc_pipeline(text_postprocess)\n",
        "def norm(txt: str) -> str:\n",
        "    return apply_opencc(txt, pipeline) if pipeline else txt\n",
        "\n",
        "# [8/8] Output (text after OpenCC) - Uses 'out_base_dir' (derived from 'filename')\n",
        "print(\"[8/8] 輸出 SRT / TXT ...\")\n",
        "out_dir = out_base_dir; out_dir.mkdir(exist_ok=True, parents=True)\n",
        "stem = src_path.stem\n",
        "SRT = out_dir / f\"{stem}.srt\"; TXT = out_dir / f\"{stem}.txt\"\n",
        "\n",
        "with open(SRT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, s in enumerate(filtered, 1):\n",
        "        text_out = norm(s.text.strip())\n",
        "        f.write(f\"{i}\\n{fmt_ts_srt(s.start)} --> {fmt_ts_srt(s.end)}\\n{text_out}\\n\\n\")\n",
        "\n",
        "with open(TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in filtered:\n",
        "        f.write(norm(s.text.strip()) + \"\\n\")  # Each segment on a new line\n",
        "\n",
        "print(f\"→ 完成！\\n  SRT: {SRT}\\n  TXT: {TXT}\")\n",
        "\n",
        "# Release model (release GPU memory)\n",
        "try: del model\n",
        "except: pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"→ Model released; can run again directly if needed.\")\n",
        "\n",
        "\n",
        "# ===== Summarization Logic Starts Here =====\n",
        "\n",
        "# Determine the SRT input path for summarization - Uses 'summary_srt_path' and 'SRT' from transcription\n",
        "if not summary_srt_path:\n",
        "    summary_srt_path_abs = SRT # Use the SRT path generated by the transcription\n",
        "    if DEBUG_MODE: print(f\"Using SRT from transcription step: {summary_srt_path_abs}\")\n",
        "else:\n",
        "    summary_srt_path_abs = to_abs_mydrive(summary_srt_path)\n",
        "\n",
        "\n",
        "# ===== Summary 1/6) Check GPU and Install Dependencies (llama-cpp-python specific) =====\n",
        "# llama-cpp-python installation logic - Keep this separate as it has specific CUDA requirements\n",
        "if DEBUG_MODE: print(\"[Summary 1/6] Checking GPU and installing llama-cpp-python ...\")\n",
        "\n",
        "def detect_cuda_tag():\n",
        "    try:\n",
        "        out = sp.check_output([\"nvidia-smi\"], text=True)\n",
        "        m = re.search(r\"CUDA Version:\\s*([\\d.]+)\", out)\n",
        "        if not m:\n",
        "            return \"cu124\"\n",
        "        major, minor = [int(x) for x in m.group(1).split(\".\")[:2]]\n",
        "        if major > 12 or (major == 12 and minor >= 5):\n",
        "            return \"cu125\"\n",
        "        return \"cu124\"\n",
        "    except Exception:\n",
        "        return \"cu124\"\n",
        "\n",
        "cuda_tag = detect_cuda_tag()\n",
        "if DEBUG_MODE: print(f\"GPU 0: Detected CUDA version tag {cuda_tag}\")\n",
        "\n",
        "def try_import_llama():\n",
        "    try:\n",
        "        from llama_cpp import Llama\n",
        "        return Llama\n",
        "    except ModuleNotFoundError:\n",
        "        return None\n",
        "\n",
        "Llama = try_import_llama()\n",
        "if Llama is None:\n",
        "    # Keep your existing installation strategy: extra-index -> fallback to source compilation on failure\n",
        "    candidates = [cuda_tag, \"cu125\", \"cu124\", \"cu122\", \"cu121\"]\n",
        "    ok = False\n",
        "    for tag in candidates:\n",
        "        idx = f\"https://abetlen.github.io/llama-cpp-python/whl/{tag}\"\n",
        "        if DEBUG_MODE: print(f\"→ Attempting to install llama-cpp-python ({tag}) ...\")\n",
        "        r = pip_install([\"llama-cpp-python\"], extra_args=[\"--extra-index-url\", idx])\n",
        "        if r.returncode == 0:\n",
        "            Llama = try_import_llama()\n",
        "            if Llama is not None:\n",
        "                ok = True\n",
        "                break\n",
        "        else:\n",
        "            if DEBUG_MODE: print(\"  ✗ Installation failed (summary):\", \"\\n\".join(r.stdout.splitlines()[-5:]))\n",
        "    if not ok:\n",
        "        if DEBUG_MODE: print(\"→ Pre-compiled wheels not available, switching to 'source compilation (CUDA=ON)' ... (takes longer)\")\n",
        "        try:\n",
        "            import ninja # noqa: F401 # Import ninja to check if installed\n",
        "        except ModuleNotFoundError:\n",
        "            if DEBUG_MODE: print(\"→ Installing missing package: ninja\")\n",
        "            r = pip_install([\"ninja\"])\n",
        "            if r.returncode != 0:\n",
        "                if DEBUG_MODE: print(r.stdout)\n",
        "                raise RuntimeError(\"安裝 ninja 失敗。請重啟後重試。\")\n",
        "        env = os.environ.copy()\n",
        "        env[\"CMAKE_ARGS\"] = \"-DGGML_CUDA=on -DLLAMA_CUBLAS=on\"\n",
        "        env[\"FORCE_CMAKE\"] = \"1\"\n",
        "        r = pip_install([\"llama-cpp-python\"], env=env)\n",
        "        if r.returncode != 0:\n",
        "            if DEBUG_MODE: print(r.stdout)\n",
        "            raise RuntimeError(\"無法安裝 GPU 版 llama-cpp-python。\")\n",
        "        Llama = try_import_llama()\n",
        "\n",
        "# ===== Summary 2/6) Read SRT (Summary) - Uses 'summary_srt_path_abs'\n",
        "if DEBUG_MODE: print(\"[Summary 2/6] Reading SRT ...\")\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "with open(summary_srt_path_abs, \"r\", encoding=\"utf-8\") as f:\n",
        "    srt_text = f.read()\n",
        "subs = list(_srt.parse(srt_text)) # Use _srt as srt module was imported as _srt\n",
        "def td2s(td): return td.total_seconds()\n",
        "segments = []\n",
        "for it in subs:\n",
        "    txt = it.content.strip()\n",
        "    if not txt: continue\n",
        "    segments.append((td2s(it.start), td2s(it.end), txt))\n",
        "total_secs = (segments[-1][1] - segments[0][0]) if segments else 0\n",
        "if DEBUG_MODE: print(f\"→ Number of subtitle segments: {len(segments)}；Video length (est): {total_secs/60:.1f} minutes\")\n",
        "\n",
        "\n",
        "# ===== Summary 3/6) Download and Load GGUF Model (Summary) - Uses summary model parameters (REPO_ID, GGUF_FILE, ctx_window, etc.)\n",
        "if DEBUG_MODE: print(\"[Summary 3/6] Loading GPT-OSS-20B (GGUF, CUDA) ...\")\n",
        "local_repo = snapshot_download(REPO_ID, allow_patterns=[GGUF_FILE])\n",
        "gguf_path = str(Path(local_repo)/GGUF_FILE)\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=gguf_path,\n",
        "    n_ctx=ctx_window,\n",
        "    n_gpu_layers=-1,\n",
        "    seed=0,\n",
        "    logits_all=False,\n",
        "    verbose=True,          # Display the actual chat format used\n",
        "    chat_format=\"chatml\",  # Directly override the GGUF built-in Unsloth template to avoid outputting <|channel|> tags\n",
        ")\n",
        "if DEBUG_MODE: print(\"→ Model loaded successfully (GPU)\")\n",
        "\n",
        "# ===== Summary 4/6) Token-aware Segmentation (Summary) - Uses ctx_window, map_max_new_tokens, prompt_overhead\n",
        "if DEBUG_MODE: print(\"[Summary 4/6] Generating segments (token-aware; single segment ≤ safety limit) ...\")\n",
        "\n",
        "def count_tokens_text(text: str) -> int:\n",
        "    return len(llm.tokenize(text.encode(\"utf-8\")))\n",
        "\n",
        "SYSTEM_INSTR = (\n",
        "  \"你是一個會議總結機器人。根據使用者提供的逐字稿（可能雜訊、重複、錯字），\"\n",
        "  \"請去除雜訊與重複、嚴守事實、不腦補。遇到不明確資訊以「待補充／未明確」標註。\"\n",
        "  \"輸出為 Markdown（繁體中文），不要輸出任何系統／思考標記。\"\n",
        ")\n",
        "\n",
        "# — Segment Summary Prompt: More concise request, avoid verbosity and system language - Uses 'topic_hint'\n",
        "MAP_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是逐字稿片段（非完整全文）：\n",
        "{chunk}\n",
        "\n",
        "請就此片段輸出「條列式重點摘要」（500–900 字，繁體中文），注意：\n",
        "- 只寫最終內容，不要寫解題想法、不要出現任何系統提示或中英括號標記。\n",
        "- 聚焦可驗證事實（時間、人物、任務、結論、未決事項、行動）。\n",
        "- 結構：可用小標題＋項目符號，語句務必短、準確、無贅詞。\n",
        "\"\"\")\n",
        "\n",
        "# — Summary Prompt: Maintain your three-section output structure - Uses 'topic_hint'\n",
        "REDUCE_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是所有片段的重點摘要彙整（仍可能有重疊）：\n",
        "{maps}\n",
        "\n",
        "請整合為一份會議筆記（Markdown，繁體）：\n",
        "1) **整體提要**（3–6 句，避免冗言）\n",
        "2) **章節要點（含時間脈絡）**：條列呈現，每點一行，可附粗略時間\n",
        "3) **可執行重點**：具體待辦（每條以動詞開頭）\n",
        "請只輸出最終筆記，不要出現系統或思考標記，不要加入未出現的新資訊。\n",
        "\"\"\")\n",
        "\n",
        "# Single segment token budget (reserve space for prompt and generation)\n",
        "prompt_overhead = 700\n",
        "chunk_target    = max(1024, min(3072, ctx_window - prompt_overhead - map_max_new_tokens))\n",
        "\n",
        "chunks: List[Tuple[float,float,str]] = []\n",
        "buf, t0, t1, cur = [], None, None, 0\n",
        "for (s, e, txt) in segments:\n",
        "    t = count_tokens_text(txt)\n",
        "    if not buf:\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "        continue\n",
        "    if cur + t <= chunk_target:\n",
        "        buf.append(txt); t1 = e; cur += t\n",
        "    else:\n",
        "        chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "if buf:\n",
        "    chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ Generated {len(chunks)} segments (target ~{chunk_target} tokens per segment)\")\n",
        "\n",
        "# ===== Common: Streaming Tools (No regex cleaning; use correct stop sequence) - Uses temperature, top_p, repeat_penalty, map_max_new_tokens, reduce_max_new_tokens\n",
        "def llm_stream(messages, max_tokens):\n",
        "    # ChatML messages end with <|im_end|>; use stop to cut off, preventing the closing tag from being written to the file\n",
        "    gen = llm.create_chat_completion(\n",
        "        messages=messages,\n",
        "        temperature=float(temperature),\n",
        "        top_p=float(top_p),\n",
        "        repeat_penalty=float(repeat_penalty),\n",
        "        max_tokens=int(max_tokens),\n",
        "        stream=True,\n",
        "        stop=[\"<|im_end|>\"],  # Key: Prevent outputting the ending template\n",
        "    )\n",
        "    for ev in gen:\n",
        "        # Compatible with different fields\n",
        "        piece = \"\"\n",
        "        try:\n",
        "            piece = ev[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "        except Exception:\n",
        "            piece = ev[\"choices\"][0].get(\"text\", \"\")\n",
        "        if piece:\n",
        "            yield piece\n",
        "\n",
        "# ===== Summary 5/6) Segment Summary (map) - Uses map_max_new_tokens, ctx_window, prompt_overhead, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 5/6] Segment summarization (map) ...\")\n",
        "live = display(Markdown(\"\"), display_id=True)\n",
        "maps: List[str] = []\n",
        "\n",
        "for i, (s, e, body) in enumerate(chunks, 1):\n",
        "    pct = i / max(len(chunks),1) * 100\n",
        "    sys.stdout.write(f\"  - 處理分段 {i}/{len(chunks)}（~{pct:.1f}%）\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Shrink to safe budget before sending (prevent prompt+segment from exceeding window and causing model to terminate early)\n",
        "    budget_tokens = max(512, ctx_window - map_max_new_tokens - prompt_overhead)\n",
        "    def shrink_to_budget(text: str, budget_tokens: int) -> str:\n",
        "        cur = text\n",
        "        for _ in range(6):\n",
        "            if count_tokens_text(cur) <= budget_tokens:\n",
        "                return cur\n",
        "            keep = max(800, int(len(cur) * 0.85))\n",
        "            cur = cur[:keep]\n",
        "        return cur\n",
        "    body2 = shrink_to_budget(body, budget_tokens)\n",
        "\n",
        "    user_txt = MAP_USER_TMPL.format(topic=(topic_hint or \"（無）\"), chunk=body2)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n",
        "        {\"role\": \"user\",   \"content\": user_txt},\n",
        "    ]\n",
        "\n",
        "    part_buf = [] # Reset part_buf for each segment\n",
        "    for token in llm_stream(messages, map_max_new_tokens):\n",
        "        part_buf.append(token)\n",
        "        # Update live display and terminal character count periodically\n",
        "        if len(part_buf) % 24 == 0:\n",
        "            cur_txt = \"\".join(part_buf)\n",
        "            live.update(Markdown(cur_txt))\n",
        "            sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "    cur_txt = \"\".join(part_buf)\n",
        "    live.update(Markdown(cur_txt))\n",
        "    sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Include the model's final output directly, no regex cleaning\n",
        "    maps.append(cur_txt.strip())\n",
        "\n",
        "if DEBUG_MODE: print(\"→ Segment summarization complete\")\n",
        "\n",
        "# ===== Summary 6/6) Consolidate (reduce) & Only write .md (Summary) - Uses summary_output_dir, summary_srt_path_abs, reduce_max_new_tokens, ctx_window, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 6/6] Consolidating summary (reduce) ...\")\n",
        "maps_md = \"\\n\\n---\\n\\n\".join(f\"### 片段 {i+1} 要點\\n\\n{m}\" for i, m in enumerate(maps))\n",
        "\n",
        "# If combined text exceeds window, truncate proportionally first (without changing text within segments to avoid breaking meaning)\n",
        "def fit_reduce_payload(md_text: str, max_ctx_tokens: int) -> str:\n",
        "    for _ in range(8):\n",
        "        need = count_tokens_text(md_text)\n",
        "        if need + reduce_max_new_tokens + 400 <= max_ctx_tokens:\n",
        "            return md_text\n",
        "        md_text = md_text[: int(len(md_text) * 0.9)]\n",
        "    return md_text\n",
        "\n",
        "md_cur = fit_reduce_payload(maps_md, ctx_window)\n",
        "\n",
        "user_txt = REDUCE_USER_TMPL.format(topic=(topic_hint or \"（無）\"), maps=md_cur)\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_INSTR},\n",
        "            {\"role\":\"user\",\"content\":user_txt}]\n",
        "\n",
        "live2 = display(Markdown(\"\"), display_id=True)\n",
        "final_buf = []\n",
        "for token in llm_stream(messages, reduce_max_new_tokens):\n",
        "    final_buf.append(token)\n",
        "    if len(final_buf) % 24 == 0:\n",
        "        live2.update(Markdown(\"\".join(final_buf)))\n",
        "        sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "live2.update(Markdown(\"\".join(final_buf)))\n",
        "sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "\n",
        "final_text = \"\".join(final_buf).strip()\n",
        "\n",
        "out_dir = Path(summary_output_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_md = out_dir / f\"{Path(summary_srt_path_abs).stem}_summary.md\" # Use the stem from the actual SRT file used for summarization\n",
        "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_text)\n",
        "\n",
        "print(f\"→ 完成 ✅  {out_md}\")\n",
        "try:\n",
        "    del llm\n",
        "except Exception:\n",
        "    pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"（顯存已釋放，如需重跑可直接再次執行）\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "→ 當前工作目錄：/content/gdrive/MyDrive\n",
            "→ 來源檔：/content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\n",
            "→ 輸出資料夾：/content/gdrive/MyDrive/whisper\n",
            "[  1%] 00:00:00,000 → 00:00:29,980  Teksting av Nicolai Winther\n",
            "[  1%] 00:00:20,000 → 00:00:49,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:00:40,000 → 00:01:09,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:00,000 → 00:01:29,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:20,000 → 00:01:49,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:01:40,000 → 00:02:09,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:02:00,000 → 00:02:29,980  Teksting av Nicolai Winther\n",
            "[  4%] 00:02:20,000 → 00:02:49,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:00,000 → 00:03:29,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:20,000 → 00:03:49,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:03:40,000 → 00:04:09,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:04:00,000 → 00:04:18,900  聽得到聲音嗎?\n",
            "[  6%] 00:04:20,000 → 00:04:24,000  Ok,ok\n",
            "[  6%] 00:04:24,000 → 00:04:28,000  Ok,那我想先確定\n",
            "[  6%] 00:04:28,000 → 00:04:32,000  威神你那邊在看完教證手冊之後\n",
            "[  6%] 00:04:32,000 → 00:04:36,000  你目前有任何的想法嗎?\n",
            "[  6%] 00:04:36,000 → 00:04:40,000  我覺得因為那時候是說\n",
            "[  6%] 00:04:40,000 → 00:04:45,240  八月底先寫完那個內容的部分嘛\n",
            "[  6%] 00:04:45,240 → 00:04:48,440  但是我覺得看完之後應該要大概\n",
            "[  6%] 00:04:48,440 → 00:04:51,180  我覺得八月底前應該沒辦法寫完\n",
            "[  7%] 00:04:51,180 → 00:04:54,040  那你覺得你什麼時候可以完成得了\n",
            "[  7%] 00:04:54,040 → 00:04:56,480  十月左右嗎\n",
            "[  7%] 00:04:56,480 → 00:04:58,400  你是說單子內容嗎\n",
            "[  7%] 00:05:00,000 → 00:05:06,000  嗯,對。\n",
            "[  7%] 00:05:06,000 → 00:05:09,500  呃,十月底。\n",
            "[  7%] 00:05:09,500 → 00:05:11,580  十月底。\n",
            "[  7%] 00:05:11,580 → 00:05:12,160  好。\n",
            "[  7%] 00:05:12,160 → 00:05:14,780  前,看看吧。\n",
            "[  7%] 00:05:14,780 → 00:05:20,040  因為我也還沒有開始,就是,照他的那個方向去改,所以我...\n",
            "[  7%] 00:05:20,000 → 00:05:23,000  I don't know how long it will take.\n",
            "[  7%] 00:05:23,000 → 00:05:25,000  Ok, ok, I got it.\n",
            "[  7%] 00:05:25,000 → 00:05:27,000  Ok, then I would like to...\n",
            "[  7%] 00:05:27,000 → 00:05:29,000  If you can speak now,\n",
            "[  7%] 00:05:29,000 → 00:05:32,000  you can briefly introduce to Wei-Chen\n",
            "[  7%] 00:05:32,000 → 00:05:35,000  the anti-epidemic prevention method.\n",
            "[  8%] 00:05:40,000 → 00:06:00,000  你要先跟他講一下,就是...\n",
            "[  8%] 00:06:00,000 → 00:06:05,000  我覺得這是一個知識存在的方面嘛 就是框架然後核心特色這樣子\n",
            "[  8%] 00:06:05,000 → 00:06:09,000  好,我發現我只要轉手機跟電腦\n",
            "[  8%] 00:06:09,000 → 00:06:13,000  你們剛剛是問到說就是未成什麼時候可以完成這本書\n",
            "[  8%] 00:06:13,000 → 00:06:18,000  然後是說是十月,十月但是不確定是什麼時候是嗎?\n",
            "[  8%] 00:06:18,000 → 00:06:20,000  Yes\n",
            "[  9%] 00:06:20,000 → 00:06:35,000  我做出這個交戰手冊主要是想說我不知道能不能去陪軍做一些類似跟AI相關的工具\n",
            "[  9%] 00:06:35,000 → 00:06:40,000  因為我的經驗會是如果有了一個標準的準則\n",
            "[  9%] 00:06:40,000 → 00:06:43,600  算是這種抽象的邏輯的話\n",
            "[  9%] 00:06:43,600 → 00:06:48,800  就能夠讓實際在寫獎益的時候\n",
            "[  9%] 00:06:48,800 → 00:06:53,200  可能就可以搭配給AI去自動生成一些類似的東西\n",
            "[  9%] 00:06:53,200 → 00:06:57,600  或是甚至可以去檢驗說這份獎益有沒有包含到\n",
            "[  9%] 00:06:57,600 → 00:07:00,000  這個交戰手冊裡面鎖定\n",
            "[  9%] 00:07:00,000 → 00:07:08,000  我覺得這可能也會讓微塵在寫講義的時候再更快一點。\n",
            "[ 10%] 00:07:08,000 → 00:07:15,000  然後具體來說這裡面的這些校章手冊裡面的所有東西,\n",
            "[ 10%] 00:07:15,000 → 00:07:20,000  玉茜你剛是問我說\n",
            "[ 10%] 00:07:20,000 → 00:07:21,200  我要講什麼\n",
            "[ 10%] 00:07:21,200 → 00:07:24,040  就你可能要稍微跟他說明一下\n",
            "[ 10%] 00:07:24,040 → 00:07:25,240  然後介紹一下\n",
            "[ 10%] 00:07:27,240 → 00:07:28,040  很多耶\n",
            "[ 10%] 00:07:32,500 → 00:07:35,240  維承目前我有幫你按照那個\n",
            "[ 10%] 00:07:35,240 → 00:07:37,400  我覺得的優先順序去排\n",
            "[ 10%] 00:07:37,400 → 00:07:39,600  就是第一個姿勢框架的話\n",
            "[ 10%] 00:07:39,600 → 00:07:40,400  就是我覺得\n",
            "[ 10%] 00:07:40,000 → 00:07:44,000  我覺得這份獎益會最迫切需要的東西\n",
            "[ 10%] 00:07:44,000 → 00:07:47,000  然後所謂的知識框架你可以把它想像成\n",
            "[ 10%] 00:07:47,000 → 00:07:51,000  或寫一個法律系的那個解題的東西\n",
            "[ 11%] 00:07:51,000 → 00:07:55,000  就是我好像記得你有學過民法\n",
            "[ 11%] 00:07:55,000 → 00:07:58,000  還是其他的法律相關的東西\n",
            "[ 11%] 00:07:58,000 → 00:08:00,000  但你也大概可以知道\n",
            "[ 11%] 00:08:00,000 → 00:08:14,980  當你面對一個複雜的案件的時候,你一定要有一套固定的思考方式跟答題方式,你才能夠快速進入到那個理解的框架裡面,然後按照這些步驟去解那個題。\n",
            "[ 11%] 00:08:14,980 → 00:08:20,000  那即便這個步驟可能有一些是形同虛設的,有一些可能在...\n",
            "[ 11%] 00:08:20,000 → 00:08:23,340  在某些題目當中其實根本就是非必要的\n",
            "[ 11%] 00:08:23,340 → 00:08:26,880  可是一旦你有了一個固定的解題框\n",
            "[ 11%] 00:08:26,880 → 00:08:28,000  這樣的思考流程\n",
            "[ 11%] 00:08:28,000 → 00:08:30,440  你在解題的時候就會更有確定感\n",
            "[ 11%] 00:08:30,440 → 00:08:34,580  然後一方面是讓學生能夠感覺自己學到\n",
            "[ 11%] 00:08:34,580 → 00:08:37,660  很具體的感受到自己有學到一套策略\n",
            "[ 12%] 00:08:37,660 → 00:08:40,000  另外一方面也是我們在行銷的\n",
            "[ 12%] 00:08:40,000 → 00:08:46,000  也會更能夠拿這一個策略,這套方法論去推廣出去。\n",
            "[ 12%] 00:08:46,000 → 00:08:54,000  所以我自己是有幫你舉的一個物理上面的例子是先聚焦再發散。\n",
            "[ 12%] 00:08:54,000 → 00:09:00,000  然後我就直接幫你寫了先聚焦再發散這個東西的\n",
            "[ 12%] 00:09:00,000 → 00:09:03,000  This is...wait a minute, the jade line is sliding down\n",
            "[ 12%] 00:09:03,000 → 00:09:06,000  Sliding down, sliding down, sliding down\n",
            "[ 12%] 00:09:06,000 → 00:09:08,000  Hey, this is the correct one\n",
            "[ 12%] 00:09:08,000 → 00:09:11,000  I forgot to delete the top\n",
            "[ 12%] 00:09:11,000 → 00:09:15,000  And then there is a physical demonstration down there\n",
            "[ 12%] 00:09:15,000 → 00:09:20,000  I will want to see that the microcosm may be speaking again\n",
            "[ 13%] 00:09:20,000 → 00:09:28,000  內容的部分先去告訴學生說所謂的先聚焦再發散這個答題策略的核心觀念是什麼\n",
            "[ 13%] 00:09:28,000 → 00:09:34,000  就是什麼是聚焦什麼是發散為什麼聚焦什麼發散然後如何聚焦如何發散\n",
            "[ 13%] 00:09:34,000 → 00:09:40,000  接下來就是透過各種抽象的步驟整理各種抽象的策略\n",
            "[ 13%] 00:09:40,000 → 00:09:46,000  一步一步的去告訴學生說這一個知識框架到底想要傳達的是什麼\n",
            "[ 13%] 00:09:46,000 → 00:09:49,000  然後進到你的題目部分\n",
            "[ 13%] 00:09:49,000 → 00:09:53,000  題目我們等下還會討論說它是要做成就是多少頁數\n",
            "[ 13%] 00:09:53,000 → 00:09:55,000  然後要不要做成電子檔\n",
            "[ 13%] 00:09:55,000 → 00:09:59,000  然後等下育前也會補充說學生對於電子檔的看法這些的\n",
            "[ 14%] 00:10:00,000 → 00:10:12,760  不論如何把題目每一題的解題過程還有每一個詳節都去套用這個不管是三步驟的發賽也好還是先聚焦的發賽\n",
            "[ 14%] 00:10:12,760 → 00:10:19,760  只要固定有一個解題的框架固定的一個算是一個噱頭或是一個包裝\n",
            "[ 14%] 00:10:20,000 → 00:10:22,560  它都可以讓學生更有一個確定感\n",
            "[ 14%] 00:10:22,560 → 00:10:25,760  所以我就會希望這本書最少最少最少最少最少\n",
            "[ 14%] 00:10:25,760 → 00:10:28,000  其他可以慢慢再補上\n",
            "[ 14%] 00:10:28,000 → 00:10:33,000  但是我覺得這個是我會希望可以加進去書\n",
            "[ 14%] 00:10:33,000 → 00:10:34,600  然後再出版會比較好\n",
            "[ 14%] 00:10:34,600 → 00:10:37,000  看我講完了\n",
            "[ 14%] 00:10:40,000 → 00:10:44,000  你目前對這部分有任何的問題嗎?\n",
            "[ 15%] 00:10:49,000 → 00:10:59,000  我要再想就是怎麼具體去把它落實到書的每個章節裡面\n",
            "[ 15%] 00:11:00,000 → 00:11:04,000  OK\n",
            "[ 15%] 00:11:04,000 → 00:11:10,000  我可以問你你自己在打題的時候也會有這樣子的\n",
            "[ 15%] 00:11:10,000 → 00:11:16,000  它會給你一種感覺嗎?就是說物理每個題目好像都有一個感覺\n",
            "[ 15%] 00:11:16,000 → 00:11:20,000  還是你是每個題目有不同的感覺?\n",
            "[ 15%] 00:11:20,000 → 00:11:24,000  好像沒有一個固定的流程\n",
            "[ 15%] 00:11:24,000 → 00:11:31,000  就是覺得可能是\n",
            "[ 15%] 00:11:31,000 → 00:11:33,000  我不會啊\n",
            "[ 15%] 00:11:33,000 → 00:11:35,000  但我覺得他們可能要先\n",
            "[ 15%] 00:11:35,000 → 00:11:37,000  抓到情況再說什麼\n",
            "[ 15%] 00:11:37,000 → 00:11:39,000  但是我就\n",
            "[ 16%] 00:11:40,000 → 00:11:44,000  我覺得我可以抓到,但我覺得他們可能是沒辦法抓到,所以寫不出來。\n",
            "[ 16%] 00:11:46,000 → 00:11:51,000  所以我覺得要先教他們怎麼把題目的點抓出來。\n",
            "[ 16%] 00:11:53,000 → 00:12:00,000  還是我在想會不會你可以跟TradeGVD聊,就你把你看的那些,你可能跟...\n",
            "[ 16%] 00:12:00,000 → 00:12:04,000  跟ChangeGPT聊個十個題目到二十個題目\n",
            "[ 16%] 00:12:04,000 → 00:12:07,000  然後你可能就請他幫你總結一下你這套思路\n",
            "[ 16%] 00:12:07,000 → 00:12:12,000  它背後的核心的步驟\n",
            "[ 16%] 00:12:12,000 → 00:12:15,000  還有你關注的重點\n",
            "[ 16%] 00:12:15,000 → 00:12:18,000  怎麼樣變成一套固定的策略\n",
            "[ 16%] 00:12:18,000 → 00:12:20,000  你可以試試看這個\n",
            "[ 16%] 00:12:20,000 → 00:12:20,500  Ok\n",
            "[ 17%] 00:12:40,000 → 00:12:43,000  你這本書最主要的核心的點是什麼東西 你這本書最主要的核心的點是什麼東西\n",
            "[ 17%] 00:12:47,000 → 00:12:52,000  如果以英文英文的書去舉例的話 就會像是作文書的話\n",
            "[ 17%] 00:12:52,000 → 00:12:58,000  雖然說它有很多很多的內容 但是我們會推出一個最主要的基點 就是它的八條公式\n",
            "[ 17%] 00:12:58,000 → 00:13:00,000  然後這個八條公式也是我們\n",
            "[ 17%] 00:13:00,000 → 00:13:04,500  主要不管是拿在書籍的生存或在社群的行銷上\n",
            "[ 17%] 00:13:04,500 → 00:13:06,700  我們都會拿著八條公式去主打\n",
            "[ 18%] 00:13:06,700 → 00:13:10,580  所以它對於學生的記憶或是這本書的整體\n",
            "[ 18%] 00:13:10,580 → 00:13:14,060  它就會有一個固定的記憶格式\n",
            "[ 18%] 00:13:14,060 → 00:13:16,040  就是大家對於這本書就會是\n",
            "[ 18%] 00:13:16,040 → 00:13:18,900  這個就是那個八條公式就是那個很屌\n",
            "[ 18%] 00:13:18,900 → 00:13:19,980  然後一模獨創的那個\n",
            "[ 18%] 00:13:20,000 → 00:13:24,640  所以也會需要你在幫我寫這本書的時候\n",
            "[ 18%] 00:13:24,640 → 00:13:27,700  也去稍微想一下你這本書的核心特色\n",
            "[ 18%] 00:13:27,700 → 00:13:29,160  最主要的那個點會是什麼\n",
            "[ 18%] 00:13:29,160 → 00:13:30,840  然後是什麼東西是可以對\n",
            "[ 18%] 00:13:30,840 → 00:13:33,760  拿出去打給社群媒體的\n",
            "[ 18%] 00:13:33,760 → 00:13:35,900  這部分有問題嗎\n",
            "[ 18%] 00:13:35,900 → 00:13:37,900  OK\n",
            "[ 18%] 00:13:37,900 → 00:13:39,220  好\n",
            "[ 18%] 00:13:40,000 → 00:13:44,960  好 子明請說\n",
            "[ 18%] 00:13:44,960 → 00:13:48,960  好 我剛剛的那個核心特色\n",
            "[ 18%] 00:13:48,960 → 00:13:53,020  如果我以前在寫物理的內容跟題目的時候\n",
            "[ 18%] 00:13:53,020 → 00:13:54,920  想不到這個特色的話\n",
            "[ 19%] 00:13:54,920 → 00:13:57,340  其實也可以就是照個路\n",
            "[ 19%] 00:13:57,340 → 00:13:59,980  把它變成說是在讀物\n",
            "[ 19%] 00:14:00,000 → 00:14:03,000  你覺得物理這個科目上面的策略\n",
            "[ 19%] 00:14:03,000 → 00:14:05,000  可能就可以想一個什麼循環圖啊\n",
            "[ 19%] 00:14:05,000 → 00:14:09,000  還是什麼正面加強的理論啊什麼的\n",
            "[ 19%] 00:14:09,000 → 00:14:13,000  但就是不一定要是物理的那些章節\n",
            "[ 19%] 00:14:13,000 → 00:14:16,000  你也可以是講你的讀書方法或筆記方法\n",
            "[ 19%] 00:14:16,000 → 00:14:18,000  它也可以變成是一個核心特色\n",
            "[ 19%] 00:14:20,000 → 00:14:23,000  我再想想。\n",
            "[ 19%] 00:14:25,000 → 00:14:35,000  那我也想順便確認一下,你有預計什麼時候可能會確定這本書的整個核心特色嗎?\n",
            "[ 19%] 00:14:35,000 → 00:14:40,000  會需要等你內容寫完嗎?還是你在這中間的過程中你可以先...\n",
            "[ 20%] 00:14:40,000 → 00:14:41,920  跟我確定\n",
            "[ 20%] 00:14:41,920 → 00:14:47,960  應該可以比內容早確定\n",
            "[ 20%] 00:14:47,960 → 00:14:49,680  但是我現在還沒有\n",
            "[ 20%] 00:14:49,680 → 00:14:52,060  就是想出來它是什麼\n",
            "[ 20%] 00:14:52,060 → 00:14:54,940  OK好沒有問題\n",
            "[ 20%] 00:14:54,940 → 00:14:58,180  然後再來下一個的話\n",
            "[ 20%] 00:14:58,180 → 00:14:59,980  會是學習方式跟記憶策略\n",
            "[ 20%] 00:15:00,000 → 00:15:08,000  因為我知道你有先看過整個的內容,所以我想確認你對於這部分有任何問題嗎?\n",
            "[ 20%] 00:15:08,000 → 00:15:17,000  或是有特別想詢問的點嗎?如果沒有的話我們就加快進度,就不用這樣一個一個特別的去講解。\n",
            "[ 21%] 00:15:20,000 → 00:15:27,000  因為就是這邊看起來比較想要說就是要理解\n",
            "[ 21%] 00:15:27,000 → 00:15:35,000  但是我不確定就是他們要理解全盤理解的話會耗費的成本要多少\n",
            "[ 21%] 00:15:35,000 → 00:15:40,000  還是有些人是不是只是想要把它把固定的流程背起來\n",
            "[ 21%] 00:15:40,000 → 00:15:42,800  然後就可以去解題\n",
            "[ 21%] 00:15:42,800 → 00:15:46,200  所以我要著重在\n",
            "[ 21%] 00:15:46,200 → 00:15:48,000  就是不用全盤理解\n",
            "[ 21%] 00:15:48,000 → 00:15:49,200  但是比較好解題\n",
            "[ 21%] 00:15:49,200 → 00:15:51,600  還是希望他們比較好理解\n",
            "[ 21%] 00:15:51,600 → 00:15:56,100  然後就是底子很穩這樣\n",
            "[ 21%] 00:15:56,100 → 00:15:58,400  方向應該在那邊\n",
            "[ 21%] 00:15:58,400 → 00:16:00,000  我覺得會比較看\n",
            "[ 21%] 00:16:00,000 → 00:16:04,200  你這本書的定位點在哪裡?\n",
            "[ 21%] 00:16:04,200 → 00:16:09,800  子民剛說有要講話,我有看到你那個框框。\n",
            "[ 22%] 00:16:09,800 → 00:16:14,000  好像上次跟維城討論的時候你是說,\n",
            "[ 22%] 00:16:14,000 → 00:16:20,000  你希望事實上不知道怎麼開始讀物理的人也可以找到一個方向。\n",
            "[ 22%] 00:16:20,000 → 00:16:25,440  所以你可能打的比較算是中間的族群,是嗎?\n",
            "[ 22%] 00:16:25,440 → 00:16:27,240  算是。\n",
            "[ 22%] 00:16:27,240 → 00:16:28,240  喔。\n",
            "[ 22%] 00:16:34,900 → 00:16:40,000  我會去做這個學習策略的這個地方其實是想說你...\n",
            "[ 22%] 00:16:40,000 → 00:16:48,220  你如果在傳達你的想法跟知識的時候,能夠不要做任何的刪減,\n",
            "[ 23%] 00:16:49,040 → 00:16:58,500  而是你就把最難的東西端出來給學生,可是呢,你還是可以面對初級跟總級的學生,\n",
            "[ 23%] 00:16:58,500 → 00:17:00,500  但是你的...\n",
            "[ 23%] 00:17:00,000 → 00:17:20,120  實施卻是最難的,那這中間的那個gap,中間的那個就是轟溝,你就要透過這些學習方式跟記憶策略的引導,就是如果你的觀念越難,你中間就要解釋越多這樣子的學習策略,然後讓這些重等到初級的學生,\n",
            "[ 23%] 00:17:20,000 → 00:17:22,000  學生也能夠學起來\n",
            "[ 23%] 00:17:22,000 → 00:17:26,000  我當初設計就有這樣的想法\n",
            "[ 23%] 00:17:26,000 → 00:17:36,000  所以我就先把全部東西都最難的部分也寫出來\n",
            "[ 23%] 00:17:36,000 → 00:17:40,000  然後我想往後面再做一個\n",
            "[ 24%] 00:17:40,000 → 00:17:58,260  比較重點的整理,這樣,就是如果你對前面的深入學習沒有興趣的話,那你就直接看重點就好了,這樣應該比較好,就是兩邊都照顧到,也可以,又或者是說你其實也可以,\n",
            "[ 24%] 00:18:00,000 → 00:18:01,840  這點我可能還是會存疑啦\n",
            "[ 24%] 00:18:01,840 → 00:18:03,760  我其實也沒有很確定\n",
            "[ 24%] 00:18:03,760 → 00:18:07,900  就是因為我自己的作文書也是寫到最難\n",
            "[ 24%] 00:18:07,900 → 00:18:10,800  確實也是有學生會覺得太難\n",
            "[ 24%] 00:18:10,800 → 00:18:14,840  但我會傾向是說如果你能夠用這些\n",
            "[ 24%] 00:18:14,840 → 00:18:17,460  就是我有給你一個檔案\n",
            "[ 24%] 00:18:17,460 → 00:18:20,000  就是在這個頁面裡面還有一個連接\n",
            "[ 24%] 00:18:20,000 → 00:18:23,000  我有一個可以出去的檔案叫核心學習策略\n",
            "[ 24%] 00:18:23,000 → 00:18:25,000  你有看過這個嗎?一個\n",
            "[ 25%] 00:18:25,000 → 00:18:28,000  對對對對現在有打開了這個\n",
            "[ 25%] 00:18:28,000 → 00:18:33,000  就是你就可以把一些這裡面的讀書策略跟技巧\n",
            "[ 25%] 00:18:37,000 → 00:18:39,000  這個檔案我還沒看過\n",
            "[ 25%] 00:18:40,000 → 00:18:43,000  你可以先把它看一下。\n",
            "[ 25%] 00:18:43,000 → 00:18:54,000  我自己教學的經驗是讓我發現說這些策略它其實不是只用在英文。\n",
            "[ 25%] 00:18:54,000 → 00:18:59,000  我昨天也是用這個東西去跟學生講數學什麼學。\n",
            "[ 25%] 00:19:00,000 → 00:19:07,000  我想說這東西其實可以一定程度幫助學生理解一些太複雜或太困難的觀念。\n",
            "[ 26%] 00:19:07,000 → 00:19:16,000  然後我就會覺得你跟他解釋越多這些學習策略,他們可能就會越能夠理解你想要傳達的物理專業知識。\n",
            "[ 26%] 00:19:16,000 → 00:19:20,000  所以就是取決於你想要寫多難的東西,然後就加多少。\n",
            "[ 26%] 00:19:20,000 → 00:19:25,000  好,講完嘅。\n",
            "[ 26%] 00:19:25,000 → 00:19:29,000  威神那邊有問題嗎?\n",
            "[ 26%] 00:19:29,000 → 00:19:31,000  暫時沒有。\n",
            "[ 26%] 00:19:31,000 → 00:19:35,000  到時候再麻煩你會後花一些時間幫我看過,\n",
            "[ 26%] 00:19:35,000 → 00:19:39,000  然後如果有不懂的地方可以再隨時跟我們講。\n",
            "[ 26%] 00:19:39,000 → 00:19:40,000  好。\n",
            "[ 26%] 00:19:40,000 → 00:19:45,100  再嚟嘅話就會系梳集咗一個大嘅架構,\n",
            "[ 26%] 00:19:45,100 → 00:19:51,880  佢就跟其實就跟你現在嗰個章節都系很像,\n",
            "[ 26%] 00:19:52,160 → 00:19:55,420  但就系我哋嘅章節架構可能要再清楚明確一點,\n",
            "[ 27%] 00:19:57,760 → 00:19:59,960  然後像呢些可能\n",
            "[ 27%] 00:20:00,000 → 00:20:07,000  你可以先幫我列完,然後如果你需要一些圖示的話,這些我們都可以直接再幫你做。\n",
            "[ 27%] 00:20:11,000 → 00:20:20,000  所以大致上那個架構的話就會是講,就是可能這本書的蓋欄,然後跟這本書的使用說明,然後第一個的大張點。\n",
            "[ 27%] 00:20:20,000 → 00:20:39,000  第二個大章節,然後可能你大章節完之後你會有一個小的,你會先有一個小的總結,然後你的小章節一樣會有一個小的總結,然後才會是這個小章節裡面的氣象,然後最後你還是需要再幫他附一個總結,這樣會是一個比較完整的架構,然後也比較能幫助學生達到一個比較好的學習方式。\n",
            "[ 27%] 00:20:40,000 → 00:20:42,000  所以書籍加關可以參考這邊\n",
            "[ 28%] 00:20:42,000 → 00:20:44,000  好 子明起說\n",
            "[ 28%] 00:20:44,000 → 00:20:46,000  我喔 我又有話要說了\n",
            "[ 28%] 00:20:46,000 → 00:20:48,000  就是你除了\n",
            "[ 28%] 00:20:48,000 → 00:20:50,000  我要說什麼\n",
            "[ 28%] 00:20:50,000 → 00:20:52,000  你的大架構裡面\n",
            "[ 28%] 00:20:52,000 → 00:20:54,000  其實可以多加入一些些\n",
            "[ 28%] 00:20:54,000 → 00:20:56,000  就是比較感性一點的東西\n",
            "[ 28%] 00:20:56,000 → 00:20:58,000  就是你在書籍的可能\n",
            "[ 28%] 00:20:58,000 → 00:21:00,000  在那個章節的開頭\n",
            "[ 28%] 00:21:00,000 → 00:21:03,400  會需要先有一個簡單的總結或是一個概覽\n",
            "[ 28%] 00:21:03,400 → 00:21:05,100  然後讓學生可以進入這個章節\n",
            "[ 28%] 00:21:05,100 → 00:21:07,560  那章節的最後結束也會有一個總結\n",
            "[ 28%] 00:21:07,560 → 00:21:10,480  只是你的那個開始跟那個總結\n",
            "[ 28%] 00:21:10,480 → 00:21:13,220  就是不一定要是很理性\n",
            "[ 28%] 00:21:13,220 → 00:21:18,420  然後很踏實的那種知識上面的整理\n",
            "[ 28%] 00:21:18,420 → 00:21:19,980  你也可以在這邊加一些\n",
            "[ 28%] 00:21:20,000 → 00:21:22,500  讓學生可以心情好一點的東西\n",
            "[ 28%] 00:21:22,500 → 00:21:24,500  譬如說剛開始就是\n",
            "[ 28%] 00:21:24,500 → 00:21:26,500  在章節開始的時候就說\n",
            "[ 29%] 00:21:26,500 → 00:21:29,500  這張適合有哪一些問題的學生\n",
            "[ 29%] 00:21:29,500 → 00:21:31,500  然後就列很多學生常見的問題\n",
            "[ 29%] 00:21:31,500 → 00:21:34,500  那學生可能就會自己跳進去對號入座\n",
            "[ 29%] 00:21:34,500 → 00:21:36,500  就領了一個身份標籤之後\n",
            "[ 29%] 00:21:36,500 → 00:21:38,000  就開始讀這個章節的時候\n",
            "[ 29%] 00:21:38,000 → 00:21:40,000  就會覺得自己的\n",
            "[ 29%] 00:21:40,000 → 00:21:42,000  問題就可以被妥善的解決\n",
            "[ 29%] 00:21:42,000 → 00:21:44,000  然後你到總結的地方再跟他說\n",
            "[ 29%] 00:21:44,000 → 00:21:48,000  恭喜你就是已經解決了這樣子的問題\n",
            "[ 29%] 00:21:48,000 → 00:21:50,000  你一定會越來越好啊什麼的\n",
            "[ 29%] 00:21:50,000 → 00:21:52,000  就可以給一些情緒上面的\n",
            "[ 29%] 00:21:52,000 → 00:21:53,000  給一些情緒價值\n",
            "[ 29%] 00:21:53,000 → 00:21:55,000  學生讀起來會比較\n",
            "[ 29%] 00:21:55,000 → 00:21:57,000  算是堅持得下去吧\n",
            "[ 29%] 00:21:57,000 → 00:22:00,000  如果你會把內容加得深入一點點的話\n",
            "[ 29%] 00:22:00,000 → 00:22:02,000  還有腳外的\n",
            "[ 29%] 00:22:02,000 → 00:22:04,000  咚\n",
            "[ 29%] 00:22:04,000 → 00:22:06,000  好\n",
            "[ 29%] 00:22:06,000 → 00:22:08,000  再來的話就是說幾個小架構\n",
            "[ 29%] 00:22:08,000 → 00:22:10,000  那個小架構就是偏\n",
            "[ 29%] 00:22:10,000 → 00:22:12,000  理論跟案例\n",
            "[ 30%] 00:22:12,000 → 00:22:14,000  這個的話前面其實也有提到\n",
            "[ 30%] 00:22:14,000 → 00:22:16,000  然後這個你可以\n",
            "[ 30%] 00:22:16,000 → 00:22:18,000  如果你沒有很懂的話可以再問我\n",
            "[ 30%] 00:22:18,000 → 00:22:20,000  然後\n",
            "[ 30%] 00:22:20,000 → 00:22:25,000  理論的主要呈現原則就是你要以系統性的東西去取代流水帳\n",
            "[ 30%] 00:22:25,000 → 00:22:30,000  就是系統性就比較像是可能第一步第二步然後原則一原則二原則三\n",
            "[ 30%] 00:22:30,000 → 00:22:34,000  然後或者是你可以用一個表格呈現可以用流程圖可以用矩陣都可以\n",
            "[ 30%] 00:22:34,000 → 00:22:40,000  然後這種方式會比起你只是跟他講說我今天去買了蘋果\n",
            "[ 30%] 00:22:40,000 → 00:22:44,500  如果怎麼樣怎麼樣,這種流水的方式好很多很多很多。\n",
            "[ 30%] 00:22:44,500 → 00:22:46,500  然後再來是案例的呈現原則。\n",
            "[ 30%] 00:22:46,500 → 00:22:50,800  你要盡量讓,就是用故事的方式去讓理論去落地。\n",
            "[ 30%] 00:22:50,800 → 00:22:56,000  就是你可以去多講幾個例子,然後但是你不能只是單純的講例子。\n",
            "[ 31%] 00:22:56,000 → 00:23:00,000  你要去刻意的選擇可以提出這些理論的關鍵點的案例。\n",
            "[ 31%] 00:23:00,000 → 00:23:03,820  然後讓案例的順序跟理論的分點是一致的\n",
            "[ 31%] 00:23:03,820 → 00:23:05,620  就是學生他可以互相對照\n",
            "[ 31%] 00:23:05,620 → 00:23:07,800  他不會覺得我現在看了這個理論\n",
            "[ 31%] 00:23:07,800 → 00:23:09,500  但是我找不到對應的案例\n",
            "[ 31%] 00:23:09,500 → 00:23:10,720  或者是我現在看了這個案例\n",
            "[ 31%] 00:23:10,720 → 00:23:12,820  但我也不知道你在講哪一個理論這樣子\n",
            "[ 31%] 00:23:12,820 → 00:23:15,740  目前這邊是OK的\n",
            "[ 31%] 00:23:15,740 → 00:23:16,920  OK\n",
            "[ 31%] 00:23:16,920 → 00:23:17,980  好\n",
            "[ 31%] 00:23:17,980 → 00:23:20,020  然後因為我們收集的內容\n",
            "[ 31%] 00:23:20,000 → 00:23:22,260  我们会以黑白色为主\n",
            "[ 31%] 00:23:22,260 → 00:23:25,540  所以如果你今天在帮我写里面的内容\n",
            "[ 31%] 00:23:25,540 → 00:23:28,920  然后有些比较想要让他们强调的重点\n",
            "[ 31%] 00:23:28,920 → 00:23:31,640  你可能需要帮我使用色块或是粗体\n",
            "[ 31%] 00:23:31,640 → 00:23:34,860  或是一些其他的框框标记都可以\n",
            "[ 31%] 00:23:34,860 → 00:23:37,840  但是你需要有一个让他们可以很好get到说\n",
            "[ 31%] 00:23:37,840 → 00:23:39,980  这里可能是相对于其他内容性\n",
            "[ 31%] 00:23:40,000 → 00:23:42,000  較為重要的地方\n",
            "[ 32%] 00:23:44,000 → 00:23:45,000  好\n",
            "[ 32%] 00:23:45,000 → 00:23:48,000  然後下面你應該也都有看過\n",
            "[ 32%] 00:23:48,000 → 00:23:50,000  那你有什麼地方有不了解\n",
            "[ 32%] 00:23:50,000 → 00:23:52,000  然後有想問的嗎\n",
            "[ 32%] 00:23:56,000 → 00:23:58,000  看起來沒有\n",
            "[ 32%] 00:23:58,000 → 00:23:59,000  好\n",
            "[ 32%] 00:23:59,000 → 00:24:00,000  線上話\n",
            "[ 32%] 00:24:00,000 → 00:24:01,200  與配套工具\n",
            "[ 32%] 00:24:01,200 → 00:24:05,040  啊沒事\n",
            "[ 32%] 00:24:05,040 → 00:24:05,720  在下面\n",
            "[ 32%] 00:24:05,720 → 00:24:08,000  對不起我插嘴了\n",
            "[ 32%] 00:24:08,000 → 00:24:08,420  對不起\n",
            "[ 32%] 00:24:08,420 → 00:24:10,940  好然後順便跟維成提\n",
            "[ 32%] 00:24:10,940 → 00:24:13,260  就是因為我知道你有做那個\n",
            "[ 32%] 00:24:13,260 → 00:24:14,180  就是\n",
            "[ 32%] 00:24:14,180 → 00:24:16,440  立貼題目\n",
            "[ 32%] 00:24:16,440 → 00:24:16,840  然後\n",
            "[ 32%] 00:24:16,840 → 00:24:18,660  就是他如果\n",
            "[ 32%] 00:24:18,660 → 00:24:20,000  如果你今天還是要把他寫在\n",
            "[ 32%] 00:24:20,000 → 00:24:27,180  你在書裡面或是你今天在書本裡面有提到,然後你不知道怎麼拍板的話,就是知名右相有一個是比較好的方式。\n",
            "[ 33%] 00:24:27,180 → 00:24:40,000  如果你今天想要讓學生,他是可以先看完題目,然後先有一個答案,然後再繼續看詳解的話,你可以變成說第一頁他有三題的題目,然後你翻頁之後是那三題的講解。\n",
            "[ 33%] 00:24:40,000 → 00:25:00,000  然後就稍微對一下拍板,才不會讓他們馬上就可以找到答案,然後也沒有,就如果直接讓他們看到答案,他們就會不去思考,所以你可以先讓他們思考完之後,然後再去翻譯了,去對照那個答案,然後去看你的想解步都是什麼,然後這樣子,一方面是它有一個比較好的拍板格式,另外一方面是可以主動去引導他們去思考。\n",
            "[ 33%] 00:25:00,000 → 00:25:02,940  而不是直接仰賴你的解答\n",
            "[ 33%] 00:25:02,940 → 00:25:04,940  OK\n",
            "[ 33%] 00:25:04,940 → 00:25:05,500  OK\n",
            "[ 33%] 00:25:05,500 → 00:25:09,540  但是上次不是說那個解答要用呈現上嗎\n",
            "[ 33%] 00:25:09,540 → 00:25:11,680  不然頁數就已經爆了\n",
            "[ 33%] 00:25:11,680 → 00:25:12,540  對\n",
            "[ 34%] 00:25:12,540 → 00:25:15,040  就只是如果你今天有在內容裡面\n",
            "[ 34%] 00:25:15,040 → 00:25:16,620  有稍微稍稍的提到\n",
            "[ 34%] 00:25:16,620 → 00:25:19,260  就是你可以有一兩題或是三四題的話\n",
            "[ 34%] 00:25:19,260 → 00:25:19,960  是可以用這樣的\n",
            "[ 34%] 00:25:20,000 → 00:25:39,940  然後關於題目答案線上話這個點,我們需要,好我先跟你抓出來討論這個點好了,因為我們有收到學生的回饋是說他們的父母其實沒有很希望讓他們嘗試這樣用平板手機或是電腦,所以關於\n",
            "[ 35%] 00:25:40,000 → 00:25:59,960  解答線上話這一點,我們可能需要再思考一下,因為不是所有的學生都可以達到很好的學習效果,也不是所有的學生都可以這樣做自由,所以我們需要想一個解決方法,讓他們不是只能完全的仰賴這個AI工具,而是AI工具會變成是輔助他們的學習效果,而不是讓他們去\n",
            "[ 35%] 00:26:00,000 → 00:26:02,000  從AI工具中\n",
            "[ 35%] 00:26:02,000 → 00:26:04,000  就他們不能只是用AI工具找到答案\n",
            "[ 35%] 00:26:04,000 → 00:26:06,000  他們應該要從其他地方也可以找到答案\n",
            "[ 35%] 00:26:06,000 → 00:26:08,000  AI工具只是一個輔助\n",
            "[ 35%] 00:26:08,000 → 00:26:10,000  所以我們可能要先解決這個\n",
            "[ 35%] 00:26:10,000 → 00:26:12,000  點\n",
            "[ 35%] 00:26:16,000 → 00:26:18,000  然後我自己有稍微想了一下\n",
            "[ 35%] 00:26:18,000 → 00:26:20,000  如果說你今天是\n",
            "[ 35%] 00:26:20,000 → 00:26:40,000  因為如果有太多業績的話,其實它是可以用一個比較簡略版的複測,就是它反正只是西馬丁,然後完完全全就是黑白印刷,那他們的題目跟解析是可以分開來的,然後當然對於印刷成本也不會跟原本一樣那麼高,然後學生也不會說如果我今天不能用手機,要不能用手機,\n",
            "[ 35%] 00:26:40,000 → 00:26:42,700  我就完全沒有辦法找到這題的答案\n",
            "[ 36%] 00:26:42,700 → 00:26:45,780  或是我也沒辦法找到這題的相接是什麼東西\n",
            "[ 36%] 00:26:45,780 → 00:26:46,640  對\n",
            "[ 36%] 00:26:46,640 → 00:26:50,020  所以想順便問問看你那邊有任何的想法嗎\n",
            "[ 36%] 00:26:50,020 → 00:26:54,780  所以\n",
            "[ 36%] 00:26:54,780 → 00:26:55,780  嗯\n",
            "[ 36%] 00:26:55,780 → 00:26:59,920  就是解答還是要包含在\n",
            "[ 36%] 00:27:00,000 → 00:27:04,000  裡面,就是包含在整份裡面嘛\n",
            "[ 36%] 00:27:04,000 → 00:27:08,900  這樣頁數不是還是一樣,只是超出\n",
            "[ 36%] 00:27:08,900 → 00:27:13,740  就會變成是以主側跟副側的方式去呈現\n",
            "[ 36%] 00:27:13,740 → 00:27:16,580  那副側的話我們的印刷品質就會是比較\n",
            "[ 36%] 00:27:16,580 → 00:27:19,260  沒有到跟主側一樣那麼好的\n",
            "[ 36%] 00:27:19,260 → 00:27:19,960  那它的印刷\n",
            "[ 36%] 00:27:20,000 → 00:27:25,000  雖然說會增加,但是不會像原本高的那麼誇張。\n",
            "[ 37%] 00:27:28,000 → 00:27:30,000  或者是有如果...\n",
            "[ 37%] 00:27:30,000 → 00:27:31,000  請說。\n",
            "[ 37%] 00:27:31,000 → 00:27:35,000  我想題目分享解葉樹很多耶,比較不像作文那樣子。\n",
            "[ 37%] 00:27:35,000 → 00:27:38,000  只有少少的就是葉。\n",
            "[ 37%] 00:27:40,000 → 00:27:53,000  因為它如果現在是要寫成題目一頁相接一頁,或是一頁三個題目,然後相接三頁的話,那個頁數應該都會比作文還要多很多。\n",
            "[ 37%] 00:28:00,000 → 00:28:05,360  但我哋冇辦法完全就把佢現場化\n",
            "[ 37%] 00:28:05,360 → 00:28:11,900  因為學生也確實冇辦法讓佢哋有個好的學習方式\n",
            "[ 38%] 00:28:11,900 → 00:28:17,060  那我哋現在壓業數是因為硬抓成本跟定價嗎?\n",
            "[ 38%] 00:28:17,060 → 00:28:20,000  就是說我哋定價如果就是要定在\n",
            "[ 38%] 00:28:20,000 → 00:28:26,000  500塊以內,業數就是不可以到300,350到400\n",
            "[ 38%] 00:28:26,000 → 00:28:27,000  對\n",
            "[ 38%] 00:28:31,000 → 00:28:34,000  你如果今天要到,就是真的業數要到三四百\n",
            "[ 38%] 00:28:34,000 → 00:28:38,000  其實是,就是沒有什麼關係啦\n",
            "[ 38%] 00:28:38,000 → 00:28:40,000  但是一方面\n",
            "[ 38%] 00:28:40,000 → 00:28:45,020  因為成本很高,所以我們分下來的利潤可能覺得是不多的。\n",
            "[ 38%] 00:28:45,020 → 00:28:58,020  第二方面是,如果我們今天是推一個他可以很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:28:58,020 → 00:29:09,980  然後這就會延伸到,如果我們今天是推一個很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:29:00,000 → 00:29:20,000  如果我們今天把排板放大,如果以A4尺寸去製作的話,A4它很吃排板功力,所以如果說你今天有任何一個排板點沒有排板好,或者是你的圖示效果不是那麼好的話,其實對於學生的學習狀況也不是到很良好。\n",
            "[ 39%] 00:29:20,000 → 00:29:22,000  如果你今天是一頁密密麻麻的文字\n",
            "[ 39%] 00:29:22,000 → 00:29:24,000  他們可能看到一半也不會想看\n",
            "[ 39%] 00:29:24,000 → 00:29:26,000  所以對於他們學習長相之後\n",
            "[ 39%] 00:29:26,000 → 00:29:28,000  不是那麼的佳\n",
            "[ 39%] 00:29:28,000 → 00:29:31,000  所以這個點我們可能要稍微想一下\n",
            "[ 39%] 00:29:31,000 → 00:29:33,000  我們去解決\n",
            "[ 39%] 00:29:35,000 → 00:29:40,000  以前如果你說學生有些會不想要用電子廠\n",
            "[ 40%] 00:29:40,000 → 00:29:46,000  那就代表之前說想借跟題目要做成線上資料庫\n",
            "[ 40%] 00:29:46,000 → 00:29:48,000  這個就等於是不可行的\n",
            "[ 40%] 00:29:48,000 → 00:29:51,000  對,會變成說如果真的要做的話\n",
            "[ 40%] 00:29:51,000 → 00:29:55,000  它更像是一個我給你一個更好的輔助工具\n",
            "[ 40%] 00:29:55,000 → 00:29:56,000  然後你如果今天想要\n",
            "[ 40%] 00:29:56,000 → 00:29:58,000  就你如果今天書籍沒有帶在身上的話\n",
            "[ 40%] 00:29:58,000 → 00:30:00,000  你也可以有一個\n",
            "[ 40%] 00:30:00,000 → 00:30:02,000  可以學習的地方\n",
            "[ 40%] 00:30:02,000 → 00:30:04,000  但現在問題點就是\n",
            "[ 40%] 00:30:04,000 → 00:30:06,000  很多家長他不願意讓學生\n",
            "[ 40%] 00:30:06,000 → 00:30:08,000  這樣去做\n",
            "[ 40%] 00:30:08,000 → 00:30:10,000  那如果\n",
            "[ 40%] 00:30:10,000 → 00:30:12,000  我們今天變成是\n",
            "[ 40%] 00:30:12,000 → 00:30:14,000  把題目跟\n",
            "[ 40%] 00:30:14,000 → 00:30:16,000  相借獨立成一本\n",
            "[ 40%] 00:30:16,000 → 00:30:18,000  複冊 然後\n",
            "[ 40%] 00:30:18,000 → 00:30:20,000  這本複冊的話\n",
            "[ 41%] 00:30:20,000 → 00:30:39,000  如果是買這本物理書,我們就會只給電子檔的複測,就是複測是用電子檔去給,然後他們可以自己印,又或是我們可以,他可以再加購,然後我們再把它印。\n",
            "[ 41%] 00:30:40,000 → 00:30:44,200  我覺得可能會以他們架構然後我們幫他印的方式\n",
            "[ 41%] 00:30:44,200 → 00:30:48,700  然後主要的話就是會印出的地方出去\n",
            "[ 41%] 00:30:48,700 → 00:30:53,000  不然我們成本一方面會拉高\n",
            "[ 41%] 00:30:53,000 → 00:30:57,900  另外一方面是他們好像不太擅長自己去印書\n",
            "[ 42%] 00:31:00,000 → 00:31:17,000  Ok,所以會需要麻煩維城,他可能還是要幫我把題目跟相機的都一樣有,就是可以有資本化的方式,就是你需要幫我拆開來寫,因為我們到時候會是以兩本書的形式推出去。\n",
            "[ 42%] 00:31:20,000 → 00:31:22,000  好,我可以提一個點嗎?\n",
            "[ 42%] 00:31:22,000 → 00:31:23,000  嗯。\n",
            "[ 42%] 00:31:23,000 → 00:31:36,000  就是微塵你可能現階段在做題目跟詳解的時候,你可能不要直接把它寫到 Word 檔,就是不要直接寫到你最後要出版的那個書上面。\n",
            "[ 42%] 00:31:36,000 → 00:31:40,000  而是你先用一個第三方的\n",
            "[ 42%] 00:31:40,000 → 00:31:43,000  另外一個的編輯的平台\n",
            "[ 42%] 00:31:43,000 → 00:31:47,000  你可能就先做在Notion上面\n",
            "[ 42%] 00:31:47,000 → 00:31:51,000  然後你把這些題目跟小節都做在Notion上面的時候\n",
            "[ 42%] 00:31:51,000 → 00:31:56,000  你一方面就是確保了我們剛剛講到的一個點是說\n",
            "[ 43%] 00:31:56,000 → 00:32:00,000  我們實體的東西要讓學生光看實體就看得懂\n",
            "[ 43%] 00:32:00,000 → 00:32:03,240  但是我們還是可以提供線上的輔助\n",
            "[ 43%] 00:32:03,240 → 00:32:06,340  這樣如果他們可能沒有帶到輔助\n",
            "[ 43%] 00:32:06,340 → 00:32:08,240  或是出了哪些狀況\n",
            "[ 43%] 00:32:08,240 → 00:32:10,340  或是他們想要用電子的方式去學\n",
            "[ 43%] 00:32:10,340 → 00:32:12,540  他們還是可以用電子的方式去做\n",
            "[ 43%] 00:32:12,540 → 00:32:14,840  所以就會變成說\n",
            "[ 43%] 00:32:14,840 → 00:32:17,000  利益\n",
            "[ 43%] 00:32:17,000 → 00:32:20,000  玉千你可不可以幫我開那個\n",
            "[ 43%] 00:32:20,000 → 00:32:25,000  英文共筆 英文選擇的那個檔案\n",
            "[ 43%] 00:32:25,000 → 00:32:27,000  對對對對\n",
            "[ 43%] 00:32:27,000 → 00:32:29,000  就是像現在的這個畫面\n",
            "[ 43%] 00:32:29,000 → 00:32:31,000  它就是一個英文的\n",
            "[ 43%] 00:32:31,000 → 00:32:33,000  英文選擇題的講義裡面的\n",
            "[ 43%] 00:32:33,000 → 00:32:36,000  線上的一個資料庫\n",
            "[ 43%] 00:32:36,000 → 00:32:39,000  你在寫你的那個題目跟詳解的時候\n",
            "[ 43%] 00:32:39,000 → 00:32:40,000  就建議你可以\n",
            "[ 44%] 00:32:40,000 → 00:33:00,000  寫在線上,然後就是在線上是一個已經有整理過的,有系統化的一個地方,然後這一個連結就可以直接分享給學生,然後學生就會有更多的自由度可以去在實體和電子上面同時的閱讀,就他們讀電子也得讀得懂,然後讀實體\n",
            "[ 44%] 00:33:00,000 → 00:33:11,060  你可以讀得懂,那你再把這個現在資料庫上面的東西再轉成實際書的排版跟內容就可以了,你這樣能聽得懂嗎?\n",
            "[ 44%] 00:33:13,860 → 00:33:19,940  我就是,因為我現在是把它拆在\n",
            "[ 44%] 00:33:20,000 → 00:33:29,000  因為我拿其他檔案,我的檔案,所以我之後寫完的話我再把它弄到 Notion上面。\n",
            "[ 45%] 00:33:29,000 → 00:33:31,000  這樣可以吧。\n",
            "[ 45%] 00:33:31,000 → 00:33:36,000  我覺得這樣應該會好一點,因為你我的檔不是會比較零散嗎?\n",
            "[ 45%] 00:33:40,000 → 00:33:44,000  欸可是notion上面就不能做那個公司那些咧?\n",
            "[ 45%] 00:33:46,000 → 00:33:48,000  Notion上可以做公司的\n",
            "[ 45%] 00:33:48,000 → 00:33:49,000  喔真的喔?\n",
            "[ 45%] 00:33:49,000 → 00:33:51,000  用Datex寫\n",
            "[ 45%] 00:33:53,000 → 00:33:55,000  你搜尋LATEX\n",
            "[ 45%] 00:34:00,000 → 00:34:02,000  等下等下等下\n",
            "[ 45%] 00:34:05,200 → 00:34:07,200  它是一個特定的滴刷\n",
            "[ 46%] 00:34:14,560 → 00:34:16,560  上面那個\n",
            "[ 46%] 00:34:20,000 → 00:34:30,340  就變成翅方,然後就要打一個固定的,就是一個字串進去,它就會變成翅方。\n",
            "[ 46%] 00:34:30,340 → 00:34:33,400  對,對,差不多了。\n",
            "[ 46%] 00:34:33,400 → 00:34:36,500  沃德裡面的公司應該是可以轉成這種模式的。\n",
            "[ 46%] 00:34:40,000 → 00:34:48,000  好,如果這方面維生不太會用的話,可以再問我,或是直接問培鈞也可以。\n",
            "[ 46%] 00:34:48,000 → 00:34:54,000  或是你也可以就直接在 Word 檔上面編輯,但是你截圖截到 Notion。\n",
            "[ 46%] 00:34:54,000 → 00:34:55,000  對。\n",
            "[ 46%] 00:34:55,000 → 00:34:59,000  因為 Notion 會有這種資料庫,就會比 Word 還要清楚一點。\n",
            "[ 47%] 00:35:00,000 → 00:35:05,000  好,那我就先在我的上面寫好了。\n",
            "[ 47%] 00:35:05,000 → 00:35:09,000  好,沒有問題。\n",
            "[ 47%] 00:35:09,000 → 00:35:20,000  然後這個的話其實剛剛子明就講到,你可以寫一個很深很深的關鍵,但是你要想辦法也要教會可能不是成都的嗎?\n",
            "[ 47%] 00:35:20,000 → 00:35:20,720  好的學生\n",
            "[ 47%] 00:35:20,720 → 00:35:26,800  那這部分剛剛你在聽的時候有問題嗎\n",
            "[ 47%] 00:35:26,800 → 00:35:34,340  你是說線上化跟配套工具\n",
            "[ 47%] 00:35:34,340 → 00:35:34,900  對\n",
            "[ 47%] 00:35:34,900 → 00:35:38,620  就是我們剛剛\n",
            "[ 47%] 00:35:40,000 → 00:35:45,000  我想講到自信框架的地方還有學習方式跟記憶策略的選擇\n",
            "[ 48%] 00:35:45,000 → 00:35:49,000  前面全部嗎?\n",
            "[ 48%] 00:35:49,000 → 00:35:52,000  對,它其實就是一樣的東西\n",
            "[ 48%] 00:35:52,000 → 00:35:55,000  就是教學理念的話我們希望它是以不間隔的方式\n",
            "[ 48%] 00:35:55,000 → 00:36:00,000  就是你要是寫好寫滿但是你要需要用方式讓可能\n",
            "[ 48%] 00:36:00,000 → 00:36:06,080  我比較沒有程度那麼高的學生去理解一個比較深奧的觀念\n",
            "[ 48%] 00:36:06,080 → 00:36:16,500  然後如果延續到前面剛剛提到的說\n",
            "[ 48%] 00:36:16,500 → 00:36:18,380  你要怎麼樣有一個很深奧的觀念\n",
            "[ 48%] 00:36:18,380 → 00:36:20,000  但是你卻不是只針對聰明\n",
            "[ 48%] 00:36:20,000 → 00:36:25,000  你只要把這個東西插成一個很碎片化的東西可以呈現。\n",
            "[ 48%] 00:36:25,000 → 00:36:28,000  它可能是三到五個獨立然後可以理解的小單元。\n",
            "[ 49%] 00:36:28,000 → 00:36:33,000  就你小單元小單元小單元讓他們去吸收,他們就比較可以接受。\n",
            "[ 49%] 00:36:33,000 → 00:36:37,000  然後再來的話是你每個單元只要專注一個最核心核心的點就好。\n",
            "[ 49%] 00:36:37,000 → 00:36:40,000  然後你可以搭配一些立體跟一些互動練習。\n",
            "[ 49%] 00:36:40,000 → 00:36:54,000  另外就是你要把那個包裝把它簡化簡化得很簡單,就是你可以用可能比較生物化的方式去解釋,或者是你可以用剩下一些視覺化的工具。\n",
            "[ 49%] 00:36:54,000 → 00:37:00,000  對,然後再來的話就是視超化落地,就是你這樣每個觀念都可以搭配一個可以讓它\n",
            "[ 49%] 00:37:00,000 → 00:37:12,000  所以我剛才會提到說你可能一個章節裡面你可能會有二到三題的練習題,你就可以搭配到視察化落地的這個部分。\n",
            "[ 50%] 00:37:12,000 → 00:37:20,000  好,然後再來的話就是剛其實就有稍微提到配套工具。\n",
            "[ 50%] 00:37:20,000 → 00:37:24,600  這幾個是我們覺得也可以用在物理講義裡面的配套工具\n",
            "[ 50%] 00:37:24,600 → 00:37:26,600  第一個就是Notion的筆記模板\n",
            "[ 50%] 00:37:26,600 → 00:37:28,600  然後再來的話就是SharedGPC的機器人\n",
            "[ 50%] 00:37:28,600 → 00:37:31,900  這個的話會是就是你先跟他聊聊聊\n",
            "[ 50%] 00:37:31,900 → 00:37:33,500  然後聊到說有一定的格式\n",
            "[ 50%] 00:37:33,500 → 00:37:37,100  然後之後我們再去轉成我們自己寫的機器人\n",
            "[ 50%] 00:37:37,100 → 00:37:40,100  就會是可能當學生輸入哪一些提示詞\n",
            "[ 50%] 00:37:40,000 → 00:37:44,420  他可以按照我們一開始就規定好的格式 然後產出相對應的內容\n",
            "[ 50%] 00:37:44,420 → 00:37:46,400  然後再來是Notebook LN\n",
            "[ 50%] 00:37:46,400 → 00:37:52,320  Notebook LN的話會比較偏向是我們一開始就先把我們的講義就先都上傳好\n",
            "[ 50%] 00:37:52,320 → 00:37:54,400  然後讓他的觀念是完整清楚的\n",
            "[ 50%] 00:37:54,400 → 00:37:56,780  那當學生他有什麼問題想要問的時候\n",
            "[ 50%] 00:37:56,780 → 00:37:59,020  他可以直接上Notebook LN然後問一個問題\n",
            "[ 50%] 00:37:59,020 → 00:37:59,300  然後\n",
            "[ 51%] 00:38:00,000 → 00:38:04,000  機器人就會想把相對應講義的內容輸出給他\n",
            "[ 51%] 00:38:04,000 → 00:38:07,000  就是一個很即時的問答\n",
            "[ 51%] 00:38:07,000 → 00:38:11,000  然後再來的話就是剛剛有給你看過的那個共編檔案\n",
            "[ 51%] 00:38:11,000 → 00:38:13,000  物理也可以這樣子做\n",
            "[ 51%] 00:38:13,000 → 00:38:17,000  但是這個的話就會很仰賴說\n",
            "[ 51%] 00:38:17,000 → 00:38:20,000  如果今天學生真的有上來留言\n",
            "[ 51%] 00:38:20,000 → 00:38:40,000  然後問問題的話,我們會需要很,就是至少在一定的時間內就可以幫他解完這樣的問題,然後並把這樣的東西再重新整理成新的內容,然後放上來,所以那個沒有到這麼急迫,但是我們還是會希望未來可以。\n",
            "[ 51%] 00:38:40,000 → 00:38:41,000  做\n",
            "[ 51%] 00:38:41,000 → 00:38:45,740  然後再來就是Notion的問答會診區\n",
            "[ 52%] 00:38:45,740 → 00:38:47,520  這個的話會是\n",
            "[ 52%] 00:38:47,520 → 00:38:49,900  譬如說我們有在IG啊\n",
            "[ 52%] 00:38:49,900 → 00:38:51,940  或者是在LINE的社群裡面\n",
            "[ 52%] 00:38:51,940 → 00:38:54,760  如果有任何人提到物理檢驗裡面的問題\n",
            "[ 52%] 00:38:54,760 → 00:38:57,020  我們都可以把它統整起來\n",
            "[ 52%] 00:38:57,020 → 00:38:58,500  然後就是你回答完之後\n",
            "[ 52%] 00:38:58,500 → 00:38:59,580  我們再把它統整起來\n",
            "[ 52%] 00:38:59,580 → 00:39:00,000  然後之後\n",
            "[ 52%] 00:39:00,000 → 00:39:03,320  有遇到一样的问题的时候学生就可以直接上来这边看\n",
            "[ 52%] 00:39:03,320 → 00:39:09,040  好那以上现在有问题吗\n",
            "[ 52%] 00:39:09,040 → 00:39:12,440  刚刚有说到那个notebook\n",
            "[ 52%] 00:39:12,440 → 00:39:16,140  它是就是上次是说它提供上来\n",
            "[ 52%] 00:39:16,140 → 00:39:17,700  然后它就会呈现解答\n",
            "[ 52%] 00:39:17,700 → 00:39:19,800  所以它是一个\n",
            "[ 52%] 00:39:20,000 → 00:39:25,020  它是AI嗎?還是它只是單純的查找的工具?\n",
            "[ 52%] 00:39:25,640 → 00:39:27,920  還是它是會生內容的那種AI?\n",
            "[ 53%] 00:39:30,120 → 00:39:33,000  它是一個幫助你去...\n",
            "[ 53%] 00:39:33,000 → 00:39:37,760  它是會自己生內容嗎?\n",
            "[ 53%] 00:39:38,360 → 00:39:39,980  還是它是拿出...\n",
            "[ 53%] 00:39:40,000 → 00:39:59,220  他會自己按照你給他的觀念格式,還有你給他的內容,然後去升,他裡面知道既有的內容,所以他不會去延伸說那些其實你並沒有輸入給他的東西,因為像ShareGP的話,他就很有可能是輸出一些\n",
            "[ 53%] 00:40:00,000 → 00:40:02,300  並唔係嗰麼正確性嘅嘢\n",
            "[ 53%] 00:40:02,300 → 00:40:06,400  但係NOPLM 佢就係完全按照你輸入乜嘢給佢\n",
            "[ 53%] 00:40:06,400 → 00:40:09,100  佢就會輸出相對應嘅嘢給學生\n",
            "[ 53%] 00:40:09,100 → 00:40:12,400  所以佢能確保佢裡面輸出嘅嘢一定係完整嘅\n",
            "[ 53%] 00:40:12,400 → 00:40:13,400  而且係正確嘅\n",
            "[ 53%] 00:40:15,600 → 00:40:16,400  好\n",
            "[ 54%] 00:40:16,400 → 00:40:19,900  對 所以會需要你完成獎益跟一些\n",
            "[ 54%] 00:40:20,000 → 00:40:23,000  我们再喂进去给那部LA\n",
            "[ 54%] 00:40:23,000 → 00:40:26,080  那到时候再用好\n",
            "[ 54%] 00:40:26,080 → 00:40:27,220  因为我现在也不会用它\n",
            "[ 54%] 00:40:27,220 → 00:40:29,160  好没有问题\n",
            "[ 54%] 00:40:29,160 → 00:40:32,440  然后善用比喻的话\n",
            "[ 54%] 00:40:32,440 → 00:40:34,380  上面也有讲过\n",
            "[ 54%] 00:40:34,380 → 00:40:35,780  然后你自己也有稍微看过\n",
            "[ 54%] 00:40:35,780 → 00:40:38,260  那这部分你有问题想询问的吗\n",
            "[ 54%] 00:40:40,000 → 00:40:44,000  應該比較還好,這部分應該比較簡單。\n",
            "[ 54%] 00:40:44,000 → 00:40:48,000  OK,那關於立場切換的部分呢?\n",
            "[ 54%] 00:40:51,000 → 00:41:00,000  這個就是子明剛剛跟你講到說,如果你今天是一個蓋籃的時候,你可以不要那麼的過於理性,或是就是一些文綽綽的\n",
            "[ 55%] 00:41:00,000 → 00:41:11,000  你可以是給他們一個對號入座的感覺,或是給他們一個比較偏向感性上面的支持,或是一些情緒支持這樣子,這就是舉例。\n",
            "[ 55%] 00:41:11,000 → 00:41:20,000  然後這個的話也是用在作文上的一個小小的行銷手段,它就是讓學生自己去想他們有什麼想法。\n",
            "[ 55%] 00:41:20,000 → 00:41:24,500  然後我們引導牠去對號入座到你真的有這個症狀\n",
            "[ 55%] 00:41:24,500 → 00:41:26,180  然後其實你很需要這個書\n",
            "[ 55%] 00:41:26,180 → 00:41:29,280  就是物理也可以用這樣的方式呈現\n",
            "[ 55%] 00:41:29,280 → 00:41:35,160  然後下面這些你在看的時候你有任何的問題嗎\n",
            "[ 55%] 00:41:35,160 → 00:41:37,300  或是有不太懂的地方嗎\n",
            "[ 56%] 00:41:40,000 → 00:42:00,000  應該都還好,剛剛前面說要給他們一些標籤,讓他們對好入座,我現在是沒想到有什麼啦,我想問你們,在寫物理的時候。\n",
            "[ 56%] 00:42:00,000 → 00:42:01,240  會有什麼問題嗎?\n",
            "[ 56%] 00:42:01,240 → 00:42:03,500  還是平常沒有在寫物理?\n",
            "[ 56%] 00:42:06,840 → 00:42:07,800  我有寫過\n",
            "[ 56%] 00:42:09,000 → 00:42:10,160  那你有什麼問題嗎?\n",
            "[ 56%] 00:42:11,540 → 00:42:12,660  我覺得從\n",
            "[ 56%] 00:42:13,660 → 00:42:16,560  如果是緯程那邊要整理這些問題的話\n",
            "[ 56%] 00:42:16,560 → 00:42:17,800  我反而會覺得\n",
            "[ 56%] 00:42:18,500 → 00:42:19,960  育謙那邊可能可以看\n",
            "[ 57%] 00:42:20,000 → 00:42:38,000  開一個物理的問答,限動的問答,然後藉由這樣子蒐集問題去知道學生的症節點在哪邊,然後就把那些問題全部灌到 CheckGPT,然後請CheckGPT整理學生有哪些類型,這樣應該就很快就可以找到那些問題。\n",
            "[ 57%] 00:42:38,000 → 00:42:40,000  但是問完那些問題之後……\n",
            "[ 57%] 00:42:40,000 → 00:42:47,000  可能未曾要幫忙簡單回答一下 因為育成可能沒辦法自己去回答物理的專業問題\n",
            "[ 57%] 00:42:47,000 → 00:42:52,000  被問問了但是沒有打算回答 這樣過分\n",
            "[ 57%] 00:42:52,000 → 00:43:00,000  我想舉一個例子就是我覺得我自己寫物理最大的祕訣是腦中藥\n",
            "[ 58%] 00:43:00,000 → 00:43:20,000  老公要有畫面,老公要有那個東西在跑的畫面,所以就可以把它當成是一個技巧,比如說看的那些物理的公式,看的那些數字,它沒有感覺怎麼樣,就可以去提。\n",
            "[ 58%] 00:43:20,000 → 00:43:28,000  提供他一些,譬如說像我剛剛講的那種讓自己比較有感覺的技巧這樣\n",
            "[ 58%] 00:43:28,000 → 00:43:30,000  類似這種方向\n",
            "[ 58%] 00:43:32,000 → 00:43:37,000  我有想過就是腦中要有畫面這件事情\n",
            "[ 58%] 00:43:37,000 → 00:43:40,000  但我後來發現就是好像不是每個人都可以做\n",
            "[ 58%] 00:43:40,000 → 00:43:44,000  就有些人特別沒有想像力\n",
            "[ 58%] 00:43:44,000 → 00:43:48,000  我要想一下就是要給我給他這個想像力\n",
            "[ 58%] 00:43:48,000 → 00:43:50,000  你要引導他去構思\n",
            "[ 58%] 00:43:50,000 → 00:43:52,000  對引導他去構思這個想像力\n",
            "[ 58%] 00:43:52,000 → 00:44:00,000  或是你也可以找一些線上的視覺化\n",
            "[ 59%] 00:44:00,000 → 00:44:04,000  現在有一些線上的物理方面的視覺化的工具\n",
            "[ 59%] 00:44:04,000 → 00:44:07,000  也可以引導他們去使用這些工具\n",
            "[ 59%] 00:44:07,000 → 00:44:10,000  然後自己去拉拉看那個訊息之類的\n",
            "[ 59%] 00:44:12,000 → 00:44:14,000  我可以稍微跟你提一個\n",
            "[ 59%] 00:44:14,000 → 00:44:17,000  可能比較像是聯想或者一個小技巧\n",
            "[ 59%] 00:44:17,000 → 00:44:20,000  像英文作文裡那個字名它就會\n",
            "[ 59%] 00:44:20,000 → 00:44:23,660  用break pin去講一些公式跟觀念\n",
            "[ 59%] 00:44:23,660 → 00:44:28,960  讓學生他們的想像畫面是以他們熟悉的東西去帶入\n",
            "[ 59%] 00:44:28,960 → 00:44:32,860  那他們就會比較好聯想到你要跟他們講什麼\n",
            "[ 59%] 00:44:32,860 → 00:44:38,020  然後當他們真的對於那個畫面沒有太大的感受的時候\n",
            "[ 59%] 00:44:38,020 → 00:44:39,900  他們也可以因為這個東西是他們比較\n",
            "[ 59%] 00:44:40,000 → 00:44:42,400  日常生活化就有在接觸的東西。\n",
            "[ 59%] 00:44:42,400 → 00:44:45,200  所以進而聯想到那個很抽象的畫面。\n",
            "[ 60%] 00:44:47,200 → 00:44:49,100  這就會是我們剛剛上面有講到的,\n",
            "[ 60%] 00:44:49,100 → 00:44:51,700  就是你可能要再多運用一些生活化\n",
            "[ 60%] 00:44:51,700 → 00:44:55,300  或是很日常的東西去做比喻,\n",
            "[ 60%] 00:44:55,300 → 00:44:57,100  然後去做例子的講解。\n",
            "[ 60%] 00:45:00,000 → 00:45:09,300  好,然後再來的話,學生需要會有一個固定的,固定默契的emoji,\n",
            "[ 60%] 00:45:09,460 → 00:45:13,680  因為它會是讓學生知道,我今天看到這個圖示的時候,\n",
            "[ 60%] 00:45:13,900 → 00:45:18,000  我就是接下來會看到什麼樣的內容,讓他們有一個小小的概念點。\n",
            "[ 61%] 00:45:20,000 → 00:45:40,000  但是如果以英文中文來講的話,這個東西就會是對應到總結的重點,然後小燈泡的話就會是一個口訣或是一個記憶法,然後如果你今天是一個手加一個筆的話,那就是你的動手練習,就是你可以稍微去幫他設計一個固定的符號,讓他們有一個小概念,他們才不會覺得...\n",
            "[ 61%] 00:45:40,000 → 00:45:44,000  看起來很亂,然後台板上我們也會比較整齊一點點。\n",
            "[ 61%] 00:45:44,000 → 00:45:48,140  然後如果今天是你想要自己跟學生講的話,\n",
            "[ 61%] 00:45:48,240 → 00:45:53,320  你也可以用一個可能老師的符號,或者是一個男生的符號,\n",
            "[ 61%] 00:45:53,500 → 00:45:56,440  然後跟他們講說這比較像是你心裡的話,\n",
            "[ 61%] 00:45:56,600 → 00:45:59,000  那他就不用那麼文綴綴,他就是真的可以很...\n",
            "[ 61%] 00:46:00,000 → 00:46:03,000  就是比較日常口語化的東西就可以了\n",
            "[ 61%] 00:46:03,000 → 00:46:06,000  然後再來就是上次就有提到的東西\n",
            "[ 61%] 00:46:06,000 → 00:46:08,000  就是說表達高用AI論搞過\n",
            "[ 61%] 00:46:08,000 → 00:46:11,000  因為現在的物理講義內容比較像是\n",
            "[ 61%] 00:46:11,000 → 00:46:13,000  你真的想到什麼然後就打什麼出來\n",
            "[ 61%] 00:46:13,000 → 00:46:15,000  它沒有一個固定的格式\n",
            "[ 62%] 00:46:15,000 → 00:46:18,000  然後甚至這樣的內容可能比較像是\n",
            "[ 62%] 00:46:18,000 → 00:46:20,000  只有你自己看得懂\n",
            "[ 62%] 00:46:20,000 → 00:46:22,000  所有的表達我們都可以丟到TradeGPT\n",
            "[ 62%] 00:46:22,000 → 00:46:24,000  就你只要把你的想法丟上去\n",
            "[ 62%] 00:46:24,000 → 00:46:26,000  然後剛才你說你可以幫我run稿嗎\n",
            "[ 62%] 00:46:26,000 → 00:46:28,000  或是你可以幫我修飾成\n",
            "[ 62%] 00:46:28,000 → 00:46:30,000  可能高中生也看得懂的話語\n",
            "[ 62%] 00:46:30,000 → 00:46:32,000  它就會直接幫你寫出來\n",
            "[ 62%] 00:46:32,000 → 00:46:34,000  但是它生成的內容\n",
            "[ 62%] 00:46:34,000 → 00:46:36,000  你還是需要再去檢查過\n",
            "[ 62%] 00:46:36,000 → 00:46:38,000  因為它有時候不一定是那麼正確\n",
            "[ 62%] 00:46:38,000 → 00:46:40,000  或是不一定那麼貼近你想要表達的\n",
            "[ 62%] 00:46:40,000 → 00:46:45,000  所以你就跟他多聊幾次就可以了。\n",
            "[ 62%] 00:46:45,000 → 00:46:47,000  好,以上是知識存在的方面。\n",
            "[ 62%] 00:46:47,000 → 00:46:51,000  然後如果是使用者體驗方面的話,\n",
            "[ 62%] 00:46:51,000 → 00:46:54,000  像是AI化、線上化跟連結種整理,\n",
            "[ 62%] 00:46:54,000 → 00:46:58,000  就會需要麻煩你在編寫獎益的內容之後,\n",
            "[ 62%] 00:46:58,000 → 00:47:00,000  在編寫獎益內容的之中,\n",
            "[ 62%] 00:47:00,000 → 00:47:02,800  我就邊想還有哪些東西可以去製作\n",
            "[ 63%] 00:47:02,800 → 00:47:04,900  然後在你撰寫的過程中\n",
            "[ 63%] 00:47:04,900 → 00:47:07,500  也可以邊製作一些AI工具\n",
            "[ 63%] 00:47:07,500 → 00:47:09,000  或是把東西線上畫\n",
            "[ 63%] 00:47:10,500 → 00:47:14,200  然後全球地圖廣告頁跟意見回饋購買東西調查\n",
            "[ 63%] 00:47:14,200 → 00:47:16,600  這些都會由e-mall這邊直接處理\n",
            "[ 63%] 00:47:18,000 → 00:47:19,500  然後再來是格式的話\n",
            "[ 63%] 00:47:20,000 → 00:47:30,000  因為我知道你現在跟小助手的方式 好像是你會先把他整理過 然後再傳檔案給他 對嗎?\n",
            "[ 63%] 00:47:32,000 → 00:47:33,000  對\n",
            "[ 63%] 00:47:33,000 → 00:47:38,000  對 所以格式的話可能要 就是從你那邊一開始打的時候\n",
            "[ 63%] 00:47:38,000 → 00:47:40,000  就是你開始編輯這個書的時候\n",
            "[ 63%] 00:47:40,000 → 00:47:42,240  你可能就要稍微幫我注意一下格式\n",
            "[ 63%] 00:47:42,240 → 00:47:43,980  我們就是以B5為主\n",
            "[ 63%] 00:47:43,980 → 00:47:46,060  然後那個初期線要稍微注意\n",
            "[ 64%] 00:47:46,060 → 00:47:48,780  至少邊邊要預留三面面\n",
            "[ 64%] 00:47:48,780 → 00:47:49,500  它會比較\n",
            "[ 64%] 00:47:49,500 → 00:47:53,520  就硬刷的時候才會比較不會卡到板\n",
            "[ 64%] 00:47:53,520 → 00:47:54,420  然後需要\n",
            "[ 64%] 00:47:54,420 → 00:47:55,620  預留多少\n",
            "[ 64%] 00:47:55,620 → 00:47:58,560  就是你開word\n",
            "[ 64%] 00:47:58,560 → 00:48:00,000  然後它會有那個\n",
            "[ 64%] 00:48:00,000 → 00:48:02,000  至少要窄\n",
            "[ 64%] 00:48:02,000 → 00:48:04,000  它有一個版面配飾\n",
            "[ 64%] 00:48:04,000 → 00:48:06,000  然後你最多最多只能選擇窄\n",
            "[ 64%] 00:48:06,000 → 00:48:08,000  然後不能再往下縮\n",
            "[ 64%] 00:48:10,000 → 00:48:12,000  等一下我再開給你看好了\n",
            "[ 64%] 00:48:12,000 → 00:48:14,000  稍等我一下\n",
            "[ 65%] 00:48:20,000 → 00:48:39,240  好,就是你在用Word等的時候,它其實有一個版面配置,然後你就,你需要先一開始就先幫我把大小分到。\n",
            "[ 65%] 00:48:40,000 → 00:48:42,640  啊我冇覆好,稍等我\n",
            "[ 65%] 00:48:42,640 → 00:48:44,080  奈咦阿捏\n",
            "[ 65%] 00:48:44,080 → 00:48:50,540  這樣有咩\n",
            "[ 65%] 00:48:50,540 → 00:48:55,720  所以你一開始就需要幫我把大小\n",
            "[ 65%] 00:48:55,720 → 00:48:57,880  就直接先選成B5的大小\n",
            "[ 65%] 00:48:57,880 → 00:48:59,780  然後邊界這邊\n",
            "[ 65%] 00:49:00,000 → 00:49:02,000  最多最多就是以窄為主\n",
            "[ 65%] 00:49:02,000 → 00:49:04,000  就是盡量不要再往下縮\n",
            "[ 65%] 00:49:04,000 → 00:49:08,000  不然我們的印刷照片可能會踩到旁邊\n",
            "[ 65%] 00:49:08,000 → 00:49:10,000  這部分OK咩?\n",
            "[ 65%] 00:49:10,000 → 00:49:12,000  OK\n",
            "[ 65%] 00:49:12,000 → 00:49:14,000  再超出一點點\n",
            "[ 65%] 00:49:14,000 → 00:49:16,000  一點點\n",
            "[ 65%] 00:49:16,000 → 00:49:18,000  對對對就是一點點\n",
            "[ 66%] 00:49:18,000 → 00:49:20,000  但不要壓得太緊\n",
            "[ 66%] 00:49:20,000 → 00:49:22,000  你可以回去剛那個地方嗎?\n",
            "[ 66%] 00:49:22,000 → 00:49:26,000  你看它的右上角\n",
            "[ 66%] 00:49:26,000 → 00:49:29,000  右上角是不是有一個L形的東西?\n",
            "[ 66%] 00:49:32,000 → 00:49:36,000  在紙張上有一個L形的框架\n",
            "[ 66%] 00:49:36,000 → 00:49:38,000  對這個\n",
            "[ 66%] 00:49:38,000 → 00:49:40,000  就是它的那個死角的那個\n",
            "[ 66%] 00:49:40,000 → 00:49:42,000  你的字可以寫到那邊\n",
            "[ 66%] 00:49:42,000 → 00:49:47,000  然後如果你字真的想要在外面再延伸一點點的話\n",
            "[ 66%] 00:49:47,000 → 00:49:52,000  就是不可以超過那個L型的中端\n",
            "[ 66%] 00:49:52,000 → 00:49:55,000  就不可以寫出L型的外面\n",
            "[ 66%] 00:49:55,000 → 00:49:59,000  就會是不會被拆到的格式\n",
            "[ 67%] 00:50:00,000 → 00:50:07,000  但是今天還是幫我縮在L型裡面會比較保險一點點\n",
            "[ 67%] 00:50:07,000 → 00:50:15,000  然後再來的話其他目前都有講過\n",
            "[ 67%] 00:50:15,000 → 00:50:20,000  這個呼籲社群宣傳\n",
            "[ 67%] 00:50:20,000 → 00:50:22,700  比較會像是你寫書已經寫到後半段之後\n",
            "[ 67%] 00:50:22,700 → 00:50:24,700  我們可以再來進行的東西\n",
            "[ 67%] 00:50:24,700 → 00:50:27,800  所以這個我們可以之後在開會的時候跟你講一下\n",
            "[ 67%] 00:50:29,800 → 00:50:33,300  然後誓願內容商品化會\n",
            "[ 67%] 00:50:33,300 → 00:50:34,800  這個就是範例\n",
            "[ 67%] 00:50:34,800 → 00:50:38,200  我們以英文作文或是英文文法\n",
            "[ 67%] 00:50:38,200 → 00:50:39,400  或是英文單字說的話\n",
            "[ 67%] 00:50:39,400 → 00:50:40,000  我們可能都會\n",
            "[ 67%] 00:50:40,000 → 00:50:46,320  給他一個備單的機器人 然後拿這個機器人去推廣我們的作文書跟其他的產品\n",
            "[ 68%] 00:50:46,320 → 00:50:49,560  就是當你使用這個機器人的時候 它底下其實會生成\n",
            "[ 68%] 00:50:49,560 → 00:50:54,860  如果你想看更多完整的內容 或者如果你想要看什麼更完整的文法解說\n",
            "[ 68%] 00:50:54,860 → 00:50:58,640  你可以購買一模一模的那本書 然後會貼一個下一個連結給他\n",
            "[ 68%] 00:50:58,640 → 00:51:00,000  就是到時候物理也可以用\n",
            "[ 68%] 00:51:00,000 → 00:51:02,800  用這種方式去做一個行銷宣傳。\n",
            "[ 68%] 00:51:02,800 → 00:51:06,800  在這裡,就是想知道如果背一個單字補輸一個觀念,\n",
            "[ 68%] 00:51:06,800 → 00:51:09,800  然後這就會是我們完整的書籍內容宣傳。\n",
            "[ 68%] 00:51:12,800 → 00:51:18,800  好,那目前以上有任何問題或是有任何想問的嗎?\n",
            "[ 68%] 00:51:20,000 → 00:51:26,120  因為Himoji那邊現在的樹就有了,所以還好。\n",
            "[ 68%] 00:51:26,120 → 00:51:31,440  然後你有一個MBTI那個是沒有要理它嗎?\n",
            "[ 69%] 00:51:34,960 → 00:51:40,020  因為這個可能就是對於物理...\n",
            "[ 69%] 00:51:40,000 → 00:51:43,200  講義有點難運用\n",
            "[ 69%] 00:51:43,200 → 00:51:43,840  其實\n",
            "[ 69%] 00:51:43,840 → 00:51:45,960  哦好那我就不理他\n",
            "[ 69%] 00:51:45,960 → 00:51:47,340  好好\n",
            "[ 69%] 00:51:47,340 → 00:51:48,280  子明你可以說\n",
            "[ 69%] 00:51:48,280 → 00:51:53,080  我寫那個其實只是一個紀錄\n",
            "[ 69%] 00:51:53,080 → 00:51:54,980  它不一定要寫NBT\n",
            "[ 69%] 00:51:54,980 → 00:51:56,820  我想講的只是說\n",
            "[ 69%] 00:51:56,820 → 00:51:59,240  你可以去設想\n",
            "[ 69%] 00:52:00,000 → 00:52:02,000  學生有千千百百多\n",
            "[ 69%] 00:52:02,000 → 00:52:04,000  就是有一些人\n",
            "[ 69%] 00:52:04,000 → 00:52:08,000  因為你自己怎麼學物理\n",
            "[ 69%] 00:52:08,000 → 00:52:10,000  跟其他人怎麼學物理\n",
            "[ 69%] 00:52:10,000 → 00:52:11,000  一定是非常不同的\n",
            "[ 69%] 00:52:11,000 → 00:52:13,000  然後除了是專業知識\n",
            "[ 69%] 00:52:13,000 → 00:52:15,000  觀念上面的落差之外\n",
            "[ 69%] 00:52:15,000 → 00:52:17,000  其實他們在理解知識\n",
            "[ 70%] 00:52:17,000 → 00:52:20,000  還有如何讀完這本書上面\n",
            "[ 70%] 00:52:20,000 → 00:52:22,500  本身就會有很大的不同\n",
            "[ 70%] 00:52:22,500 → 00:52:24,500  像譬如說喻謙好了\n",
            "[ 70%] 00:52:24,500 → 00:52:26,500  他如果今天讀到一本書\n",
            "[ 70%] 00:52:26,500 → 00:52:28,500  然後事實上他覺得很用心\n",
            "[ 70%] 00:52:33,500 → 00:52:35,500  如果是那本書讓喻謙覺得很用心\n",
            "[ 70%] 00:52:35,500 → 00:52:37,500  然後很有溫度\n",
            "[ 70%] 00:52:37,500 → 00:52:39,500  然後是很想把學徒顧好\n",
            "[ 70%] 00:52:39,500 → 00:52:40,500  喻謙就會想\n",
            "[ 70%] 00:52:40,000 → 00:52:42,000  你想把它讀完,你說是不是?\n",
            "[ 70%] 00:52:42,000 → 00:52:44,000  對\n",
            "[ 70%] 00:52:44,000 → 00:52:46,000  但是我的個性可能就會是\n",
            "[ 70%] 00:52:46,000 → 00:52:48,000  我想要看到超級爆炸具體的東西\n",
            "[ 70%] 00:52:48,000 → 00:52:50,000  你不要給我扯一些有的沒的的\n",
            "[ 70%] 00:52:50,000 → 00:52:52,000  剛才跟我講的重點\n",
            "[ 70%] 00:52:52,000 → 00:52:57,000  然後其他學生有些可能會喜歡圖像化的解說\n",
            "[ 70%] 00:52:57,000 → 00:53:00,000  然後就是你比起用文字去寫\n",
            "[ 70%] 00:53:00,000 → 00:53:01,800  寫第一步驟第二步驟第三步驟\n",
            "[ 71%] 00:53:01,800 → 00:53:05,300  你還不如直接用一張圖片或Canva的字圖\n",
            "[ 71%] 00:53:05,300 → 00:53:07,300  去告訴他三步驟是什麼\n",
            "[ 71%] 00:53:07,300 → 00:53:09,500  那又會有一些可能又會喜歡\n",
            "[ 71%] 00:53:09,500 → 00:53:13,100  就是兩個人的對話去推進一個觀念\n",
            "[ 71%] 00:53:13,100 → 00:53:14,600  就大家都有不同學習方式\n",
            "[ 71%] 00:53:14,600 → 00:53:16,900  然後我覺得你不一定要用MVTI\n",
            "[ 71%] 00:53:16,900 → 00:53:19,100  去把16個全部都想過一次\n",
            "[ 71%] 00:53:19,100 → 00:53:19,900  而是你\n",
            "[ 71%] 00:53:20,000 → 00:53:21,640  至少在寫獎音的時候\n",
            "[ 71%] 00:53:21,640 → 00:53:25,760  你要先抓幾個學生的標籤跟概念出來\n",
            "[ 71%] 00:53:25,760 → 00:53:28,640  可能是圖像化學生、理論化學生\n",
            "[ 71%] 00:53:28,640 → 00:53:31,040  然後比較情緒化的學生\n",
            "[ 71%] 00:53:31,040 → 00:53:32,000  抓幾個標籤出來\n",
            "[ 71%] 00:53:32,000 → 00:53:35,240  然後去寫獎音的時候照顧到這些學生的需求\n",
            "[ 71%] 00:53:37,240 → 00:53:39,040  好,我講完了\n",
            "[ 71%] 00:53:40,000 → 00:53:43,000  Ok, this part, do you think it's ok?\n",
            "[ 71%] 00:53:44,000 → 00:53:45,000  Yes, it's ok.\n",
            "[ 71%] 00:53:46,000 → 00:53:48,000  Ok, and then...\n",
            "[ 72%] 00:53:51,000 → 00:53:56,000  If you are in the process of making it, or you need some AI tools to help you,\n",
            "[ 72%] 00:53:56,000 → 00:54:00,000  you can find Pei Jun, he is a very good...\n",
            "[ 72%] 00:54:00,000 → 00:54:04,200  所以如果你在這雙方沒有問題的話都可以問他\n",
            "[ 72%] 00:54:04,200 → 00:54:16,000  我們不是還有一個是要問Pedro的事情嗎\n",
            "[ 72%] 00:54:20,000 → 00:54:22,000  我可以分享我的畫面嗎?\n",
            "[ 72%] 00:54:22,000 → 00:54:24,000  欸等一下,物理那邊都講完了吧?\n",
            "[ 72%] 00:54:24,000 → 00:54:26,000  對\n",
            "[ 72%] 00:54:26,000 → 00:54:30,000  好,那我想要問一下裴娟一個東西\n",
            "[ 72%] 00:54:30,000 → 00:54:32,000  我分享一下我的畫面\n",
            "[ 73%] 00:54:40,000 → 00:54:59,920  我们刚刚有讲到很多写讲义上面的东西,只是如果我们这边有这套准则,但是像伟臣可能写的时候还是会需要时不时回去看交战手册,然后有时候可能还是会不小心漏掉一些东西,或不知道怎么去使用,然后我在想如果我们未来\n",
            "[ 73%] 00:55:00,000 → 00:55:06,000  可能會需要同時跑很多本書 很多個合作者一起寫這樣一個話\n",
            "[ 73%] 00:55:06,000 → 00:55:09,000  我們來回溝通可能會需要花很多時間\n",
            "[ 73%] 00:55:09,000 → 00:55:14,000  然後就想到說 之前我在學SEO的時候\n",
            "[ 73%] 00:55:14,000 → 00:55:17,000  有一個像這樣子的工具\n",
            "[ 74%] 00:55:17,000 → 00:55:20,000  就是它的左邊是你在寫書\n",
            "[ 74%] 00:55:20,000 → 00:55:40,000  文章的頁面,然後右邊他就會告訴你說你現在拿到多少分,就是你有做到多少需求之內的事情,然後他就會一直提醒你說你還要再寫什麼,你還要再寫什麼才會足夠完整,然後在想就是這樣子的一個工具他製作的難度。\n",
            "[ 74%] 00:55:40,000 → 00:55:59,100  我覺得應該,這個東西他看起來是有機會整合在Notion裡面,但是我覺得他看起來,因為我們獎勵的內容其實是非常多嘛,我覺得他看起來對於Token的開銷會非常大,就是\n",
            "[ 75%] 00:56:00,000 → 00:56:10,000  我覺得我們透過應用程式去跟AI做串接,它中間其實是以量計價的。\n",
            "[ 75%] 00:56:10,000 → 00:56:20,000  我覺得這東西它或許是可以嘗試看看來做,但是因為\n",
            "[ 75%] 00:56:20,000 → 00:56:27,000  另一方面講義的內容很多,另一方面教單手字的內容也蠻多的\n",
            "[ 75%] 00:56:27,000 → 00:56:32,000  我覺得這個可能使用量的部分會比較大一點點\n",
            "[ 75%] 00:56:32,000 → 00:56:36,000  但這個東西會越來越便宜啦\n",
            "[ 75%] 00:56:36,000 → 00:56:40,000  所以或許我可以嘗試看看用\n",
            "[ 75%] 00:56:40,000 → 00:56:45,640  比較之前的,應該說用量比較小比較便宜的模型來試試看\n",
            "[ 75%] 00:56:46,660 → 00:56:49,720  因為畢竟他這個東西他不會要求說\n",
            "[ 76%] 00:56:49,980 → 00:56:53,320  就是我AI傳出的內容要到多進去\n",
            "[ 76%] 00:56:55,360 → 00:56:59,960  我覺得可以研究看看有沒有機會把它整合在Notion裡面\n",
            "[ 76%] 00:57:00,000 → 00:57:02,760  可能他更新頻率不會到這麼的高\n",
            "[ 76%] 00:57:02,760 → 00:57:09,760  可能就是寫作者完成一整階段的工作之後\n",
            "[ 76%] 00:57:09,760 → 00:57:14,500  再去再用AI去做這個提醒這樣\n",
            "[ 76%] 00:57:18,240 → 00:57:19,000  那如果\n",
            "[ 76%] 00:57:20,000 → 00:57:29,300  如果把這個工具切成是很多個更小的工具 那如果把這個工具切成是很多個更小的工具\n",
            "[ 76%] 00:57:29,300 → 00:57:33,780  就是我們不一定要是一戰式的解決所有講義變形的問題\n",
            "[ 77%] 00:57:33,780 → 00:57:40,000  可能把剛剛教授的手冊細分成五個層面或三個層面\n",
            "[ 77%] 00:57:40,000 → 00:57:47,000  要分別套這樣子的工具,它的用量這樣子會再更大,還是可以節省一點。\n",
            "[ 77%] 00:58:00,000 → 00:58:07,000  要怎麼切我覺得後續可以再來想了,目前就是我覺得可能要再研究一下。\n",
            "[ 77%] 00:58:07,000 → 00:58:14,000  好,不然我也先用ChangeGPT做做看好了,我先打一張手冊寫ChangeGPT。\n",
            "[ 77%] 00:58:14,000 → 00:58:20,000  然後維城如果會,如果想要看看說自己有沒有\n",
            "[ 78%] 00:58:20,000 → 00:58:24,680  有一些東西漏掉的話,你就可以先把你的獎金丟進去,change your VT\n",
            "[ 78%] 00:58:24,680 → 00:58:27,680  但是你一次可能就只能丟個十頁\n",
            "[ 78%] 00:58:27,680 → 00:58:30,680  就不能一次丟那個幾百頁進去\n",
            "[ 78%] 00:58:30,680 → 00:58:34,680  然後他可能就會告訴你說你還有哪些地方需要再錄\n",
            "[ 78%] 00:58:34,680 → 00:58:40,680  現階段先這樣子,然後這個可以之後有研究出來\n",
            "[ 78%] 00:58:40,000 → 00:58:43,000  讓我們再拿出來討論看看。\n",
            "[ 78%] 00:58:45,000 → 00:58:47,000  好,我講完了。\n",
            "[ 78%] 00:58:47,000 → 00:58:49,000  好耶。\n",
            "[ 78%] 00:58:49,000 → 00:58:52,000  那目前維生有任何想問的嗎?\n",
            "[ 78%] 00:58:52,000 → 00:58:56,000  或者也想分享看看你的想法也都可以。\n",
            "[ 79%] 00:59:00,000 → 00:59:09,440  我問個問題,就是之前不是有說你要開另外一個物理的帳號嗎?\n",
            "[ 79%] 00:59:09,440 → 00:59:11,440  嗯\n",
            "[ 79%] 00:59:11,440 → 00:59:20,000  就是我覺得應該要開另外一個跟英文獨立的帳號會比較好,不管你之後有沒有要掛e-mail的問題\n",
            "[ 79%] 00:59:20,000 → 00:59:22,000  我覺得分開會比較好\n",
            "[ 79%] 00:59:22,000 → 00:59:24,000  有原因嗎?\n",
            "[ 79%] 00:59:24,000 → 00:59:26,000  就是覺得分開會比較好\n",
            "[ 79%] 00:59:26,000 → 00:59:28,000  因為emote本來就是文科嘛\n",
            "[ 79%] 00:59:28,000 → 00:59:30,000  然後如果突然變成理科的話\n",
            "[ 79%] 00:59:30,000 → 00:59:32,000  就是你如果發的內容都混在一起\n",
            "[ 80%] 00:59:40,000 → 00:59:59,000  至少理科跟文科一個比較專業的分別,我會傾向把它分開,至少我看到這個帳號的時候我也知道它的專業是英文,這個帳號的專業是什麼,雖然它背後的人可能是同一批人。\n",
            "[ 80%] 01:00:00,000 → 01:00:02,000  我覺得它好像是不同的處理邏輯\n",
            "[ 80%] 01:00:02,000 → 01:00:04,000  就是我們現在如果把物理\n",
            "[ 80%] 01:00:04,000 → 01:00:06,000  它是兩種都是正確的狀況\n",
            "[ 80%] 01:00:06,000 → 01:00:08,000  然後我可能先跟你分享看看\n",
            "[ 80%] 01:00:08,000 → 01:00:10,000  要看你會不會有不同想法\n",
            "[ 80%] 01:00:20,000 → 01:00:25,000  如果是把講義掛到英文帳號的話\n",
            "[ 80%] 01:00:25,000 → 01:00:33,000  那其實是變成我們是幫助你在私領域去找客人\n",
            "[ 81%] 01:00:33,000 → 01:00:37,000  就是我們的瀏覽\n",
            "[ 81%] 01:00:37,000 → 01:00:40,000  我有做過一張圖秀給你看一下\n",
            "[ 81%] 01:00:40,000 → 01:00:48,300  就是我們的流量入口 IG的那些貼文就不太會真的去做物理專業知識相關的東西\n",
            "[ 81%] 01:00:48,300 → 01:00:52,580  那個就是真的跟英文真的太不相關\n",
            "[ 81%] 01:00:52,580 → 01:00:56,840  然後那個內容這樣跳來跳去也比較不符合學生的習慣\n",
            "[ 81%] 01:00:56,840 → 01:00:59,880  所以物理的專業知識不會\n",
            "[ 81%] 01:01:00,000 → 01:01:09,000  作為流量入口,我們的流量入口都會是以內容為主,只是那些流量進來之後\n",
            "[ 81%] 01:01:14,000 → 01:01:16,000  這邊沒有斷掉\n",
            "[ 82%] 01:01:20,000 → 01:01:34,080  他們還會被導到像是我們的節目或Line群然後限動\n",
            "[ 82%] 01:01:34,080 → 01:01:37,940  等於說是可能有6萬個追蹤者是追我們的IG\n",
            "[ 82%] 01:01:37,940 → 01:01:39,980  但是可能進入到死領域的\n",
            "[ 82%] 01:01:40,000 → 01:01:41,000  可能就只有一萬個\n",
            "[ 82%] 01:01:41,000 → 01:01:44,000  然後一萬個當中我們再想辦法幫你推銷\n",
            "[ 82%] 01:01:44,000 → 01:01:46,000  最後推銷出來\n",
            "[ 82%] 01:01:46,000 → 01:01:51,000  成交的數量就會比英文還要少\n",
            "[ 82%] 01:01:51,000 → 01:01:53,000  這是比較正常的狀況\n",
            "[ 82%] 01:01:53,000 → 01:01:55,000  但是相對來說\n",
            "[ 82%] 01:01:55,000 → 01:01:57,000  如果我們今天就開個全新的帳號\n",
            "[ 82%] 01:01:57,000 → 01:02:00,000  那我們那個全新的帳號也必須達到一定的粉絲級\n",
            "[ 82%] 01:02:00,000 → 01:02:02,760  才可以去平衡掉我剛剛說\n",
            "[ 82%] 01:02:02,760 → 01:02:04,800  比如說導到死領域的可能有一萬個\n",
            "[ 83%] 01:02:04,800 → 01:02:06,980  那就代表如果我們要重開一個帳號\n",
            "[ 83%] 01:02:06,980 → 01:02:10,300  那個帳號可能至少就要光靠自然科\n",
            "[ 83%] 01:02:10,300 → 01:02:14,060  光靠物理可能就要至少達到一萬個粉絲\n",
            "[ 83%] 01:02:14,060 → 01:02:16,220  它才會比較有機率\n",
            "[ 83%] 01:02:16,220 → 01:02:18,480  可以達到跟英文一樣的宣傳效果\n",
            "[ 83%] 01:02:18,480 → 01:02:19,980  就有點像我這邊\n",
            "[ 83%] 01:02:20,000 → 01:02:22,000  我沒有做一個圖\n",
            "[ 83%] 01:02:22,000 → 01:02:27,000  就是打開熱量漏斗的地方其實是我們會用英文去做\n",
            "[ 83%] 01:02:27,000 → 01:02:29,000  但是其他的這個地方\n",
            "[ 83%] 01:02:29,000 → 01:02:31,000  YouTube 跟 IG 限動\n",
            "[ 83%] 01:02:31,000 → 01:02:34,000  還有專業的一些課程\n",
            "[ 83%] 01:02:34,000 → 01:02:35,000  就是講義啊\n",
            "[ 83%] 01:02:35,000 → 01:02:38,000  然後現在是沒有在做直播跟團課啦\n",
            "[ 83%] 01:02:38,000 → 01:02:40,000  但是其他的一些專業的\n",
            "[ 83%] 01:02:40,000 → 01:02:46,600  像私訊的問題回答還有Line群的問題回答都會幫你的物理數據倒流\n",
            "[ 83%] 01:02:46,600 → 01:02:49,000  這樣你要懂意思嗎\n",
            "[ 84%] 01:02:49,000 → 01:03:00,000  但我剛意思其實是說如果你要發物理的文章的話或什麼東西的話我覺得就是要有另外一個帳號\n",
            "[ 84%] 01:03:00,000 → 01:03:02,000  喔對啊確實\n",
            "[ 84%] 01:03:02,000 → 01:03:06,000  可是誰要來發物理的文章\n",
            "[ 84%] 01:03:06,000 → 01:03:08,000  你會想要發物理的文章嗎\n",
            "[ 84%] 01:03:08,000 → 01:03:10,000  如果我有寫的話\n",
            "[ 84%] 01:03:10,000 → 01:03:14,000  或者就是你之前不是說要做一些奇怪的實驗\n",
            "[ 84%] 01:03:14,000 → 01:03:16,000  所以我不知道你要做什麼實驗\n",
            "[ 84%] 01:03:16,000 → 01:03:20,000  喔對啊我之前不是有傳給你一個\n",
            "[ 84%] 01:03:20,000 → 01:03:23,000  你有看過這個嗎?\n",
            "[ 84%] 01:03:23,000 → 01:03:25,000  你有傳給我嗎?\n",
            "[ 84%] 01:03:25,000 → 01:03:28,000  我傳在 Slack 啦\n",
            "[ 84%] 01:03:28,000 → 01:03:30,000  就是我們會\n",
            "[ 84%] 01:03:30,000 → 01:03:33,000  如果是我幫你做內容的話\n",
            "[ 84%] 01:03:33,000 → 01:03:35,000  我理想上會是\n",
            "[ 85%] 01:03:35,000 → 01:03:37,000  我找一下那個\n",
            "[ 85%] 01:03:37,000 → 01:03:39,000  如果是專業的物理知識\n",
            "[ 85%] 01:03:39,000 → 01:03:41,000  就會是需要你來幫忙\n",
            "[ 85%] 01:03:40,000 → 01:03:45,000  如果是我們幫你做內容可能會做的比較類似這種\n",
            "[ 85%] 01:03:45,000 → 01:03:47,000  欸這個\n",
            "[ 85%] 01:03:51,000 → 01:03:53,000  喔我有看到這個\n",
            "[ 85%] 01:03:54,000 → 01:03:58,000  喔就只能做的比較娛樂化一點\n",
            "[ 85%] 01:03:59,000 → 01:04:00,000  然後再把你放寡\n",
            "[ 85%] 01:04:00,000 → 01:04:02,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:02,000 → 01:04:04,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:04,000 → 01:04:06,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:06,000 → 01:04:08,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:08,000 → 01:04:10,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:10,000 → 01:04:12,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:12,000 → 01:04:14,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:14,000 → 01:04:16,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:16,000 → 01:04:18,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:18,000 → 01:04:20,000  如果你是開一個全新的賬號\n",
            "[ 86%] 01:04:20,000 → 01:04:24,600  其實會需要有穩定的內容才處理\n",
            "[ 86%] 01:04:24,600 → 01:04:29,600  就是你可能不能是想到文章再發\n",
            "[ 86%] 01:04:29,600 → 01:04:33,000  然後我們這邊就會是需要\n",
            "[ 86%] 01:04:33,000 → 01:04:35,800  每次都就是幫你去做布林的帖文\n",
            "[ 86%] 01:04:40,000 → 01:05:00,000  如果是掛在英文上的話,有時候就可以像我之前有給你看單字數的ChangeGPT,有時候我覺得把那個ChangeGPT放在英文,然後讓它流傳下去的話,像現在的ChangeGPT就有三千多個對話,然後如果三千多個對話,每一次對話都會有三千多個對話,\n",
            "[ 86%] 01:05:00,000 → 01:05:02,000  如果有一個肯定的廣告的話\n",
            "[ 86%] 01:05:02,000 → 01:05:04,000  我覺得導流效果也蠻不錯的\n",
            "[ 86%] 01:05:04,000 → 01:05:06,000  所以這個可以再想想看\n",
            "[ 87%] 01:05:06,000 → 01:05:08,000  但如果你會希望\n",
            "[ 87%] 01:05:08,000 → 01:05:10,000  開個線上號\n",
            "[ 87%] 01:05:10,000 → 01:05:12,000  然後希望可以做一些\n",
            "[ 87%] 01:05:12,000 → 01:05:14,000  專門輸入的內容\n",
            "[ 87%] 01:05:14,000 → 01:05:16,000  我覺得也沒有問題\n",
            "[ 87%] 01:05:16,000 → 01:05:18,000  但是我們之後可以再一起把細節\n",
            "[ 87%] 01:05:18,000 → 01:05:20,000  就是我可以\n",
            "[ 87%] 01:05:20,000 → 01:05:22,500  直接先開帳號,然後可能先做做看\n",
            "[ 87%] 01:05:22,500 → 01:05:24,400  然後再告訴你有沒有困難的點\n",
            "[ 87%] 01:05:25,700 → 01:05:28,600  那如果你現在要發一個立刻的東西\n",
            "[ 87%] 01:05:28,600 → 01:05:29,800  你是要發在哪邊?\n",
            "[ 87%] 01:05:32,100 → 01:05:34,100  現在要發一個立刻的東西\n",
            "[ 87%] 01:05:34,800 → 01:05:38,100  就是如果你沒有打算再開一個行政帳號的話\n",
            "[ 87%] 01:05:38,700 → 01:05:40,100  啊,立刻的東西\n",
            "[ 88%] 01:05:40,000 → 01:05:59,380  我就會把他放在YouTube的影片,我會幫你講,然後再用IG去引導學生去YouTube的影片,然後會是IG行動,還有Threads的,在Threads上面我就不會教物理,而是我會直接\n",
            "[ 88%] 01:06:00,000 → 01:06:06,800  丟免費的工具給學生,然後讓那個免費的工具自己下去學生之間流傳。\n",
            "[ 88%] 01:06:06,800 → 01:06:16,360  比如說你的事業檔案,那就算是一種免費的工具。\n",
            "[ 88%] 01:06:16,360 → 01:06:17,240  大概理解。\n",
            "[ 88%] 01:06:20,000 → 01:06:27,000  還有你的商品掛在蝦皮機就會有一定的流量\n",
            "[ 88%] 01:06:27,000 → 01:06:33,000  因為我們賣場也會有既定的客源進來\n",
            "[ 89%] 01:06:33,000 → 01:06:38,000  還有LINE群\n",
            "[ 89%] 01:06:38,000 → 01:06:40,000  LINE群會有選手喔\n",
            "[ 89%] 01:06:40,000 → 01:06:42,760  喔對之前有講到Live群\n",
            "[ 89%] 01:06:42,760 → 01:06:46,940  所以現在是有學生在問物理的問題嗎\n",
            "[ 89%] 01:06:46,940 → 01:06:48,360  還是還沒有\n",
            "[ 89%] 01:06:48,360 → 01:06:49,620  還沒有\n",
            "[ 89%] 01:06:49,620 → 01:06:55,740  可能我們也還沒有引導他們去問物理的\n",
            "[ 89%] 01:06:55,740 → 01:06:59,980  你現在有在這個群組\n",
            "[ 89%] 01:07:00,000 → 01:07:14,400  還有其他問題呢?\n",
            "[ 89%] 01:07:18,400 → 01:07:20,400  這部分應該就到這裡了\n",
            "[ 90%] 01:07:20,000 → 01:07:26,100  然後我提問一下,這是你的公司名稱嗎?\n",
            "[ 90%] 01:07:27,140 → 01:07:31,000  公司名稱是成學文教有限公司,\n",
            "[ 90%] 01:07:31,600 → 01:07:33,840  陰謀比較像是品牌名稱。\n",
            "[ 90%] 01:07:33,840 → 01:07:36,540  所以那你的陰謀是申請商標嗎?\n",
            "[ 90%] 01:07:37,420 → 01:07:38,000  我是好奇。\n",
            "[ 90%] 01:07:40,000 → 01:07:42,000  喔好\n",
            "[ 90%] 01:07:42,000 → 01:07:45,820  你要搶住嗎\n",
            "[ 90%] 01:07:45,820 → 01:07:47,420  我都沒想到\n",
            "[ 90%] 01:07:47,420 → 01:07:49,880  惡意搶住\n",
            "[ 90%] 01:07:49,880 → 01:07:53,340  你是學了民法之後學壞了是不是\n",
            "[ 90%] 01:07:53,340 → 01:07:57,720  我好像記得有的是法律系\n",
            "[ 90%] 01:07:57,720 → 01:08:00,000  我是法律系\n",
            "[ 90%] 01:08:00,000 → 01:08:05,000  好\n",
            "[ 91%] 01:08:05,000 → 01:08:07,700  那應該沒有其他問題耶\n",
            "[ 91%] 01:08:07,700 → 01:08:08,940  好\n",
            "[ 91%] 01:08:08,940 → 01:08:10,620  你應該沒有\n",
            "[ 91%] 01:08:10,620 → 01:08:12,160  打算先註冊對吧\n",
            "[ 91%] 01:08:12,160 → 01:08:12,660  沒有沒有\n",
            "[ 91%] 01:08:12,660 → 01:08:13,460  OKOK\n",
            "[ 91%] 01:08:13,460 → 01:08:15,180  有點麻煩\n",
            "[ 91%] 01:08:15,180 → 01:08:16,300  沒有想要做這種事\n",
            "[ 91%] 01:08:20,000 → 01:08:28,000  如果沒有的話,我們今天會先到這邊喔。\n",
            "[ 91%] 01:08:28,000 → 01:08:30,000  好。\n",
            "[ 91%] 01:08:30,000 → 01:08:32,000  好,辛苦了,謝謝你。\n",
            "[ 91%] 01:08:32,000 → 01:08:34,000  掰掰。\n",
            "[ 91%] 01:08:34,000 → 01:08:36,000  掰掰。\n",
            "[ 91%] 01:08:40,000 → 01:08:49,860  我要影片嗎?想要影片?\n",
            "[ 91%] 01:08:50,000 → 01:08:51,440  我有,好,我再傳\n",
            "[ 92%] 01:08:51,440 → 01:08:53,280  做完可以改AI\n",
            "[ 92%] 01:08:53,280 → 01:08:54,060  OK\n",
            "[ 92%] 01:08:54,060 → 01:08:57,760  為什麼我媽留著?\n",
            "[ 92%] 01:08:57,860 → 01:08:59,320  我媽有什麼事情要討論嗎?\n",
            "[ 92%] 01:09:00,000 → 01:09:02,000  沒有啊\n",
            "[ 92%] 01:09:02,000 → 01:09:04,000  那我先撤囉\n",
            "[ 92%] 01:09:04,000 → 01:09:05,000  好嘞\n",
            "[ 92%] 01:09:05,000 → 01:09:08,000  我會去玩國粹職之後再去你那邊喔\n",
            "[ 92%] 01:09:08,000 → 01:09:09,000  好喔沒問題\n",
            "[ 92%] 01:09:09,000 → 01:09:10,000  你就直接進來就好\n",
            "[ 92%] 01:09:10,000 → 01:09:11,000  我會穿褲子\n",
            "[ 92%] 01:09:11,000 → 01:09:12,000  好掰掰\n",
            "[ 92%] 01:09:12,000 → 01:09:14,000  好掰掰\n",
            "[ 92%] 01:09:16,000 → 01:09:17,000  拜啦老孫\n",
            "[ 92%] 01:09:17,000 → 01:09:19,000  你剛聽起來有什麼問題嗎\n",
            "[ 92%] 01:09:20,000 → 01:09:26,000  沒有,但是我想到有很嚴重的事情要做\n",
            "[ 92%] 01:09:26,000 → 01:09:27,400  你說?\n",
            "[ 92%] 01:09:27,400 → 01:09:32,240  就是那個那個那個那個常常需要驗證的問題\n",
            "[ 92%] 01:09:32,240 → 01:09:35,760  我們現在把它解決掉了嘛\n",
            "[ 92%] 01:09:35,760 → 01:09:37,360  會很久嗎?\n",
            "[ 93%] 01:09:37,360 → 01:09:39,960  不會不會\n",
            "[ 93%] 01:09:40,000 → 01:09:50,000  比較就是我開個分享的分享分享\n",
            "[ 93%] 01:09:50,000 → 01:09:54,000  我的IG快快的\n",
            "[ 93%] 01:09:54,000 → 01:09:58,000  你的IG快快的\n",
            "[ 93%] 01:09:58,000 → 01:10:00,000  等一下你說\n",
            "[ 93%] 01:10:00,000 → 01:10:19,940  我來新增一下,因為目前都是要發去你的手機,然後\n",
            "[ 93%] 01:10:20,000 → 01:10:23,000  你的手機去做驗證嗎?\n",
            "[ 94%] 01:10:23,000 → 01:10:24,000  嗯\n",
            "[ 94%] 01:10:24,000 → 01:10:29,000  對 然後我是想說就是我們直接來進入這個\n",
            "[ 94%] 01:10:29,000 → 01:10:33,000  就是我們直接弄一個這個動態驗證嘛\n",
            "[ 94%] 01:10:33,000 → 01:10:34,000  就是它可以\n",
            "[ 94%] 01:10:34,000 → 01:10:35,000  原來我們有這個東西啊\n",
            "[ 94%] 01:10:35,000 → 01:10:36,000  蛤?\n",
            "[ 94%] 01:10:36,000 → 01:10:38,000  我們有這個東西啊\n",
            "[ 94%] 01:10:38,000 → 01:10:40,000  你們有這個東西\n",
            "[ 94%] 01:10:40,000 → 01:10:44,000  不是不是不是 不是我們有動態驗證碼\n",
            "[ 94%] 01:10:44,000 → 01:10:48,000  你們有動態驗證碼 可是我在帳號裡面沒看到你\n",
            "[ 94%] 01:10:48,000 → 01:10:52,000  因為我們是綁openai跟ig消息\n",
            "[ 94%] 01:10:52,000 → 01:10:56,000  那你這個要不要綁一下 可以可以 四十嗎\n",
            "[ 94%] 01:10:56,000 → 01:11:00,000  不然我每次半夜在搞東西\n",
            "[ 94%] 01:11:00,000 → 01:11:02,000  都會卡住\n",
            "[ 94%] 01:11:02,000 → 01:11:04,000  好有嗎?\n",
            "[ 94%] 01:11:04,000 → 01:11:06,000  有啊它進去了\n",
            "[ 94%] 01:11:06,000 → 01:11:08,000  等等等\n",
            "[ 95%] 01:11:08,000 → 01:11:10,000  那我現在新增一個然後截圖給你們\n",
            "[ 95%] 01:11:10,000 → 01:11:12,000  沒有好等一下我直接\n",
            "[ 95%] 01:11:12,000 → 01:11:14,000  我只新增\n",
            "[ 95%] 01:11:14,000 → 01:11:16,000  沒有我是截個圖啊\n",
            "[ 95%] 01:11:16,000 → 01:11:18,000  它不是會一直跑嗎?\n",
            "[ 95%] 01:11:18,000 → 01:11:20,000  它一直都會跑啊\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  沒有沒有這個不會\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  這個圖不會\n",
            "[ 95%] 01:11:22,000 → 01:11:24,000  這個圖不會 為什麼\n",
            "[ 95%] 01:11:24,000 → 01:11:26,000  因為它跑的不是這個圖\n",
            "[ 95%] 01:11:26,000 → 01:11:28,000  它跑的是這個圖裡面有精藥\n",
            "[ 95%] 01:11:28,000 → 01:11:30,000  然後它會根據這個精藥\n",
            "[ 95%] 01:11:30,000 → 01:11:32,000  加上時間\n",
            "[ 95%] 01:11:32,000 → 01:11:34,000  那個數字不是一直都會跑嗎\n",
            "[ 95%] 01:11:34,000 → 01:11:36,000  對 但是這個圖不會跑\n",
            "[ 95%] 01:11:38,000 → 01:11:40,000  對 它是用這個圖加上時間去\n",
            "[ 95%] 01:11:40,000 → 01:11:42,000  你去算出那個數字\n",
            "[ 95%] 01:11:42,000 → 01:11:44,000  這樣這樣\n",
            "[ 95%] 01:11:45,120 → 01:11:47,120  那我要放在notion裡面了\n",
            "[ 95%] 01:11:48,580 → 01:11:50,580  這樣會太危險嗎\n",
            "[ 95%] 01:11:50,580 → 01:11:52,580  你直接幫我查個指名好不好\n",
            "[ 96%] 01:11:54,840 → 01:11:56,840  等等等等等等\n",
            "[ 96%] 01:11:56,840 → 01:11:58,840  等等喔\n",
            "[ 96%] 01:11:58,840 → 01:12:00,840  我要建個頻道\n",
            "[ 96%] 01:12:00,000 → 01:12:02,000  你用平常名稱叫什麼?\n",
            "[ 96%] 01:12:04,000 → 01:12:06,000  工程部門\n",
            "[ 96%] 01:12:15,000 → 01:12:18,000  為什麼你現在用的那個Gmail是你自己的嗎?\n",
            "[ 96%] 01:12:18,000 → 01:12:20,000  你幫我貼在那個工程部門\n",
            "[ 97%] 01:12:20,000 → 01:12:40,000  我哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋\n",
            "[ 97%] 01:12:40,000 → 01:12:40,840  還是你本來就有在用?\n",
            "[ 97%] 01:12:40,840 → 01:12:41,340  沒有啊\n",
            "[ 97%] 01:12:42,000 → 01:12:43,840  那是我的主力帳號啊\n",
            "[ 97%] 01:12:43,840 → 01:12:45,160  因為這個帳號\n",
            "[ 97%] 01:12:45,160 → 01:12:46,460  幼稚園的時候就創了\n",
            "[ 97%] 01:12:46,460 → 01:12:48,500  所以那個名字是亂打的\n",
            "[ 97%] 01:12:49,340 → 01:12:50,000  打動了\n",
            "[ 97%] 01:12:55,800 → 01:12:58,500  啊你剛剛那個婚姻紀錄有開完嗎?\n",
            "[ 97%] 01:12:58,840 → 01:12:59,340  你有打動嗎?\n",
            "[ 97%] 01:12:59,340 → 01:12:59,840  有有有\n",
            "[ 97%] 01:13:00,000 → 01:13:04,600  你可能要跟他講一下那個東西是幹嘛的\n",
            "[ 97%] 01:13:04,600 → 01:13:09,700  就是你傳到工程部門那個東西是幹嘛的\n",
            "[ 97%] 01:13:09,700 → 01:13:10,760  他可能不太知道\n",
            "[ 97%] 01:13:10,760 → 01:13:14,520  他拿iPhone還安儲\n",
            "[ 97%] 01:13:14,520 → 01:13:16,060  他拿iPhone\n",
            "[ 98%] 01:13:20,000 → 01:13:24,000  好了,我們要去尿尿,然後我要出發了,bye!\n",
            "[ 98%] 01:13:25,280 → 01:13:25,520  好\n",
            "[ 98%] 01:13:25,520 → 01:13:29,780  下午的會議如果需要你,我再call你進來可以嗎?\n",
            "[ 98%] 01:13:34,400 → 01:13:35,080  可以嗎?\n",
            "[ 98%] 01:13:37,020 → 01:13:39,540  哇,那我怎麼知道你什麼時候要call我進來?\n",
            "[ 98%] 01:13:40,000 → 01:13:42,800  好吧,那你就去忙,你就去做你自己的生意\n",
            "[ 98%] 01:13:42,800 → 01:13:43,800  如果你剛好有\n",
            "[ 98%] 01:13:43,800 → 01:13:45,600  我可以進來沒關係啊\n",
            "[ 98%] 01:13:45,600 → 01:13:47,100  好,那你就順便停\n",
            "[ 98%] 01:13:47,100 → 01:13:49,140  OK,好,Bye\n",
            "[ 98%] 01:13:49,140 → 01:13:52,360  2點啊,2點到4點\n",
            "[ 98%] 01:13:52,360 → 01:13:53,180  好\n",
            "[ 98%] 01:13:53,180 → 01:13:53,840  再見\n",
            "[ 99%] 01:14:00,000 → 01:14:29,980  Teksting av Nicolai Winther\n",
            "[ 99%] 01:14:20,000 → 01:14:49,980  Takk for att du så med.\n",
            "[100%] 01:14:40,000 → 01:15:09,980  Teksting av Nicolai Winther\n",
            "[100%] 01:15:00,000 → 01:15:29,980  Teksting av Nicolai Winther\n",
            "[8/8] 輸出 SRT / TXT ...\n",
            "→ 完成！\n",
            "  SRT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).srt\n",
            "  TXT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01d270dbeee74c69807db8c6edc37af3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_load_from_file_impl: using device CUDA0 (Tesla T4) - 14974 MiB free\n",
            "llama_model_loader: loaded meta data with 37 key-value pairs and 459 tensors from /root/.cache/huggingface/hub/models--unsloth--gpt-oss-20b-GGUF/snapshots/c6cedd4259adbfe7e4d4d983a0400bf4cc38e7db/gpt-oss-20b-Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gpt-oss\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   3:                           general.basename str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   4:                       general.quantized_by str              = Unsloth\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 20B\n",
            "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
            "llama_model_loader: - kv   7:                           general.repo_url str              = https://huggingface.co/unsloth\n",
            "llama_model_loader: - kv   8:                               general.tags arr[str,2]       = [\"vllm\", \"text-generation\"]\n",
            "llama_model_loader: - kv   9:                        gpt-oss.block_count u32              = 24\n",
            "llama_model_loader: - kv  10:                     gpt-oss.context_length u32              = 131072\n",
            "llama_model_loader: - kv  11:                   gpt-oss.embedding_length u32              = 2880\n",
            "llama_model_loader: - kv  12:                gpt-oss.feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  13:               gpt-oss.attention.head_count u32              = 64\n",
            "llama_model_loader: - kv  14:            gpt-oss.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  15:                     gpt-oss.rope.freq_base f32              = 150000.000000\n",
            "llama_model_loader: - kv  16:   gpt-oss.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  17:                       gpt-oss.expert_count u32              = 32\n",
            "llama_model_loader: - kv  18:                  gpt-oss.expert_used_count u32              = 4\n",
            "llama_model_loader: - kv  19:               gpt-oss.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  20:             gpt-oss.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  21:           gpt-oss.attention.sliding_window u32              = 128\n",
            "llama_model_loader: - kv  22:         gpt-oss.expert_feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  23:                  gpt-oss.rope.scaling.type str              = yarn\n",
            "llama_model_loader: - kv  24:                gpt-oss.rope.scaling.factor f32              = 32.000000\n",
            "llama_model_loader: - kv  25: gpt-oss.rope.scaling.original_context_length u32              = 4096\n",
            "llama_model_loader: - kv  26:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  27:                         tokenizer.ggml.pre str              = gpt-4o\n",
            "llama_model_loader: - kv  28:                      tokenizer.ggml.tokens arr[str,201088]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  29:                  tokenizer.ggml.token_type arr[i32,201088]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  30:                      tokenizer.ggml.merges arr[str,446189]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  31:                tokenizer.ggml.bos_token_id u32              = 199998\n",
            "llama_model_loader: - kv  32:                tokenizer.ggml.eos_token_id u32              = 200002\n",
            "llama_model_loader: - kv  33:            tokenizer.ggml.padding_token_id u32              = 200017\n",
            "llama_model_loader: - kv  34:                    tokenizer.chat_template str              = {# Chat template fixes by Unsloth #}\\n...\n",
            "llama_model_loader: - kv  35:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  36:                          general.file_type u32              = 15\n",
            "llama_model_loader: - type  f32:  289 tensors\n",
            "llama_model_loader: - type q5_0:   61 tensors\n",
            "llama_model_loader: - type q8_0:   13 tensors\n",
            "llama_model_loader: - type q4_K:   24 tensors\n",
            "llama_model_loader: - type mxfp4:   72 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 10.81 GiB (4.44 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 200017 '<|reserved_200017|>' is not marked as EOG\n",
            "load: control token: 200014 '<|reserved_200014|>' is not marked as EOG\n",
            "load: control token: 200011 '<|reserved_200011|>' is not marked as EOG\n",
            "load: control token: 200009 '<|reserved_200009|>' is not marked as EOG\n",
            "load: control token: 200008 '<|message|>' is not marked as EOG\n",
            "load: control token: 200006 '<|start|>' is not marked as EOG\n",
            "load: control token: 200004 '<|reserved_200004|>' is not marked as EOG\n",
            "load: control token: 200003 '<|constrain|>' is not marked as EOG\n",
            "load: control token: 200000 '<|reserved_200000|>' is not marked as EOG\n",
            "load: control token: 200005 '<|channel|>' is not marked as EOG\n",
            "load: control token: 200010 '<|reserved_200010|>' is not marked as EOG\n",
            "load: control token: 200016 '<|reserved_200016|>' is not marked as EOG\n",
            "load: control token: 200013 '<|reserved_200013|>' is not marked as EOG\n",
            "load: control token: 199998 '<|startoftext|>' is not marked as EOG\n",
            "load: control token: 200018 '<|endofprompt|>' is not marked as EOG\n",
            "load: control token: 200001 '<|reserved_200001|>' is not marked as EOG\n",
            "load: control token: 200015 '<|reserved_200015|>' is not marked as EOG\n",
            "load: printing all EOG tokens:\n",
            "load:   - 199999 ('<|endoftext|>')\n",
            "load:   - 200002 ('<|return|>')\n",
            "load:   - 200007 ('<|end|>')\n",
            "load:   - 200012 ('<|call|>')\n",
            "load: special_eog_ids contains both '<|return|>' and '<|call|>' tokens, removing '<|end|>' token from EOG list\n",
            "load: special tokens cache size = 21\n",
            "load: token to piece cache size = 1.3332 MB\n",
            "print_info: arch             = gpt-oss\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 131072\n",
            "print_info: n_embd           = 2880\n",
            "print_info: n_layer          = 24\n",
            "print_info: n_head           = 64\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 64\n",
            "print_info: n_swa            = 128\n",
            "print_info: is_swa_any       = 1\n",
            "print_info: n_embd_head_k    = 64\n",
            "print_info: n_embd_head_v    = 64\n",
            "print_info: n_gqa            = 8\n",
            "print_info: n_embd_k_gqa     = 512\n",
            "print_info: n_embd_v_gqa     = 512\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 2880\n",
            "print_info: n_expert         = 32\n",
            "print_info: n_expert_used    = 4\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 2\n",
            "print_info: rope scaling     = yarn\n",
            "print_info: freq_base_train  = 150000.0\n",
            "print_info: freq_scale_train = 0.03125\n",
            "print_info: n_ctx_orig_yarn  = 4096\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = ?B\n",
            "print_info: model params     = 20.91 B\n",
            "print_info: general.name     = Gpt-Oss-20B\n",
            "print_info: n_ff_exp         = 2880\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 201088\n",
            "print_info: n_merges         = 446189\n",
            "print_info: BOS token        = 199998 '<|startoftext|>'\n",
            "print_info: EOS token        = 200002 '<|return|>'\n",
            "print_info: EOT token        = 199999 '<|endoftext|>'\n",
            "print_info: PAD token        = 200017 '<|reserved_200017|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 199999 '<|endoftext|>'\n",
            "print_info: EOG token        = 200002 '<|return|>'\n",
            "print_info: EOG token        = 200012 '<|call|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   1 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   3 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   5 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   7 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   9 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  11 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  13 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  15 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  17 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  19 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  21 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  23 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q5_0) (and 0 others) cannot be used with preferred buffer type CUDA_Host, using CPU instead\n",
            "load_tensors: offloading 24 repeating layers to GPU\n",
            "load_tensors: offloading output layer to GPU\n",
            "load_tensors: offloaded 25/25 layers to GPU\n",
            "load_tensors:        CUDA0 model buffer size = 10694.15 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =   379.71 MiB\n",
            "...............................................................................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 8192\n",
            "llama_context: n_ctx_per_seq = 8192\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 150000.0\n",
            "llama_context: freq_scale    = 0.03125\n",
            "llama_context: n_ctx_per_seq (8192) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:  CUDA_Host  output buffer size =     0.77 MiB\n",
            "create_memory: n_ctx = 8192 (padded)\n",
            "llama_kv_cache_unified_iswa: using full-size SWA cache (ref: https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)\n",
            "llama_kv_cache_unified_iswa: creating non-SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: skipped\n",
            "llama_kv_cache_unified: layer   1: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   2: skipped\n",
            "llama_kv_cache_unified: layer   3: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   4: skipped\n",
            "llama_kv_cache_unified: layer   5: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   6: skipped\n",
            "llama_kv_cache_unified: layer   7: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   8: skipped\n",
            "llama_kv_cache_unified: layer   9: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  10: skipped\n",
            "llama_kv_cache_unified: layer  11: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  12: skipped\n",
            "llama_kv_cache_unified: layer  13: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  14: skipped\n",
            "llama_kv_cache_unified: layer  15: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  16: skipped\n",
            "llama_kv_cache_unified: layer  17: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  18: skipped\n",
            "llama_kv_cache_unified: layer  19: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  20: skipped\n",
            "llama_kv_cache_unified: layer  21: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  22: skipped\n",
            "llama_kv_cache_unified: layer  23: dev = CUDA0\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_kv_cache_unified_iswa: creating     SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   1: skipped\n",
            "llama_kv_cache_unified: layer   2: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   3: skipped\n",
            "llama_kv_cache_unified: layer   4: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   5: skipped\n",
            "llama_kv_cache_unified: layer   6: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   7: skipped\n",
            "llama_kv_cache_unified: layer   8: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   9: skipped\n",
            "llama_kv_cache_unified: layer  10: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  11: skipped\n",
            "llama_kv_cache_unified: layer  12: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  13: skipped\n",
            "llama_kv_cache_unified: layer  14: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  15: skipped\n",
            "llama_kv_cache_unified: layer  16: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  17: skipped\n",
            "llama_kv_cache_unified: layer  18: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  19: skipped\n",
            "llama_kv_cache_unified: layer  20: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  21: skipped\n",
            "llama_kv_cache_unified: layer  22: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  23: skipped\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 2\n",
            "llama_context: max_nodes = 3672\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "llama_context:      CUDA0 compute buffer size =  1087.26 MiB\n",
            "llama_context:  CUDA_Host compute buffer size =    41.64 MiB\n",
            "llama_context: graph nodes  = 1446\n",
            "llama_context: graph splits = 2\n",
            "CUDA : ARCHS = 500,520,530,600,610,620,700,720,750,800,860,870,890,900 | FORCE_MMQ = 1 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'general.file_type': '15', 'general.quantization_version': '2', 'tokenizer.chat_template': '{# Chat template fixes by Unsloth #}\\n{#-\\n  In addition to the normal inputs of `messages` and `tools`, this template also accepts the\\n  following kwargs:\\n  - \"builtin_tools\": A list, can contain \"browser\" and/or \"python\".\\n  - \"model_identity\": A string that optionally describes the model identity.\\n  - \"reasoning_effort\": A string that describes the reasoning effort, defaults to \"medium\".\\n #}\\n\\n{#- Tool Definition Rendering ============================================== #}\\n{%- macro render_typescript_type(param_spec, required_params, is_nullable=false) -%}\\n    {%- if param_spec.type == \"array\" -%}\\n        {%- if param_spec[\\'items\\'] -%}\\n            {%- if param_spec[\\'items\\'][\\'type\\'] == \"string\" -%}\\n                {{- \"string[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"number\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"integer\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"boolean\" -%}\\n                {{- \"boolean[]\" }}\\n            {%- else -%}\\n                {%- set inner_type = render_typescript_type(param_spec[\\'items\\'], required_params) -%}\\n                {%- if inner_type == \"object | object\" or inner_type|length > 50 -%}\\n                    {{- \"any[]\" }}\\n                {%- else -%}\\n                    {{- inner_type + \"[]\" }}\\n                {%- endif -%}\\n            {%- endif -%}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- else -%}\\n            {{- \"any[]\" }}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type is defined and param_spec.type is iterable and param_spec.type is not string and param_spec.type is not mapping and param_spec.type[0] is defined -%}\\n        {#- Handle array of types like [\"object\", \"object\"] from Union[dict, list] #}\\n        {%- if param_spec.type | length > 1 -%}\\n            {{- param_spec.type | join(\" | \") }}\\n        {%- else -%}\\n            {{- param_spec.type[0] }}\\n        {%- endif -%}\\n    {%- elif param_spec.oneOf -%}\\n        {#- Handle oneOf schemas - check for complex unions and fallback to any #}\\n        {%- set has_object_variants = false -%}\\n        {%- for variant in param_spec.oneOf -%}\\n            {%- if variant.type == \"object\" -%}\\n                {%- set has_object_variants = true -%}\\n            {%- endif -%}\\n        {%- endfor -%}\\n        {%- if has_object_variants and param_spec.oneOf|length > 1 -%}\\n            {{- \"any\" }}\\n        {%- else -%}\\n            {%- for variant in param_spec.oneOf -%}\\n                {{- render_typescript_type(variant, required_params) -}}\\n                {%- if variant.description %}\\n                    {{- \"// \" + variant.description }}\\n                {%- endif -%}\\n                {%- if variant.default is defined %}\\n                    {{ \"// default: \" + variant.default|tojson }}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \" | \" }}\\n                {% endif -%}\\n            {%- endfor -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"string\" -%}\\n        {%- if param_spec.enum -%}\\n            {{- \\'\"\\' + param_spec.enum|join(\\'\" | \"\\') + \\'\"\\' -}}\\n        {%- else -%}\\n            {{- \"string\" }}\\n            {%- if param_spec.nullable %}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"number\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"integer\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"boolean\" -%}\\n        {{- \"boolean\" }}\\n\\n    {%- elif param_spec.type == \"object\" -%}\\n        {%- if param_spec.properties -%}\\n            {{- \"{\\\\n\" }}\\n            {%- for prop_name, prop_spec in param_spec.properties.items() -%}\\n                {{- prop_name -}}\\n                {%- if prop_name not in (param_spec.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{ render_typescript_type(prop_spec, param_spec.required or []) }}\\n                {%- if not loop.last -%}\\n                    {{-\", \" }}\\n                {%- endif -%}\\n            {%- endfor -%}\\n            {{- \"}\" }}\\n        {%- else -%}\\n            {{- \"object\" }}\\n        {%- endif -%}\\n    {%- else -%}\\n        {{- \"any\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{%- macro render_tool_namespace(namespace_name, tools) -%}\\n    {{- \"## \" + namespace_name + \"\\\\n\\\\n\" }}\\n    {{- \"namespace \" + namespace_name + \" {\\\\n\\\\n\" }}\\n    {%- for tool in tools %}\\n        {%- set tool = tool.function %}\\n        {{- \"// \" + tool.description + \"\\\\n\" }}\\n        {{- \"type \"+ tool.name + \" = \" }}\\n        {%- if tool.parameters and tool.parameters.properties %}\\n            {{- \"(_: {\\\\n\" }}\\n            {%- for param_name, param_spec in tool.parameters.properties.items() %}\\n                {%- if param_spec.description %}\\n                    {{- \"// \" + param_spec.description + \"\\\\n\" }}\\n                {%- endif %}\\n                {{- param_name }}\\n                {%- if param_name not in (tool.parameters.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{- render_typescript_type(param_spec, tool.parameters.required or []) }}\\n                {%- if param_spec.default is defined -%}\\n                    {%- if param_spec.enum %}\\n                        {{- \", // default: \" + param_spec.default }}\\n                    {%- elif param_spec.oneOf %}\\n                        {{- \"// default: \" + param_spec.default }}\\n                    {%- else %}\\n                        {{- \", // default: \" + param_spec.default|tojson }}\\n                    {%- endif -%}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \",\\\\n\" }}\\n                {%- else %}\\n                    {{- \",\\\\n\" }}\\n                {%- endif -%}\\n            {%- endfor %}\\n            {{- \"}) => any;\\\\n\\\\n\" }}\\n        {%- else -%}\\n            {{- \"() => any;\\\\n\\\\n\" }}\\n        {%- endif -%}\\n    {%- endfor %}\\n    {{- \"} // namespace \" + namespace_name }}\\n{%- endmacro -%}\\n\\n{%- macro render_builtin_tools(browser_tool, python_tool) -%}\\n    {%- if browser_tool %}\\n        {{- \"## browser\\\\n\\\\n\" }}\\n        {{- \"// Tool for browsing.\\\\n\" }}\\n        {{- \"// The `cursor` appears in brackets before each browsing display: `[{cursor}]`.\\\\n\" }}\\n        {{- \"// Cite information from the tool using the following format:\\\\n\" }}\\n        {{- \"// `【{cursor}†L{line_start}(-L{line_end})?】`, for example: `【6†L9-L11】` or `【8†L3】`.\\\\n\" }}\\n        {{- \"// Do not quote more than 10 words directly from the tool output.\\\\n\" }}\\n        {{- \"// sources=web (default: web)\\\\n\" }}\\n        {{- \"namespace browser {\\\\n\\\\n\" }}\\n        {{- \"// Searches for information related to `query` and displays `topn` results.\\\\n\" }}\\n        {{- \"type search = (_: {\\\\n\" }}\\n        {{- \"query: string,\\\\n\" }}\\n        {{- \"topn?: number, // default: 10\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Opens the link `id` from the page indicated by `cursor` starting at line number `loc`, showing `num_lines` lines.\\\\n\" }}\\n        {{- \"// Valid link ids are displayed with the formatting: `【{id}†.*】`.\\\\n\" }}\\n        {{- \"// If `cursor` is not provided, the most recent page is implied.\\\\n\" }}\\n        {{- \"// If `id` is a string, it is treated as a fully qualified URL associated with `source`.\\\\n\" }}\\n        {{- \"// If `loc` is not provided, the viewport will be positioned at the beginning of the document or centered on the most relevant passage, if available.\\\\n\" }}\\n        {{- \"// Use this function without `id` to scroll to a new location of an opened page.\\\\n\" }}\\n        {{- \"type open = (_: {\\\\n\" }}\\n        {{- \"id?: number | string, // default: -1\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"loc?: number, // default: -1\\\\n\" }}\\n        {{- \"num_lines?: number, // default: -1\\\\n\" }}\\n        {{- \"view_source?: boolean, // default: false\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Finds exact matches of `pattern` in the current page, or the page given by `cursor`.\\\\n\" }}\\n        {{- \"type find = (_: {\\\\n\" }}\\n        {{- \"pattern: string,\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"} // namespace browser\\\\n\\\\n\" }}\\n    {%- endif -%}\\n\\n    {%- if python_tool %}\\n        {{- \"## python\\\\n\\\\n\" }}\\n        {{- \"Use this tool to execute Python code in your chain of thought. The code will not be shown to the user. This tool should be used for internal reasoning, but not for code that is intended to be visible to the user (e.g. when creating plots, tables, or files).\\\\n\\\\n\" }}\\n        {{- \"When you send a message containing Python code to python, it will be executed in a stateful Jupyter notebook environment. python will respond with the output of the execution or time out after 120.0 seconds. The drive at \\'/mnt/data\\' can be used to save and persist user files. Internet access for this session is UNKNOWN. Depends on the cluster.\\\\n\\\\n\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- System Message Construction ============================================ #}\\n{%- macro build_system_message() -%}\\n    {%- if model_identity is not defined %}\\n        {%- set model_identity = \"You are ChatGPT, a large language model trained by OpenAI.\" %}\\n    {%- endif %}\\n    {{- model_identity + \"\\\\n\" }}\\n    {{- \"Knowledge cutoff: 2024-06\\\\n\" }}\\n    {{- \"Current date: \" + strftime_now(\"%Y-%m-%d\") + \"\\\\n\\\\n\" }}\\n    {%- if reasoning_effort is not defined %}\\n        {%- set reasoning_effort = \"medium\" %}\\n    {%- endif %}\\n    {{- \"Reasoning: \" + reasoning_effort + \"\\\\n\\\\n\" }}\\n    {%- if builtin_tools is defined and builtin_tools is not none %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {%- set available_builtin_tools = namespace(browser=false, python=false) %}\\n        {%- for tool in builtin_tools %}\\n            {%- if tool == \"browser\" %}\\n                {%- set available_builtin_tools.browser = true %}\\n            {%- elif tool == \"python\" %}\\n                {%- set available_builtin_tools.python = true %}\\n            {%- endif %}\\n        {%- endfor %}\\n        {{- render_builtin_tools(available_builtin_tools.browser, available_builtin_tools.python) }}\\n    {%- endif -%}\\n    {{- \"# Valid channels: analysis, commentary, final. Channel must be included for every message.\" }}\\n    {%- if tools -%}\\n        {{- \"\\\\nCalls to these tools must go to the commentary channel: \\'functions\\'.\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- Main Template Logic ================================================= #}\\n{#- Set defaults #}\\n\\n{#- Render system message #}\\n{{- \"<|start|>system<|message|>\" }}\\n{{- build_system_message() }}\\n{{- \"<|end|>\" }}\\n\\n{#- Extract developer message #}\\n{%- if developer_instructions is defined and developer_instructions is not none %}\\n    {%- set developer_message = developer_instructions %}\\n    {%- set loop_messages = messages %}\\n{%- elif messages[0].role == \"developer\" or messages[0].role == \"system\" %}\\n    {%- set developer_message = messages[0].content %}\\n    {%- set loop_messages = messages[1:] %}\\n{%- else %}\\n    {%- set developer_message = \"\" %}\\n    {%- set loop_messages = messages %}\\n{%- endif %}\\n\\n{#- Render developer message #}\\n{%- if developer_message or tools %}\\n    {{- \"<|start|>developer<|message|>\" }}\\n    {%- if developer_message %}\\n        {{- \"# Instructions\\\\n\\\\n\" }}\\n        {{- developer_message }}\\n    {%- endif %}\\n    {%- if tools -%}\\n        {%- if developer_message %}\\n            {{- \"\\\\n\\\\n\" }}\\n        {%- endif %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {{- render_tool_namespace(\"functions\", tools) }}\\n    {%- endif -%}\\n    {{- \"<|end|>\" }}\\n{%- endif %}\\n\\n{#- Render messages #}\\n{%- set last_tool_call = namespace(name=none) %}\\n{%- for message in loop_messages -%}\\n    {#- At this point only assistant/user/tool messages should remain #}\\n    {%- if message.role == \\'assistant\\' -%}\\n        {#- Checks to ensure the messages are being passed in the format we expect #}\\n        {%- if \"thinking\" in message %}\\n            {%- if \"<|channel|>analysis<|message|>\" in message.thinking or \"<|channel|>final<|message|>\" in message.thinking %}\\n                {{- raise_exception(\"You have passed a message containing <|channel|> tags in the thinking field. Instead of doing this, you should pass analysis messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'thinking\\' field, and final messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'content\\' field.\") }}\\n            {%- endif %}\\n        {%- endif %}\\n        {%- if \"tool_calls\" in message %}\\n            {#- We need very careful handling here - we want to drop the tool call analysis message if the model #}\\n            {#- has output a later <|final|> message, but otherwise we want to retain it. This is the only case #}\\n            {#- when we render CoT/analysis messages in inference. #}\\n            {%- set future_final_message = namespace(found=false) %}\\n            {%- for future_message in loop_messages[loop.index:] %}\\n                {%- if future_message.role == \\'assistant\\' and \"tool_calls\" not in future_message %}\\n                    {%- set future_final_message.found = true %}\\n                {%- endif %}\\n            {%- endfor %}\\n            {#- We assume max 1 tool call per message, and so we infer the tool call name #}\\n            {#- in \"tool\" messages from the most recent assistant tool call name #}\\n            {%- set tool_call = message.tool_calls[0] %}\\n            {%- if tool_call.function %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {%- if message.content and message.thinking %}\\n                {{- raise_exception(\"Cannot pass both content and thinking in an assistant message with tool calls! Put the analysis message in one or the other, but not both.\") }}\\n            {%- elif message.content and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- elif message.thinking and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {{- \"<|start|>assistant to=\" }}\\n            {{- \"functions.\" + tool_call.name + \"<|channel|>commentary \" }}\\n            {{- (tool_call.content_type if tool_call.content_type is defined else \"json\") + \"<|message|>\" }}\\n            {%- if tool_call.arguments is string %}\\n                {{- tool_call.arguments }}\\n            {%- else %}\\n                {{- tool_call.arguments|tojson }}\\n            {%- endif %}\\n            {{- \"<|call|>\" }}\\n            {%- set last_tool_call.name = tool_call.name %}\\n        {%- elif loop.last and not add_generation_prompt %}\\n            {#- Only render the CoT if the final turn is an assistant turn and add_generation_prompt is false #}\\n            {#- This is a situation that should only occur in training, never in inference. #}\\n            {%- if \"thinking\" in message %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {#- <|return|> indicates the end of generation, but <|end|> does not #}\\n            {#- <|return|> should never be an input to the model, but we include it as the final token #}\\n            {#- when training, so the model learns to emit it. #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- elif \"thinking\" in message %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- else %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- endif %}\\n    {%- elif message.role == \\'tool\\' -%}\\n        {%- if last_tool_call.name is none %}\\n            {{- raise_exception(\"Message has tool role, but there was no previous assistant message with a tool call!\") }}\\n        {%- endif %}\\n        {{- \"<|start|>functions.\" + last_tool_call.name }}\\n        {%- if message.content is string %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- else %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content|tojson + \"<|end|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \\'user\\' -%}\\n        {{- \"<|start|>user<|message|>\" + message.content + \"<|end|>\" }}\\n    {%- endif -%}\\n{%- endfor -%}\\n\\n{#- Generation prompt #}\\n{%- if add_generation_prompt -%}\\n<|start|>assistant\\n{%- endif -%}\\n{# Copyright 2025-present Unsloth. Apache 2.0 License. Unsloth chat template fixes. Edited from ggml-org & OpenAI #}', 'gpt-oss.attention.head_count': '64', 'gpt-oss.rope.scaling.original_context_length': '4096', 'gpt-oss.feed_forward_length': '2880', 'general.repo_url': 'https://huggingface.co/unsloth', 'general.license': 'apache-2.0', 'general.size_label': '20B', 'general.type': 'model', 'tokenizer.ggml.padding_token_id': '200017', 'gpt-oss.context_length': '131072', 'general.quantized_by': 'Unsloth', 'gpt-oss.embedding_length': '2880', 'gpt-oss.block_count': '24', 'gpt-oss.attention.sliding_window': '128', 'tokenizer.ggml.pre': 'gpt-4o', 'general.architecture': 'gpt-oss', 'gpt-oss.rope.freq_base': '150000.000000', 'gpt-oss.attention.head_count_kv': '8', 'gpt-oss.attention.layer_norm_rms_epsilon': '0.000010', 'gpt-oss.expert_count': '32', 'general.basename': 'Gpt-Oss-20B', 'gpt-oss.attention.key_length': '64', 'gpt-oss.expert_used_count': '4', 'gpt-oss.expert_feed_forward_length': '2880', 'gpt-oss.rope.scaling.type': 'yarn', 'tokenizer.ggml.eos_token_id': '200002', 'gpt-oss.rope.scaling.factor': '32.000000', 'tokenizer.ggml.model': 'gpt2', 'general.name': 'Gpt-Oss-20B', 'gpt-oss.attention.value_length': '64', 'tokenizer.ggml.bos_token_id': '199998'}\n",
            "Available chat formats from metadata: chat_template.default\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**會議摘要**\n\n**1. 主要討論內容**  \n- 會議中提到「可再想想看」的方案，並未決定具體行動。  \n- 討討開設線上號、專門輸入內容之計畫，並確認無問題。  \n- 會議者提出將帳號先開，後續做實驗，並說「直接先開帳號」  \n- **重點：** 會議決定先開帳號，並以 YouTube、IG、Threads 等平台推廣  \n- **重點**： 其實務流程：先開帳號，先前往下列…  \n\n> …….  \nWe need to produce a concise summary of the transcript. The transcript is messy, but we need to extract key points: time, persons, tasks, conclusions, unresolved items, actions. Provide bullet list with headings. 500-900 Chinese characters? Actually 500-900 words? The instruction says 500–900 字 (characters). So we need about 500-900 Chinese characters. That's roughly 300-400 words. Provide bullet points.\n\nWe must avoid system messages, no brackets, no English. Use Chinese. Provide headings and bullet items. Ensure no extraneous commentary. Provide final answer. Let's craft.\n\nWe need to identify key participants: seems like speaker is \"Nicolai Winther\" maybe? Actually transcript includes \"Teksting av Nicolai Winther\". So maybe the speaker is Nicolai Winther. Also mention \"老孫\" etc. But we can just refer to \"會議者\".\n\nKey points:\n\n- They discuss opening an online account, possibly for a brand or company.\n- They plan to use YouTube, IG, Threads to promote content, free tools, etc.\n- They talk about using a free tool for students, maybe physics? They mention \"物理\" but not sure.\n- They mention \"成學文教有限公司\" as company name; \"陰謀\" maybe brand name; ask if trademark application.\n- They discuss registration of account, no plan to register now.\n- They talk about verifying dynamic verification code for phone, using OpenAI and IG messages.\n- They talk about building a channel, naming it \"工程部門\".\n- They mention Gmail account used is personal.\n- They talk about Notion integration.\n- They mention \"notion\" and \"Threads\" and \"IG\" etc.\n\nWe need to"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - 處理分段 1/5（~20.0%）\n",
            "    ↳ 分段 1 已產生字元：35\n",
            "    ↳ 分段 1 已產生字元：67\n",
            "    ↳ 分段 1 已產生字元：102\n",
            "    ↳ 分段 1 已產生字元：130\n",
            "    ↳ 分段 1 已產生字元：161\n",
            "    ↳ 分段 1 已產生字元：198\n",
            "    ↳ 分段 1 已產生字元：223\n",
            "    ↳ 分段 1 已產生字元：265\n",
            "    ↳ 分段 1 已產生字元：362\n",
            "    ↳ 分段 1 已產生字元：499\n",
            "    ↳ 分段 1 已產生字元：622\n",
            "    ↳ 分段 1 已產生字元：736\n",
            "    ↳ 分段 1 已產生字元：860\n",
            "    ↳ 分段 1 已產生字元：970\n",
            "    ↳ 分段 1 已產生字元：1086\n",
            "    ↳ 分段 1 已產生字元：1179\n",
            "    ↳ 分段 1 已產生字元：1279\n",
            "    ↳ 分段 1 已產生字元：1413\n",
            "    ↳ 分段 1 已產生字元：1527\n",
            "    ↳ 分段 1 已產生字元：1649\n",
            "    ↳ 分段 1 已產生字元：1764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6135.13 ms\n",
            "llama_perf_context_print: prompt eval time =    6134.27 ms /  3472 tokens (    1.77 ms per token,   566.00 tokens per second)\n",
            "llama_perf_context_print:        eval time =   13082.55 ms /   511 runs   (   25.60 ms per token,    39.06 tokens per second)\n",
            "llama_perf_context_print:       total time =   21907.98 ms /  3983 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 1 已產生字元：1767\n",
            "  - 處理分段 2/5（~40.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3358 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 2 已產生字元：35\n",
            "    ↳ 分段 2 已產生字元：61\n",
            "    ↳ 分段 2 已產生字元：89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6135.13 ms\n",
            "llama_perf_context_print: prompt eval time =    5171.98 ms /  3358 tokens (    1.54 ms per token,   649.27 tokens per second)\n",
            "llama_perf_context_print:        eval time =    2170.84 ms /    84 runs   (   25.84 ms per token,    38.69 tokens per second)\n",
            "llama_perf_context_print:       total time =    7826.09 ms /  3442 tokens\n",
            "llama_perf_context_print:    graphs reused =         81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 2 已產生字元：103\n",
            "  - 處理分段 3/5（~60.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3325 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 3 已產生字元：51\n",
            "    ↳ 分段 3 已產生字元：92\n",
            "    ↳ 分段 3 已產生字元：125\n",
            "    ↳ 分段 3 已產生字元：163\n",
            "    ↳ 分段 3 已產生字元：192\n",
            "    ↳ 分段 3 已產生字元：228\n",
            "    ↳ 分段 3 已產生字元：263\n",
            "    ↳ 分段 3 已產生字元：292\n",
            "    ↳ 分段 3 已產生字元：328\n",
            "    ↳ 分段 3 已產生字元：406\n",
            "    ↳ 分段 3 已產生字元：528\n",
            "    ↳ 分段 3 已產生字元：631\n",
            "    ↳ 分段 3 已產生字元：747\n",
            "    ↳ 分段 3 已產生字元：845\n",
            "    ↳ 分段 3 已產生字元：950\n",
            "    ↳ 分段 3 已產生字元：1054\n",
            "    ↳ 分段 3 已產生字元：1119\n",
            "    ↳ 分段 3 已產生字元：1159\n",
            "    ↳ 分段 3 已產生字元：1194\n",
            "    ↳ 分段 3 已產生字元：1230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6135.13 ms\n",
            "llama_perf_context_print: prompt eval time =    5114.01 ms /  3325 tokens (    1.54 ms per token,   650.17 tokens per second)\n",
            "llama_perf_context_print:        eval time =   13193.51 ms /   511 runs   (   25.82 ms per token,    38.73 tokens per second)\n",
            "llama_perf_context_print:       total time =   21227.07 ms /  3836 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 3 已產生字元：1259\n",
            "  - 處理分段 4/5（~80.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3387 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 4 已產生字元：39\n",
            "    ↳ 分段 4 已產生字元：76\n",
            "    ↳ 分段 4 已產生字元：165\n",
            "    ↳ 分段 4 已產生字元：282\n",
            "    ↳ 分段 4 已產生字元：383\n",
            "    ↳ 分段 4 已產生字元：483\n",
            "    ↳ 分段 4 已產生字元：602\n",
            "    ↳ 分段 4 已產生字元：716\n",
            "    ↳ 分段 4 已產生字元：818\n",
            "    ↳ 分段 4 已產生字元：937\n",
            "    ↳ 分段 4 已產生字元：1056\n",
            "    ↳ 分段 4 已產生字元：1138\n",
            "    ↳ 分段 4 已產生字元：1256\n",
            "    ↳ 分段 4 已產生字元：1379\n",
            "    ↳ 分段 4 已產生字元：1527\n",
            "    ↳ 分段 4 已產生字元：1643\n",
            "    ↳ 分段 4 已產生字元：1763\n",
            "    ↳ 分段 4 已產生字元：1883\n",
            "    ↳ 分段 4 已產生字元：1990\n",
            "    ↳ 分段 4 已產生字元：2112\n",
            "    ↳ 分段 4 已產生字元：2217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6135.13 ms\n",
            "llama_perf_context_print: prompt eval time =    5128.21 ms /  3387 tokens (    1.51 ms per token,   660.46 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12907.16 ms /   511 runs   (   25.26 ms per token,    39.59 tokens per second)\n",
            "llama_perf_context_print:       total time =   21037.48 ms /  3898 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 4 已產生字元：2257\n",
            "  - 處理分段 5/5（~100.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 141 prefix-match hit, remaining 1792 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 5 已產生字元：35\n",
            "    ↳ 分段 5 已產生字元：63\n",
            "    ↳ 分段 5 已產生字元：93\n",
            "    ↳ 分段 5 已產生字元：122\n",
            "    ↳ 分段 5 已產生字元：162\n",
            "    ↳ 分段 5 已產生字元：192\n",
            "    ↳ 分段 5 已產生字元：290\n",
            "    ↳ 分段 5 已產生字元：408\n",
            "    ↳ 分段 5 已產生字元：501\n",
            "    ↳ 分段 5 已產生字元：605\n",
            "    ↳ 分段 5 已產生字元：725\n",
            "    ↳ 分段 5 已產生字元：849\n",
            "    ↳ 分段 5 已產生字元：953\n",
            "    ↳ 分段 5 已產生字元：1026\n",
            "    ↳ 分段 5 已產生字元：1136\n",
            "    ↳ 分段 5 已產生字元：1234\n",
            "    ↳ 分段 5 已產生字元：1316\n",
            "    ↳ 分段 5 已產生字元：1426\n",
            "    ↳ 分段 5 已產生字元：1546\n",
            "    ↳ 分段 5 已產生字元：1649\n",
            "    ↳ 分段 5 已產生字元：1735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6135.13 ms\n",
            "llama_perf_context_print: prompt eval time =    2451.40 ms /  1792 tokens (    1.37 ms per token,   731.01 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12126.47 ms /   511 runs   (   23.73 ms per token,    42.14 tokens per second)\n",
            "llama_perf_context_print:       total time =   17479.75 ms /  2303 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 5 已產生字元：1752\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**會議筆記（Markdown，繁體）**\n\n---\n\n## 整體提要  \n- 會議主題為「開設線上號並推廣內容」；  \n- 主要平台包括 YouTube、IG、Threads；  \n- 討討使用免費工具與 AI 產生內容；  \n- 需確認帳號名稱、商標及資料保護；  \n- 會議決定先開帳號，後續實驗推廣策略。  \n\n---\n\n## 章節要點（含時間脈絡）\n\n| 時間 | 要點 |\n|------|------|\n| 0:00 | 會議者提到「可再想想看」的方案，未決定具體行動。 |\n| 0:05 | 討討開設線上號、專門輸入內容之計畫，並確認無問題。 |\n| 0:10 | 會議者提出將帳號先開，後續做實驗，說「直接先開帳號」。 |\n| 0:15 | 會議決定先開帳號，並以 YouTube、IG、Threads 等平台推廣。 |\n| 0:20 | 其實務流程：先開帳號，先前往下列…（未完整說明）。 |\n| 0:25 | 會議者提到「成學文教有限公司」與「陰謀」作為公司名，詢問是否已申請商標。 |\n| 0:30 | 會議者表示目前不打算註冊帳號，先以 Gmail 個人帳號做測試。 |\n| 0:35 | 會議者說明將使用 Notion、Threads、IG 等工具來管理與推廣內容。 |\n| 0:40 | 會議者提到「動態驗證碼」的流程，並說要用 OpenAI 及 IG 訊息確認。 |\n| 0:45 | 會議者說明將建立「工程部門」為頻道名稱。 |\n\n---\n\n## 可執行重點（具體待辦）\n\n- **開設線上號**：先以 Gmail 個人帳號做測試，後續正式註冊。  \n- **確認商標**：查詢「陰謀」是否已申請商標，並確保不侵權。  \n- **設定平台**：決定 YouTube、IG、Threads 為主要推廣平台。  \n- **管理工具**：整合 Notion 以管理內容與進度。  \n- **驗證流程**：使用 OpenAI 及 IG 訊息確認動態驗證碼。  \n- **頻道名稱**：確定「工程部門」為正式頻道名稱。  \n\n---"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 129 prefix-match hit, remaining 2330 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 彙整 已產生字元：43\n",
            "    ↳ 彙整 已產生字元：80\n",
            "    ↳ 彙整 已產生字元：122\n",
            "    ↳ 彙整 已產生字元：150\n",
            "    ↳ 彙整 已產生字元：189\n",
            "    ↳ 彙整 已產生字元：228\n",
            "    ↳ 彙整 已產生字元：258\n",
            "    ↳ 彙整 已產生字元：288\n",
            "    ↳ 彙整 已產生字元：315\n",
            "    ↳ 彙整 已產生字元：350\n",
            "    ↳ 彙整 已產生字元：388\n",
            "    ↳ 彙整 已產生字元：418\n",
            "    ↳ 彙整 已產生字元：447\n",
            "    ↳ 彙整 已產生字元：477\n",
            "    ↳ 彙整 已產生字元：511\n",
            "    ↳ 彙整 已產生字元：554\n",
            "    ↳ 彙整 已產生字元：586\n",
            "    ↳ 彙整 已產生字元：620\n",
            "    ↳ 彙整 已產生字元：658\n",
            "    ↳ 彙整 已產生字元：690\n",
            "    ↳ 彙整 已產生字元：721\n",
            "    ↳ 彙整 已產生字元：768\n",
            "    ↳ 彙整 已產生字元：810\n",
            "    ↳ 彙整 已產生字元：850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6135.13 ms\n",
            "llama_perf_context_print: prompt eval time =    3332.26 ms /  2330 tokens (    1.43 ms per token,   699.22 tokens per second)\n",
            "llama_perf_context_print:        eval time =   14874.84 ms /   606 runs   (   24.55 ms per token,    40.74 tokens per second)\n",
            "llama_perf_context_print:       total time =   21684.37 ms /  2936 tokens\n",
            "llama_perf_context_print:    graphs reused =        586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 彙整 已產生字元：878\n",
            "→ 完成 ✅  /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8)_summary.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ff01db2"
      },
      "source": [
        "## Refine developer options\n",
        "\n",
        "### Subtask:\n",
        "Keep the developer options section separate within the code, clearly commented.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0b4bb8a"
      },
      "source": [
        "**Reasoning**:\n",
        "Ensure the developer options are clearly commented and separated, verifying all intended parameters are included.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2522ae85bd99479a95953834e70aa67d",
            "60d250c7936a42fc8a22eaf8e1554412",
            "908b949fc9df47cca76fdf38b7265f3a",
            "8f320e06792d4826980b9102f129b5d5",
            "cc8daa865afb45d5b2e091fe5399baa3",
            "683d373a753e4812861b0d55886fdf78",
            "e2f3b6838bbf4c57a130874e3b0faeb0",
            "103313f38c444e3a864dab25bb327e9f",
            "a05bfdec839349a8b72e4e41e78060a3",
            "7f7248dc94704d50a054e704d67b7e54",
            "be36a527b6eb41cfaa37bfea98ad38c5"
          ]
        },
        "id": "9db05e8e",
        "outputId": "efb1c88f-f2e4-47a5-8ae5-d42ae0d49554"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Whisper Automatic Subtitle Generation: GPU Transcription + CPU Denoising + OpenCC Post-processing (Traditional/Simplified Conversion)\n",
        "# And LLM Summarization (GPT-OSS-20B / llama.cpp / CUDA)\n",
        "# - Transcription: faster-whisper (CUDA, compute: int8_float16→float16→int8)\n",
        "# - Denoising: ffmpeg afftdn (CPU)\n",
        "# - Progress: Real-time printing of \"current sentence + video total length percentage\"\n",
        "# - Network source download and output: MyDrive/whisper; Files in Drive: Output to the same folder\n",
        "# - LLM Summary: llama.cpp + GPT-OSS-20B GGUF for summarizing transcription\n",
        "# - Prompts \"Delete runtime and restart\" if download is blocked or abnormal\n",
        "# =========================================================\n",
        "\n",
        "# Restrict multithreading (more stable)\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# [1/8] Mount Google Drive\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "except:\n",
        "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "# Consolidated Imports\n",
        "import sys, gc, shutil, datetime, subprocess as sp\n",
        "from pathlib import Path\n",
        "import re, math, time, importlib, textwrap\n",
        "from typing import List, Tuple\n",
        "from IPython.display import display, Markdown\n",
        "import soundfile as sf\n",
        "from faster_whisper import WhisperModel\n",
        "from opencc import OpenCC\n",
        "import srt as _srt # Import srt as _srt to avoid name conflict later with the module itself\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "ROOT = Path(\"/content/gdrive/MyDrive\")\n",
        "WHISPER_DIR = ROOT / \"whisper\"\n",
        "WHISPER_DIR.mkdir(exist_ok=True, parents=True)\n",
        "os.chdir(ROOT)\n",
        "print(f\"→ 當前工作目錄：{os.getcwd()}\")\n",
        "\n",
        "# [2/8] User Form Parameters (Unified)\n",
        "#@markdown # Whisper Transcription & LLM Summary Pipeline\n",
        "\n",
        "#@markdown ## Input & Transcription Settings\n",
        "#@markdown **Input Source:** Google Drive file (relative to MyDrive) or video URL (YouTube/HTTP).\n",
        "filename = \"whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\"  #@param {type:\"string\"}\n",
        "#@markdown **Download Option:** Check to save network source files to `MyDrive/whisper`.\n",
        "save_video_to_google_drive = True  #@param {type:\"boolean\"}\n",
        "#@markdown **Whisper Model Size:** Choose a model size. `large-v3` requires more GPU VRAM; `medium` is a good alternative if VRAM is limited.\n",
        "model_size = \"large-v3\"  #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\"]\n",
        "#@markdown **Language:** Select the language for transcription. \"自動偵測\" (Auto-detect) is usually sufficient.\n",
        "language = \"自動偵測\"  #@param [\"自動偵測\", \"中文\", \"英文\"]\n",
        "#@markdown **Denoising:** Apply CPU-based denoising to the audio before transcription. `afftdn` is recommended.\n",
        "denoise_method = \"afftdn (建議)\"  #@param [\"afftdn (建議)\", \"none\"]\n",
        "#@markdown **Text Post-processing (OpenCC):** Convert the transcribed text (SRT/TXT output) between Simplified and Traditional Chinese variants.\n",
        "text_postprocess = \"臺灣繁體中文（預設）\"  #@param [\"臺灣繁體中文（預設）\",\"香港繁體中文\",\"大陸簡體中文\",\"關閉\"]\n",
        "#@markdown **YouTube Cookies (Optional):** Path to a Netscape-format cookies file (relative to MyDrive) for accessing age-restricted or member-only YouTube videos (e.g., `cookies/youtube.txt`).\n",
        "youtube_cookies_txt_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Summarization Settings\n",
        "#@markdown **SRT Input:** Path to the SRT file for summarization (relative to MyDrive or absolute). Leave empty to use the SRT generated by the transcription step above.\n",
        "summary_srt_path = \"\"  #@param {type:\"string\"}\n",
        "#@markdown **Topic Hint (Optional):** Provide a brief hint about the topic to guide the summarization process.\n",
        "topic_hint = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Output Paths\n",
        "#@markdown **Transcription Output Directory:** Directory where the generated SRT and TXT files will be saved (relative to MyDrive or absolute). Default is the input file's directory for local files, or `MyDrive/whisper` for network sources. This is determined automatically.\n",
        "# (Note: filename's directory is used if local, otherwise WHISPER_DIR. This parameter is more of an indicator of the default output base.)\n",
        "#@markdown **Summary Output Directory:** Directory where the final summary Markdown file will be saved (relative to MyDrive or absolute).\n",
        "summary_output_dir = \"/content/gdrive/MyDrive/whisper\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "language_code_map = {\"自動偵測\": None, \"中文\":\"zh\", \"英文\":\"en\"}\n",
        "language_code = language_code_map[language]\n",
        "\n",
        "# =========================================================\n",
        "# Developer Options\n",
        "# Advanced users can fine-tune parameters in this section.\n",
        "# Modify only if you understand the impact.\n",
        "# =========================================================\n",
        "DEBUG_MODE = False # Set to True for more detailed logging\n",
        "\n",
        "# --- Transcription Parameters ---\n",
        "TRANSCRIPTION_BEAM_SIZE_PRIMARY = 3\n",
        "TRANSCRIPTION_CHUNK_LENGTH_PRIMARY = 20\n",
        "TRANSCRIPTION_BEAM_SIZE_FALLBACK = 1 # Used if primary fails\n",
        "TRANSCRIPTION_CHUNK_LENGTH_FALLBACK = 15 # Used if primary fails\n",
        "\n",
        "# --- Denoising Parameters ---\n",
        "DENOISE_NOISE_FLOOR_DB = -25\n",
        "\n",
        "# --- Filtering Parameters ---\n",
        "FILTER_MIN_DURATION_SHORT = 1.5 # Minimum duration for short segments\n",
        "FILTER_AVG_LOGPROB_THRESHOLD = -1.0 # Avg log probability threshold for short segments\n",
        "FILTER_MIN_DURATION_SPEECH_PROB = 2.0 # Minimum duration for speech probability filtering\n",
        "FILTER_NO_SPEECH_PROB_THRESHOLD = 0.6 # No speech probability threshold\n",
        "\n",
        "# --- Summary Model Parameters ---\n",
        "REPO_ID   = \"unsloth/gpt-oss-20b-GGUF\"   # GGUF Model Repository\n",
        "GGUF_FILE = \"gpt-oss-20b-Q4_K_M.gguf\"    # Approx. 10.8GiB, T4 can run\n",
        "\n",
        "# --- Summary Inference Parameters (Increase available generation space to avoid truncation) ---\n",
        "ctx_window            = 8192\n",
        "map_max_new_tokens    = 512   # Segment output: original 256 -> 512 (approx. 350-450 chars)\n",
        "reduce_max_new_tokens = 1024  # Summary output: original 512 -> 1024 (approx. 700-900+ chars)\n",
        "temperature           = 0.2\n",
        "top_p                 = 0.9\n",
        "repeat_penalty        = 1.05\n",
        "# =========================================================\n",
        "# End of Developer Options\n",
        "# =========================================================\n",
        "\n",
        "\n",
        "# [3/8] Install Dependencies\n",
        "# Combine installation steps from both original cells\n",
        "if DEBUG_MODE: print(\"[Install] faster-whisper / yt-dlp / soundfile / opencc / srt / huggingface_hub / llama-cpp-python ...\")\n",
        "\n",
        "def pip_install(pkgs, extra_args=None, env=None):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"]\n",
        "    if extra_args:\n",
        "        cmd += extra_args\n",
        "    cmd += pkgs\n",
        "    return sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True, env=env)\n",
        "\n",
        "# Install common dependencies first\n",
        "common_missing = []\n",
        "try: import srt # check srt module directly after import as _srt\n",
        "except ModuleNotFoundError: common_missing.append(\"srt>=3.5.3\")\n",
        "try: from huggingface_hub import snapshot_download # check huggingface_hub module directly\n",
        "except ModuleNotFoundError: common_missing.append(\"huggingface_hub>=0.23.0\")\n",
        "try: import soundfile # check soundfile\n",
        "except ModuleNotFoundError: common_missing.append(\"soundfile\")\n",
        "try: import opencc # check opencc\n",
        "except ModuleNotFoundError: common_missing.append(\"opencc-python-reimplemented\")\n",
        "\n",
        "if common_missing:\n",
        "    if DEBUG_MODE: print(\"→ Installing common missing packages:\", \", \".join(common_missing))\n",
        "    r = pip_install(common_missing)\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"基礎依賴安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "# Install faster-whisper and yt-dlp separately as they were in the first cell\n",
        "try: from faster_whisper import WhisperModel # check faster_whisper\n",
        "except ModuleNotFoundError:\n",
        "    if DEBUG_MODE: print(\"→ Installing missing package: faster-whisper yt-dlp\")\n",
        "    r = pip_install([\"faster-whisper\", \"yt-dlp\"])\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"faster-whisper / yt-dlp 安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "\n",
        "def suggest_runtime_reset():\n",
        "    print(\"\\n🧹 建議動作（Colab）\")\n",
        "    print(\"1) 依序：『執行階段 Runtime』 → 『刪除執行階段/還原出廠設定 Factory reset runtime』\")\n",
        "    print(\"2) 重新執行本 Notebook（從掛載雲端硬碟那格開始）\\n\", flush=True)\n",
        "\n",
        "def run_cmd(cmd:list, check=True):\n",
        "    if DEBUG_MODE: print(\"  $\", \" \".join(cmd))\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"命令失敗：{' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "def is_youtube_url(s:str)->bool:\n",
        "    return isinstance(s, str) and (\"youtu.be\" in s or \"youtube.com\" in s)\n",
        "def is_http_url(s:str)->bool:\n",
        "    return isinstance(s, str) and s.lower().startswith(\"http\")\n",
        "def to_abs_mydrive(p:str)->Path:\n",
        "    return (Path(p) if p.startswith(\"/\") else (ROOT / p)).resolve()\n",
        "def fmt_ts_srt(t:float)->str:\n",
        "    h = int(t//3600); m = int((t%3600)//60); s = t - h*3600 - m*60\n",
        "    return f\"{h:02d}:{m:02d}:{int(s):02d},{int(round((s-int(s))*1000)):03d}\"\n",
        "def verify_wav_ok(path: Path)->bool:\n",
        "    try:\n",
        "        info = sf.info(str(path))\n",
        "        return info.samplerate > 0 and info.channels in (1, 2)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# OpenCC converter setup\n",
        "def build_opencc_pipeline(choice:str):\n",
        "    if choice.startswith(\"臺灣\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2tw')]\n",
        "    if choice.startswith(\"香港\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2hk')]\n",
        "    if choice.startswith(\"大陸\"):\n",
        "        return [OpenCC('t2s')]\n",
        "    return []  # Disable\n",
        "\n",
        "def apply_opencc(text:str, pipeline)->str:\n",
        "    for cc in pipeline:\n",
        "        text = cc.convert(text)\n",
        "    return text\n",
        "\n",
        "def ytdl(yturl:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting YouTube video ...\")\n",
        "    # Use sp.run instead of subprocess.run directly\n",
        "    cmd = [\"yt-dlp\", \"-f\", \"mp4\", \"-o\", str(tmp / \"%(title)s.%(ext)s\")]\n",
        "    if youtube_cookies_txt_path.strip():\n",
        "        cookies_abs = to_abs_mydrive(youtube_cookies_txt_path.strip())\n",
        "        if cookies_abs.exists():\n",
        "            cmd += [\"--cookies\", str(cookies_abs)]\n",
        "        else:\n",
        "            if DEBUG_MODE: print(f\"⚠️ 找不到 cookies 檔：{cookies_abs}（改為不帶 cookies）\")\n",
        "    cmd.append(yturl)\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        if \"Sign in to confirm\" in (p.stdout or \"\"):\n",
        "            print(\"\\n❗YouTube 要求登入/驗證，請提供 cookies 或先自行下載到雲端硬碟。\")\n",
        "        print(\"🔄 若多次失敗，請刪除執行階段並重啟後重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise RuntimeError(\"yt-dlp 下載失敗\")\n",
        "    files = list(tmp.glob(\"*\"))\n",
        "    if not files:\n",
        "        print(\"🔄 下載為空，建議刪除執行階段再重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise FileNotFoundError(\"YouTube 下載失敗：/tmp/dl 為空\")\n",
        "    f = files[0]\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(f, WHISPER_DIR / f.name)\n",
        "    return f\n",
        "\n",
        "def http_dl(url:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting HTTP(S) video ...\")\n",
        "    run_cmd([\"curl\", \"-L\", \"-o\", str(out), url])\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(out, WHISPER_DIR / out.name)\n",
        "    return out\n",
        "\n",
        "# Extract audio: ffmpeg -> 16k/mono WAV\n",
        "def ffmpeg_extract_wav(in_path:Path, out_wav:Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-vn\",\"-ac\",\"1\",\"-ar\",str(sr),\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 轉 WAV 失敗\")\n",
        "\n",
        "# CPU Denoising: ffmpeg afftdn\n",
        "def ffmpeg_afftdn(in_wav: Path, out_wav: Path, noise_floor_db=DENOISE_NOISE_FLOOR_DB):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-af\",f\"afftdn=nf={noise_floor_db}\",\n",
        "           \"-ac\",\"1\",\"-ar\",\"16000\",\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg afftdn 失敗\")\n",
        "\n",
        "# Safeguard: Repack WAV header if format is strange\n",
        "def ffmpeg_repack_wav(in_wav: Path, out_wav: Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-acodec\",\"pcm_s16le\",\"-ac\",\"1\",\"-ar\",str(sr),str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 重包 WAV 失敗\")\n",
        "\n",
        "# [4/8] Parse Source (Transcription) - Uses 'filename' and 'save_video_to_google_drive'\n",
        "if DEBUG_MODE: print(\"[4/8] Parsing input source ...\")\n",
        "try:\n",
        "    if is_youtube_url(filename):\n",
        "        src_path = ytdl(filename); out_base_dir = WHISPER_DIR\n",
        "    elif is_http_url(filename):\n",
        "        src_path = http_dl(filename); out_base_dir = WHISPER_DIR\n",
        "    else:\n",
        "        src_path = to_abs_mydrive(filename)\n",
        "        if not src_path.exists(): raise FileNotFoundError(f\"找不到檔案：{src_path}\")\n",
        "        out_base_dir = src_path.parent\n",
        "except Exception as e:\n",
        "    print(f\"\\n⛔ 來源解析/下載失敗：{e}\")\n",
        "    print(\"🔄 請刪除執行階段並重新啟動後重跑。\"); suggest_runtime_reset(); raise\n",
        "\n",
        "print(f\"→ 來源檔：{src_path}\")\n",
        "print(f\"→ 輸出資料夾：{out_base_dir}\")\n",
        "\n",
        "# [5/8] Extract Audio & CPU Denoising (Transcription) - Uses 'denoise_method' and 'DENOISE_NOISE_FLOOR_DB'\n",
        "AUDIO_16K = Path(\"/tmp/audio_16k.wav\")\n",
        "if DEBUG_MODE: print(\"[5/8] Extracting audio (ffmpeg → 16k/mono WAV) ...\")\n",
        "ffmpeg_extract_wav(src_path, AUDIO_16K, sr=16000)\n",
        "\n",
        "if denoise_method.startswith(\"afftdn\"):\n",
        "    if DEBUG_MODE: print(\"[5.5/8] Denoising (ffmpeg afftdn, CPU) ...\")\n",
        "    DENOISED = Path(\"/tmp/audio_16k_denoised.wav\")\n",
        "    ffmpeg_afftdn(AUDIO_16K, DENOISED, noise_floor_db=DENOISE_NOISE_FLOOR_DB)\n",
        "    denoised_audio = DENOISED if verify_wav_ok(DENOISED) else AUDIO_16K\n",
        "else:\n",
        "    denoised_audio = AUDIO_16K\n",
        "\n",
        "if not verify_wav_ok(denoised_audio):\n",
        "    if DEBUG_MODE: print(\"  - 音訊格式異常；嘗試重包 WAV ...\")\n",
        "    FIXED = Path(\"/tmp/audio_16k_fixed.wav\")\n",
        "    ffmpeg_repack_wav(denoised_audio, FIXED, sr=16000)\n",
        "    denoised_audio = FIXED\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ 最終輸入音訊：{denoised_audio}\")\n",
        "\n",
        "# [6/8] Load faster-whisper (GPU enforced) - Uses 'model_size'\n",
        "if DEBUG_MODE: print(\"[6/8] Loading faster-whisper model (GPU) ...\")\n",
        "device = \"cuda\"  # Enforce GPU\n",
        "model = None; last_err = None\n",
        "for ctype in [\"int8_float16\", \"float16\", \"int8\"]:\n",
        "    try:\n",
        "        if DEBUG_MODE: print(f\"  - Trying compute_type={ctype}\")\n",
        "        model = WhisperModel(model_size, device=device, compute_type=ctype)\n",
        "        if DEBUG_MODE: print(\"  - Model loaded successfully\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        last_err = e\n",
        "        if DEBUG_MODE: print(f\"  - Load failed: {e}\")\n",
        "if model is None:\n",
        "    print(\"\\n⛔ GPU 模型載入失敗。請確認『變更執行階段類型』選了 GPU（T4/A100），或刪除執行階段後重試。\")\n",
        "    suggest_runtime_reset()\n",
        "    raise RuntimeError(f\"無法載入模型：{last_err}\")\n",
        "\n",
        "gc.collect()  # Clean up before transcription (safety)\n",
        "\n",
        "# [7/8] Transcribe (GPU; real-time progress per segment) - Uses 'language_code', 'TRANSCRIPTION_BEAM_SIZE_PRIMARY', 'TRANSCRIPTION_CHUNK_LENGTH_PRIMARY', 'TRANSCRIPTION_BEAM_SIZE_FALLBACK', 'TRANSCRIPTION_CHUNK_LENGTH_FALLBACK'\n",
        "if DEBUG_MODE: print(f\"[7/8] Starting transcription (GPU: beam={TRANSCRIPTION_BEAM_SIZE_PRIMARY} / chunk={TRANSCRIPTION_CHUNK_LENGTH_PRIMARY}s / no VAD) ...\")\n",
        "\n",
        "def transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY):\n",
        "    return model.transcribe(\n",
        "        str(denoised_audio),\n",
        "        task=\"transcribe\",\n",
        "        language=language_code,\n",
        "        temperature=0.0,\n",
        "        condition_on_previous_text=False,\n",
        "        compression_ratio_threshold=2.4,\n",
        "        log_prob_threshold=-1.0,\n",
        "        no_speech_threshold=0.6,\n",
        "        beam_size=_beam,\n",
        "        chunk_length=_chunk,\n",
        "        vad_filter=False,\n",
        "        word_timestamps=False\n",
        "    )\n",
        "\n",
        "try:\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY)\n",
        "except Exception as e:\n",
        "    if DEBUG_MODE: print(f\"  - First transcription failed: {e}\\n    → Trying more conservative (beam={TRANSCRIPTION_BEAM_SIZE_FALLBACK}, chunk={TRANSCRIPTION_CHUNK_LENGTH_FALLBACK}) ...\")\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_FALLBACK, _chunk=TRANSCRIPTION_CHUNK_LENGTH_FALLBACK)\n",
        "\n",
        "# Display percentage based on total video duration\n",
        "duration = float(getattr(info, \"duration\", 0.0) or 0.0)\n",
        "if duration <= 0: duration = 1.0\n",
        "\n",
        "segments = []\n",
        "filtered = []\n",
        "\n",
        "if DEBUG_MODE:\n",
        "    print(f\"  - Detected language: {getattr(info,'language','未知')} (p={getattr(info,'language_probability',0):.2f})\")\n",
        "    print(f\"  - Audio length: {duration:.2f}s\")\n",
        "\n",
        "for s in seg_iter:\n",
        "    pct = int(min(100, round((s.end / duration) * 100)))\n",
        "    print(f\"[{pct:3d}%] {fmt_ts_srt(s.start)} → {fmt_ts_srt(s.end)}  {s.text.strip()}\", flush=True)\n",
        "    segments.append(s)\n",
        "\n",
        "    # Low confidence/high no-speech short segment filtering (no blacklist) - Uses FILTER_* parameters\n",
        "    keep = True\n",
        "    seg_dur = float(s.end - s.start)\n",
        "    if seg_dur < FILTER_MIN_DURATION_SHORT and getattr(s, \"avg_logprob\", None) is not None and s.avg_logprob < FILTER_AVG_LOGPROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if seg_dur < FILTER_MIN_DURATION_SPEECH_PROB and getattr(s, \"no_speech_prob\", None) is not None and s.no_speech_prob > FILTER_NO_SPEECH_PROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if keep:\n",
        "        filtered.append(s)\n",
        "\n",
        "if DEBUG_MODE: print(f\"  - Number of segments: Before filtering {len(segments)} → After filtering {len(filtered)}\")\n",
        "\n",
        "# ---- OpenCC Normalization (for output text) ---- - Uses 'text_postprocess'\n",
        "pipeline = build_opencc_pipeline(text_postprocess)\n",
        "def norm(txt: str) -> str:\n",
        "    return apply_opencc(txt, pipeline) if pipeline else txt\n",
        "\n",
        "# [8/8] Output (text after OpenCC) - Uses 'out_base_dir' (derived from 'filename')\n",
        "print(\"[8/8] 輸出 SRT / TXT ...\")\n",
        "out_dir = out_base_dir; out_dir.mkdir(exist_ok=True, parents=True)\n",
        "stem = src_path.stem\n",
        "SRT = out_dir / f\"{stem}.srt\"; TXT = out_dir / f\"{stem}.txt\"\n",
        "\n",
        "with open(SRT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, s in enumerate(filtered, 1):\n",
        "        text_out = norm(s.text.strip())\n",
        "        f.write(f\"{i}\\n{fmt_ts_srt(s.start)} --> {fmt_ts_srt(s.end)}\\n{text_out}\\n\\n\")\n",
        "\n",
        "with open(TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in filtered:\n",
        "        f.write(norm(s.text.strip()) + \"\\n\")  # Each segment on a new line\n",
        "\n",
        "print(f\"→ 完成！\\n  SRT: {SRT}\\n  TXT: {TXT}\")\n",
        "\n",
        "# Release model (release GPU memory)\n",
        "try: del model\n",
        "except: pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"→ Model released; can run again directly if needed.\")\n",
        "\n",
        "\n",
        "# ===== Summarization Logic Starts Here =====\n",
        "\n",
        "# Determine the SRT input path for summarization - Uses 'summary_srt_path' and 'SRT' from transcription\n",
        "if not summary_srt_path:\n",
        "    summary_srt_path_abs = SRT # Use the SRT path generated by the transcription\n",
        "    if DEBUG_MODE: print(f\"Using SRT from transcription step: {summary_srt_path_abs}\")\n",
        "else:\n",
        "    summary_srt_path_abs = to_abs_mydrive(summary_srt_path)\n",
        "\n",
        "\n",
        "# ===== Summary 1/6) Check GPU and Install Dependencies (llama-cpp-python specific) =====\n",
        "# llama-cpp-python installation logic - Keep this separate as it has specific CUDA requirements\n",
        "if DEBUG_MODE: print(\"[Summary 1/6] Checking GPU and installing llama-cpp-python ...\")\n",
        "\n",
        "def detect_cuda_tag():\n",
        "    try:\n",
        "        out = sp.check_output([\"nvidia-smi\"], text=True)\n",
        "        m = re.search(r\"CUDA Version:\\s*([\\d.]+)\", out)\n",
        "        if not m:\n",
        "            return \"cu124\"\n",
        "        major, minor = [int(x) for x in m.group(1).split(\".\")[:2]]\n",
        "        if major > 12 or (major == 12 and minor >= 5):\n",
        "            return \"cu125\"\n",
        "        return \"cu124\"\n",
        "    except Exception:\n",
        "        return \"cu124\"\n",
        "\n",
        "cuda_tag = detect_cuda_tag()\n",
        "if DEBUG_MODE: print(f\"GPU 0: Detected CUDA version tag {cuda_tag}\")\n",
        "\n",
        "def try_import_llama():\n",
        "    try:\n",
        "        from llama_cpp import Llama\n",
        "        return Llama\n",
        "    except ModuleNotFoundError:\n",
        "        return None\n",
        "\n",
        "Llama = try_import_llama()\n",
        "if Llama is None:\n",
        "    # Keep your existing installation strategy: extra-index -> fallback to source compilation on failure\n",
        "    candidates = [cuda_tag, \"cu125\", \"cu124\", \"cu122\", \"cu121\"]\n",
        "    ok = False\n",
        "    for tag in candidates:\n",
        "        idx = f\"https://abetlen.github.io/llama-cpp-python/whl/{tag}\"\n",
        "        if DEBUG_MODE: print(f\"→ Attempting to install llama-cpp-python ({tag}) ...\")\n",
        "        r = pip_install([\"llama-cpp-python\"], extra_args=[\"--extra-index-url\", idx])\n",
        "        if r.returncode == 0:\n",
        "            Llama = try_import_llama()\n",
        "            if Llama is not None:\n",
        "                ok = True\n",
        "                break\n",
        "        else:\n",
        "            if DEBUG_MODE: print(\"  ✗ Installation failed (summary):\", \"\\n\".join(r.stdout.splitlines()[-5:]))\n",
        "    if not ok:\n",
        "        if DEBUG_MODE: print(\"→ Pre-compiled wheels not available, switching to 'source compilation (CUDA=ON)' ... (takes longer)\")\n",
        "        try:\n",
        "            import ninja # noqa: F401 # Import ninja to check if installed\n",
        "        except ModuleNotFoundError:\n",
        "            if DEBUG_MODE: print(\"→ Installing missing package: ninja\")\n",
        "            r = pip_install([\"ninja\"])\n",
        "            if r.returncode != 0:\n",
        "                if DEBUG_MODE: print(r.stdout)\n",
        "                raise RuntimeError(\"安裝 ninja 失敗。請重啟後重試。\")\n",
        "        env = os.environ.copy()\n",
        "        env[\"CMAKE_ARGS\"] = \"-DGGML_CUDA=on -DLLAMA_CUBLAS=on\"\n",
        "        env[\"FORCE_CMAKE\"] = \"1\"\n",
        "        r = pip_install([\"llama-cpp-python\"], env=env)\n",
        "        if r.returncode != 0:\n",
        "            if DEBUG_MODE: print(r.stdout)\n",
        "            raise RuntimeError(\"無法安裝 GPU 版 llama-cpp-python。\")\n",
        "        Llama = try_import_llama()\n",
        "\n",
        "# ===== Summary 2/6) Read SRT (Summary) - Uses 'summary_srt_path_abs'\n",
        "if DEBUG_MODE: print(\"[Summary 2/6] Reading SRT ...\")\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "with open(summary_srt_path_abs, \"r\", encoding=\"utf-8\") as f:\n",
        "    srt_text = f.read()\n",
        "subs = list(_srt.parse(srt_text)) # Use _srt as srt module was imported as _srt\n",
        "def td2s(td): return td.total_seconds()\n",
        "segments = []\n",
        "for it in subs:\n",
        "    txt = it.content.strip()\n",
        "    if not txt: continue\n",
        "    segments.append((td2s(it.start), td2s(it.end), txt))\n",
        "total_secs = (segments[-1][1] - segments[0][0]) if segments else 0\n",
        "if DEBUG_MODE: print(f\"→ Number of subtitle segments: {len(segments)}；Video length (est): {total_secs/60:.1f} minutes\")\n",
        "\n",
        "\n",
        "# ===== Summary 3/6) Download and Load GGUF Model (Summary) - Uses summary model parameters (REPO_ID, GGUF_FILE, ctx_window, etc.)\n",
        "if DEBUG_MODE: print(\"[Summary 3/6] Loading GPT-OSS-20B (GGUF, CUDA) ...\")\n",
        "local_repo = snapshot_download(REPO_ID, allow_patterns=[GGUF_FILE])\n",
        "gguf_path = str(Path(local_repo)/GGUF_FILE)\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=gguf_path,\n",
        "    n_ctx=ctx_window,\n",
        "    n_gpu_layers=-1,\n",
        "    seed=0,\n",
        "    logits_all=False,\n",
        "    verbose=True,          # Display the actual chat format used\n",
        "    chat_format=\"chatml\",  # Directly override the GGUF built-in Unsloth template to avoid outputting <|channel|> tags\n",
        ")\n",
        "if DEBUG_MODE: print(\"→ Model loaded successfully (GPU)\")\n",
        "\n",
        "# ===== Summary 4/6) Token-aware Segmentation (Summary) - Uses ctx_window, map_max_new_tokens, prompt_overhead\n",
        "if DEBUG_MODE: print(\"[Summary 4/6] Generating segments (token-aware; single segment ≤ safety limit) ...\")\n",
        "\n",
        "def count_tokens_text(text: str) -> int:\n",
        "    return len(llm.tokenize(text.encode(\"utf-8\")))\n",
        "\n",
        "SYSTEM_INSTR = (\n",
        "  \"你是一個會議總結機器人。根據使用者提供的逐字稿（可能雜訊、重複、錯字），\"\n",
        "  \"請去除雜訊與重複、嚴守事實、不腦補。遇到不明確資訊以「待補充／未明確」標註。\"\n",
        "  \"輸出為 Markdown（繁體中文），不要輸出任何系統／思考標記。\"\n",
        ")\n",
        "\n",
        "# — Segment Summary Prompt: More concise request, avoid verbosity and system language - Uses 'topic_hint'\n",
        "MAP_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是逐字稿片段（非完整全文）：\n",
        "{chunk}\n",
        "\n",
        "請就此片段輸出「條列式重點摘要」（500–900 字，繁體中文），注意：\n",
        "- 只寫最終內容，不要寫解題想法、不要出現任何系統提示或中英括號標記。\n",
        "- 聚焦可驗證事實（時間、人物、任務、結論、未決事項、行動）。\n",
        "- 結構：可用小標題＋項目符號，語句務必短、準確、無贅詞。\n",
        "\"\"\")\n",
        "\n",
        "# — Summary Prompt: Maintain your three-section output structure - Uses 'topic_hint'\n",
        "REDUCE_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是所有片段的重點摘要彙整（仍可能有重疊）：\n",
        "{maps}\n",
        "\n",
        "請整合為一份會議筆記（Markdown，繁體）：\n",
        "1) **整體提要**（3–6 句，避免冗言）\n",
        "2) **章節要點（含時間脈絡）**：條列呈現，每點一行，可附粗略時間\n",
        "3) **可執行重點**：具體待辦（每條以動詞開頭）\n",
        "請只輸出最終筆記，不要出現系統或思考標記，不要加入未出現的新資訊。\n",
        "\"\"\")\n",
        "\n",
        "# Single segment token budget (reserve space for prompt and generation)\n",
        "prompt_overhead = 700\n",
        "chunk_target    = max(1024, min(3072, ctx_window - prompt_overhead - map_max_new_tokens))\n",
        "\n",
        "chunks: List[Tuple[float,float,str]] = []\n",
        "buf, t0, t1, cur = [], None, None, 0\n",
        "for (s, e, txt) in segments:\n",
        "    t = count_tokens_text(txt)\n",
        "    if not buf:\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "        continue\n",
        "    if cur + t <= chunk_target:\n",
        "        buf.append(txt); t1 = e; cur += t\n",
        "    else:\n",
        "        chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "if buf:\n",
        "    chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ Generated {len(chunks)} segments (target ~{chunk_target} tokens per segment)\")\n",
        "\n",
        "# ===== Common: Streaming Tools (No regex cleaning; use correct stop sequence) - Uses temperature, top_p, repeat_penalty, map_max_new_tokens, reduce_max_new_tokens\n",
        "def llm_stream(messages, max_tokens):\n",
        "    # ChatML messages end with <|im_end|>; use stop to cut off, preventing the closing tag from being written to the file\n",
        "    gen = llm.create_chat_completion(\n",
        "        messages=messages,\n",
        "        temperature=float(temperature),\n",
        "        top_p=float(top_p),\n",
        "        repeat_penalty=float(repeat_penalty),\n",
        "        max_tokens=int(max_tokens),\n",
        "        stream=True,\n",
        "        stop=[\"<|im_end|>\"],  # Key: Prevent outputting the ending template\n",
        "    )\n",
        "    for ev in gen:\n",
        "        # Compatible with different fields\n",
        "        piece = \"\"\n",
        "        try:\n",
        "            piece = ev[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "        except Exception:\n",
        "            piece = ev[\"choices\"][0].get(\"text\", \"\")\n",
        "        if piece:\n",
        "            yield piece\n",
        "\n",
        "# ===== Summary 5/6) Segment Summary (map) - Uses map_max_new_tokens, ctx_window, prompt_overhead, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 5/6] Segment summarization (map) ...\")\n",
        "live = display(Markdown(\"\"), display_id=True)\n",
        "maps: List[str] = []\n",
        "\n",
        "for i, (s, e, body) in enumerate(chunks, 1):\n",
        "    pct = i / max(len(chunks),1) * 100\n",
        "    sys.stdout.write(f\"  - 處理分段 {i}/{len(chunks)}（~{pct:.1f}%）\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Shrink to safe budget before sending (prevent prompt+segment from exceeding window and causing model to terminate early)\n",
        "    budget_tokens = max(512, ctx_window - map_max_new_tokens - prompt_overhead)\n",
        "    def shrink_to_budget(text: str, budget_tokens: int) -> str:\n",
        "        cur = text\n",
        "        for _ in range(6):\n",
        "            if count_tokens_text(cur) <= budget_tokens:\n",
        "                return cur\n",
        "            keep = max(800, int(len(cur) * 0.85))\n",
        "            cur = cur[:keep]\n",
        "        return cur\n",
        "    body2 = shrink_to_budget(body, budget_tokens)\n",
        "\n",
        "    user_txt = MAP_USER_TMPL.format(topic=(topic_hint or \"（無）\"), chunk=body2)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n",
        "        {\"role\": \"user\",   \"content\": user_txt},\n",
        "    ]\n",
        "\n",
        "    part_buf = [] # Reset part_buf for each segment\n",
        "    for token in llm_stream(messages, map_max_new_tokens):\n",
        "        part_buf.append(token)\n",
        "        # Update live display and terminal character count periodically\n",
        "        if len(part_buf) % 24 == 0:\n",
        "            cur_txt = \"\".join(part_buf)\n",
        "            live.update(Markdown(cur_txt))\n",
        "            sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "    cur_txt = \"\".join(part_buf)\n",
        "    live.update(Markdown(cur_txt))\n",
        "    sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Include the model's final output directly, no regex cleaning\n",
        "    maps.append(cur_txt.strip())\n",
        "\n",
        "if DEBUG_MODE: print(\"→ Segment summarization complete\")\n",
        "\n",
        "# ===== Summary 6/6) Consolidate (reduce) & Only write .md (Summary) - Uses summary_output_dir, summary_srt_path_abs, reduce_max_new_tokens, ctx_window, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 6/6] Consolidating summary (reduce) ...\")\n",
        "maps_md = \"\\n\\n---\\n\\n\".join(f\"### 片段 {i+1} 要點\\n\\n{m}\" for i, m in enumerate(maps))\n",
        "\n",
        "# If combined text exceeds window, truncate proportionally first (without changing text within segments to avoid breaking meaning)\n",
        "def fit_reduce_payload(md_text: str, max_ctx_tokens: int) -> str:\n",
        "    for _ in range(8):\n",
        "        need = count_tokens_text(md_text)\n",
        "        if need + reduce_max_new_tokens + 400 <= max_ctx_tokens:\n",
        "            return md_text\n",
        "        md_text = md_text[: int(len(md_text) * 0.9)]\n",
        "    return md_text\n",
        "\n",
        "md_cur = fit_reduce_payload(maps_md, ctx_window)\n",
        "\n",
        "user_txt = REDUCE_USER_TMPL.format(topic=(topic_hint or \"（無）\"), maps=md_cur)\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_INSTR},\n",
        "            {\"role\":\"user\",\"content\":user_txt}]\n",
        "\n",
        "live2 = display(Markdown(\"\"), display_id=True)\n",
        "final_buf = []\n",
        "for token in llm_stream(messages, reduce_max_new_tokens):\n",
        "    final_buf.append(token)\n",
        "    if len(final_buf) % 24 == 0:\n",
        "        live2.update(Markdown(\"\".join(final_buf)))\n",
        "        sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "live2.update(Markdown(\"\".join(final_buf)))\n",
        "sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "\n",
        "final_text = \"\".join(final_buf).strip()\n",
        "\n",
        "out_dir = Path(summary_output_dir); out_dir.mkdir(parents=True, exist_ok=True)\n",
        "out_md = out_dir / f\"{Path(summary_srt_path_abs).stem}_summary.md\" # Use the stem from the actual SRT file used for summarization\n",
        "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_text)\n",
        "\n",
        "print(f\"→ 完成 ✅  {out_md}\")\n",
        "try:\n",
        "    del llm\n",
        "except Exception:\n",
        "    pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"（顯存已釋放，如需重跑可直接再次執行）\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "→ 當前工作目錄：/content/gdrive/MyDrive\n",
            "→ 來源檔：/content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\n",
            "→ 輸出資料夾：/content/gdrive/MyDrive/whisper\n",
            "[  1%] 00:00:00,000 → 00:00:29,980  Teksting av Nicolai Winther\n",
            "[  1%] 00:00:20,000 → 00:00:49,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:00:40,000 → 00:01:09,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:00,000 → 00:01:29,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:20,000 → 00:01:49,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:01:40,000 → 00:02:09,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:02:00,000 → 00:02:29,980  Teksting av Nicolai Winther\n",
            "[  4%] 00:02:20,000 → 00:02:49,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:00,000 → 00:03:29,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:20,000 → 00:03:49,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:03:40,000 → 00:04:09,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:04:00,000 → 00:04:18,900  聽得到聲音嗎?\n",
            "[  6%] 00:04:20,000 → 00:04:24,000  Ok,ok\n",
            "[  6%] 00:04:24,000 → 00:04:28,000  Ok,那我想先確定\n",
            "[  6%] 00:04:28,000 → 00:04:32,000  威神你那邊在看完教證手冊之後\n",
            "[  6%] 00:04:32,000 → 00:04:36,000  你目前有任何的想法嗎?\n",
            "[  6%] 00:04:36,000 → 00:04:40,000  我覺得因為那時候是說\n",
            "[  6%] 00:04:40,000 → 00:04:45,240  八月底先寫完那個內容的部分嘛\n",
            "[  6%] 00:04:45,240 → 00:04:48,440  但是我覺得看完之後應該要大概\n",
            "[  6%] 00:04:48,440 → 00:04:51,180  我覺得八月底前應該沒辦法寫完\n",
            "[  7%] 00:04:51,180 → 00:04:54,040  那你覺得你什麼時候可以完成得了\n",
            "[  7%] 00:04:54,040 → 00:04:56,480  十月左右嗎\n",
            "[  7%] 00:04:56,480 → 00:04:58,400  你是說單子內容嗎\n",
            "[  7%] 00:05:00,000 → 00:05:06,000  嗯,對。\n",
            "[  7%] 00:05:06,000 → 00:05:09,500  呃,十月底。\n",
            "[  7%] 00:05:09,500 → 00:05:11,580  十月底。\n",
            "[  7%] 00:05:11,580 → 00:05:12,160  好。\n",
            "[  7%] 00:05:12,160 → 00:05:14,780  前,看看吧。\n",
            "[  7%] 00:05:14,780 → 00:05:20,040  因為我也還沒有開始,就是,照他的那個方向去改,所以我...\n",
            "[  7%] 00:05:20,000 → 00:05:23,000  I don't know how long it will take.\n",
            "[  7%] 00:05:23,000 → 00:05:25,000  Ok, ok, I got it.\n",
            "[  7%] 00:05:25,000 → 00:05:27,000  Ok, then I would like to...\n",
            "[  7%] 00:05:27,000 → 00:05:29,000  If you can speak now,\n",
            "[  7%] 00:05:29,000 → 00:05:32,000  you can briefly introduce to Wei-Chen\n",
            "[  7%] 00:05:32,000 → 00:05:35,000  the anti-epidemic prevention method.\n",
            "[  8%] 00:05:40,000 → 00:06:00,000  你要先跟他講一下,就是...\n",
            "[  8%] 00:06:00,000 → 00:06:05,000  我覺得這是一個知識存在的方面嘛 就是框架然後核心特色這樣子\n",
            "[  8%] 00:06:05,000 → 00:06:09,000  好,我發現我只要轉手機跟電腦\n",
            "[  8%] 00:06:09,000 → 00:06:13,000  你們剛剛是問到說就是未成什麼時候可以完成這本書\n",
            "[  8%] 00:06:13,000 → 00:06:18,000  然後是說是十月,十月但是不確定是什麼時候是嗎?\n",
            "[  8%] 00:06:18,000 → 00:06:20,000  Yes\n",
            "[  9%] 00:06:20,000 → 00:06:35,000  我做出這個交戰手冊主要是想說我不知道能不能去陪軍做一些類似跟AI相關的工具\n",
            "[  9%] 00:06:35,000 → 00:06:40,000  因為我的經驗會是如果有了一個標準的準則\n",
            "[  9%] 00:06:40,000 → 00:06:43,600  算是這種抽象的邏輯的話\n",
            "[  9%] 00:06:43,600 → 00:06:48,800  就能夠讓實際在寫獎益的時候\n",
            "[  9%] 00:06:48,800 → 00:06:53,200  可能就可以搭配給AI去自動生成一些類似的東西\n",
            "[  9%] 00:06:53,200 → 00:06:57,600  或是甚至可以去檢驗說這份獎益有沒有包含到\n",
            "[  9%] 00:06:57,600 → 00:07:00,000  這個交戰手冊裡面鎖定\n",
            "[  9%] 00:07:00,000 → 00:07:08,000  我覺得這可能也會讓微塵在寫講義的時候再更快一點。\n",
            "[ 10%] 00:07:08,000 → 00:07:15,000  然後具體來說這裡面的這些校章手冊裡面的所有東西,\n",
            "[ 10%] 00:07:15,000 → 00:07:20,000  玉茜你剛是問我說\n",
            "[ 10%] 00:07:20,000 → 00:07:21,200  我要講什麼\n",
            "[ 10%] 00:07:21,200 → 00:07:24,040  就你可能要稍微跟他說明一下\n",
            "[ 10%] 00:07:24,040 → 00:07:25,240  然後介紹一下\n",
            "[ 10%] 00:07:27,240 → 00:07:28,040  很多耶\n",
            "[ 10%] 00:07:32,500 → 00:07:35,240  維承目前我有幫你按照那個\n",
            "[ 10%] 00:07:35,240 → 00:07:37,400  我覺得的優先順序去排\n",
            "[ 10%] 00:07:37,400 → 00:07:39,600  就是第一個姿勢框架的話\n",
            "[ 10%] 00:07:39,600 → 00:07:40,400  就是我覺得\n",
            "[ 10%] 00:07:40,000 → 00:07:44,000  我覺得這份獎益會最迫切需要的東西\n",
            "[ 10%] 00:07:44,000 → 00:07:47,000  然後所謂的知識框架你可以把它想像成\n",
            "[ 10%] 00:07:47,000 → 00:07:51,000  或寫一個法律系的那個解題的東西\n",
            "[ 11%] 00:07:51,000 → 00:07:55,000  就是我好像記得你有學過民法\n",
            "[ 11%] 00:07:55,000 → 00:07:58,000  還是其他的法律相關的東西\n",
            "[ 11%] 00:07:58,000 → 00:08:00,000  但你也大概可以知道\n",
            "[ 11%] 00:08:00,000 → 00:08:14,980  當你面對一個複雜的案件的時候,你一定要有一套固定的思考方式跟答題方式,你才能夠快速進入到那個理解的框架裡面,然後按照這些步驟去解那個題。\n",
            "[ 11%] 00:08:14,980 → 00:08:20,000  那即便這個步驟可能有一些是形同虛設的,有一些可能在...\n",
            "[ 11%] 00:08:20,000 → 00:08:23,340  在某些題目當中其實根本就是非必要的\n",
            "[ 11%] 00:08:23,340 → 00:08:26,880  可是一旦你有了一個固定的解題框\n",
            "[ 11%] 00:08:26,880 → 00:08:28,000  這樣的思考流程\n",
            "[ 11%] 00:08:28,000 → 00:08:30,440  你在解題的時候就會更有確定感\n",
            "[ 11%] 00:08:30,440 → 00:08:34,580  然後一方面是讓學生能夠感覺自己學到\n",
            "[ 11%] 00:08:34,580 → 00:08:37,660  很具體的感受到自己有學到一套策略\n",
            "[ 12%] 00:08:37,660 → 00:08:40,000  另外一方面也是我們在行銷的\n",
            "[ 12%] 00:08:40,000 → 00:08:46,000  也會更能夠拿這一個策略,這套方法論去推廣出去。\n",
            "[ 12%] 00:08:46,000 → 00:08:54,000  所以我自己是有幫你舉的一個物理上面的例子是先聚焦再發散。\n",
            "[ 12%] 00:08:54,000 → 00:09:00,000  然後我就直接幫你寫了先聚焦再發散這個東西的\n",
            "[ 12%] 00:09:00,000 → 00:09:03,000  This is...wait a minute, the jade line is sliding down\n",
            "[ 12%] 00:09:03,000 → 00:09:06,000  Sliding down, sliding down, sliding down\n",
            "[ 12%] 00:09:06,000 → 00:09:08,000  Hey, this is the correct one\n",
            "[ 12%] 00:09:08,000 → 00:09:11,000  I forgot to delete the top\n",
            "[ 12%] 00:09:11,000 → 00:09:15,000  And then there is a physical demonstration down there\n",
            "[ 12%] 00:09:15,000 → 00:09:20,000  I will want to see that the microcosm may be speaking again\n",
            "[ 13%] 00:09:20,000 → 00:09:28,000  內容的部分先去告訴學生說所謂的先聚焦再發散這個答題策略的核心觀念是什麼\n",
            "[ 13%] 00:09:28,000 → 00:09:34,000  就是什麼是聚焦什麼是發散為什麼聚焦什麼發散然後如何聚焦如何發散\n",
            "[ 13%] 00:09:34,000 → 00:09:40,000  接下來就是透過各種抽象的步驟整理各種抽象的策略\n",
            "[ 13%] 00:09:40,000 → 00:09:46,000  一步一步的去告訴學生說這一個知識框架到底想要傳達的是什麼\n",
            "[ 13%] 00:09:46,000 → 00:09:49,000  然後進到你的題目部分\n",
            "[ 13%] 00:09:49,000 → 00:09:53,000  題目我們等下還會討論說它是要做成就是多少頁數\n",
            "[ 13%] 00:09:53,000 → 00:09:55,000  然後要不要做成電子檔\n",
            "[ 13%] 00:09:55,000 → 00:09:59,000  然後等下育前也會補充說學生對於電子檔的看法這些的\n",
            "[ 14%] 00:10:00,000 → 00:10:12,760  不論如何把題目每一題的解題過程還有每一個詳節都去套用這個不管是三步驟的發賽也好還是先聚焦的發賽\n",
            "[ 14%] 00:10:12,760 → 00:10:19,760  只要固定有一個解題的框架固定的一個算是一個噱頭或是一個包裝\n",
            "[ 14%] 00:10:20,000 → 00:10:22,560  它都可以讓學生更有一個確定感\n",
            "[ 14%] 00:10:22,560 → 00:10:25,760  所以我就會希望這本書最少最少最少最少最少\n",
            "[ 14%] 00:10:25,760 → 00:10:28,000  其他可以慢慢再補上\n",
            "[ 14%] 00:10:28,000 → 00:10:33,000  但是我覺得這個是我會希望可以加進去書\n",
            "[ 14%] 00:10:33,000 → 00:10:34,600  然後再出版會比較好\n",
            "[ 14%] 00:10:34,600 → 00:10:37,000  看我講完了\n",
            "[ 14%] 00:10:40,000 → 00:10:44,000  你目前對這部分有任何的問題嗎?\n",
            "[ 15%] 00:10:49,000 → 00:10:59,000  我要再想就是怎麼具體去把它落實到書的每個章節裡面\n",
            "[ 15%] 00:11:00,000 → 00:11:04,000  OK\n",
            "[ 15%] 00:11:04,000 → 00:11:10,000  我可以問你你自己在打題的時候也會有這樣子的\n",
            "[ 15%] 00:11:10,000 → 00:11:16,000  它會給你一種感覺嗎?就是說物理每個題目好像都有一個感覺\n",
            "[ 15%] 00:11:16,000 → 00:11:20,000  還是你是每個題目有不同的感覺?\n",
            "[ 15%] 00:11:20,000 → 00:11:24,000  好像沒有一個固定的流程\n",
            "[ 15%] 00:11:24,000 → 00:11:31,000  就是覺得可能是\n",
            "[ 15%] 00:11:31,000 → 00:11:33,000  我不會啊\n",
            "[ 15%] 00:11:33,000 → 00:11:35,000  但我覺得他們可能要先\n",
            "[ 15%] 00:11:35,000 → 00:11:37,000  抓到情況再說什麼\n",
            "[ 15%] 00:11:37,000 → 00:11:39,000  但是我就\n",
            "[ 16%] 00:11:40,000 → 00:11:44,000  我覺得我可以抓到,但我覺得他們可能是沒辦法抓到,所以寫不出來。\n",
            "[ 16%] 00:11:46,000 → 00:11:51,000  所以我覺得要先教他們怎麼把題目的點抓出來。\n",
            "[ 16%] 00:11:53,000 → 00:12:00,000  還是我在想會不會你可以跟TradeGVD聊,就你把你看的那些,你可能跟...\n",
            "[ 16%] 00:12:00,000 → 00:12:04,000  跟ChangeGPT聊個十個題目到二十個題目\n",
            "[ 16%] 00:12:04,000 → 00:12:07,000  然後你可能就請他幫你總結一下你這套思路\n",
            "[ 16%] 00:12:07,000 → 00:12:12,000  它背後的核心的步驟\n",
            "[ 16%] 00:12:12,000 → 00:12:15,000  還有你關注的重點\n",
            "[ 16%] 00:12:15,000 → 00:12:18,000  怎麼樣變成一套固定的策略\n",
            "[ 16%] 00:12:18,000 → 00:12:20,000  你可以試試看這個\n",
            "[ 16%] 00:12:20,000 → 00:12:20,500  Ok\n",
            "[ 17%] 00:12:40,000 → 00:12:43,000  你這本書最主要的核心的點是什麼東西 你這本書最主要的核心的點是什麼東西\n",
            "[ 17%] 00:12:47,000 → 00:12:52,000  如果以英文英文的書去舉例的話 就會像是作文書的話\n",
            "[ 17%] 00:12:52,000 → 00:12:58,000  雖然說它有很多很多的內容 但是我們會推出一個最主要的基點 就是它的八條公式\n",
            "[ 17%] 00:12:58,000 → 00:13:00,000  然後這個八條公式也是我們\n",
            "[ 17%] 00:13:00,000 → 00:13:04,500  主要不管是拿在書籍的生存或在社群的行銷上\n",
            "[ 17%] 00:13:04,500 → 00:13:06,700  我們都會拿著八條公式去主打\n",
            "[ 18%] 00:13:06,700 → 00:13:10,580  所以它對於學生的記憶或是這本書的整體\n",
            "[ 18%] 00:13:10,580 → 00:13:14,060  它就會有一個固定的記憶格式\n",
            "[ 18%] 00:13:14,060 → 00:13:16,040  就是大家對於這本書就會是\n",
            "[ 18%] 00:13:16,040 → 00:13:18,900  這個就是那個八條公式就是那個很屌\n",
            "[ 18%] 00:13:18,900 → 00:13:19,980  然後一模獨創的那個\n",
            "[ 18%] 00:13:20,000 → 00:13:24,640  所以也會需要你在幫我寫這本書的時候\n",
            "[ 18%] 00:13:24,640 → 00:13:27,700  也去稍微想一下你這本書的核心特色\n",
            "[ 18%] 00:13:27,700 → 00:13:29,160  最主要的那個點會是什麼\n",
            "[ 18%] 00:13:29,160 → 00:13:30,840  然後是什麼東西是可以對\n",
            "[ 18%] 00:13:30,840 → 00:13:33,760  拿出去打給社群媒體的\n",
            "[ 18%] 00:13:33,760 → 00:13:35,900  這部分有問題嗎\n",
            "[ 18%] 00:13:35,900 → 00:13:37,900  OK\n",
            "[ 18%] 00:13:37,900 → 00:13:39,220  好\n",
            "[ 18%] 00:13:40,000 → 00:13:44,960  好 子明請說\n",
            "[ 18%] 00:13:44,960 → 00:13:48,960  好 我剛剛的那個核心特色\n",
            "[ 18%] 00:13:48,960 → 00:13:53,020  如果我以前在寫物理的內容跟題目的時候\n",
            "[ 18%] 00:13:53,020 → 00:13:54,920  想不到這個特色的話\n",
            "[ 19%] 00:13:54,920 → 00:13:57,340  其實也可以就是照個路\n",
            "[ 19%] 00:13:57,340 → 00:13:59,980  把它變成說是在讀物\n",
            "[ 19%] 00:14:00,000 → 00:14:03,000  你覺得物理這個科目上面的策略\n",
            "[ 19%] 00:14:03,000 → 00:14:05,000  可能就可以想一個什麼循環圖啊\n",
            "[ 19%] 00:14:05,000 → 00:14:09,000  還是什麼正面加強的理論啊什麼的\n",
            "[ 19%] 00:14:09,000 → 00:14:13,000  但就是不一定要是物理的那些章節\n",
            "[ 19%] 00:14:13,000 → 00:14:16,000  你也可以是講你的讀書方法或筆記方法\n",
            "[ 19%] 00:14:16,000 → 00:14:18,000  它也可以變成是一個核心特色\n",
            "[ 19%] 00:14:20,000 → 00:14:23,000  我再想想。\n",
            "[ 19%] 00:14:25,000 → 00:14:35,000  那我也想順便確認一下,你有預計什麼時候可能會確定這本書的整個核心特色嗎?\n",
            "[ 19%] 00:14:35,000 → 00:14:40,000  會需要等你內容寫完嗎?還是你在這中間的過程中你可以先...\n",
            "[ 20%] 00:14:40,000 → 00:14:41,920  跟我確定\n",
            "[ 20%] 00:14:41,920 → 00:14:47,960  應該可以比內容早確定\n",
            "[ 20%] 00:14:47,960 → 00:14:49,680  但是我現在還沒有\n",
            "[ 20%] 00:14:49,680 → 00:14:52,060  就是想出來它是什麼\n",
            "[ 20%] 00:14:52,060 → 00:14:54,940  OK好沒有問題\n",
            "[ 20%] 00:14:54,940 → 00:14:58,180  然後再來下一個的話\n",
            "[ 20%] 00:14:58,180 → 00:14:59,980  會是學習方式跟記憶策略\n",
            "[ 20%] 00:15:00,000 → 00:15:08,000  因為我知道你有先看過整個的內容,所以我想確認你對於這部分有任何問題嗎?\n",
            "[ 20%] 00:15:08,000 → 00:15:17,000  或是有特別想詢問的點嗎?如果沒有的話我們就加快進度,就不用這樣一個一個特別的去講解。\n",
            "[ 21%] 00:15:20,000 → 00:15:27,000  因為就是這邊看起來比較想要說就是要理解\n",
            "[ 21%] 00:15:27,000 → 00:15:35,000  但是我不確定就是他們要理解全盤理解的話會耗費的成本要多少\n",
            "[ 21%] 00:15:35,000 → 00:15:40,000  還是有些人是不是只是想要把它把固定的流程背起來\n",
            "[ 21%] 00:15:40,000 → 00:15:42,800  然後就可以去解題\n",
            "[ 21%] 00:15:42,800 → 00:15:46,200  所以我要著重在\n",
            "[ 21%] 00:15:46,200 → 00:15:48,000  就是不用全盤理解\n",
            "[ 21%] 00:15:48,000 → 00:15:49,200  但是比較好解題\n",
            "[ 21%] 00:15:49,200 → 00:15:51,600  還是希望他們比較好理解\n",
            "[ 21%] 00:15:51,600 → 00:15:56,100  然後就是底子很穩這樣\n",
            "[ 21%] 00:15:56,100 → 00:15:58,400  方向應該在那邊\n",
            "[ 21%] 00:15:58,400 → 00:16:00,000  我覺得會比較看\n",
            "[ 21%] 00:16:00,000 → 00:16:04,200  你這本書的定位點在哪裡?\n",
            "[ 21%] 00:16:04,200 → 00:16:09,800  子民剛說有要講話,我有看到你那個框框。\n",
            "[ 22%] 00:16:09,800 → 00:16:14,000  好像上次跟維城討論的時候你是說,\n",
            "[ 22%] 00:16:14,000 → 00:16:20,000  你希望事實上不知道怎麼開始讀物理的人也可以找到一個方向。\n",
            "[ 22%] 00:16:20,000 → 00:16:25,440  所以你可能打的比較算是中間的族群,是嗎?\n",
            "[ 22%] 00:16:25,440 → 00:16:27,240  算是。\n",
            "[ 22%] 00:16:27,240 → 00:16:28,240  喔。\n",
            "[ 22%] 00:16:34,900 → 00:16:40,000  我會去做這個學習策略的這個地方其實是想說你...\n",
            "[ 22%] 00:16:40,000 → 00:16:48,220  你如果在傳達你的想法跟知識的時候,能夠不要做任何的刪減,\n",
            "[ 23%] 00:16:49,040 → 00:16:58,500  而是你就把最難的東西端出來給學生,可是呢,你還是可以面對初級跟總級的學生,\n",
            "[ 23%] 00:16:58,500 → 00:17:00,500  但是你的...\n",
            "[ 23%] 00:17:00,000 → 00:17:20,120  實施卻是最難的,那這中間的那個gap,中間的那個就是轟溝,你就要透過這些學習方式跟記憶策略的引導,就是如果你的觀念越難,你中間就要解釋越多這樣子的學習策略,然後讓這些重等到初級的學生,\n",
            "[ 23%] 00:17:20,000 → 00:17:22,000  學生也能夠學起來\n",
            "[ 23%] 00:17:22,000 → 00:17:26,000  我當初設計就有這樣的想法\n",
            "[ 23%] 00:17:26,000 → 00:17:36,000  所以我就先把全部東西都最難的部分也寫出來\n",
            "[ 23%] 00:17:36,000 → 00:17:40,000  然後我想往後面再做一個\n",
            "[ 24%] 00:17:40,000 → 00:17:58,260  比較重點的整理,這樣,就是如果你對前面的深入學習沒有興趣的話,那你就直接看重點就好了,這樣應該比較好,就是兩邊都照顧到,也可以,又或者是說你其實也可以,\n",
            "[ 24%] 00:18:00,000 → 00:18:01,840  這點我可能還是會存疑啦\n",
            "[ 24%] 00:18:01,840 → 00:18:03,760  我其實也沒有很確定\n",
            "[ 24%] 00:18:03,760 → 00:18:07,900  就是因為我自己的作文書也是寫到最難\n",
            "[ 24%] 00:18:07,900 → 00:18:10,800  確實也是有學生會覺得太難\n",
            "[ 24%] 00:18:10,800 → 00:18:14,840  但我會傾向是說如果你能夠用這些\n",
            "[ 24%] 00:18:14,840 → 00:18:17,460  就是我有給你一個檔案\n",
            "[ 24%] 00:18:17,460 → 00:18:20,000  就是在這個頁面裡面還有一個連接\n",
            "[ 24%] 00:18:20,000 → 00:18:23,000  我有一個可以出去的檔案叫核心學習策略\n",
            "[ 24%] 00:18:23,000 → 00:18:25,000  你有看過這個嗎?一個\n",
            "[ 25%] 00:18:25,000 → 00:18:28,000  對對對對現在有打開了這個\n",
            "[ 25%] 00:18:28,000 → 00:18:33,000  就是你就可以把一些這裡面的讀書策略跟技巧\n",
            "[ 25%] 00:18:37,000 → 00:18:39,000  這個檔案我還沒看過\n",
            "[ 25%] 00:18:40,000 → 00:18:43,000  你可以先把它看一下。\n",
            "[ 25%] 00:18:43,000 → 00:18:54,000  我自己教學的經驗是讓我發現說這些策略它其實不是只用在英文。\n",
            "[ 25%] 00:18:54,000 → 00:18:59,000  我昨天也是用這個東西去跟學生講數學什麼學。\n",
            "[ 25%] 00:19:00,000 → 00:19:07,000  我想說這東西其實可以一定程度幫助學生理解一些太複雜或太困難的觀念。\n",
            "[ 26%] 00:19:07,000 → 00:19:16,000  然後我就會覺得你跟他解釋越多這些學習策略,他們可能就會越能夠理解你想要傳達的物理專業知識。\n",
            "[ 26%] 00:19:16,000 → 00:19:20,000  所以就是取決於你想要寫多難的東西,然後就加多少。\n",
            "[ 26%] 00:19:20,000 → 00:19:25,000  好,講完嘅。\n",
            "[ 26%] 00:19:25,000 → 00:19:29,000  威神那邊有問題嗎?\n",
            "[ 26%] 00:19:29,000 → 00:19:31,000  暫時沒有。\n",
            "[ 26%] 00:19:31,000 → 00:19:35,000  到時候再麻煩你會後花一些時間幫我看過,\n",
            "[ 26%] 00:19:35,000 → 00:19:39,000  然後如果有不懂的地方可以再隨時跟我們講。\n",
            "[ 26%] 00:19:39,000 → 00:19:40,000  好。\n",
            "[ 26%] 00:19:40,000 → 00:19:45,100  再嚟嘅話就會系梳集咗一個大嘅架構,\n",
            "[ 26%] 00:19:45,100 → 00:19:51,880  佢就跟其實就跟你現在嗰個章節都系很像,\n",
            "[ 26%] 00:19:52,160 → 00:19:55,420  但就系我哋嘅章節架構可能要再清楚明確一點,\n",
            "[ 27%] 00:19:57,760 → 00:19:59,960  然後像呢些可能\n",
            "[ 27%] 00:20:00,000 → 00:20:07,000  你可以先幫我列完,然後如果你需要一些圖示的話,這些我們都可以直接再幫你做。\n",
            "[ 27%] 00:20:11,000 → 00:20:20,000  所以大致上那個架構的話就會是講,就是可能這本書的蓋欄,然後跟這本書的使用說明,然後第一個的大張點。\n",
            "[ 27%] 00:20:20,000 → 00:20:39,000  第二個大章節,然後可能你大章節完之後你會有一個小的,你會先有一個小的總結,然後你的小章節一樣會有一個小的總結,然後才會是這個小章節裡面的氣象,然後最後你還是需要再幫他附一個總結,這樣會是一個比較完整的架構,然後也比較能幫助學生達到一個比較好的學習方式。\n",
            "[ 27%] 00:20:40,000 → 00:20:42,000  所以書籍加關可以參考這邊\n",
            "[ 28%] 00:20:42,000 → 00:20:44,000  好 子明起說\n",
            "[ 28%] 00:20:44,000 → 00:20:46,000  我喔 我又有話要說了\n",
            "[ 28%] 00:20:46,000 → 00:20:48,000  就是你除了\n",
            "[ 28%] 00:20:48,000 → 00:20:50,000  我要說什麼\n",
            "[ 28%] 00:20:50,000 → 00:20:52,000  你的大架構裡面\n",
            "[ 28%] 00:20:52,000 → 00:20:54,000  其實可以多加入一些些\n",
            "[ 28%] 00:20:54,000 → 00:20:56,000  就是比較感性一點的東西\n",
            "[ 28%] 00:20:56,000 → 00:20:58,000  就是你在書籍的可能\n",
            "[ 28%] 00:20:58,000 → 00:21:00,000  在那個章節的開頭\n",
            "[ 28%] 00:21:00,000 → 00:21:03,400  會需要先有一個簡單的總結或是一個概覽\n",
            "[ 28%] 00:21:03,400 → 00:21:05,100  然後讓學生可以進入這個章節\n",
            "[ 28%] 00:21:05,100 → 00:21:07,560  那章節的最後結束也會有一個總結\n",
            "[ 28%] 00:21:07,560 → 00:21:10,480  只是你的那個開始跟那個總結\n",
            "[ 28%] 00:21:10,480 → 00:21:13,220  就是不一定要是很理性\n",
            "[ 28%] 00:21:13,220 → 00:21:18,420  然後很踏實的那種知識上面的整理\n",
            "[ 28%] 00:21:18,420 → 00:21:19,980  你也可以在這邊加一些\n",
            "[ 28%] 00:21:20,000 → 00:21:22,500  讓學生可以心情好一點的東西\n",
            "[ 28%] 00:21:22,500 → 00:21:24,500  譬如說剛開始就是\n",
            "[ 28%] 00:21:24,500 → 00:21:26,500  在章節開始的時候就說\n",
            "[ 29%] 00:21:26,500 → 00:21:29,500  這張適合有哪一些問題的學生\n",
            "[ 29%] 00:21:29,500 → 00:21:31,500  然後就列很多學生常見的問題\n",
            "[ 29%] 00:21:31,500 → 00:21:34,500  那學生可能就會自己跳進去對號入座\n",
            "[ 29%] 00:21:34,500 → 00:21:36,500  就領了一個身份標籤之後\n",
            "[ 29%] 00:21:36,500 → 00:21:38,000  就開始讀這個章節的時候\n",
            "[ 29%] 00:21:38,000 → 00:21:40,000  就會覺得自己的\n",
            "[ 29%] 00:21:40,000 → 00:21:42,000  問題就可以被妥善的解決\n",
            "[ 29%] 00:21:42,000 → 00:21:44,000  然後你到總結的地方再跟他說\n",
            "[ 29%] 00:21:44,000 → 00:21:48,000  恭喜你就是已經解決了這樣子的問題\n",
            "[ 29%] 00:21:48,000 → 00:21:50,000  你一定會越來越好啊什麼的\n",
            "[ 29%] 00:21:50,000 → 00:21:52,000  就可以給一些情緒上面的\n",
            "[ 29%] 00:21:52,000 → 00:21:53,000  給一些情緒價值\n",
            "[ 29%] 00:21:53,000 → 00:21:55,000  學生讀起來會比較\n",
            "[ 29%] 00:21:55,000 → 00:21:57,000  算是堅持得下去吧\n",
            "[ 29%] 00:21:57,000 → 00:22:00,000  如果你會把內容加得深入一點點的話\n",
            "[ 29%] 00:22:00,000 → 00:22:02,000  還有腳外的\n",
            "[ 29%] 00:22:02,000 → 00:22:04,000  咚\n",
            "[ 29%] 00:22:04,000 → 00:22:06,000  好\n",
            "[ 29%] 00:22:06,000 → 00:22:08,000  再來的話就是說幾個小架構\n",
            "[ 29%] 00:22:08,000 → 00:22:10,000  那個小架構就是偏\n",
            "[ 29%] 00:22:10,000 → 00:22:12,000  理論跟案例\n",
            "[ 30%] 00:22:12,000 → 00:22:14,000  這個的話前面其實也有提到\n",
            "[ 30%] 00:22:14,000 → 00:22:16,000  然後這個你可以\n",
            "[ 30%] 00:22:16,000 → 00:22:18,000  如果你沒有很懂的話可以再問我\n",
            "[ 30%] 00:22:18,000 → 00:22:20,000  然後\n",
            "[ 30%] 00:22:20,000 → 00:22:25,000  理論的主要呈現原則就是你要以系統性的東西去取代流水帳\n",
            "[ 30%] 00:22:25,000 → 00:22:30,000  就是系統性就比較像是可能第一步第二步然後原則一原則二原則三\n",
            "[ 30%] 00:22:30,000 → 00:22:34,000  然後或者是你可以用一個表格呈現可以用流程圖可以用矩陣都可以\n",
            "[ 30%] 00:22:34,000 → 00:22:40,000  然後這種方式會比起你只是跟他講說我今天去買了蘋果\n",
            "[ 30%] 00:22:40,000 → 00:22:44,500  如果怎麼樣怎麼樣,這種流水的方式好很多很多很多。\n",
            "[ 30%] 00:22:44,500 → 00:22:46,500  然後再來是案例的呈現原則。\n",
            "[ 30%] 00:22:46,500 → 00:22:50,800  你要盡量讓,就是用故事的方式去讓理論去落地。\n",
            "[ 30%] 00:22:50,800 → 00:22:56,000  就是你可以去多講幾個例子,然後但是你不能只是單純的講例子。\n",
            "[ 31%] 00:22:56,000 → 00:23:00,000  你要去刻意的選擇可以提出這些理論的關鍵點的案例。\n",
            "[ 31%] 00:23:00,000 → 00:23:03,820  然後讓案例的順序跟理論的分點是一致的\n",
            "[ 31%] 00:23:03,820 → 00:23:05,620  就是學生他可以互相對照\n",
            "[ 31%] 00:23:05,620 → 00:23:07,800  他不會覺得我現在看了這個理論\n",
            "[ 31%] 00:23:07,800 → 00:23:09,500  但是我找不到對應的案例\n",
            "[ 31%] 00:23:09,500 → 00:23:10,720  或者是我現在看了這個案例\n",
            "[ 31%] 00:23:10,720 → 00:23:12,820  但我也不知道你在講哪一個理論這樣子\n",
            "[ 31%] 00:23:12,820 → 00:23:15,740  目前這邊是OK的\n",
            "[ 31%] 00:23:15,740 → 00:23:16,920  OK\n",
            "[ 31%] 00:23:16,920 → 00:23:17,980  好\n",
            "[ 31%] 00:23:17,980 → 00:23:20,020  然後因為我們收集的內容\n",
            "[ 31%] 00:23:20,000 → 00:23:22,260  我们会以黑白色为主\n",
            "[ 31%] 00:23:22,260 → 00:23:25,540  所以如果你今天在帮我写里面的内容\n",
            "[ 31%] 00:23:25,540 → 00:23:28,920  然后有些比较想要让他们强调的重点\n",
            "[ 31%] 00:23:28,920 → 00:23:31,640  你可能需要帮我使用色块或是粗体\n",
            "[ 31%] 00:23:31,640 → 00:23:34,860  或是一些其他的框框标记都可以\n",
            "[ 31%] 00:23:34,860 → 00:23:37,840  但是你需要有一个让他们可以很好get到说\n",
            "[ 31%] 00:23:37,840 → 00:23:39,980  这里可能是相对于其他内容性\n",
            "[ 31%] 00:23:40,000 → 00:23:42,000  較為重要的地方\n",
            "[ 32%] 00:23:44,000 → 00:23:45,000  好\n",
            "[ 32%] 00:23:45,000 → 00:23:48,000  然後下面你應該也都有看過\n",
            "[ 32%] 00:23:48,000 → 00:23:50,000  那你有什麼地方有不了解\n",
            "[ 32%] 00:23:50,000 → 00:23:52,000  然後有想問的嗎\n",
            "[ 32%] 00:23:56,000 → 00:23:58,000  看起來沒有\n",
            "[ 32%] 00:23:58,000 → 00:23:59,000  好\n",
            "[ 32%] 00:23:59,000 → 00:24:00,000  線上話\n",
            "[ 32%] 00:24:00,000 → 00:24:01,200  與配套工具\n",
            "[ 32%] 00:24:01,200 → 00:24:05,040  啊沒事\n",
            "[ 32%] 00:24:05,040 → 00:24:05,720  在下面\n",
            "[ 32%] 00:24:05,720 → 00:24:08,000  對不起我插嘴了\n",
            "[ 32%] 00:24:08,000 → 00:24:08,420  對不起\n",
            "[ 32%] 00:24:08,420 → 00:24:10,940  好然後順便跟維成提\n",
            "[ 32%] 00:24:10,940 → 00:24:13,260  就是因為我知道你有做那個\n",
            "[ 32%] 00:24:13,260 → 00:24:14,180  就是\n",
            "[ 32%] 00:24:14,180 → 00:24:16,440  立貼題目\n",
            "[ 32%] 00:24:16,440 → 00:24:16,840  然後\n",
            "[ 32%] 00:24:16,840 → 00:24:18,660  就是他如果\n",
            "[ 32%] 00:24:18,660 → 00:24:20,000  如果你今天還是要把他寫在\n",
            "[ 32%] 00:24:20,000 → 00:24:27,180  你在書裡面或是你今天在書本裡面有提到,然後你不知道怎麼拍板的話,就是知名右相有一個是比較好的方式。\n",
            "[ 33%] 00:24:27,180 → 00:24:40,000  如果你今天想要讓學生,他是可以先看完題目,然後先有一個答案,然後再繼續看詳解的話,你可以變成說第一頁他有三題的題目,然後你翻頁之後是那三題的講解。\n",
            "[ 33%] 00:24:40,000 → 00:25:00,000  然後就稍微對一下拍板,才不會讓他們馬上就可以找到答案,然後也沒有,就如果直接讓他們看到答案,他們就會不去思考,所以你可以先讓他們思考完之後,然後再去翻譯了,去對照那個答案,然後去看你的想解步都是什麼,然後這樣子,一方面是它有一個比較好的拍板格式,另外一方面是可以主動去引導他們去思考。\n",
            "[ 33%] 00:25:00,000 → 00:25:02,940  而不是直接仰賴你的解答\n",
            "[ 33%] 00:25:02,940 → 00:25:04,940  OK\n",
            "[ 33%] 00:25:04,940 → 00:25:05,500  OK\n",
            "[ 33%] 00:25:05,500 → 00:25:09,540  但是上次不是說那個解答要用呈現上嗎\n",
            "[ 33%] 00:25:09,540 → 00:25:11,680  不然頁數就已經爆了\n",
            "[ 33%] 00:25:11,680 → 00:25:12,540  對\n",
            "[ 34%] 00:25:12,540 → 00:25:15,040  就只是如果你今天有在內容裡面\n",
            "[ 34%] 00:25:15,040 → 00:25:16,620  有稍微稍稍的提到\n",
            "[ 34%] 00:25:16,620 → 00:25:19,260  就是你可以有一兩題或是三四題的話\n",
            "[ 34%] 00:25:19,260 → 00:25:19,960  是可以用這樣的\n",
            "[ 34%] 00:25:20,000 → 00:25:39,940  然後關於題目答案線上話這個點,我們需要,好我先跟你抓出來討論這個點好了,因為我們有收到學生的回饋是說他們的父母其實沒有很希望讓他們嘗試這樣用平板手機或是電腦,所以關於\n",
            "[ 35%] 00:25:40,000 → 00:25:59,960  解答線上話這一點,我們可能需要再思考一下,因為不是所有的學生都可以達到很好的學習效果,也不是所有的學生都可以這樣做自由,所以我們需要想一個解決方法,讓他們不是只能完全的仰賴這個AI工具,而是AI工具會變成是輔助他們的學習效果,而不是讓他們去\n",
            "[ 35%] 00:26:00,000 → 00:26:02,000  從AI工具中\n",
            "[ 35%] 00:26:02,000 → 00:26:04,000  就他們不能只是用AI工具找到答案\n",
            "[ 35%] 00:26:04,000 → 00:26:06,000  他們應該要從其他地方也可以找到答案\n",
            "[ 35%] 00:26:06,000 → 00:26:08,000  AI工具只是一個輔助\n",
            "[ 35%] 00:26:08,000 → 00:26:10,000  所以我們可能要先解決這個\n",
            "[ 35%] 00:26:10,000 → 00:26:12,000  點\n",
            "[ 35%] 00:26:16,000 → 00:26:18,000  然後我自己有稍微想了一下\n",
            "[ 35%] 00:26:18,000 → 00:26:20,000  如果說你今天是\n",
            "[ 35%] 00:26:20,000 → 00:26:40,000  因為如果有太多業績的話,其實它是可以用一個比較簡略版的複測,就是它反正只是西馬丁,然後完完全全就是黑白印刷,那他們的題目跟解析是可以分開來的,然後當然對於印刷成本也不會跟原本一樣那麼高,然後學生也不會說如果我今天不能用手機,要不能用手機,\n",
            "[ 35%] 00:26:40,000 → 00:26:42,700  我就完全沒有辦法找到這題的答案\n",
            "[ 36%] 00:26:42,700 → 00:26:45,780  或是我也沒辦法找到這題的相接是什麼東西\n",
            "[ 36%] 00:26:45,780 → 00:26:46,640  對\n",
            "[ 36%] 00:26:46,640 → 00:26:50,020  所以想順便問問看你那邊有任何的想法嗎\n",
            "[ 36%] 00:26:50,020 → 00:26:54,780  所以\n",
            "[ 36%] 00:26:54,780 → 00:26:55,780  嗯\n",
            "[ 36%] 00:26:55,780 → 00:26:59,920  就是解答還是要包含在\n",
            "[ 36%] 00:27:00,000 → 00:27:04,000  裡面,就是包含在整份裡面嘛\n",
            "[ 36%] 00:27:04,000 → 00:27:08,900  這樣頁數不是還是一樣,只是超出\n",
            "[ 36%] 00:27:08,900 → 00:27:13,740  就會變成是以主側跟副側的方式去呈現\n",
            "[ 36%] 00:27:13,740 → 00:27:16,580  那副側的話我們的印刷品質就會是比較\n",
            "[ 36%] 00:27:16,580 → 00:27:19,260  沒有到跟主側一樣那麼好的\n",
            "[ 36%] 00:27:19,260 → 00:27:19,960  那它的印刷\n",
            "[ 36%] 00:27:20,000 → 00:27:25,000  雖然說會增加,但是不會像原本高的那麼誇張。\n",
            "[ 37%] 00:27:28,000 → 00:27:30,000  或者是有如果...\n",
            "[ 37%] 00:27:30,000 → 00:27:31,000  請說。\n",
            "[ 37%] 00:27:31,000 → 00:27:35,000  我想題目分享解葉樹很多耶,比較不像作文那樣子。\n",
            "[ 37%] 00:27:35,000 → 00:27:38,000  只有少少的就是葉。\n",
            "[ 37%] 00:27:40,000 → 00:27:53,000  因為它如果現在是要寫成題目一頁相接一頁,或是一頁三個題目,然後相接三頁的話,那個頁數應該都會比作文還要多很多。\n",
            "[ 37%] 00:28:00,000 → 00:28:05,360  但我哋冇辦法完全就把佢現場化\n",
            "[ 37%] 00:28:05,360 → 00:28:11,900  因為學生也確實冇辦法讓佢哋有個好的學習方式\n",
            "[ 38%] 00:28:11,900 → 00:28:17,060  那我哋現在壓業數是因為硬抓成本跟定價嗎?\n",
            "[ 38%] 00:28:17,060 → 00:28:20,000  就是說我哋定價如果就是要定在\n",
            "[ 38%] 00:28:20,000 → 00:28:26,000  500塊以內,業數就是不可以到300,350到400\n",
            "[ 38%] 00:28:26,000 → 00:28:27,000  對\n",
            "[ 38%] 00:28:31,000 → 00:28:34,000  你如果今天要到,就是真的業數要到三四百\n",
            "[ 38%] 00:28:34,000 → 00:28:38,000  其實是,就是沒有什麼關係啦\n",
            "[ 38%] 00:28:38,000 → 00:28:40,000  但是一方面\n",
            "[ 38%] 00:28:40,000 → 00:28:45,020  因為成本很高,所以我們分下來的利潤可能覺得是不多的。\n",
            "[ 38%] 00:28:45,020 → 00:28:58,020  第二方面是,如果我們今天是推一個他可以很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:28:58,020 → 00:29:09,980  然後這就會延伸到,如果我們今天是推一個很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:29:00,000 → 00:29:20,000  如果我們今天把排板放大,如果以A4尺寸去製作的話,A4它很吃排板功力,所以如果說你今天有任何一個排板點沒有排板好,或者是你的圖示效果不是那麼好的話,其實對於學生的學習狀況也不是到很良好。\n",
            "[ 39%] 00:29:20,000 → 00:29:22,000  如果你今天是一頁密密麻麻的文字\n",
            "[ 39%] 00:29:22,000 → 00:29:24,000  他們可能看到一半也不會想看\n",
            "[ 39%] 00:29:24,000 → 00:29:26,000  所以對於他們學習長相之後\n",
            "[ 39%] 00:29:26,000 → 00:29:28,000  不是那麼的佳\n",
            "[ 39%] 00:29:28,000 → 00:29:31,000  所以這個點我們可能要稍微想一下\n",
            "[ 39%] 00:29:31,000 → 00:29:33,000  我們去解決\n",
            "[ 39%] 00:29:35,000 → 00:29:40,000  以前如果你說學生有些會不想要用電子廠\n",
            "[ 40%] 00:29:40,000 → 00:29:46,000  那就代表之前說想借跟題目要做成線上資料庫\n",
            "[ 40%] 00:29:46,000 → 00:29:48,000  這個就等於是不可行的\n",
            "[ 40%] 00:29:48,000 → 00:29:51,000  對,會變成說如果真的要做的話\n",
            "[ 40%] 00:29:51,000 → 00:29:55,000  它更像是一個我給你一個更好的輔助工具\n",
            "[ 40%] 00:29:55,000 → 00:29:56,000  然後你如果今天想要\n",
            "[ 40%] 00:29:56,000 → 00:29:58,000  就你如果今天書籍沒有帶在身上的話\n",
            "[ 40%] 00:29:58,000 → 00:30:00,000  你也可以有一個\n",
            "[ 40%] 00:30:00,000 → 00:30:02,000  可以學習的地方\n",
            "[ 40%] 00:30:02,000 → 00:30:04,000  但現在問題點就是\n",
            "[ 40%] 00:30:04,000 → 00:30:06,000  很多家長他不願意讓學生\n",
            "[ 40%] 00:30:06,000 → 00:30:08,000  這樣去做\n",
            "[ 40%] 00:30:08,000 → 00:30:10,000  那如果\n",
            "[ 40%] 00:30:10,000 → 00:30:12,000  我們今天變成是\n",
            "[ 40%] 00:30:12,000 → 00:30:14,000  把題目跟\n",
            "[ 40%] 00:30:14,000 → 00:30:16,000  相借獨立成一本\n",
            "[ 40%] 00:30:16,000 → 00:30:18,000  複冊 然後\n",
            "[ 40%] 00:30:18,000 → 00:30:20,000  這本複冊的話\n",
            "[ 41%] 00:30:20,000 → 00:30:39,000  如果是買這本物理書,我們就會只給電子檔的複測,就是複測是用電子檔去給,然後他們可以自己印,又或是我們可以,他可以再加購,然後我們再把它印。\n",
            "[ 41%] 00:30:40,000 → 00:30:44,200  我覺得可能會以他們架構然後我們幫他印的方式\n",
            "[ 41%] 00:30:44,200 → 00:30:48,700  然後主要的話就是會印出的地方出去\n",
            "[ 41%] 00:30:48,700 → 00:30:53,000  不然我們成本一方面會拉高\n",
            "[ 41%] 00:30:53,000 → 00:30:57,900  另外一方面是他們好像不太擅長自己去印書\n",
            "[ 42%] 00:31:00,000 → 00:31:17,000  Ok,所以會需要麻煩維城,他可能還是要幫我把題目跟相機的都一樣有,就是可以有資本化的方式,就是你需要幫我拆開來寫,因為我們到時候會是以兩本書的形式推出去。\n",
            "[ 42%] 00:31:20,000 → 00:31:22,000  好,我可以提一個點嗎?\n",
            "[ 42%] 00:31:22,000 → 00:31:23,000  嗯。\n",
            "[ 42%] 00:31:23,000 → 00:31:36,000  就是微塵你可能現階段在做題目跟詳解的時候,你可能不要直接把它寫到 Word 檔,就是不要直接寫到你最後要出版的那個書上面。\n",
            "[ 42%] 00:31:36,000 → 00:31:40,000  而是你先用一個第三方的\n",
            "[ 42%] 00:31:40,000 → 00:31:43,000  另外一個的編輯的平台\n",
            "[ 42%] 00:31:43,000 → 00:31:47,000  你可能就先做在Notion上面\n",
            "[ 42%] 00:31:47,000 → 00:31:51,000  然後你把這些題目跟小節都做在Notion上面的時候\n",
            "[ 42%] 00:31:51,000 → 00:31:56,000  你一方面就是確保了我們剛剛講到的一個點是說\n",
            "[ 43%] 00:31:56,000 → 00:32:00,000  我們實體的東西要讓學生光看實體就看得懂\n",
            "[ 43%] 00:32:00,000 → 00:32:03,240  但是我們還是可以提供線上的輔助\n",
            "[ 43%] 00:32:03,240 → 00:32:06,340  這樣如果他們可能沒有帶到輔助\n",
            "[ 43%] 00:32:06,340 → 00:32:08,240  或是出了哪些狀況\n",
            "[ 43%] 00:32:08,240 → 00:32:10,340  或是他們想要用電子的方式去學\n",
            "[ 43%] 00:32:10,340 → 00:32:12,540  他們還是可以用電子的方式去做\n",
            "[ 43%] 00:32:12,540 → 00:32:14,840  所以就會變成說\n",
            "[ 43%] 00:32:14,840 → 00:32:17,000  利益\n",
            "[ 43%] 00:32:17,000 → 00:32:20,000  玉千你可不可以幫我開那個\n",
            "[ 43%] 00:32:20,000 → 00:32:25,000  英文共筆 英文選擇的那個檔案\n",
            "[ 43%] 00:32:25,000 → 00:32:27,000  對對對對\n",
            "[ 43%] 00:32:27,000 → 00:32:29,000  就是像現在的這個畫面\n",
            "[ 43%] 00:32:29,000 → 00:32:31,000  它就是一個英文的\n",
            "[ 43%] 00:32:31,000 → 00:32:33,000  英文選擇題的講義裡面的\n",
            "[ 43%] 00:32:33,000 → 00:32:36,000  線上的一個資料庫\n",
            "[ 43%] 00:32:36,000 → 00:32:39,000  你在寫你的那個題目跟詳解的時候\n",
            "[ 43%] 00:32:39,000 → 00:32:40,000  就建議你可以\n",
            "[ 44%] 00:32:40,000 → 00:33:00,000  寫在線上,然後就是在線上是一個已經有整理過的,有系統化的一個地方,然後這一個連結就可以直接分享給學生,然後學生就會有更多的自由度可以去在實體和電子上面同時的閱讀,就他們讀電子也得讀得懂,然後讀實體\n",
            "[ 44%] 00:33:00,000 → 00:33:11,060  你可以讀得懂,那你再把這個現在資料庫上面的東西再轉成實際書的排版跟內容就可以了,你這樣能聽得懂嗎?\n",
            "[ 44%] 00:33:13,860 → 00:33:19,940  我就是,因為我現在是把它拆在\n",
            "[ 44%] 00:33:20,000 → 00:33:29,000  因為我拿其他檔案,我的檔案,所以我之後寫完的話我再把它弄到 Notion上面。\n",
            "[ 45%] 00:33:29,000 → 00:33:31,000  這樣可以吧。\n",
            "[ 45%] 00:33:31,000 → 00:33:36,000  我覺得這樣應該會好一點,因為你我的檔不是會比較零散嗎?\n",
            "[ 45%] 00:33:40,000 → 00:33:44,000  欸可是notion上面就不能做那個公司那些咧?\n",
            "[ 45%] 00:33:46,000 → 00:33:48,000  Notion上可以做公司的\n",
            "[ 45%] 00:33:48,000 → 00:33:49,000  喔真的喔?\n",
            "[ 45%] 00:33:49,000 → 00:33:51,000  用Datex寫\n",
            "[ 45%] 00:33:53,000 → 00:33:55,000  你搜尋LATEX\n",
            "[ 45%] 00:34:00,000 → 00:34:02,000  等下等下等下\n",
            "[ 45%] 00:34:05,200 → 00:34:07,200  它是一個特定的滴刷\n",
            "[ 46%] 00:34:14,560 → 00:34:16,560  上面那個\n",
            "[ 46%] 00:34:20,000 → 00:34:30,340  就變成翅方,然後就要打一個固定的,就是一個字串進去,它就會變成翅方。\n",
            "[ 46%] 00:34:30,340 → 00:34:33,400  對,對,差不多了。\n",
            "[ 46%] 00:34:33,400 → 00:34:36,500  沃德裡面的公司應該是可以轉成這種模式的。\n",
            "[ 46%] 00:34:40,000 → 00:34:48,000  好,如果這方面維生不太會用的話,可以再問我,或是直接問培鈞也可以。\n",
            "[ 46%] 00:34:48,000 → 00:34:54,000  或是你也可以就直接在 Word 檔上面編輯,但是你截圖截到 Notion。\n",
            "[ 46%] 00:34:54,000 → 00:34:55,000  對。\n",
            "[ 46%] 00:34:55,000 → 00:34:59,000  因為 Notion 會有這種資料庫,就會比 Word 還要清楚一點。\n",
            "[ 47%] 00:35:00,000 → 00:35:05,000  好,那我就先在我的上面寫好了。\n",
            "[ 47%] 00:35:05,000 → 00:35:09,000  好,沒有問題。\n",
            "[ 47%] 00:35:09,000 → 00:35:20,000  然後這個的話其實剛剛子明就講到,你可以寫一個很深很深的關鍵,但是你要想辦法也要教會可能不是成都的嗎?\n",
            "[ 47%] 00:35:20,000 → 00:35:20,720  好的學生\n",
            "[ 47%] 00:35:20,720 → 00:35:26,800  那這部分剛剛你在聽的時候有問題嗎\n",
            "[ 47%] 00:35:26,800 → 00:35:34,340  你是說線上化跟配套工具\n",
            "[ 47%] 00:35:34,340 → 00:35:34,900  對\n",
            "[ 47%] 00:35:34,900 → 00:35:38,620  就是我們剛剛\n",
            "[ 47%] 00:35:40,000 → 00:35:45,000  我想講到自信框架的地方還有學習方式跟記憶策略的選擇\n",
            "[ 48%] 00:35:45,000 → 00:35:49,000  前面全部嗎?\n",
            "[ 48%] 00:35:49,000 → 00:35:52,000  對,它其實就是一樣的東西\n",
            "[ 48%] 00:35:52,000 → 00:35:55,000  就是教學理念的話我們希望它是以不間隔的方式\n",
            "[ 48%] 00:35:55,000 → 00:36:00,000  就是你要是寫好寫滿但是你要需要用方式讓可能\n",
            "[ 48%] 00:36:00,000 → 00:36:06,080  我比較沒有程度那麼高的學生去理解一個比較深奧的觀念\n",
            "[ 48%] 00:36:06,080 → 00:36:16,500  然後如果延續到前面剛剛提到的說\n",
            "[ 48%] 00:36:16,500 → 00:36:18,380  你要怎麼樣有一個很深奧的觀念\n",
            "[ 48%] 00:36:18,380 → 00:36:20,000  但是你卻不是只針對聰明\n",
            "[ 48%] 00:36:20,000 → 00:36:25,000  你只要把這個東西插成一個很碎片化的東西可以呈現。\n",
            "[ 48%] 00:36:25,000 → 00:36:28,000  它可能是三到五個獨立然後可以理解的小單元。\n",
            "[ 49%] 00:36:28,000 → 00:36:33,000  就你小單元小單元小單元讓他們去吸收,他們就比較可以接受。\n",
            "[ 49%] 00:36:33,000 → 00:36:37,000  然後再來的話是你每個單元只要專注一個最核心核心的點就好。\n",
            "[ 49%] 00:36:37,000 → 00:36:40,000  然後你可以搭配一些立體跟一些互動練習。\n",
            "[ 49%] 00:36:40,000 → 00:36:54,000  另外就是你要把那個包裝把它簡化簡化得很簡單,就是你可以用可能比較生物化的方式去解釋,或者是你可以用剩下一些視覺化的工具。\n",
            "[ 49%] 00:36:54,000 → 00:37:00,000  對,然後再來的話就是視超化落地,就是你這樣每個觀念都可以搭配一個可以讓它\n",
            "[ 49%] 00:37:00,000 → 00:37:12,000  所以我剛才會提到說你可能一個章節裡面你可能會有二到三題的練習題,你就可以搭配到視察化落地的這個部分。\n",
            "[ 50%] 00:37:12,000 → 00:37:20,000  好,然後再來的話就是剛其實就有稍微提到配套工具。\n",
            "[ 50%] 00:37:20,000 → 00:37:24,600  這幾個是我們覺得也可以用在物理講義裡面的配套工具\n",
            "[ 50%] 00:37:24,600 → 00:37:26,600  第一個就是Notion的筆記模板\n",
            "[ 50%] 00:37:26,600 → 00:37:28,600  然後再來的話就是SharedGPC的機器人\n",
            "[ 50%] 00:37:28,600 → 00:37:31,900  這個的話會是就是你先跟他聊聊聊\n",
            "[ 50%] 00:37:31,900 → 00:37:33,500  然後聊到說有一定的格式\n",
            "[ 50%] 00:37:33,500 → 00:37:37,100  然後之後我們再去轉成我們自己寫的機器人\n",
            "[ 50%] 00:37:37,100 → 00:37:40,100  就會是可能當學生輸入哪一些提示詞\n",
            "[ 50%] 00:37:40,000 → 00:37:44,420  他可以按照我們一開始就規定好的格式 然後產出相對應的內容\n",
            "[ 50%] 00:37:44,420 → 00:37:46,400  然後再來是Notebook LN\n",
            "[ 50%] 00:37:46,400 → 00:37:52,320  Notebook LN的話會比較偏向是我們一開始就先把我們的講義就先都上傳好\n",
            "[ 50%] 00:37:52,320 → 00:37:54,400  然後讓他的觀念是完整清楚的\n",
            "[ 50%] 00:37:54,400 → 00:37:56,780  那當學生他有什麼問題想要問的時候\n",
            "[ 50%] 00:37:56,780 → 00:37:59,020  他可以直接上Notebook LN然後問一個問題\n",
            "[ 50%] 00:37:59,020 → 00:37:59,300  然後\n",
            "[ 51%] 00:38:00,000 → 00:38:04,000  機器人就會想把相對應講義的內容輸出給他\n",
            "[ 51%] 00:38:04,000 → 00:38:07,000  就是一個很即時的問答\n",
            "[ 51%] 00:38:07,000 → 00:38:11,000  然後再來的話就是剛剛有給你看過的那個共編檔案\n",
            "[ 51%] 00:38:11,000 → 00:38:13,000  物理也可以這樣子做\n",
            "[ 51%] 00:38:13,000 → 00:38:17,000  但是這個的話就會很仰賴說\n",
            "[ 51%] 00:38:17,000 → 00:38:20,000  如果今天學生真的有上來留言\n",
            "[ 51%] 00:38:20,000 → 00:38:40,000  然後問問題的話,我們會需要很,就是至少在一定的時間內就可以幫他解完這樣的問題,然後並把這樣的東西再重新整理成新的內容,然後放上來,所以那個沒有到這麼急迫,但是我們還是會希望未來可以。\n",
            "[ 51%] 00:38:40,000 → 00:38:41,000  做\n",
            "[ 51%] 00:38:41,000 → 00:38:45,740  然後再來就是Notion的問答會診區\n",
            "[ 52%] 00:38:45,740 → 00:38:47,520  這個的話會是\n",
            "[ 52%] 00:38:47,520 → 00:38:49,900  譬如說我們有在IG啊\n",
            "[ 52%] 00:38:49,900 → 00:38:51,940  或者是在LINE的社群裡面\n",
            "[ 52%] 00:38:51,940 → 00:38:54,760  如果有任何人提到物理檢驗裡面的問題\n",
            "[ 52%] 00:38:54,760 → 00:38:57,020  我們都可以把它統整起來\n",
            "[ 52%] 00:38:57,020 → 00:38:58,500  然後就是你回答完之後\n",
            "[ 52%] 00:38:58,500 → 00:38:59,580  我們再把它統整起來\n",
            "[ 52%] 00:38:59,580 → 00:39:00,000  然後之後\n",
            "[ 52%] 00:39:00,000 → 00:39:03,320  有遇到一样的问题的时候学生就可以直接上来这边看\n",
            "[ 52%] 00:39:03,320 → 00:39:09,040  好那以上现在有问题吗\n",
            "[ 52%] 00:39:09,040 → 00:39:12,440  刚刚有说到那个notebook\n",
            "[ 52%] 00:39:12,440 → 00:39:16,140  它是就是上次是说它提供上来\n",
            "[ 52%] 00:39:16,140 → 00:39:17,700  然后它就会呈现解答\n",
            "[ 52%] 00:39:17,700 → 00:39:19,800  所以它是一个\n",
            "[ 52%] 00:39:20,000 → 00:39:25,020  它是AI嗎?還是它只是單純的查找的工具?\n",
            "[ 52%] 00:39:25,640 → 00:39:27,920  還是它是會生內容的那種AI?\n",
            "[ 53%] 00:39:30,120 → 00:39:33,000  它是一個幫助你去...\n",
            "[ 53%] 00:39:33,000 → 00:39:37,760  它是會自己生內容嗎?\n",
            "[ 53%] 00:39:38,360 → 00:39:39,980  還是它是拿出...\n",
            "[ 53%] 00:39:40,000 → 00:39:59,220  他會自己按照你給他的觀念格式,還有你給他的內容,然後去升,他裡面知道既有的內容,所以他不會去延伸說那些其實你並沒有輸入給他的東西,因為像ShareGP的話,他就很有可能是輸出一些\n",
            "[ 53%] 00:40:00,000 → 00:40:02,300  並唔係嗰麼正確性嘅嘢\n",
            "[ 53%] 00:40:02,300 → 00:40:06,400  但係NOPLM 佢就係完全按照你輸入乜嘢給佢\n",
            "[ 53%] 00:40:06,400 → 00:40:09,100  佢就會輸出相對應嘅嘢給學生\n",
            "[ 53%] 00:40:09,100 → 00:40:12,400  所以佢能確保佢裡面輸出嘅嘢一定係完整嘅\n",
            "[ 53%] 00:40:12,400 → 00:40:13,400  而且係正確嘅\n",
            "[ 53%] 00:40:15,600 → 00:40:16,400  好\n",
            "[ 54%] 00:40:16,400 → 00:40:19,900  對 所以會需要你完成獎益跟一些\n",
            "[ 54%] 00:40:20,000 → 00:40:23,000  我们再喂进去给那部LA\n",
            "[ 54%] 00:40:23,000 → 00:40:26,080  那到时候再用好\n",
            "[ 54%] 00:40:26,080 → 00:40:27,220  因为我现在也不会用它\n",
            "[ 54%] 00:40:27,220 → 00:40:29,160  好没有问题\n",
            "[ 54%] 00:40:29,160 → 00:40:32,440  然后善用比喻的话\n",
            "[ 54%] 00:40:32,440 → 00:40:34,380  上面也有讲过\n",
            "[ 54%] 00:40:34,380 → 00:40:35,780  然后你自己也有稍微看过\n",
            "[ 54%] 00:40:35,780 → 00:40:38,260  那这部分你有问题想询问的吗\n",
            "[ 54%] 00:40:40,000 → 00:40:44,000  應該比較還好,這部分應該比較簡單。\n",
            "[ 54%] 00:40:44,000 → 00:40:48,000  OK,那關於立場切換的部分呢?\n",
            "[ 54%] 00:40:51,000 → 00:41:00,000  這個就是子明剛剛跟你講到說,如果你今天是一個蓋籃的時候,你可以不要那麼的過於理性,或是就是一些文綽綽的\n",
            "[ 55%] 00:41:00,000 → 00:41:11,000  你可以是給他們一個對號入座的感覺,或是給他們一個比較偏向感性上面的支持,或是一些情緒支持這樣子,這就是舉例。\n",
            "[ 55%] 00:41:11,000 → 00:41:20,000  然後這個的話也是用在作文上的一個小小的行銷手段,它就是讓學生自己去想他們有什麼想法。\n",
            "[ 55%] 00:41:20,000 → 00:41:24,500  然後我們引導牠去對號入座到你真的有這個症狀\n",
            "[ 55%] 00:41:24,500 → 00:41:26,180  然後其實你很需要這個書\n",
            "[ 55%] 00:41:26,180 → 00:41:29,280  就是物理也可以用這樣的方式呈現\n",
            "[ 55%] 00:41:29,280 → 00:41:35,160  然後下面這些你在看的時候你有任何的問題嗎\n",
            "[ 55%] 00:41:35,160 → 00:41:37,300  或是有不太懂的地方嗎\n",
            "[ 56%] 00:41:40,000 → 00:42:00,000  應該都還好,剛剛前面說要給他們一些標籤,讓他們對好入座,我現在是沒想到有什麼啦,我想問你們,在寫物理的時候。\n",
            "[ 56%] 00:42:00,000 → 00:42:01,240  會有什麼問題嗎?\n",
            "[ 56%] 00:42:01,240 → 00:42:03,500  還是平常沒有在寫物理?\n",
            "[ 56%] 00:42:06,840 → 00:42:07,800  我有寫過\n",
            "[ 56%] 00:42:09,000 → 00:42:10,160  那你有什麼問題嗎?\n",
            "[ 56%] 00:42:11,540 → 00:42:12,660  我覺得從\n",
            "[ 56%] 00:42:13,660 → 00:42:16,560  如果是緯程那邊要整理這些問題的話\n",
            "[ 56%] 00:42:16,560 → 00:42:17,800  我反而會覺得\n",
            "[ 56%] 00:42:18,500 → 00:42:19,960  育謙那邊可能可以看\n",
            "[ 57%] 00:42:20,000 → 00:42:38,000  開一個物理的問答,限動的問答,然後藉由這樣子蒐集問題去知道學生的症節點在哪邊,然後就把那些問題全部灌到 CheckGPT,然後請CheckGPT整理學生有哪些類型,這樣應該就很快就可以找到那些問題。\n",
            "[ 57%] 00:42:38,000 → 00:42:40,000  但是問完那些問題之後……\n",
            "[ 57%] 00:42:40,000 → 00:42:47,000  可能未曾要幫忙簡單回答一下 因為育成可能沒辦法自己去回答物理的專業問題\n",
            "[ 57%] 00:42:47,000 → 00:42:52,000  被問問了但是沒有打算回答 這樣過分\n",
            "[ 57%] 00:42:52,000 → 00:43:00,000  我想舉一個例子就是我覺得我自己寫物理最大的祕訣是腦中藥\n",
            "[ 58%] 00:43:00,000 → 00:43:20,000  老公要有畫面,老公要有那個東西在跑的畫面,所以就可以把它當成是一個技巧,比如說看的那些物理的公式,看的那些數字,它沒有感覺怎麼樣,就可以去提。\n",
            "[ 58%] 00:43:20,000 → 00:43:28,000  提供他一些,譬如說像我剛剛講的那種讓自己比較有感覺的技巧這樣\n",
            "[ 58%] 00:43:28,000 → 00:43:30,000  類似這種方向\n",
            "[ 58%] 00:43:32,000 → 00:43:37,000  我有想過就是腦中要有畫面這件事情\n",
            "[ 58%] 00:43:37,000 → 00:43:40,000  但我後來發現就是好像不是每個人都可以做\n",
            "[ 58%] 00:43:40,000 → 00:43:44,000  就有些人特別沒有想像力\n",
            "[ 58%] 00:43:44,000 → 00:43:48,000  我要想一下就是要給我給他這個想像力\n",
            "[ 58%] 00:43:48,000 → 00:43:50,000  你要引導他去構思\n",
            "[ 58%] 00:43:50,000 → 00:43:52,000  對引導他去構思這個想像力\n",
            "[ 58%] 00:43:52,000 → 00:44:00,000  或是你也可以找一些線上的視覺化\n",
            "[ 59%] 00:44:00,000 → 00:44:04,000  現在有一些線上的物理方面的視覺化的工具\n",
            "[ 59%] 00:44:04,000 → 00:44:07,000  也可以引導他們去使用這些工具\n",
            "[ 59%] 00:44:07,000 → 00:44:10,000  然後自己去拉拉看那個訊息之類的\n",
            "[ 59%] 00:44:12,000 → 00:44:14,000  我可以稍微跟你提一個\n",
            "[ 59%] 00:44:14,000 → 00:44:17,000  可能比較像是聯想或者一個小技巧\n",
            "[ 59%] 00:44:17,000 → 00:44:20,000  像英文作文裡那個字名它就會\n",
            "[ 59%] 00:44:20,000 → 00:44:23,660  用break pin去講一些公式跟觀念\n",
            "[ 59%] 00:44:23,660 → 00:44:28,960  讓學生他們的想像畫面是以他們熟悉的東西去帶入\n",
            "[ 59%] 00:44:28,960 → 00:44:32,860  那他們就會比較好聯想到你要跟他們講什麼\n",
            "[ 59%] 00:44:32,860 → 00:44:38,020  然後當他們真的對於那個畫面沒有太大的感受的時候\n",
            "[ 59%] 00:44:38,020 → 00:44:39,900  他們也可以因為這個東西是他們比較\n",
            "[ 59%] 00:44:40,000 → 00:44:42,400  日常生活化就有在接觸的東西。\n",
            "[ 59%] 00:44:42,400 → 00:44:45,200  所以進而聯想到那個很抽象的畫面。\n",
            "[ 60%] 00:44:47,200 → 00:44:49,100  這就會是我們剛剛上面有講到的,\n",
            "[ 60%] 00:44:49,100 → 00:44:51,700  就是你可能要再多運用一些生活化\n",
            "[ 60%] 00:44:51,700 → 00:44:55,300  或是很日常的東西去做比喻,\n",
            "[ 60%] 00:44:55,300 → 00:44:57,100  然後去做例子的講解。\n",
            "[ 60%] 00:45:00,000 → 00:45:09,300  好,然後再來的話,學生需要會有一個固定的,固定默契的emoji,\n",
            "[ 60%] 00:45:09,460 → 00:45:13,680  因為它會是讓學生知道,我今天看到這個圖示的時候,\n",
            "[ 60%] 00:45:13,900 → 00:45:18,000  我就是接下來會看到什麼樣的內容,讓他們有一個小小的概念點。\n",
            "[ 61%] 00:45:20,000 → 00:45:40,000  但是如果以英文中文來講的話,這個東西就會是對應到總結的重點,然後小燈泡的話就會是一個口訣或是一個記憶法,然後如果你今天是一個手加一個筆的話,那就是你的動手練習,就是你可以稍微去幫他設計一個固定的符號,讓他們有一個小概念,他們才不會覺得...\n",
            "[ 61%] 00:45:40,000 → 00:45:44,000  看起來很亂,然後台板上我們也會比較整齊一點點。\n",
            "[ 61%] 00:45:44,000 → 00:45:48,140  然後如果今天是你想要自己跟學生講的話,\n",
            "[ 61%] 00:45:48,240 → 00:45:53,320  你也可以用一個可能老師的符號,或者是一個男生的符號,\n",
            "[ 61%] 00:45:53,500 → 00:45:56,440  然後跟他們講說這比較像是你心裡的話,\n",
            "[ 61%] 00:45:56,600 → 00:45:59,000  那他就不用那麼文綴綴,他就是真的可以很...\n",
            "[ 61%] 00:46:00,000 → 00:46:03,000  就是比較日常口語化的東西就可以了\n",
            "[ 61%] 00:46:03,000 → 00:46:06,000  然後再來就是上次就有提到的東西\n",
            "[ 61%] 00:46:06,000 → 00:46:08,000  就是說表達高用AI論搞過\n",
            "[ 61%] 00:46:08,000 → 00:46:11,000  因為現在的物理講義內容比較像是\n",
            "[ 61%] 00:46:11,000 → 00:46:13,000  你真的想到什麼然後就打什麼出來\n",
            "[ 61%] 00:46:13,000 → 00:46:15,000  它沒有一個固定的格式\n",
            "[ 62%] 00:46:15,000 → 00:46:18,000  然後甚至這樣的內容可能比較像是\n",
            "[ 62%] 00:46:18,000 → 00:46:20,000  只有你自己看得懂\n",
            "[ 62%] 00:46:20,000 → 00:46:22,000  所有的表達我們都可以丟到TradeGPT\n",
            "[ 62%] 00:46:22,000 → 00:46:24,000  就你只要把你的想法丟上去\n",
            "[ 62%] 00:46:24,000 → 00:46:26,000  然後剛才你說你可以幫我run稿嗎\n",
            "[ 62%] 00:46:26,000 → 00:46:28,000  或是你可以幫我修飾成\n",
            "[ 62%] 00:46:28,000 → 00:46:30,000  可能高中生也看得懂的話語\n",
            "[ 62%] 00:46:30,000 → 00:46:32,000  它就會直接幫你寫出來\n",
            "[ 62%] 00:46:32,000 → 00:46:34,000  但是它生成的內容\n",
            "[ 62%] 00:46:34,000 → 00:46:36,000  你還是需要再去檢查過\n",
            "[ 62%] 00:46:36,000 → 00:46:38,000  因為它有時候不一定是那麼正確\n",
            "[ 62%] 00:46:38,000 → 00:46:40,000  或是不一定那麼貼近你想要表達的\n",
            "[ 62%] 00:46:40,000 → 00:46:45,000  所以你就跟他多聊幾次就可以了。\n",
            "[ 62%] 00:46:45,000 → 00:46:47,000  好,以上是知識存在的方面。\n",
            "[ 62%] 00:46:47,000 → 00:46:51,000  然後如果是使用者體驗方面的話,\n",
            "[ 62%] 00:46:51,000 → 00:46:54,000  像是AI化、線上化跟連結種整理,\n",
            "[ 62%] 00:46:54,000 → 00:46:58,000  就會需要麻煩你在編寫獎益的內容之後,\n",
            "[ 62%] 00:46:58,000 → 00:47:00,000  在編寫獎益內容的之中,\n",
            "[ 62%] 00:47:00,000 → 00:47:02,800  我就邊想還有哪些東西可以去製作\n",
            "[ 63%] 00:47:02,800 → 00:47:04,900  然後在你撰寫的過程中\n",
            "[ 63%] 00:47:04,900 → 00:47:07,500  也可以邊製作一些AI工具\n",
            "[ 63%] 00:47:07,500 → 00:47:09,000  或是把東西線上畫\n",
            "[ 63%] 00:47:10,500 → 00:47:14,200  然後全球地圖廣告頁跟意見回饋購買東西調查\n",
            "[ 63%] 00:47:14,200 → 00:47:16,600  這些都會由e-mall這邊直接處理\n",
            "[ 63%] 00:47:18,000 → 00:47:19,500  然後再來是格式的話\n",
            "[ 63%] 00:47:20,000 → 00:47:30,000  因為我知道你現在跟小助手的方式 好像是你會先把他整理過 然後再傳檔案給他 對嗎?\n",
            "[ 63%] 00:47:32,000 → 00:47:33,000  對\n",
            "[ 63%] 00:47:33,000 → 00:47:38,000  對 所以格式的話可能要 就是從你那邊一開始打的時候\n",
            "[ 63%] 00:47:38,000 → 00:47:40,000  就是你開始編輯這個書的時候\n",
            "[ 63%] 00:47:40,000 → 00:47:42,240  你可能就要稍微幫我注意一下格式\n",
            "[ 63%] 00:47:42,240 → 00:47:43,980  我們就是以B5為主\n",
            "[ 63%] 00:47:43,980 → 00:47:46,060  然後那個初期線要稍微注意\n",
            "[ 64%] 00:47:46,060 → 00:47:48,780  至少邊邊要預留三面面\n",
            "[ 64%] 00:47:48,780 → 00:47:49,500  它會比較\n",
            "[ 64%] 00:47:49,500 → 00:47:53,520  就硬刷的時候才會比較不會卡到板\n",
            "[ 64%] 00:47:53,520 → 00:47:54,420  然後需要\n",
            "[ 64%] 00:47:54,420 → 00:47:55,620  預留多少\n",
            "[ 64%] 00:47:55,620 → 00:47:58,560  就是你開word\n",
            "[ 64%] 00:47:58,560 → 00:48:00,000  然後它會有那個\n",
            "[ 64%] 00:48:00,000 → 00:48:02,000  至少要窄\n",
            "[ 64%] 00:48:02,000 → 00:48:04,000  它有一個版面配飾\n",
            "[ 64%] 00:48:04,000 → 00:48:06,000  然後你最多最多只能選擇窄\n",
            "[ 64%] 00:48:06,000 → 00:48:08,000  然後不能再往下縮\n",
            "[ 64%] 00:48:10,000 → 00:48:12,000  等一下我再開給你看好了\n",
            "[ 64%] 00:48:12,000 → 00:48:14,000  稍等我一下\n",
            "[ 65%] 00:48:20,000 → 00:48:39,240  好,就是你在用Word等的時候,它其實有一個版面配置,然後你就,你需要先一開始就先幫我把大小分到。\n",
            "[ 65%] 00:48:40,000 → 00:48:42,640  啊我冇覆好,稍等我\n",
            "[ 65%] 00:48:42,640 → 00:48:44,080  奈咦阿捏\n",
            "[ 65%] 00:48:44,080 → 00:48:50,540  這樣有咩\n",
            "[ 65%] 00:48:50,540 → 00:48:55,720  所以你一開始就需要幫我把大小\n",
            "[ 65%] 00:48:55,720 → 00:48:57,880  就直接先選成B5的大小\n",
            "[ 65%] 00:48:57,880 → 00:48:59,780  然後邊界這邊\n",
            "[ 65%] 00:49:00,000 → 00:49:02,000  最多最多就是以窄為主\n",
            "[ 65%] 00:49:02,000 → 00:49:04,000  就是盡量不要再往下縮\n",
            "[ 65%] 00:49:04,000 → 00:49:08,000  不然我們的印刷照片可能會踩到旁邊\n",
            "[ 65%] 00:49:08,000 → 00:49:10,000  這部分OK咩?\n",
            "[ 65%] 00:49:10,000 → 00:49:12,000  OK\n",
            "[ 65%] 00:49:12,000 → 00:49:14,000  再超出一點點\n",
            "[ 65%] 00:49:14,000 → 00:49:16,000  一點點\n",
            "[ 65%] 00:49:16,000 → 00:49:18,000  對對對就是一點點\n",
            "[ 66%] 00:49:18,000 → 00:49:20,000  但不要壓得太緊\n",
            "[ 66%] 00:49:20,000 → 00:49:22,000  你可以回去剛那個地方嗎?\n",
            "[ 66%] 00:49:22,000 → 00:49:26,000  你看它的右上角\n",
            "[ 66%] 00:49:26,000 → 00:49:29,000  右上角是不是有一個L形的東西?\n",
            "[ 66%] 00:49:32,000 → 00:49:36,000  在紙張上有一個L形的框架\n",
            "[ 66%] 00:49:36,000 → 00:49:38,000  對這個\n",
            "[ 66%] 00:49:38,000 → 00:49:40,000  就是它的那個死角的那個\n",
            "[ 66%] 00:49:40,000 → 00:49:42,000  你的字可以寫到那邊\n",
            "[ 66%] 00:49:42,000 → 00:49:47,000  然後如果你字真的想要在外面再延伸一點點的話\n",
            "[ 66%] 00:49:47,000 → 00:49:52,000  就是不可以超過那個L型的中端\n",
            "[ 66%] 00:49:52,000 → 00:49:55,000  就不可以寫出L型的外面\n",
            "[ 66%] 00:49:55,000 → 00:49:59,000  就會是不會被拆到的格式\n",
            "[ 67%] 00:50:00,000 → 00:50:07,000  但是今天還是幫我縮在L型裡面會比較保險一點點\n",
            "[ 67%] 00:50:07,000 → 00:50:15,000  然後再來的話其他目前都有講過\n",
            "[ 67%] 00:50:15,000 → 00:50:20,000  這個呼籲社群宣傳\n",
            "[ 67%] 00:50:20,000 → 00:50:22,700  比較會像是你寫書已經寫到後半段之後\n",
            "[ 67%] 00:50:22,700 → 00:50:24,700  我們可以再來進行的東西\n",
            "[ 67%] 00:50:24,700 → 00:50:27,800  所以這個我們可以之後在開會的時候跟你講一下\n",
            "[ 67%] 00:50:29,800 → 00:50:33,300  然後誓願內容商品化會\n",
            "[ 67%] 00:50:33,300 → 00:50:34,800  這個就是範例\n",
            "[ 67%] 00:50:34,800 → 00:50:38,200  我們以英文作文或是英文文法\n",
            "[ 67%] 00:50:38,200 → 00:50:39,400  或是英文單字說的話\n",
            "[ 67%] 00:50:39,400 → 00:50:40,000  我們可能都會\n",
            "[ 67%] 00:50:40,000 → 00:50:46,320  給他一個備單的機器人 然後拿這個機器人去推廣我們的作文書跟其他的產品\n",
            "[ 68%] 00:50:46,320 → 00:50:49,560  就是當你使用這個機器人的時候 它底下其實會生成\n",
            "[ 68%] 00:50:49,560 → 00:50:54,860  如果你想看更多完整的內容 或者如果你想要看什麼更完整的文法解說\n",
            "[ 68%] 00:50:54,860 → 00:50:58,640  你可以購買一模一模的那本書 然後會貼一個下一個連結給他\n",
            "[ 68%] 00:50:58,640 → 00:51:00,000  就是到時候物理也可以用\n",
            "[ 68%] 00:51:00,000 → 00:51:02,800  用這種方式去做一個行銷宣傳。\n",
            "[ 68%] 00:51:02,800 → 00:51:06,800  在這裡,就是想知道如果背一個單字補輸一個觀念,\n",
            "[ 68%] 00:51:06,800 → 00:51:09,800  然後這就會是我們完整的書籍內容宣傳。\n",
            "[ 68%] 00:51:12,800 → 00:51:18,800  好,那目前以上有任何問題或是有任何想問的嗎?\n",
            "[ 68%] 00:51:20,000 → 00:51:26,120  因為Himoji那邊現在的樹就有了,所以還好。\n",
            "[ 68%] 00:51:26,120 → 00:51:31,440  然後你有一個MBTI那個是沒有要理它嗎?\n",
            "[ 69%] 00:51:34,960 → 00:51:40,020  因為這個可能就是對於物理...\n",
            "[ 69%] 00:51:40,000 → 00:51:43,200  講義有點難運用\n",
            "[ 69%] 00:51:43,200 → 00:51:43,840  其實\n",
            "[ 69%] 00:51:43,840 → 00:51:45,960  哦好那我就不理他\n",
            "[ 69%] 00:51:45,960 → 00:51:47,340  好好\n",
            "[ 69%] 00:51:47,340 → 00:51:48,280  子明你可以說\n",
            "[ 69%] 00:51:48,280 → 00:51:53,080  我寫那個其實只是一個紀錄\n",
            "[ 69%] 00:51:53,080 → 00:51:54,980  它不一定要寫NBT\n",
            "[ 69%] 00:51:54,980 → 00:51:56,820  我想講的只是說\n",
            "[ 69%] 00:51:56,820 → 00:51:59,240  你可以去設想\n",
            "[ 69%] 00:52:00,000 → 00:52:02,000  學生有千千百百多\n",
            "[ 69%] 00:52:02,000 → 00:52:04,000  就是有一些人\n",
            "[ 69%] 00:52:04,000 → 00:52:08,000  因為你自己怎麼學物理\n",
            "[ 69%] 00:52:08,000 → 00:52:10,000  跟其他人怎麼學物理\n",
            "[ 69%] 00:52:10,000 → 00:52:11,000  一定是非常不同的\n",
            "[ 69%] 00:52:11,000 → 00:52:13,000  然後除了是專業知識\n",
            "[ 69%] 00:52:13,000 → 00:52:15,000  觀念上面的落差之外\n",
            "[ 69%] 00:52:15,000 → 00:52:17,000  其實他們在理解知識\n",
            "[ 70%] 00:52:17,000 → 00:52:20,000  還有如何讀完這本書上面\n",
            "[ 70%] 00:52:20,000 → 00:52:22,500  本身就會有很大的不同\n",
            "[ 70%] 00:52:22,500 → 00:52:24,500  像譬如說喻謙好了\n",
            "[ 70%] 00:52:24,500 → 00:52:26,500  他如果今天讀到一本書\n",
            "[ 70%] 00:52:26,500 → 00:52:28,500  然後事實上他覺得很用心\n",
            "[ 70%] 00:52:33,500 → 00:52:35,500  如果是那本書讓喻謙覺得很用心\n",
            "[ 70%] 00:52:35,500 → 00:52:37,500  然後很有溫度\n",
            "[ 70%] 00:52:37,500 → 00:52:39,500  然後是很想把學徒顧好\n",
            "[ 70%] 00:52:39,500 → 00:52:40,500  喻謙就會想\n",
            "[ 70%] 00:52:40,000 → 00:52:42,000  你想把它讀完,你說是不是?\n",
            "[ 70%] 00:52:42,000 → 00:52:44,000  對\n",
            "[ 70%] 00:52:44,000 → 00:52:46,000  但是我的個性可能就會是\n",
            "[ 70%] 00:52:46,000 → 00:52:48,000  我想要看到超級爆炸具體的東西\n",
            "[ 70%] 00:52:48,000 → 00:52:50,000  你不要給我扯一些有的沒的的\n",
            "[ 70%] 00:52:50,000 → 00:52:52,000  剛才跟我講的重點\n",
            "[ 70%] 00:52:52,000 → 00:52:57,000  然後其他學生有些可能會喜歡圖像化的解說\n",
            "[ 70%] 00:52:57,000 → 00:53:00,000  然後就是你比起用文字去寫\n",
            "[ 70%] 00:53:00,000 → 00:53:01,800  寫第一步驟第二步驟第三步驟\n",
            "[ 71%] 00:53:01,800 → 00:53:05,300  你還不如直接用一張圖片或Canva的字圖\n",
            "[ 71%] 00:53:05,300 → 00:53:07,300  去告訴他三步驟是什麼\n",
            "[ 71%] 00:53:07,300 → 00:53:09,500  那又會有一些可能又會喜歡\n",
            "[ 71%] 00:53:09,500 → 00:53:13,100  就是兩個人的對話去推進一個觀念\n",
            "[ 71%] 00:53:13,100 → 00:53:14,600  就大家都有不同學習方式\n",
            "[ 71%] 00:53:14,600 → 00:53:16,900  然後我覺得你不一定要用MVTI\n",
            "[ 71%] 00:53:16,900 → 00:53:19,100  去把16個全部都想過一次\n",
            "[ 71%] 00:53:19,100 → 00:53:19,900  而是你\n",
            "[ 71%] 00:53:20,000 → 00:53:21,640  至少在寫獎音的時候\n",
            "[ 71%] 00:53:21,640 → 00:53:25,760  你要先抓幾個學生的標籤跟概念出來\n",
            "[ 71%] 00:53:25,760 → 00:53:28,640  可能是圖像化學生、理論化學生\n",
            "[ 71%] 00:53:28,640 → 00:53:31,040  然後比較情緒化的學生\n",
            "[ 71%] 00:53:31,040 → 00:53:32,000  抓幾個標籤出來\n",
            "[ 71%] 00:53:32,000 → 00:53:35,240  然後去寫獎音的時候照顧到這些學生的需求\n",
            "[ 71%] 00:53:37,240 → 00:53:39,040  好,我講完了\n",
            "[ 71%] 00:53:40,000 → 00:53:43,000  Ok, this part, do you think it's ok?\n",
            "[ 71%] 00:53:44,000 → 00:53:45,000  Yes, it's ok.\n",
            "[ 71%] 00:53:46,000 → 00:53:48,000  Ok, and then...\n",
            "[ 72%] 00:53:51,000 → 00:53:56,000  If you are in the process of making it, or you need some AI tools to help you,\n",
            "[ 72%] 00:53:56,000 → 00:54:00,000  you can find Pei Jun, he is a very good...\n",
            "[ 72%] 00:54:00,000 → 00:54:04,200  所以如果你在這雙方沒有問題的話都可以問他\n",
            "[ 72%] 00:54:04,200 → 00:54:16,000  我們不是還有一個是要問Pedro的事情嗎\n",
            "[ 72%] 00:54:20,000 → 00:54:22,000  我可以分享我的畫面嗎?\n",
            "[ 72%] 00:54:22,000 → 00:54:24,000  欸等一下,物理那邊都講完了吧?\n",
            "[ 72%] 00:54:24,000 → 00:54:26,000  對\n",
            "[ 72%] 00:54:26,000 → 00:54:30,000  好,那我想要問一下裴娟一個東西\n",
            "[ 72%] 00:54:30,000 → 00:54:32,000  我分享一下我的畫面\n",
            "[ 73%] 00:54:40,000 → 00:54:59,920  我们刚刚有讲到很多写讲义上面的东西,只是如果我们这边有这套准则,但是像伟臣可能写的时候还是会需要时不时回去看交战手册,然后有时候可能还是会不小心漏掉一些东西,或不知道怎么去使用,然后我在想如果我们未来\n",
            "[ 73%] 00:55:00,000 → 00:55:06,000  可能會需要同時跑很多本書 很多個合作者一起寫這樣一個話\n",
            "[ 73%] 00:55:06,000 → 00:55:09,000  我們來回溝通可能會需要花很多時間\n",
            "[ 73%] 00:55:09,000 → 00:55:14,000  然後就想到說 之前我在學SEO的時候\n",
            "[ 73%] 00:55:14,000 → 00:55:17,000  有一個像這樣子的工具\n",
            "[ 74%] 00:55:17,000 → 00:55:20,000  就是它的左邊是你在寫書\n",
            "[ 74%] 00:55:20,000 → 00:55:40,000  文章的頁面,然後右邊他就會告訴你說你現在拿到多少分,就是你有做到多少需求之內的事情,然後他就會一直提醒你說你還要再寫什麼,你還要再寫什麼才會足夠完整,然後在想就是這樣子的一個工具他製作的難度。\n",
            "[ 74%] 00:55:40,000 → 00:55:59,100  我覺得應該,這個東西他看起來是有機會整合在Notion裡面,但是我覺得他看起來,因為我們獎勵的內容其實是非常多嘛,我覺得他看起來對於Token的開銷會非常大,就是\n",
            "[ 75%] 00:56:00,000 → 00:56:10,000  我覺得我們透過應用程式去跟AI做串接,它中間其實是以量計價的。\n",
            "[ 75%] 00:56:10,000 → 00:56:20,000  我覺得這東西它或許是可以嘗試看看來做,但是因為\n",
            "[ 75%] 00:56:20,000 → 00:56:27,000  另一方面講義的內容很多,另一方面教單手字的內容也蠻多的\n",
            "[ 75%] 00:56:27,000 → 00:56:32,000  我覺得這個可能使用量的部分會比較大一點點\n",
            "[ 75%] 00:56:32,000 → 00:56:36,000  但這個東西會越來越便宜啦\n",
            "[ 75%] 00:56:36,000 → 00:56:40,000  所以或許我可以嘗試看看用\n",
            "[ 75%] 00:56:40,000 → 00:56:45,640  比較之前的,應該說用量比較小比較便宜的模型來試試看\n",
            "[ 75%] 00:56:46,660 → 00:56:49,720  因為畢竟他這個東西他不會要求說\n",
            "[ 76%] 00:56:49,980 → 00:56:53,320  就是我AI傳出的內容要到多進去\n",
            "[ 76%] 00:56:55,360 → 00:56:59,960  我覺得可以研究看看有沒有機會把它整合在Notion裡面\n",
            "[ 76%] 00:57:00,000 → 00:57:02,760  可能他更新頻率不會到這麼的高\n",
            "[ 76%] 00:57:02,760 → 00:57:09,760  可能就是寫作者完成一整階段的工作之後\n",
            "[ 76%] 00:57:09,760 → 00:57:14,500  再去再用AI去做這個提醒這樣\n",
            "[ 76%] 00:57:18,240 → 00:57:19,000  那如果\n",
            "[ 76%] 00:57:20,000 → 00:57:29,300  如果把這個工具切成是很多個更小的工具 那如果把這個工具切成是很多個更小的工具\n",
            "[ 76%] 00:57:29,300 → 00:57:33,780  就是我們不一定要是一戰式的解決所有講義變形的問題\n",
            "[ 77%] 00:57:33,780 → 00:57:40,000  可能把剛剛教授的手冊細分成五個層面或三個層面\n",
            "[ 77%] 00:57:40,000 → 00:57:47,000  要分別套這樣子的工具,它的用量這樣子會再更大,還是可以節省一點。\n",
            "[ 77%] 00:58:00,000 → 00:58:07,000  要怎麼切我覺得後續可以再來想了,目前就是我覺得可能要再研究一下。\n",
            "[ 77%] 00:58:07,000 → 00:58:14,000  好,不然我也先用ChangeGPT做做看好了,我先打一張手冊寫ChangeGPT。\n",
            "[ 77%] 00:58:14,000 → 00:58:20,000  然後維城如果會,如果想要看看說自己有沒有\n",
            "[ 78%] 00:58:20,000 → 00:58:24,680  有一些東西漏掉的話,你就可以先把你的獎金丟進去,change your VT\n",
            "[ 78%] 00:58:24,680 → 00:58:27,680  但是你一次可能就只能丟個十頁\n",
            "[ 78%] 00:58:27,680 → 00:58:30,680  就不能一次丟那個幾百頁進去\n",
            "[ 78%] 00:58:30,680 → 00:58:34,680  然後他可能就會告訴你說你還有哪些地方需要再錄\n",
            "[ 78%] 00:58:34,680 → 00:58:40,680  現階段先這樣子,然後這個可以之後有研究出來\n",
            "[ 78%] 00:58:40,000 → 00:58:43,000  讓我們再拿出來討論看看。\n",
            "[ 78%] 00:58:45,000 → 00:58:47,000  好,我講完了。\n",
            "[ 78%] 00:58:47,000 → 00:58:49,000  好耶。\n",
            "[ 78%] 00:58:49,000 → 00:58:52,000  那目前維生有任何想問的嗎?\n",
            "[ 78%] 00:58:52,000 → 00:58:56,000  或者也想分享看看你的想法也都可以。\n",
            "[ 79%] 00:59:00,000 → 00:59:09,440  我問個問題,就是之前不是有說你要開另外一個物理的帳號嗎?\n",
            "[ 79%] 00:59:09,440 → 00:59:11,440  嗯\n",
            "[ 79%] 00:59:11,440 → 00:59:20,000  就是我覺得應該要開另外一個跟英文獨立的帳號會比較好,不管你之後有沒有要掛e-mail的問題\n",
            "[ 79%] 00:59:20,000 → 00:59:22,000  我覺得分開會比較好\n",
            "[ 79%] 00:59:22,000 → 00:59:24,000  有原因嗎?\n",
            "[ 79%] 00:59:24,000 → 00:59:26,000  就是覺得分開會比較好\n",
            "[ 79%] 00:59:26,000 → 00:59:28,000  因為emote本來就是文科嘛\n",
            "[ 79%] 00:59:28,000 → 00:59:30,000  然後如果突然變成理科的話\n",
            "[ 79%] 00:59:30,000 → 00:59:32,000  就是你如果發的內容都混在一起\n",
            "[ 80%] 00:59:40,000 → 00:59:59,000  至少理科跟文科一個比較專業的分別,我會傾向把它分開,至少我看到這個帳號的時候我也知道它的專業是英文,這個帳號的專業是什麼,雖然它背後的人可能是同一批人。\n",
            "[ 80%] 01:00:00,000 → 01:00:02,000  我覺得它好像是不同的處理邏輯\n",
            "[ 80%] 01:00:02,000 → 01:00:04,000  就是我們現在如果把物理\n",
            "[ 80%] 01:00:04,000 → 01:00:06,000  它是兩種都是正確的狀況\n",
            "[ 80%] 01:00:06,000 → 01:00:08,000  然後我可能先跟你分享看看\n",
            "[ 80%] 01:00:08,000 → 01:00:10,000  要看你會不會有不同想法\n",
            "[ 80%] 01:00:20,000 → 01:00:25,000  如果是把講義掛到英文帳號的話\n",
            "[ 80%] 01:00:25,000 → 01:00:33,000  那其實是變成我們是幫助你在私領域去找客人\n",
            "[ 81%] 01:00:33,000 → 01:00:37,000  就是我們的瀏覽\n",
            "[ 81%] 01:00:37,000 → 01:00:40,000  我有做過一張圖秀給你看一下\n",
            "[ 81%] 01:00:40,000 → 01:00:48,300  就是我們的流量入口 IG的那些貼文就不太會真的去做物理專業知識相關的東西\n",
            "[ 81%] 01:00:48,300 → 01:00:52,580  那個就是真的跟英文真的太不相關\n",
            "[ 81%] 01:00:52,580 → 01:00:56,840  然後那個內容這樣跳來跳去也比較不符合學生的習慣\n",
            "[ 81%] 01:00:56,840 → 01:00:59,880  所以物理的專業知識不會\n",
            "[ 81%] 01:01:00,000 → 01:01:09,000  作為流量入口,我們的流量入口都會是以內容為主,只是那些流量進來之後\n",
            "[ 81%] 01:01:14,000 → 01:01:16,000  這邊沒有斷掉\n",
            "[ 82%] 01:01:20,000 → 01:01:34,080  他們還會被導到像是我們的節目或Line群然後限動\n",
            "[ 82%] 01:01:34,080 → 01:01:37,940  等於說是可能有6萬個追蹤者是追我們的IG\n",
            "[ 82%] 01:01:37,940 → 01:01:39,980  但是可能進入到死領域的\n",
            "[ 82%] 01:01:40,000 → 01:01:41,000  可能就只有一萬個\n",
            "[ 82%] 01:01:41,000 → 01:01:44,000  然後一萬個當中我們再想辦法幫你推銷\n",
            "[ 82%] 01:01:44,000 → 01:01:46,000  最後推銷出來\n",
            "[ 82%] 01:01:46,000 → 01:01:51,000  成交的數量就會比英文還要少\n",
            "[ 82%] 01:01:51,000 → 01:01:53,000  這是比較正常的狀況\n",
            "[ 82%] 01:01:53,000 → 01:01:55,000  但是相對來說\n",
            "[ 82%] 01:01:55,000 → 01:01:57,000  如果我們今天就開個全新的帳號\n",
            "[ 82%] 01:01:57,000 → 01:02:00,000  那我們那個全新的帳號也必須達到一定的粉絲級\n",
            "[ 82%] 01:02:00,000 → 01:02:02,760  才可以去平衡掉我剛剛說\n",
            "[ 82%] 01:02:02,760 → 01:02:04,800  比如說導到死領域的可能有一萬個\n",
            "[ 83%] 01:02:04,800 → 01:02:06,980  那就代表如果我們要重開一個帳號\n",
            "[ 83%] 01:02:06,980 → 01:02:10,300  那個帳號可能至少就要光靠自然科\n",
            "[ 83%] 01:02:10,300 → 01:02:14,060  光靠物理可能就要至少達到一萬個粉絲\n",
            "[ 83%] 01:02:14,060 → 01:02:16,220  它才會比較有機率\n",
            "[ 83%] 01:02:16,220 → 01:02:18,480  可以達到跟英文一樣的宣傳效果\n",
            "[ 83%] 01:02:18,480 → 01:02:19,980  就有點像我這邊\n",
            "[ 83%] 01:02:20,000 → 01:02:22,000  我沒有做一個圖\n",
            "[ 83%] 01:02:22,000 → 01:02:27,000  就是打開熱量漏斗的地方其實是我們會用英文去做\n",
            "[ 83%] 01:02:27,000 → 01:02:29,000  但是其他的這個地方\n",
            "[ 83%] 01:02:29,000 → 01:02:31,000  YouTube 跟 IG 限動\n",
            "[ 83%] 01:02:31,000 → 01:02:34,000  還有專業的一些課程\n",
            "[ 83%] 01:02:34,000 → 01:02:35,000  就是講義啊\n",
            "[ 83%] 01:02:35,000 → 01:02:38,000  然後現在是沒有在做直播跟團課啦\n",
            "[ 83%] 01:02:38,000 → 01:02:40,000  但是其他的一些專業的\n",
            "[ 83%] 01:02:40,000 → 01:02:46,600  像私訊的問題回答還有Line群的問題回答都會幫你的物理數據倒流\n",
            "[ 83%] 01:02:46,600 → 01:02:49,000  這樣你要懂意思嗎\n",
            "[ 84%] 01:02:49,000 → 01:03:00,000  但我剛意思其實是說如果你要發物理的文章的話或什麼東西的話我覺得就是要有另外一個帳號\n",
            "[ 84%] 01:03:00,000 → 01:03:02,000  喔對啊確實\n",
            "[ 84%] 01:03:02,000 → 01:03:06,000  可是誰要來發物理的文章\n",
            "[ 84%] 01:03:06,000 → 01:03:08,000  你會想要發物理的文章嗎\n",
            "[ 84%] 01:03:08,000 → 01:03:10,000  如果我有寫的話\n",
            "[ 84%] 01:03:10,000 → 01:03:14,000  或者就是你之前不是說要做一些奇怪的實驗\n",
            "[ 84%] 01:03:14,000 → 01:03:16,000  所以我不知道你要做什麼實驗\n",
            "[ 84%] 01:03:16,000 → 01:03:20,000  喔對啊我之前不是有傳給你一個\n",
            "[ 84%] 01:03:20,000 → 01:03:23,000  你有看過這個嗎?\n",
            "[ 84%] 01:03:23,000 → 01:03:25,000  你有傳給我嗎?\n",
            "[ 84%] 01:03:25,000 → 01:03:28,000  我傳在 Slack 啦\n",
            "[ 84%] 01:03:28,000 → 01:03:30,000  就是我們會\n",
            "[ 84%] 01:03:30,000 → 01:03:33,000  如果是我幫你做內容的話\n",
            "[ 84%] 01:03:33,000 → 01:03:35,000  我理想上會是\n",
            "[ 85%] 01:03:35,000 → 01:03:37,000  我找一下那個\n",
            "[ 85%] 01:03:37,000 → 01:03:39,000  如果是專業的物理知識\n",
            "[ 85%] 01:03:39,000 → 01:03:41,000  就會是需要你來幫忙\n",
            "[ 85%] 01:03:40,000 → 01:03:45,000  如果是我們幫你做內容可能會做的比較類似這種\n",
            "[ 85%] 01:03:45,000 → 01:03:47,000  欸這個\n",
            "[ 85%] 01:03:51,000 → 01:03:53,000  喔我有看到這個\n",
            "[ 85%] 01:03:54,000 → 01:03:58,000  喔就只能做的比較娛樂化一點\n",
            "[ 85%] 01:03:59,000 → 01:04:00,000  然後再把你放寡\n",
            "[ 85%] 01:04:00,000 → 01:04:02,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:02,000 → 01:04:04,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:04,000 → 01:04:06,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:06,000 → 01:04:08,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:08,000 → 01:04:10,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:10,000 → 01:04:12,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:12,000 → 01:04:14,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:14,000 → 01:04:16,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:16,000 → 01:04:18,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:18,000 → 01:04:20,000  如果你是開一個全新的賬號\n",
            "[ 86%] 01:04:20,000 → 01:04:24,600  其實會需要有穩定的內容才處理\n",
            "[ 86%] 01:04:24,600 → 01:04:29,600  就是你可能不能是想到文章再發\n",
            "[ 86%] 01:04:29,600 → 01:04:33,000  然後我們這邊就會是需要\n",
            "[ 86%] 01:04:33,000 → 01:04:35,800  每次都就是幫你去做布林的帖文\n",
            "[ 86%] 01:04:40,000 → 01:05:00,000  如果是掛在英文上的話,有時候就可以像我之前有給你看單字數的ChangeGPT,有時候我覺得把那個ChangeGPT放在英文,然後讓它流傳下去的話,像現在的ChangeGPT就有三千多個對話,然後如果三千多個對話,每一次對話都會有三千多個對話,\n",
            "[ 86%] 01:05:00,000 → 01:05:02,000  如果有一個肯定的廣告的話\n",
            "[ 86%] 01:05:02,000 → 01:05:04,000  我覺得導流效果也蠻不錯的\n",
            "[ 86%] 01:05:04,000 → 01:05:06,000  所以這個可以再想想看\n",
            "[ 87%] 01:05:06,000 → 01:05:08,000  但如果你會希望\n",
            "[ 87%] 01:05:08,000 → 01:05:10,000  開個線上號\n",
            "[ 87%] 01:05:10,000 → 01:05:12,000  然後希望可以做一些\n",
            "[ 87%] 01:05:12,000 → 01:05:14,000  專門輸入的內容\n",
            "[ 87%] 01:05:14,000 → 01:05:16,000  我覺得也沒有問題\n",
            "[ 87%] 01:05:16,000 → 01:05:18,000  但是我們之後可以再一起把細節\n",
            "[ 87%] 01:05:18,000 → 01:05:20,000  就是我可以\n",
            "[ 87%] 01:05:20,000 → 01:05:22,500  直接先開帳號,然後可能先做做看\n",
            "[ 87%] 01:05:22,500 → 01:05:24,400  然後再告訴你有沒有困難的點\n",
            "[ 87%] 01:05:25,700 → 01:05:28,600  那如果你現在要發一個立刻的東西\n",
            "[ 87%] 01:05:28,600 → 01:05:29,800  你是要發在哪邊?\n",
            "[ 87%] 01:05:32,100 → 01:05:34,100  現在要發一個立刻的東西\n",
            "[ 87%] 01:05:34,800 → 01:05:38,100  就是如果你沒有打算再開一個行政帳號的話\n",
            "[ 87%] 01:05:38,700 → 01:05:40,100  啊,立刻的東西\n",
            "[ 88%] 01:05:40,000 → 01:05:59,380  我就會把他放在YouTube的影片,我會幫你講,然後再用IG去引導學生去YouTube的影片,然後會是IG行動,還有Threads的,在Threads上面我就不會教物理,而是我會直接\n",
            "[ 88%] 01:06:00,000 → 01:06:06,800  丟免費的工具給學生,然後讓那個免費的工具自己下去學生之間流傳。\n",
            "[ 88%] 01:06:06,800 → 01:06:16,360  比如說你的事業檔案,那就算是一種免費的工具。\n",
            "[ 88%] 01:06:16,360 → 01:06:17,240  大概理解。\n",
            "[ 88%] 01:06:20,000 → 01:06:27,000  還有你的商品掛在蝦皮機就會有一定的流量\n",
            "[ 88%] 01:06:27,000 → 01:06:33,000  因為我們賣場也會有既定的客源進來\n",
            "[ 89%] 01:06:33,000 → 01:06:38,000  還有LINE群\n",
            "[ 89%] 01:06:38,000 → 01:06:40,000  LINE群會有選手喔\n",
            "[ 89%] 01:06:40,000 → 01:06:42,760  喔對之前有講到Live群\n",
            "[ 89%] 01:06:42,760 → 01:06:46,940  所以現在是有學生在問物理的問題嗎\n",
            "[ 89%] 01:06:46,940 → 01:06:48,360  還是還沒有\n",
            "[ 89%] 01:06:48,360 → 01:06:49,620  還沒有\n",
            "[ 89%] 01:06:49,620 → 01:06:55,740  可能我們也還沒有引導他們去問物理的\n",
            "[ 89%] 01:06:55,740 → 01:06:59,980  你現在有在這個群組\n",
            "[ 89%] 01:07:00,000 → 01:07:14,400  還有其他問題呢?\n",
            "[ 89%] 01:07:18,400 → 01:07:20,400  這部分應該就到這裡了\n",
            "[ 90%] 01:07:20,000 → 01:07:26,100  然後我提問一下,這是你的公司名稱嗎?\n",
            "[ 90%] 01:07:27,140 → 01:07:31,000  公司名稱是成學文教有限公司,\n",
            "[ 90%] 01:07:31,600 → 01:07:33,840  陰謀比較像是品牌名稱。\n",
            "[ 90%] 01:07:33,840 → 01:07:36,540  所以那你的陰謀是申請商標嗎?\n",
            "[ 90%] 01:07:37,420 → 01:07:38,000  我是好奇。\n",
            "[ 90%] 01:07:40,000 → 01:07:42,000  喔好\n",
            "[ 90%] 01:07:42,000 → 01:07:45,820  你要搶住嗎\n",
            "[ 90%] 01:07:45,820 → 01:07:47,420  我都沒想到\n",
            "[ 90%] 01:07:47,420 → 01:07:49,880  惡意搶住\n",
            "[ 90%] 01:07:49,880 → 01:07:53,340  你是學了民法之後學壞了是不是\n",
            "[ 90%] 01:07:53,340 → 01:07:57,720  我好像記得有的是法律系\n",
            "[ 90%] 01:07:57,720 → 01:08:00,000  我是法律系\n",
            "[ 90%] 01:08:00,000 → 01:08:05,000  好\n",
            "[ 91%] 01:08:05,000 → 01:08:07,700  那應該沒有其他問題耶\n",
            "[ 91%] 01:08:07,700 → 01:08:08,940  好\n",
            "[ 91%] 01:08:08,940 → 01:08:10,620  你應該沒有\n",
            "[ 91%] 01:08:10,620 → 01:08:12,160  打算先註冊對吧\n",
            "[ 91%] 01:08:12,160 → 01:08:12,660  沒有沒有\n",
            "[ 91%] 01:08:12,660 → 01:08:13,460  OKOK\n",
            "[ 91%] 01:08:13,460 → 01:08:15,180  有點麻煩\n",
            "[ 91%] 01:08:15,180 → 01:08:16,300  沒有想要做這種事\n",
            "[ 91%] 01:08:20,000 → 01:08:28,000  如果沒有的話,我們今天會先到這邊喔。\n",
            "[ 91%] 01:08:28,000 → 01:08:30,000  好。\n",
            "[ 91%] 01:08:30,000 → 01:08:32,000  好,辛苦了,謝謝你。\n",
            "[ 91%] 01:08:32,000 → 01:08:34,000  掰掰。\n",
            "[ 91%] 01:08:34,000 → 01:08:36,000  掰掰。\n",
            "[ 91%] 01:08:40,000 → 01:08:49,860  我要影片嗎?想要影片?\n",
            "[ 91%] 01:08:50,000 → 01:08:51,440  我有,好,我再傳\n",
            "[ 92%] 01:08:51,440 → 01:08:53,280  做完可以改AI\n",
            "[ 92%] 01:08:53,280 → 01:08:54,060  OK\n",
            "[ 92%] 01:08:54,060 → 01:08:57,760  為什麼我媽留著?\n",
            "[ 92%] 01:08:57,860 → 01:08:59,320  我媽有什麼事情要討論嗎?\n",
            "[ 92%] 01:09:00,000 → 01:09:02,000  沒有啊\n",
            "[ 92%] 01:09:02,000 → 01:09:04,000  那我先撤囉\n",
            "[ 92%] 01:09:04,000 → 01:09:05,000  好嘞\n",
            "[ 92%] 01:09:05,000 → 01:09:08,000  我會去玩國粹職之後再去你那邊喔\n",
            "[ 92%] 01:09:08,000 → 01:09:09,000  好喔沒問題\n",
            "[ 92%] 01:09:09,000 → 01:09:10,000  你就直接進來就好\n",
            "[ 92%] 01:09:10,000 → 01:09:11,000  我會穿褲子\n",
            "[ 92%] 01:09:11,000 → 01:09:12,000  好掰掰\n",
            "[ 92%] 01:09:12,000 → 01:09:14,000  好掰掰\n",
            "[ 92%] 01:09:16,000 → 01:09:17,000  拜啦老孫\n",
            "[ 92%] 01:09:17,000 → 01:09:19,000  你剛聽起來有什麼問題嗎\n",
            "[ 92%] 01:09:20,000 → 01:09:26,000  沒有,但是我想到有很嚴重的事情要做\n",
            "[ 92%] 01:09:26,000 → 01:09:27,400  你說?\n",
            "[ 92%] 01:09:27,400 → 01:09:32,240  就是那個那個那個那個常常需要驗證的問題\n",
            "[ 92%] 01:09:32,240 → 01:09:35,760  我們現在把它解決掉了嘛\n",
            "[ 92%] 01:09:35,760 → 01:09:37,360  會很久嗎?\n",
            "[ 93%] 01:09:37,360 → 01:09:39,960  不會不會\n",
            "[ 93%] 01:09:40,000 → 01:09:50,000  比較就是我開個分享的分享分享\n",
            "[ 93%] 01:09:50,000 → 01:09:54,000  我的IG快快的\n",
            "[ 93%] 01:09:54,000 → 01:09:58,000  你的IG快快的\n",
            "[ 93%] 01:09:58,000 → 01:10:00,000  等一下你說\n",
            "[ 93%] 01:10:00,000 → 01:10:19,940  我來新增一下,因為目前都是要發去你的手機,然後\n",
            "[ 93%] 01:10:20,000 → 01:10:23,000  你的手機去做驗證嗎?\n",
            "[ 94%] 01:10:23,000 → 01:10:24,000  嗯\n",
            "[ 94%] 01:10:24,000 → 01:10:29,000  對 然後我是想說就是我們直接來進入這個\n",
            "[ 94%] 01:10:29,000 → 01:10:33,000  就是我們直接弄一個這個動態驗證嘛\n",
            "[ 94%] 01:10:33,000 → 01:10:34,000  就是它可以\n",
            "[ 94%] 01:10:34,000 → 01:10:35,000  原來我們有這個東西啊\n",
            "[ 94%] 01:10:35,000 → 01:10:36,000  蛤?\n",
            "[ 94%] 01:10:36,000 → 01:10:38,000  我們有這個東西啊\n",
            "[ 94%] 01:10:38,000 → 01:10:40,000  你們有這個東西\n",
            "[ 94%] 01:10:40,000 → 01:10:44,000  不是不是不是 不是我們有動態驗證碼\n",
            "[ 94%] 01:10:44,000 → 01:10:48,000  你們有動態驗證碼 可是我在帳號裡面沒看到你\n",
            "[ 94%] 01:10:48,000 → 01:10:52,000  因為我們是綁openai跟ig消息\n",
            "[ 94%] 01:10:52,000 → 01:10:56,000  那你這個要不要綁一下 可以可以 四十嗎\n",
            "[ 94%] 01:10:56,000 → 01:11:00,000  不然我每次半夜在搞東西\n",
            "[ 94%] 01:11:00,000 → 01:11:02,000  都會卡住\n",
            "[ 94%] 01:11:02,000 → 01:11:04,000  好有嗎?\n",
            "[ 94%] 01:11:04,000 → 01:11:06,000  有啊它進去了\n",
            "[ 94%] 01:11:06,000 → 01:11:08,000  等等等\n",
            "[ 95%] 01:11:08,000 → 01:11:10,000  那我現在新增一個然後截圖給你們\n",
            "[ 95%] 01:11:10,000 → 01:11:12,000  沒有好等一下我直接\n",
            "[ 95%] 01:11:12,000 → 01:11:14,000  我只新增\n",
            "[ 95%] 01:11:14,000 → 01:11:16,000  沒有我是截個圖啊\n",
            "[ 95%] 01:11:16,000 → 01:11:18,000  它不是會一直跑嗎?\n",
            "[ 95%] 01:11:18,000 → 01:11:20,000  它一直都會跑啊\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  沒有沒有這個不會\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  這個圖不會\n",
            "[ 95%] 01:11:22,000 → 01:11:24,000  這個圖不會 為什麼\n",
            "[ 95%] 01:11:24,000 → 01:11:26,000  因為它跑的不是這個圖\n",
            "[ 95%] 01:11:26,000 → 01:11:28,000  它跑的是這個圖裡面有精藥\n",
            "[ 95%] 01:11:28,000 → 01:11:30,000  然後它會根據這個精藥\n",
            "[ 95%] 01:11:30,000 → 01:11:32,000  加上時間\n",
            "[ 95%] 01:11:32,000 → 01:11:34,000  那個數字不是一直都會跑嗎\n",
            "[ 95%] 01:11:34,000 → 01:11:36,000  對 但是這個圖不會跑\n",
            "[ 95%] 01:11:38,000 → 01:11:40,000  對 它是用這個圖加上時間去\n",
            "[ 95%] 01:11:40,000 → 01:11:42,000  你去算出那個數字\n",
            "[ 95%] 01:11:42,000 → 01:11:44,000  這樣這樣\n",
            "[ 95%] 01:11:45,120 → 01:11:47,120  那我要放在notion裡面了\n",
            "[ 95%] 01:11:48,580 → 01:11:50,580  這樣會太危險嗎\n",
            "[ 95%] 01:11:50,580 → 01:11:52,580  你直接幫我查個指名好不好\n",
            "[ 96%] 01:11:54,840 → 01:11:56,840  等等等等等等\n",
            "[ 96%] 01:11:56,840 → 01:11:58,840  等等喔\n",
            "[ 96%] 01:11:58,840 → 01:12:00,840  我要建個頻道\n",
            "[ 96%] 01:12:00,000 → 01:12:02,000  你用平常名稱叫什麼?\n",
            "[ 96%] 01:12:04,000 → 01:12:06,000  工程部門\n",
            "[ 96%] 01:12:15,000 → 01:12:18,000  為什麼你現在用的那個Gmail是你自己的嗎?\n",
            "[ 96%] 01:12:18,000 → 01:12:20,000  你幫我貼在那個工程部門\n",
            "[ 97%] 01:12:20,000 → 01:12:40,000  我哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋\n",
            "[ 97%] 01:12:40,000 → 01:12:40,840  還是你本來就有在用?\n",
            "[ 97%] 01:12:40,840 → 01:12:41,340  沒有啊\n",
            "[ 97%] 01:12:42,000 → 01:12:43,840  那是我的主力帳號啊\n",
            "[ 97%] 01:12:43,840 → 01:12:45,160  因為這個帳號\n",
            "[ 97%] 01:12:45,160 → 01:12:46,460  幼稚園的時候就創了\n",
            "[ 97%] 01:12:46,460 → 01:12:48,500  所以那個名字是亂打的\n",
            "[ 97%] 01:12:49,340 → 01:12:50,000  打動了\n",
            "[ 97%] 01:12:55,800 → 01:12:58,500  啊你剛剛那個婚姻紀錄有開完嗎?\n",
            "[ 97%] 01:12:58,840 → 01:12:59,340  你有打動嗎?\n",
            "[ 97%] 01:12:59,340 → 01:12:59,840  有有有\n",
            "[ 97%] 01:13:00,000 → 01:13:04,600  你可能要跟他講一下那個東西是幹嘛的\n",
            "[ 97%] 01:13:04,600 → 01:13:09,700  就是你傳到工程部門那個東西是幹嘛的\n",
            "[ 97%] 01:13:09,700 → 01:13:10,760  他可能不太知道\n",
            "[ 97%] 01:13:10,760 → 01:13:14,520  他拿iPhone還安儲\n",
            "[ 97%] 01:13:14,520 → 01:13:16,060  他拿iPhone\n",
            "[ 98%] 01:13:20,000 → 01:13:24,000  好了,我們要去尿尿,然後我要出發了,bye!\n",
            "[ 98%] 01:13:25,280 → 01:13:25,520  好\n",
            "[ 98%] 01:13:25,520 → 01:13:29,780  下午的會議如果需要你,我再call你進來可以嗎?\n",
            "[ 98%] 01:13:34,400 → 01:13:35,080  可以嗎?\n",
            "[ 98%] 01:13:37,020 → 01:13:39,540  哇,那我怎麼知道你什麼時候要call我進來?\n",
            "[ 98%] 01:13:40,000 → 01:13:42,800  好吧,那你就去忙,你就去做你自己的生意\n",
            "[ 98%] 01:13:42,800 → 01:13:43,800  如果你剛好有\n",
            "[ 98%] 01:13:43,800 → 01:13:45,600  我可以進來沒關係啊\n",
            "[ 98%] 01:13:45,600 → 01:13:47,100  好,那你就順便停\n",
            "[ 98%] 01:13:47,100 → 01:13:49,140  OK,好,Bye\n",
            "[ 98%] 01:13:49,140 → 01:13:52,360  2點啊,2點到4點\n",
            "[ 98%] 01:13:52,360 → 01:13:53,180  好\n",
            "[ 98%] 01:13:53,180 → 01:13:53,840  再見\n",
            "[ 99%] 01:14:00,000 → 01:14:29,980  Teksting av Nicolai Winther\n",
            "[ 99%] 01:14:20,000 → 01:14:49,980  Takk for att du så med.\n",
            "[100%] 01:14:40,000 → 01:15:09,980  Teksting av Nicolai Winther\n",
            "[100%] 01:15:00,000 → 01:15:29,980  Teksting av Nicolai Winther\n",
            "[8/8] 輸出 SRT / TXT ...\n",
            "→ 完成！\n",
            "  SRT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).srt\n",
            "  TXT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2522ae85bd99479a95953834e70aa67d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_load_from_file_impl: using device CUDA0 (Tesla T4) - 14974 MiB free\n",
            "llama_model_loader: loaded meta data with 37 key-value pairs and 459 tensors from /root/.cache/huggingface/hub/models--unsloth--gpt-oss-20b-GGUF/snapshots/c6cedd4259adbfe7e4d4d983a0400bf4cc38e7db/gpt-oss-20b-Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gpt-oss\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   3:                           general.basename str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   4:                       general.quantized_by str              = Unsloth\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 20B\n",
            "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
            "llama_model_loader: - kv   7:                           general.repo_url str              = https://huggingface.co/unsloth\n",
            "llama_model_loader: - kv   8:                               general.tags arr[str,2]       = [\"vllm\", \"text-generation\"]\n",
            "llama_model_loader: - kv   9:                        gpt-oss.block_count u32              = 24\n",
            "llama_model_loader: - kv  10:                     gpt-oss.context_length u32              = 131072\n",
            "llama_model_loader: - kv  11:                   gpt-oss.embedding_length u32              = 2880\n",
            "llama_model_loader: - kv  12:                gpt-oss.feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  13:               gpt-oss.attention.head_count u32              = 64\n",
            "llama_model_loader: - kv  14:            gpt-oss.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  15:                     gpt-oss.rope.freq_base f32              = 150000.000000\n",
            "llama_model_loader: - kv  16:   gpt-oss.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  17:                       gpt-oss.expert_count u32              = 32\n",
            "llama_model_loader: - kv  18:                  gpt-oss.expert_used_count u32              = 4\n",
            "llama_model_loader: - kv  19:               gpt-oss.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  20:             gpt-oss.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  21:           gpt-oss.attention.sliding_window u32              = 128\n",
            "llama_model_loader: - kv  22:         gpt-oss.expert_feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  23:                  gpt-oss.rope.scaling.type str              = yarn\n",
            "llama_model_loader: - kv  24:                gpt-oss.rope.scaling.factor f32              = 32.000000\n",
            "llama_model_loader: - kv  25: gpt-oss.rope.scaling.original_context_length u32              = 4096\n",
            "llama_model_loader: - kv  26:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  27:                         tokenizer.ggml.pre str              = gpt-4o\n",
            "llama_model_loader: - kv  28:                      tokenizer.ggml.tokens arr[str,201088]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  29:                  tokenizer.ggml.token_type arr[i32,201088]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  30:                      tokenizer.ggml.merges arr[str,446189]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  31:                tokenizer.ggml.bos_token_id u32              = 199998\n",
            "llama_model_loader: - kv  32:                tokenizer.ggml.eos_token_id u32              = 200002\n",
            "llama_model_loader: - kv  33:            tokenizer.ggml.padding_token_id u32              = 200017\n",
            "llama_model_loader: - kv  34:                    tokenizer.chat_template str              = {# Chat template fixes by Unsloth #}\\n...\n",
            "llama_model_loader: - kv  35:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  36:                          general.file_type u32              = 15\n",
            "llama_model_loader: - type  f32:  289 tensors\n",
            "llama_model_loader: - type q5_0:   61 tensors\n",
            "llama_model_loader: - type q8_0:   13 tensors\n",
            "llama_model_loader: - type q4_K:   24 tensors\n",
            "llama_model_loader: - type mxfp4:   72 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 10.81 GiB (4.44 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 200017 '<|reserved_200017|>' is not marked as EOG\n",
            "load: control token: 200014 '<|reserved_200014|>' is not marked as EOG\n",
            "load: control token: 200011 '<|reserved_200011|>' is not marked as EOG\n",
            "load: control token: 200009 '<|reserved_200009|>' is not marked as EOG\n",
            "load: control token: 200008 '<|message|>' is not marked as EOG\n",
            "load: control token: 200006 '<|start|>' is not marked as EOG\n",
            "load: control token: 200004 '<|reserved_200004|>' is not marked as EOG\n",
            "load: control token: 200003 '<|constrain|>' is not marked as EOG\n",
            "load: control token: 200000 '<|reserved_200000|>' is not marked as EOG\n",
            "load: control token: 200005 '<|channel|>' is not marked as EOG\n",
            "load: control token: 200010 '<|reserved_200010|>' is not marked as EOG\n",
            "load: control token: 200016 '<|reserved_200016|>' is not marked as EOG\n",
            "load: control token: 200013 '<|reserved_200013|>' is not marked as EOG\n",
            "load: control token: 199998 '<|startoftext|>' is not marked as EOG\n",
            "load: control token: 200018 '<|endofprompt|>' is not marked as EOG\n",
            "load: control token: 200001 '<|reserved_200001|>' is not marked as EOG\n",
            "load: control token: 200015 '<|reserved_200015|>' is not marked as EOG\n",
            "load: printing all EOG tokens:\n",
            "load:   - 199999 ('<|endoftext|>')\n",
            "load:   - 200002 ('<|return|>')\n",
            "load:   - 200007 ('<|end|>')\n",
            "load:   - 200012 ('<|call|>')\n",
            "load: special_eog_ids contains both '<|return|>' and '<|call|>' tokens, removing '<|end|>' token from EOG list\n",
            "load: special tokens cache size = 21\n",
            "load: token to piece cache size = 1.3332 MB\n",
            "print_info: arch             = gpt-oss\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 131072\n",
            "print_info: n_embd           = 2880\n",
            "print_info: n_layer          = 24\n",
            "print_info: n_head           = 64\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 64\n",
            "print_info: n_swa            = 128\n",
            "print_info: is_swa_any       = 1\n",
            "print_info: n_embd_head_k    = 64\n",
            "print_info: n_embd_head_v    = 64\n",
            "print_info: n_gqa            = 8\n",
            "print_info: n_embd_k_gqa     = 512\n",
            "print_info: n_embd_v_gqa     = 512\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 2880\n",
            "print_info: n_expert         = 32\n",
            "print_info: n_expert_used    = 4\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 2\n",
            "print_info: rope scaling     = yarn\n",
            "print_info: freq_base_train  = 150000.0\n",
            "print_info: freq_scale_train = 0.03125\n",
            "print_info: n_ctx_orig_yarn  = 4096\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = ?B\n",
            "print_info: model params     = 20.91 B\n",
            "print_info: general.name     = Gpt-Oss-20B\n",
            "print_info: n_ff_exp         = 2880\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 201088\n",
            "print_info: n_merges         = 446189\n",
            "print_info: BOS token        = 199998 '<|startoftext|>'\n",
            "print_info: EOS token        = 200002 '<|return|>'\n",
            "print_info: EOT token        = 199999 '<|endoftext|>'\n",
            "print_info: PAD token        = 200017 '<|reserved_200017|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 199999 '<|endoftext|>'\n",
            "print_info: EOG token        = 200002 '<|return|>'\n",
            "print_info: EOG token        = 200012 '<|call|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   1 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   3 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   5 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   7 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   9 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  11 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  13 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  15 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  17 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  19 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  21 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  23 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q5_0) (and 0 others) cannot be used with preferred buffer type CUDA_Host, using CPU instead\n",
            "load_tensors: offloading 24 repeating layers to GPU\n",
            "load_tensors: offloading output layer to GPU\n",
            "load_tensors: offloaded 25/25 layers to GPU\n",
            "load_tensors:        CUDA0 model buffer size = 10694.15 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =   379.71 MiB\n",
            "...............................................................................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 8192\n",
            "llama_context: n_ctx_per_seq = 8192\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 150000.0\n",
            "llama_context: freq_scale    = 0.03125\n",
            "llama_context: n_ctx_per_seq (8192) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:  CUDA_Host  output buffer size =     0.77 MiB\n",
            "create_memory: n_ctx = 8192 (padded)\n",
            "llama_kv_cache_unified_iswa: using full-size SWA cache (ref: https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)\n",
            "llama_kv_cache_unified_iswa: creating non-SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: skipped\n",
            "llama_kv_cache_unified: layer   1: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   2: skipped\n",
            "llama_kv_cache_unified: layer   3: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   4: skipped\n",
            "llama_kv_cache_unified: layer   5: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   6: skipped\n",
            "llama_kv_cache_unified: layer   7: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   8: skipped\n",
            "llama_kv_cache_unified: layer   9: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  10: skipped\n",
            "llama_kv_cache_unified: layer  11: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  12: skipped\n",
            "llama_kv_cache_unified: layer  13: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  14: skipped\n",
            "llama_kv_cache_unified: layer  15: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  16: skipped\n",
            "llama_kv_cache_unified: layer  17: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  18: skipped\n",
            "llama_kv_cache_unified: layer  19: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  20: skipped\n",
            "llama_kv_cache_unified: layer  21: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  22: skipped\n",
            "llama_kv_cache_unified: layer  23: dev = CUDA0\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_kv_cache_unified_iswa: creating     SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   1: skipped\n",
            "llama_kv_cache_unified: layer   2: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   3: skipped\n",
            "llama_kv_cache_unified: layer   4: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   5: skipped\n",
            "llama_kv_cache_unified: layer   6: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   7: skipped\n",
            "llama_kv_cache_unified: layer   8: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   9: skipped\n",
            "llama_kv_cache_unified: layer  10: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  11: skipped\n",
            "llama_kv_cache_unified: layer  12: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  13: skipped\n",
            "llama_kv_cache_unified: layer  14: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  15: skipped\n",
            "llama_kv_cache_unified: layer  16: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  17: skipped\n",
            "llama_kv_cache_unified: layer  18: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  19: skipped\n",
            "llama_kv_cache_unified: layer  20: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  21: skipped\n",
            "llama_kv_cache_unified: layer  22: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  23: skipped\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 2\n",
            "llama_context: max_nodes = 3672\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "llama_context:      CUDA0 compute buffer size =  1087.26 MiB\n",
            "llama_context:  CUDA_Host compute buffer size =    41.64 MiB\n",
            "llama_context: graph nodes  = 1446\n",
            "llama_context: graph splits = 2\n",
            "CUDA : ARCHS = 500,520,530,600,610,620,700,720,750,800,860,870,890,900 | FORCE_MMQ = 1 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'general.file_type': '15', 'general.quantization_version': '2', 'tokenizer.chat_template': '{# Chat template fixes by Unsloth #}\\n{#-\\n  In addition to the normal inputs of `messages` and `tools`, this template also accepts the\\n  following kwargs:\\n  - \"builtin_tools\": A list, can contain \"browser\" and/or \"python\".\\n  - \"model_identity\": A string that optionally describes the model identity.\\n  - \"reasoning_effort\": A string that describes the reasoning effort, defaults to \"medium\".\\n #}\\n\\n{#- Tool Definition Rendering ============================================== #}\\n{%- macro render_typescript_type(param_spec, required_params, is_nullable=false) -%}\\n    {%- if param_spec.type == \"array\" -%}\\n        {%- if param_spec[\\'items\\'] -%}\\n            {%- if param_spec[\\'items\\'][\\'type\\'] == \"string\" -%}\\n                {{- \"string[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"number\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"integer\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"boolean\" -%}\\n                {{- \"boolean[]\" }}\\n            {%- else -%}\\n                {%- set inner_type = render_typescript_type(param_spec[\\'items\\'], required_params) -%}\\n                {%- if inner_type == \"object | object\" or inner_type|length > 50 -%}\\n                    {{- \"any[]\" }}\\n                {%- else -%}\\n                    {{- inner_type + \"[]\" }}\\n                {%- endif -%}\\n            {%- endif -%}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- else -%}\\n            {{- \"any[]\" }}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type is defined and param_spec.type is iterable and param_spec.type is not string and param_spec.type is not mapping and param_spec.type[0] is defined -%}\\n        {#- Handle array of types like [\"object\", \"object\"] from Union[dict, list] #}\\n        {%- if param_spec.type | length > 1 -%}\\n            {{- param_spec.type | join(\" | \") }}\\n        {%- else -%}\\n            {{- param_spec.type[0] }}\\n        {%- endif -%}\\n    {%- elif param_spec.oneOf -%}\\n        {#- Handle oneOf schemas - check for complex unions and fallback to any #}\\n        {%- set has_object_variants = false -%}\\n        {%- for variant in param_spec.oneOf -%}\\n            {%- if variant.type == \"object\" -%}\\n                {%- set has_object_variants = true -%}\\n            {%- endif -%}\\n        {%- endfor -%}\\n        {%- if has_object_variants and param_spec.oneOf|length > 1 -%}\\n            {{- \"any\" }}\\n        {%- else -%}\\n            {%- for variant in param_spec.oneOf -%}\\n                {{- render_typescript_type(variant, required_params) -}}\\n                {%- if variant.description %}\\n                    {{- \"// \" + variant.description }}\\n                {%- endif -%}\\n                {%- if variant.default is defined %}\\n                    {{ \"// default: \" + variant.default|tojson }}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \" | \" }}\\n                {% endif -%}\\n            {%- endfor -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"string\" -%}\\n        {%- if param_spec.enum -%}\\n            {{- \\'\"\\' + param_spec.enum|join(\\'\" | \"\\') + \\'\"\\' -}}\\n        {%- else -%}\\n            {{- \"string\" }}\\n            {%- if param_spec.nullable %}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"number\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"integer\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"boolean\" -%}\\n        {{- \"boolean\" }}\\n\\n    {%- elif param_spec.type == \"object\" -%}\\n        {%- if param_spec.properties -%}\\n            {{- \"{\\\\n\" }}\\n            {%- for prop_name, prop_spec in param_spec.properties.items() -%}\\n                {{- prop_name -}}\\n                {%- if prop_name not in (param_spec.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{ render_typescript_type(prop_spec, param_spec.required or []) }}\\n                {%- if not loop.last -%}\\n                    {{-\", \" }}\\n                {%- endif -%}\\n            {%- endfor -%}\\n            {{- \"}\" }}\\n        {%- else -%}\\n            {{- \"object\" }}\\n        {%- endif -%}\\n    {%- else -%}\\n        {{- \"any\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{%- macro render_tool_namespace(namespace_name, tools) -%}\\n    {{- \"## \" + namespace_name + \"\\\\n\\\\n\" }}\\n    {{- \"namespace \" + namespace_name + \" {\\\\n\\\\n\" }}\\n    {%- for tool in tools %}\\n        {%- set tool = tool.function %}\\n        {{- \"// \" + tool.description + \"\\\\n\" }}\\n        {{- \"type \"+ tool.name + \" = \" }}\\n        {%- if tool.parameters and tool.parameters.properties %}\\n            {{- \"(_: {\\\\n\" }}\\n            {%- for param_name, param_spec in tool.parameters.properties.items() %}\\n                {%- if param_spec.description %}\\n                    {{- \"// \" + param_spec.description + \"\\\\n\" }}\\n                {%- endif %}\\n                {{- param_name }}\\n                {%- if param_name not in (tool.parameters.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{- render_typescript_type(param_spec, tool.parameters.required or []) }}\\n                {%- if param_spec.default is defined -%}\\n                    {%- if param_spec.enum %}\\n                        {{- \", // default: \" + param_spec.default }}\\n                    {%- elif param_spec.oneOf %}\\n                        {{- \"// default: \" + param_spec.default }}\\n                    {%- else %}\\n                        {{- \", // default: \" + param_spec.default|tojson }}\\n                    {%- endif -%}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \",\\\\n\" }}\\n                {%- else %}\\n                    {{- \",\\\\n\" }}\\n                {%- endif -%}\\n            {%- endfor %}\\n            {{- \"}) => any;\\\\n\\\\n\" }}\\n        {%- else -%}\\n            {{- \"() => any;\\\\n\\\\n\" }}\\n        {%- endif -%}\\n    {%- endfor %}\\n    {{- \"} // namespace \" + namespace_name }}\\n{%- endmacro -%}\\n\\n{%- macro render_builtin_tools(browser_tool, python_tool) -%}\\n    {%- if browser_tool %}\\n        {{- \"## browser\\\\n\\\\n\" }}\\n        {{- \"// Tool for browsing.\\\\n\" }}\\n        {{- \"// The `cursor` appears in brackets before each browsing display: `[{cursor}]`.\\\\n\" }}\\n        {{- \"// Cite information from the tool using the following format:\\\\n\" }}\\n        {{- \"// `【{cursor}†L{line_start}(-L{line_end})?】`, for example: `【6†L9-L11】` or `【8†L3】`.\\\\n\" }}\\n        {{- \"// Do not quote more than 10 words directly from the tool output.\\\\n\" }}\\n        {{- \"// sources=web (default: web)\\\\n\" }}\\n        {{- \"namespace browser {\\\\n\\\\n\" }}\\n        {{- \"// Searches for information related to `query` and displays `topn` results.\\\\n\" }}\\n        {{- \"type search = (_: {\\\\n\" }}\\n        {{- \"query: string,\\\\n\" }}\\n        {{- \"topn?: number, // default: 10\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Opens the link `id` from the page indicated by `cursor` starting at line number `loc`, showing `num_lines` lines.\\\\n\" }}\\n        {{- \"// Valid link ids are displayed with the formatting: `【{id}†.*】`.\\\\n\" }}\\n        {{- \"// If `cursor` is not provided, the most recent page is implied.\\\\n\" }}\\n        {{- \"// If `id` is a string, it is treated as a fully qualified URL associated with `source`.\\\\n\" }}\\n        {{- \"// If `loc` is not provided, the viewport will be positioned at the beginning of the document or centered on the most relevant passage, if available.\\\\n\" }}\\n        {{- \"// Use this function without `id` to scroll to a new location of an opened page.\\\\n\" }}\\n        {{- \"type open = (_: {\\\\n\" }}\\n        {{- \"id?: number | string, // default: -1\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"loc?: number, // default: -1\\\\n\" }}\\n        {{- \"num_lines?: number, // default: -1\\\\n\" }}\\n        {{- \"view_source?: boolean, // default: false\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Finds exact matches of `pattern` in the current page, or the page given by `cursor`.\\\\n\" }}\\n        {{- \"type find = (_: {\\\\n\" }}\\n        {{- \"pattern: string,\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"} // namespace browser\\\\n\\\\n\" }}\\n    {%- endif -%}\\n\\n    {%- if python_tool %}\\n        {{- \"## python\\\\n\\\\n\" }}\\n        {{- \"Use this tool to execute Python code in your chain of thought. The code will not be shown to the user. This tool should be used for internal reasoning, but not for code that is intended to be visible to the user (e.g. when creating plots, tables, or files).\\\\n\\\\n\" }}\\n        {{- \"When you send a message containing Python code to python, it will be executed in a stateful Jupyter notebook environment. python will respond with the output of the execution or time out after 120.0 seconds. The drive at \\'/mnt/data\\' can be used to save and persist user files. Internet access for this session is UNKNOWN. Depends on the cluster.\\\\n\\\\n\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- System Message Construction ============================================ #}\\n{%- macro build_system_message() -%}\\n    {%- if model_identity is not defined %}\\n        {%- set model_identity = \"You are ChatGPT, a large language model trained by OpenAI.\" %}\\n    {%- endif %}\\n    {{- model_identity + \"\\\\n\" }}\\n    {{- \"Knowledge cutoff: 2024-06\\\\n\" }}\\n    {{- \"Current date: \" + strftime_now(\"%Y-%m-%d\") + \"\\\\n\\\\n\" }}\\n    {%- if reasoning_effort is not defined %}\\n        {%- set reasoning_effort = \"medium\" %}\\n    {%- endif %}\\n    {{- \"Reasoning: \" + reasoning_effort + \"\\\\n\\\\n\" }}\\n    {%- if builtin_tools is defined and builtin_tools is not none %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {%- set available_builtin_tools = namespace(browser=false, python=false) %}\\n        {%- for tool in builtin_tools %}\\n            {%- if tool == \"browser\" %}\\n                {%- set available_builtin_tools.browser = true %}\\n            {%- elif tool == \"python\" %}\\n                {%- set available_builtin_tools.python = true %}\\n            {%- endif %}\\n        {%- endfor %}\\n        {{- render_builtin_tools(available_builtin_tools.browser, available_builtin_tools.python) }}\\n    {%- endif -%}\\n    {{- \"# Valid channels: analysis, commentary, final. Channel must be included for every message.\" }}\\n    {%- if tools -%}\\n        {{- \"\\\\nCalls to these tools must go to the commentary channel: \\'functions\\'.\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- Main Template Logic ================================================= #}\\n{#- Set defaults #}\\n\\n{#- Render system message #}\\n{{- \"<|start|>system<|message|>\" }}\\n{{- build_system_message() }}\\n{{- \"<|end|>\" }}\\n\\n{#- Extract developer message #}\\n{%- if developer_instructions is defined and developer_instructions is not none %}\\n    {%- set developer_message = developer_instructions %}\\n    {%- set loop_messages = messages %}\\n{%- elif messages[0].role == \"developer\" or messages[0].role == \"system\" %}\\n    {%- set developer_message = messages[0].content %}\\n    {%- set loop_messages = messages[1:] %}\\n{%- else %}\\n    {%- set developer_message = \"\" %}\\n    {%- set loop_messages = messages %}\\n{%- endif %}\\n\\n{#- Render developer message #}\\n{%- if developer_message or tools %}\\n    {{- \"<|start|>developer<|message|>\" }}\\n    {%- if developer_message %}\\n        {{- \"# Instructions\\\\n\\\\n\" }}\\n        {{- developer_message }}\\n    {%- endif %}\\n    {%- if tools -%}\\n        {%- if developer_message %}\\n            {{- \"\\\\n\\\\n\" }}\\n        {%- endif %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {{- render_tool_namespace(\"functions\", tools) }}\\n    {%- endif -%}\\n    {{- \"<|end|>\" }}\\n{%- endif %}\\n\\n{#- Render messages #}\\n{%- set last_tool_call = namespace(name=none) %}\\n{%- for message in loop_messages -%}\\n    {#- At this point only assistant/user/tool messages should remain #}\\n    {%- if message.role == \\'assistant\\' -%}\\n        {#- Checks to ensure the messages are being passed in the format we expect #}\\n        {%- if \"thinking\" in message %}\\n            {%- if \"<|channel|>analysis<|message|>\" in message.thinking or \"<|channel|>final<|message|>\" in message.thinking %}\\n                {{- raise_exception(\"You have passed a message containing <|channel|> tags in the thinking field. Instead of doing this, you should pass analysis messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'thinking\\' field, and final messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'content\\' field.\") }}\\n            {%- endif %}\\n        {%- endif %}\\n        {%- if \"tool_calls\" in message %}\\n            {#- We need very careful handling here - we want to drop the tool call analysis message if the model #}\\n            {#- has output a later <|final|> message, but otherwise we want to retain it. This is the only case #}\\n            {#- when we render CoT/analysis messages in inference. #}\\n            {%- set future_final_message = namespace(found=false) %}\\n            {%- for future_message in loop_messages[loop.index:] %}\\n                {%- if future_message.role == \\'assistant\\' and \"tool_calls\" not in future_message %}\\n                    {%- set future_final_message.found = true %}\\n                {%- endif %}\\n            {%- endfor %}\\n            {#- We assume max 1 tool call per message, and so we infer the tool call name #}\\n            {#- in \"tool\" messages from the most recent assistant tool call name #}\\n            {%- set tool_call = message.tool_calls[0] %}\\n            {%- if tool_call.function %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {%- if message.content and message.thinking %}\\n                {{- raise_exception(\"Cannot pass both content and thinking in an assistant message with tool calls! Put the analysis message in one or the other, but not both.\") }}\\n            {%- elif message.content and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- elif message.thinking and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {{- \"<|start|>assistant to=\" }}\\n            {{- \"functions.\" + tool_call.name + \"<|channel|>commentary \" }}\\n            {{- (tool_call.content_type if tool_call.content_type is defined else \"json\") + \"<|message|>\" }}\\n            {%- if tool_call.arguments is string %}\\n                {{- tool_call.arguments }}\\n            {%- else %}\\n                {{- tool_call.arguments|tojson }}\\n            {%- endif %}\\n            {{- \"<|call|>\" }}\\n            {%- set last_tool_call.name = tool_call.name %}\\n        {%- elif loop.last and not add_generation_prompt %}\\n            {#- Only render the CoT if the final turn is an assistant turn and add_generation_prompt is false #}\\n            {#- This is a situation that should only occur in training, never in inference. #}\\n            {%- if \"thinking\" in message %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {#- <|return|> indicates the end of generation, but <|end|> does not #}\\n            {#- <|return|> should never be an input to the model, but we include it as the final token #}\\n            {#- when training, so the model learns to emit it. #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- elif \"thinking\" in message %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- else %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- endif %}\\n    {%- elif message.role == \\'tool\\' -%}\\n        {%- if last_tool_call.name is none %}\\n            {{- raise_exception(\"Message has tool role, but there was no previous assistant message with a tool call!\") }}\\n        {%- endif %}\\n        {{- \"<|start|>functions.\" + last_tool_call.name }}\\n        {%- if message.content is string %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- else %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content|tojson + \"<|end|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \\'user\\' -%}\\n        {{- \"<|start|>user<|message|>\" + message.content + \"<|end|>\" }}\\n    {%- endif -%}\\n{%- endfor -%}\\n\\n{#- Generation prompt #}\\n{%- if add_generation_prompt -%}\\n<|start|>assistant\\n{%- endif -%}\\n{# Copyright 2025-present Unsloth. Apache 2.0 License. Unsloth chat template fixes. Edited from ggml-org & OpenAI #}', 'gpt-oss.attention.head_count': '64', 'gpt-oss.rope.scaling.original_context_length': '4096', 'gpt-oss.feed_forward_length': '2880', 'general.repo_url': 'https://huggingface.co/unsloth', 'general.license': 'apache-2.0', 'general.size_label': '20B', 'general.type': 'model', 'tokenizer.ggml.padding_token_id': '200017', 'gpt-oss.context_length': '131072', 'general.quantized_by': 'Unsloth', 'gpt-oss.embedding_length': '2880', 'gpt-oss.block_count': '24', 'gpt-oss.attention.sliding_window': '128', 'tokenizer.ggml.pre': 'gpt-4o', 'general.architecture': 'gpt-oss', 'gpt-oss.rope.freq_base': '150000.000000', 'gpt-oss.attention.head_count_kv': '8', 'gpt-oss.attention.layer_norm_rms_epsilon': '0.000010', 'gpt-oss.expert_count': '32', 'general.basename': 'Gpt-Oss-20B', 'gpt-oss.attention.key_length': '64', 'gpt-oss.expert_used_count': '4', 'gpt-oss.expert_feed_forward_length': '2880', 'gpt-oss.rope.scaling.type': 'yarn', 'tokenizer.ggml.eos_token_id': '200002', 'gpt-oss.rope.scaling.factor': '32.000000', 'tokenizer.ggml.model': 'gpt2', 'general.name': 'Gpt-Oss-20B', 'gpt-oss.attention.value_length': '64', 'tokenizer.ggml.bos_token_id': '199998'}\n",
            "Available chat formats from metadata: chat_template.default\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**會議摘要**\n\n**1. 主要討論內容**  \n- 會議中提到「可再想想看」的方案，並未決定具體行動。  \n- 討討開設線上號、專門輸入內容之計畫，並確認無問題。  \n- 會議者提出將帳號先開，後續做實驗，並說「直接先開帳號」  \n- **重點：** 會議決定先開帳號，並以 YouTube、IG、Threads 等平台推廣  \n- **重點**： 其實務流程：先開帳號，先前往下列…  \n\n> …….  \nWe need to produce a concise summary of the transcript. The transcript is messy, but we need to extract key points: time, persons, tasks, conclusions, unresolved items, actions. Provide bullet list with headings. 500-900 Chinese characters? Actually 500-900 words? The instruction says 500–900 字 (characters). So we need about 500-900 Chinese characters. That's roughly 300-400 words. Provide bullet points.\n\nWe must avoid system messages, no brackets, no English. Use Chinese. Provide headings and bullet items. Ensure no extraneous commentary. Provide final answer. Let's craft.\n\nWe need to identify key participants: seems like speaker is \"Nicolai Winther\" maybe? Actually transcript includes \"Teksting av Nicolai Winther\". So maybe the speaker is Nicolai Winther. Also mention \"老孫\" etc. But we can just refer to \"會議者\".\n\nKey points:\n\n- They discuss opening an online account, possibly for a brand or company.\n- They plan to use YouTube, IG, Threads to promote content, free tools, etc.\n- They talk about using a free tool for students, maybe physics? They mention \"物理\" but not sure.\n- They mention \"成學文教有限公司\" as company name; \"陰謀\" maybe brand name; ask if trademark application.\n- They discuss registration of account, no plan to register now.\n- They talk about verifying dynamic verification code for phone, using OpenAI and IG messages.\n- They talk about building a channel, naming it \"工程部門\".\n- They mention Gmail account used is personal.\n- They talk about Notion integration.\n- They mention \"notion\" and \"Threads\" and \"IG\" etc.\n\nWe need to"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  - 處理分段 1/5（~20.0%）\n",
            "    ↳ 分段 1 已產生字元：35\n",
            "    ↳ 分段 1 已產生字元：67\n",
            "    ↳ 分段 1 已產生字元：102\n",
            "    ↳ 分段 1 已產生字元：130\n",
            "    ↳ 分段 1 已產生字元：161\n",
            "    ↳ 分段 1 已產生字元：198\n",
            "    ↳ 分段 1 已產生字元：223\n",
            "    ↳ 分段 1 已產生字元：265\n",
            "    ↳ 分段 1 已產生字元：362\n",
            "    ↳ 分段 1 已產生字元：499\n",
            "    ↳ 分段 1 已產生字元：622\n",
            "    ↳ 分段 1 已產生字元：736\n",
            "    ↳ 分段 1 已產生字元：860\n",
            "    ↳ 分段 1 已產生字元：970\n",
            "    ↳ 分段 1 已產生字元：1086\n",
            "    ↳ 分段 1 已產生字元：1179\n",
            "    ↳ 分段 1 已產生字元：1279\n",
            "    ↳ 分段 1 已產生字元：1413\n",
            "    ↳ 分段 1 已產生字元：1527\n",
            "    ↳ 分段 1 已產生字元：1649\n",
            "    ↳ 分段 1 已產生字元：1764\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6120.68 ms\n",
            "llama_perf_context_print: prompt eval time =    6119.88 ms /  3472 tokens (    1.76 ms per token,   567.33 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12180.98 ms /   511 runs   (   23.84 ms per token,    41.95 tokens per second)\n",
            "llama_perf_context_print:       total time =   21063.67 ms /  3983 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 1 已產生字元：1767\n",
            "  - 處理分段 2/5（~40.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3358 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 2 已產生字元：35\n",
            "    ↳ 分段 2 已產生字元：61\n",
            "    ↳ 分段 2 已產生字元：89\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6120.68 ms\n",
            "llama_perf_context_print: prompt eval time =    4843.50 ms /  3358 tokens (    1.44 ms per token,   693.30 tokens per second)\n",
            "llama_perf_context_print:        eval time =    2013.90 ms /    84 runs   (   23.98 ms per token,    41.71 tokens per second)\n",
            "llama_perf_context_print:       total time =    7246.88 ms /  3442 tokens\n",
            "llama_perf_context_print:    graphs reused =         81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 2 已產生字元：103\n",
            "  - 處理分段 3/5（~60.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3325 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 3 已產生字元：51\n",
            "    ↳ 分段 3 已產生字元：92\n",
            "    ↳ 分段 3 已產生字元：125\n",
            "    ↳ 分段 3 已產生字元：163\n",
            "    ↳ 分段 3 已產生字元：192\n",
            "    ↳ 分段 3 已產生字元：228\n",
            "    ↳ 分段 3 已產生字元：263\n",
            "    ↳ 分段 3 已產生字元：292\n",
            "    ↳ 分段 3 已產生字元：328\n",
            "    ↳ 分段 3 已產生字元：406\n",
            "    ↳ 分段 3 已產生字元：528\n",
            "    ↳ 分段 3 已產生字元：631\n",
            "    ↳ 分段 3 已產生字元：747\n",
            "    ↳ 分段 3 已產生字元：845\n",
            "    ↳ 分段 3 已產生字元：950\n",
            "    ↳ 分段 3 已產生字元：1054\n",
            "    ↳ 分段 3 已產生字元：1119\n",
            "    ↳ 分段 3 已產生字元：1159\n",
            "    ↳ 分段 3 已產生字元：1194\n",
            "    ↳ 分段 3 已產生字元：1230\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6120.68 ms\n",
            "llama_perf_context_print: prompt eval time =    4769.27 ms /  3325 tokens (    1.43 ms per token,   697.17 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12297.89 ms /   511 runs   (   24.07 ms per token,    41.55 tokens per second)\n",
            "llama_perf_context_print:       total time =   19942.31 ms /  3836 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 3 已產生字元：1259\n",
            "  - 處理分段 4/5（~80.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 140 prefix-match hit, remaining 3387 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 4 已產生字元：39\n",
            "    ↳ 分段 4 已產生字元：76\n",
            "    ↳ 分段 4 已產生字元：165\n",
            "    ↳ 分段 4 已產生字元：282\n",
            "    ↳ 分段 4 已產生字元：383\n",
            "    ↳ 分段 4 已產生字元：483\n",
            "    ↳ 分段 4 已產生字元：602\n",
            "    ↳ 分段 4 已產生字元：716\n",
            "    ↳ 分段 4 已產生字元：818\n",
            "    ↳ 分段 4 已產生字元：937\n",
            "    ↳ 分段 4 已產生字元：1056\n",
            "    ↳ 分段 4 已產生字元：1138\n",
            "    ↳ 分段 4 已產生字元：1256\n",
            "    ↳ 分段 4 已產生字元：1379\n",
            "    ↳ 分段 4 已產生字元：1527\n",
            "    ↳ 分段 4 已產生字元：1643\n",
            "    ↳ 分段 4 已產生字元：1763\n",
            "    ↳ 分段 4 已產生字元：1883\n",
            "    ↳ 分段 4 已產生字元：1990\n",
            "    ↳ 分段 4 已產生字元：2112\n",
            "    ↳ 分段 4 已產生字元：2217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6120.68 ms\n",
            "llama_perf_context_print: prompt eval time =    4876.93 ms /  3387 tokens (    1.44 ms per token,   694.49 tokens per second)\n",
            "llama_perf_context_print:        eval time =   12495.12 ms /   511 runs   (   24.45 ms per token,    40.90 tokens per second)\n",
            "llama_perf_context_print:       total time =   20238.70 ms /  3898 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 4 已產生字元：2257\n",
            "  - 處理分段 5/5（~100.0%）\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 141 prefix-match hit, remaining 1792 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 5 已產生字元：35\n",
            "    ↳ 分段 5 已產生字元：63\n",
            "    ↳ 分段 5 已產生字元：93\n",
            "    ↳ 分段 5 已產生字元：122\n",
            "    ↳ 分段 5 已產生字元：162\n",
            "    ↳ 分段 5 已產生字元：192\n",
            "    ↳ 分段 5 已產生字元：290\n",
            "    ↳ 分段 5 已產生字元：408\n",
            "    ↳ 分段 5 已產生字元：501\n",
            "    ↳ 分段 5 已產生字元：605\n",
            "    ↳ 分段 5 已產生字元：725\n",
            "    ↳ 分段 5 已產生字元：849\n",
            "    ↳ 分段 5 已產生字元：953\n",
            "    ↳ 分段 5 已產生字元：1026\n",
            "    ↳ 分段 5 已產生字元：1136\n",
            "    ↳ 分段 5 已產生字元：1234\n",
            "    ↳ 分段 5 已產生字元：1316\n",
            "    ↳ 分段 5 已產生字元：1426\n",
            "    ↳ 分段 5 已產生字元：1546\n",
            "    ↳ 分段 5 已產生字元：1649\n",
            "    ↳ 分段 5 已產生字元：1735\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6120.68 ms\n",
            "llama_perf_context_print: prompt eval time =    2385.55 ms /  1792 tokens (    1.33 ms per token,   751.19 tokens per second)\n",
            "llama_perf_context_print:        eval time =   11665.55 ms /   511 runs   (   22.83 ms per token,    43.80 tokens per second)\n",
            "llama_perf_context_print:       total time =   16955.58 ms /  2303 tokens\n",
            "llama_perf_context_print:    graphs reused =        494\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 分段 5 已產生字元：1752\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**會議筆記（Markdown，繁體）**\n\n---\n\n## 整體提要  \n- 會議主題為「開設線上號並推廣內容」；  \n- 主要平台包括 YouTube、IG、Threads；  \n- 討討使用免費工具與 AI 產生內容；  \n- 需確認帳號名稱、商標及資料保護；  \n- 會議決定先開帳號，後續實驗推廣策略。  \n\n---\n\n## 章節要點（含時間脈絡）\n\n| 時間 | 要點 |\n|------|------|\n| 0:00 | 會議者提到「可再想想看」的方案，未決定具體行動。 |\n| 0:05 | 討討開設線上號、專門輸入內容之計畫，並確認無問題。 |\n| 0:10 | 會議者提出將帳號先開，後續做實驗，說「直接先開帳號」。 |\n| 0:15 | 會議決定先開帳號，並以 YouTube、IG、Threads 等平台推廣。 |\n| 0:20 | 其實務流程：先開帳號，先前往下列…（未完整說明）。 |\n| 0:25 | 會議者提到「成學文教有限公司」與「陰謀」作為公司名，詢問是否已申請商標。 |\n| 0:30 | 會議者表示目前不打算註冊帳號，先以 Gmail 個人帳號做測試。 |\n| 0:35 | 會議者說明將使用 Notion、Threads、IG 等工具來管理與推廣內容。 |\n| 0:40 | 會議者提到「動態驗證碼」的流程，並說要用 OpenAI 及 IG 訊息確認。 |\n| 0:45 | 會議者說明將建立「工程部門」為頻道名稱。 |\n\n---\n\n## 可執行重點（具體待辦）\n\n- **開設線上號**：先以 Gmail 個人帳號做測試，後續正式註冊。  \n- **確認商標**：查詢「陰謀」是否已申請商標，並確保不侵權。  \n- **設定平台**：決定 YouTube、IG、Threads 為主要推廣平台。  \n- **管理工具**：整合 Notion 以管理內容與進度。  \n- **驗證流程**：使用 OpenAI 及 IG 訊息確認動態驗證碼。  \n- **頻道名稱**：確定「工程部門」為正式頻道名稱。  \n\n---"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: 129 prefix-match hit, remaining 2330 prompt tokens to eval\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 彙整 已產生字元：43\n",
            "    ↳ 彙整 已產生字元：80\n",
            "    ↳ 彙整 已產生字元：122\n",
            "    ↳ 彙整 已產生字元：150\n",
            "    ↳ 彙整 已產生字元：189\n",
            "    ↳ 彙整 已產生字元：228\n",
            "    ↳ 彙整 已產生字元：258\n",
            "    ↳ 彙整 已產生字元：288\n",
            "    ↳ 彙整 已產生字元：315\n",
            "    ↳ 彙整 已產生字元：350\n",
            "    ↳ 彙整 已產生字元：388\n",
            "    ↳ 彙整 已產生字元：418\n",
            "    ↳ 彙整 已產生字元：447\n",
            "    ↳ 彙整 已產生字元：477\n",
            "    ↳ 彙整 已產生字元：511\n",
            "    ↳ 彙整 已產生字元：554\n",
            "    ↳ 彙整 已產生字元：586\n",
            "    ↳ 彙整 已產生字元：620\n",
            "    ↳ 彙整 已產生字元：658\n",
            "    ↳ 彙整 已產生字元：690\n",
            "    ↳ 彙整 已產生字元：721\n",
            "    ↳ 彙整 已產生字元：768\n",
            "    ↳ 彙整 已產生字元：810\n",
            "    ↳ 彙整 已產生字元：850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_perf_context_print:        load time =    6120.68 ms\n",
            "llama_perf_context_print: prompt eval time =    3231.40 ms /  2330 tokens (    1.39 ms per token,   721.05 tokens per second)\n",
            "llama_perf_context_print:        eval time =   14272.65 ms /   606 runs   (   23.55 ms per token,    42.46 tokens per second)\n",
            "llama_perf_context_print:       total time =   20790.99 ms /  2936 tokens\n",
            "llama_perf_context_print:    graphs reused =        586\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    ↳ 彙整 已產生字元：878\n",
            "→ 完成 ✅  /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8)_summary.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4255d34"
      },
      "source": [
        "## Update output paths\n",
        "\n",
        "### Subtask:\n",
        "Verify and update the logic for determining output paths to work correctly within the single cell structure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "796aaf44"
      },
      "source": [
        "**Reasoning**:\n",
        "Review the code to ensure the output path logic for transcription and summarization is correct and handles directory creation.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "ffa4b9b4",
        "outputId": "23035e47-bd8e-4fe7-92f8-5477b9b89709"
      },
      "source": [
        "# [8/8] Output (text after OpenCC) - Uses 'out_base_dir' (derived from 'filename')\n",
        "print(\"[8/8] 輸出 SRT / TXT ...\")\n",
        "# Determine the output directory for transcription based on input type\n",
        "# If input is a network source, output to WHISPER_DIR\n",
        "# If input is a local file, output to the same directory as the input file\n",
        "if is_youtube_url(filename) or is_http_url(filename):\n",
        "    out_base_dir = WHISPER_DIR\n",
        "else:\n",
        "    src_path_abs = to_abs_mydrive(filename)\n",
        "    out_base_dir = src_path_abs.parent\n",
        "\n",
        "# Create the transcription output directory if it doesn't exist\n",
        "out_dir = out_base_dir\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Determine the stem from the original source file path\n",
        "stem = Path(src_path).stem\n",
        "SRT = out_dir / f\"{stem}.srt\"\n",
        "TXT = out_dir / f\"{stem}.txt\"\n",
        "\n",
        "with open(SRT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, s in enumerate(filtered, 1):\n",
        "        text_out = norm(s.text.strip())\n",
        "        f.write(f\"{i}\\n{fmt_ts_srt(s.start)} --> {fmt_ts_srt(s.end)}\\n{text_out}\\n\\n\")\n",
        "\n",
        "with open(TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in filtered:\n",
        "        f.write(norm(s.text.strip()) + \"\\n\")  # Each segment on a new line\n",
        "\n",
        "print(f\"→ 完成！\\n  SRT: {SRT}\\n  TXT: {TXT}\")\n",
        "\n",
        "# Release model (release GPU memory)\n",
        "try: del model\n",
        "except: pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"→ Model released; can run again directly if needed.\")\n",
        "\n",
        "\n",
        "# ===== Summarization Logic Starts Here =====\n",
        "\n",
        "# Determine the SRT input path for summarization - Uses 'summary_srt_path' and 'SRT' from transcription\n",
        "if not summary_srt_path:\n",
        "    # If summary_srt_path is empty, use the SRT generated by the transcription step\n",
        "    summary_srt_path_abs = SRT\n",
        "    if DEBUG_MODE: print(f\"Using SRT from transcription step: {summary_srt_path_abs}\")\n",
        "else:\n",
        "    # If summary_srt_path is provided, convert it to an absolute path relative to MyDrive\n",
        "    summary_srt_path_abs = to_abs_mydrive(summary_srt_path)\n",
        "\n",
        "# Ensure the input SRT file for summarization exists\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "\n",
        "\n",
        "# ===== Summary 6/6) Consolidate (reduce) & Only write .md (Summary) - Uses summary_output_dir, summary_srt_path_abs, reduce_max_new_tokens, ctx_window, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 6/6] Consolidating summary (reduce) ...\")\n",
        "maps_md = \"\\n\\n---\\n\\n\".join(f\"### 片段 {i+1} 要點\\n\\n{m}\" for i, m in enumerate(maps))\n",
        "\n",
        "# If combined text exceeds window, truncate proportionally first (without changing text within segments to avoid breaking meaning)\n",
        "def fit_reduce_payload(md_text: str, max_ctx_tokens: int) -> str:\n",
        "    for _ in range(8):\n",
        "        need = count_tokens_text(md_text)\n",
        "        if need + reduce_max_new_tokens + 400 <= max_ctx_tokens:\n",
        "            return md_text\n",
        "        md_text = md_text[: int(len(md_text) * 0.9)]\n",
        "    return md_text\n",
        "\n",
        "md_cur = fit_reduce_payload(maps_md, ctx_window)\n",
        "\n",
        "user_txt = REDUCE_USER_TMPL.format(topic=(topic_hint or \"（無）\"), maps=md_cur)\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_INSTR},\n",
        "            {\"role\":\"user\",\"content\":user_txt}]\n",
        "\n",
        "live2 = display(Markdown(\"\"), display_id=True)\n",
        "final_buf = []\n",
        "for token in llm_stream(messages, reduce_max_new_tokens):\n",
        "    final_buf.append(token)\n",
        "    if len(final_buf) % 24 == 0:\n",
        "        live2.update(Markdown(\"\".join(final_buf)))\n",
        "        sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "live2.update(Markdown(\"\".join(final_buf)))\n",
        "sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "\n",
        "final_text = \"\".join(final_buf).strip()\n",
        "\n",
        "# Determine and create the summary output directory\n",
        "summary_output_dir_abs = to_abs_mydrive(summary_output_dir)\n",
        "summary_output_dir_abs.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Determine the summary output file path using the stem of the input SRT\n",
        "out_md = summary_output_dir_abs / f\"{Path(summary_srt_path_abs).stem}_summary.md\"\n",
        "\n",
        "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_text)\n",
        "\n",
        "print(f\"→ 完成 ✅  {out_md}\")\n",
        "try:\n",
        "    del llm\n",
        "except Exception:\n",
        "    pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"（顯存已釋放，如需重跑可直接再次執行）\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8/8] 輸出 SRT / TXT ...\n",
            "→ 完成！\n",
            "  SRT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).srt\n",
            "  TXT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).txt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'llm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4141189744.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmd_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mmd_cur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_reduce_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaps_md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx_window\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0muser_txt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mREDUCE_USER_TMPL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtopic_hint\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"（無）\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmd_cur\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4141189744.py\u001b[0m in \u001b[0;36mfit_reduce_payload\u001b[0;34m(md_text, max_ctx_tokens)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfit_reduce_payload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_text\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_ctx_tokens\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mneed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_tokens_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmd_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreduce_max_new_tokens\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m400\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_ctx_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmd_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3282525746.py\u001b[0m in \u001b[0;36mcount_tokens_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcount_tokens_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m SYSTEM_INSTR = (\n",
            "\u001b[0;31mNameError\u001b[0m: name 'llm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afadc972"
      },
      "source": [
        "**Reasoning**:\n",
        "The `llm` object was not defined because the summarization steps were executed without the model being loaded first. The code needs to load the summarization model *before* attempting to use it for token counting or generation. The `llama-cpp-python` installation and model loading steps (`[Summary 1/6]` and `[Summary 3/6]`) should occur before the token-aware segmentation (`[Summary 4/6]`) and summarization steps (`[Summary 5/6]` and `[Summary 6/6]`). I will regenerate the full code with the corrected execution order for the summarization part.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ae82c25f33084774bf7b06bde73c997d",
            "565ede674ed94d62bf3b47bc94773039",
            "aea8e34970264fef85549630f4360e4c",
            "2bba020ca5d44ad4be4a39cbf92375c6",
            "dcb3c4d76cbd4142bb4865f591f4768f",
            "5c075ecfb7324b42af680edb704258dc",
            "905870b83d344d3a9dfc1d32de45ecd0",
            "699da63442f24116b809006f7c43000b",
            "c3c0d0dee82a4660a818d83780a64ef1",
            "e136d17ce8b34967afa139602ac837b1",
            "9bf0b980ce274095a1ad49df83670c06"
          ]
        },
        "id": "RAxAeUyUFnY8",
        "outputId": "c4335c9d-9b40-44ea-c38f-7de0908cbf67"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Whisper Automatic Subtitle Generation: GPU Transcription + CPU Denoising + OpenCC Post-processing (Traditional/Simplified Conversion)\n",
        "# And LLM Summarization (GPT-OSS-20B / llama.cpp / CUDA)\n",
        "# - Transcription: faster-whisper (CUDA, compute: int8_float16→float16→int8)\n",
        "# - Denoising: ffmpeg afftdn (CPU)\n",
        "# - Progress: Real-time printing of \"current sentence + video total length percentage\"\n",
        "# - Network source download and output: MyDrive/whisper; Files in Drive: Output to the same folder\n",
        "# - LLM Summary: llama.cpp + GPT-OSS-20B GGUF for summarizing transcription\n",
        "# - Prompts \"Delete runtime and restart\" if download is blocked or abnormal\n",
        "# =========================================================\n",
        "\n",
        "# Restrict multithreading (more stable)\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# [1/8] Mount Google Drive\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "except:\n",
        "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "# Consolidated Imports\n",
        "import sys, gc, shutil, datetime, subprocess as sp\n",
        "from pathlib import Path\n",
        "import re, math, time, importlib, textwrap\n",
        "from typing import List, Tuple\n",
        "from IPython.display import display, Markdown\n",
        "import soundfile as sf\n",
        "from faster_whisper import WhisperModel\n",
        "from opencc import OpenCC\n",
        "import srt as _srt # Import srt as _srt to avoid name conflict later with the module itself\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "ROOT = Path(\"/content/gdrive/MyDrive\")\n",
        "WHISPER_DIR = ROOT / \"whisper\"\n",
        "WHISPER_DIR.mkdir(exist_ok=True, parents=True)\n",
        "os.chdir(ROOT)\n",
        "print(f\"→ 當前工作目錄：{os.getcwd()}\")\n",
        "\n",
        "# [2/8] User Form Parameters (Unified)\n",
        "#@markdown # Whisper Transcription & LLM Summary Pipeline\n",
        "\n",
        "#@markdown ## Input & Transcription Settings\n",
        "#@markdown **Input Source:** Google Drive file (relative to MyDrive) or video URL (YouTube/HTTP).\n",
        "filename = \"whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\"  #@param {type:\"string\"}\n",
        "#@markdown **Download Option:** Check to save network source files to `MyDrive/whisper`.\n",
        "save_video_to_google_drive = True  #@param {type:\"boolean\"}\n",
        "#@markdown **Whisper Model Size:** Choose a model size. `large-v3` requires more GPU VRAM; `medium` is a good alternative if VRAM is limited.\n",
        "model_size = \"large-v3\"  #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\"]\n",
        "#@markdown **Language:** Select the language for transcription. \"自動偵測\" (Auto-detect) is usually sufficient.\n",
        "language = \"自動偵測\"  #@param [\"自動偵測\", \"中文\", \"英文\"]\n",
        "#@markdown **Denoising:** Apply CPU-based denoising to the audio before transcription. `afftdn` is recommended.\n",
        "denoise_method = \"afftdn (建議)\"  #@param [\"afftdn (建議)\", \"none\"]\n",
        "#@markdown **Text Post-processing (OpenCC):** Convert the transcribed text (SRT/TXT output) between Simplified and Traditional Chinese variants.\n",
        "text_postprocess = \"臺灣繁體中文（預設）\"  #@param [\"臺灣繁體中文（預設）\",\"香港繁體中文\",\"大陸簡體中文\",\"關閉\"]\n",
        "#@markdown **YouTube Cookies (Optional):** Path to a Netscape-format cookies file (relative to MyDrive) for accessing age-restricted or member-only YouTube videos (e.g., `cookies/youtube.txt`).\n",
        "youtube_cookies_txt_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Summarization Settings\n",
        "#@markdown **SRT Input:** Path to the SRT file for summarization (relative to MyDrive or absolute). Leave empty to use the SRT generated by the transcription step above.\n",
        "summary_srt_path = \"\"  #@param {type:\"string\"}\n",
        "#@markdown **Topic Hint (Optional):** Provide a brief hint about the topic to guide the summarization process.\n",
        "topic_hint = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Output Paths\n",
        "#@markdown **Transcription Output Directory:** Directory where the generated SRT and TXT files will be saved (relative to MyDrive or absolute). Default is the input file's directory for local files, or `MyDrive/whisper` for network sources. This is determined automatically.\n",
        "# (Note: filename's directory is used if local, otherwise WHISPER_DIR. This parameter is more of an indicator of the default output base.)\n",
        "#@markdown **Summary Output Directory:** Directory where the final summary Markdown file will be saved (relative to MyDrive or absolute).\n",
        "summary_output_dir = \"/content/gdrive/MyDrive/whisper\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "language_code_map = {\"自動偵測\": None, \"中文\":\"zh\", \"英文\":\"en\"}\n",
        "language_code = language_code_map[language]\n",
        "\n",
        "# =========================================================\n",
        "# Developer Options\n",
        "# Advanced users can fine-tune parameters in this section.\n",
        "# Modify only if you understand the impact.\n",
        "# =========================================================\n",
        "DEBUG_MODE = False # Set to True for more detailed logging\n",
        "\n",
        "# --- Transcription Parameters ---\n",
        "TRANSCRIPTION_BEAM_SIZE_PRIMARY = 3\n",
        "TRANSCRIPTION_CHUNK_LENGTH_PRIMARY = 20\n",
        "TRANSCRIPTION_BEAM_SIZE_FALLBACK = 1 # Used if primary fails\n",
        "TRANSCRIPTION_CHUNK_LENGTH_FALLBACK = 15 # Used if primary fails\n",
        "\n",
        "# --- Denoising Parameters ---\n",
        "DENOISE_NOISE_FLOOR_DB = -25\n",
        "\n",
        "# --- Filtering Parameters ---\n",
        "FILTER_MIN_DURATION_SHORT = 1.5 # Minimum duration for short segments\n",
        "FILTER_AVG_LOGPROB_THRESHOLD = -1.0 # Avg log probability threshold for short segments\n",
        "FILTER_MIN_DURATION_SPEECH_PROB = 2.0 # Minimum duration for speech probability filtering\n",
        "FILTER_NO_SPEECH_PROB_THRESHOLD = 0.6 # No speech probability threshold\n",
        "\n",
        "# --- Summary Model Parameters ---\n",
        "REPO_ID   = \"unsloth/gpt-oss-20b-GGUF\"   # GGUF Model Repository\n",
        "GGUF_FILE = \"gpt-oss-20b-Q4_K_M.gguf\"    # Approx. 10.8GiB, T4 can run\n",
        "\n",
        "# --- Summary Inference Parameters (Increase available generation space to avoid truncation) ---\n",
        "ctx_window            = 8192\n",
        "map_max_new_tokens    = 512   # Segment output: original 256 -> 512 (approx. 350-450 chars)\n",
        "reduce_max_new_tokens = 1024  # Summary output: original 512 -> 1024 (approx. 700-900+ chars)\n",
        "temperature           = 0.2\n",
        "top_p                 = 0.9\n",
        "repeat_penalty        = 1.05\n",
        "# =========================================================\n",
        "# End of Developer Options\n",
        "# =========================================================\n",
        "\n",
        "\n",
        "# [3/8] Install Dependencies\n",
        "# Combine installation steps from both original cells\n",
        "if DEBUG_MODE: print(\"[Install] faster-whisper / yt-dlp / soundfile / opencc / srt / huggingface_hub / llama-cpp-python ...\")\n",
        "\n",
        "def pip_install(pkgs, extra_args=None, env=None):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"]\n",
        "    if extra_args:\n",
        "        cmd += extra_args\n",
        "    cmd += pkgs\n",
        "    return sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True, env=env)\n",
        "\n",
        "# Install common dependencies first\n",
        "common_missing = []\n",
        "try: import srt # check srt module directly after import as _srt\n",
        "except ModuleNotFoundError: common_missing.append(\"srt>=3.5.3\")\n",
        "try: from huggingface_hub import snapshot_download # check huggingface_hub module directly\n",
        "except ModuleNotFoundError: common_missing.append(\"huggingface_hub>=0.23.0\")\n",
        "try: import soundfile # check soundfile\n",
        "except ModuleNotFoundError: common_missing.append(\"soundfile\")\n",
        "try: import opencc # check opencc\n",
        "except ModuleNotFoundError: common_missing.append(\"opencc-python-reimplemented\")\n",
        "\n",
        "if common_missing:\n",
        "    if DEBUG_MODE: print(\"→ Installing common missing packages:\", \", \".join(common_missing))\n",
        "    r = pip_install(common_missing)\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"基礎依賴安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "# Install faster-whisper and yt-dlp separately as they were in the first cell\n",
        "try: from faster_whisper import WhisperModel # check faster_whisper\n",
        "except ModuleNotFoundError:\n",
        "    if DEBUG_MODE: print(\"→ Installing missing package: faster-whisper yt-dlp\")\n",
        "    r = pip_install([\"faster-whisper\", \"yt-dlp\"])\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"faster-whisper / yt-dlp 安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "\n",
        "def suggest_runtime_reset():\n",
        "    print(\"\\n🧹 建議動作（Colab）\")\n",
        "    print(\"1) 依序：『執行階段 Runtime』 → 『刪除執行階段/還原出廠設定 Factory reset runtime』\")\n",
        "    print(\"2) 重新執行本 Notebook（從掛載雲端硬碟那格開始）\\n\", flush=True)\n",
        "\n",
        "def run_cmd(cmd:list, check=True):\n",
        "    if DEBUG_MODE: print(\"  $\", \" \".join(cmd))\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"命令失敗：{' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "def is_youtube_url(s:str)->bool:\n",
        "    return isinstance(s, str) and (\"youtu.be\" in s or \"youtube.com\" in s)\n",
        "def is_http_url(s:str)->bool:\n",
        "    return isinstance(s, str) and s.lower().startswith(\"http\")\n",
        "def to_abs_mydrive(p:str)->Path:\n",
        "    return (Path(p) if p.startswith(\"/\") else (ROOT / p)).resolve()\n",
        "def fmt_ts_srt(t:float)->str:\n",
        "    h = int(t//3600); m = int((t%3600)//60); s = t - h*3600 - m*60\n",
        "    return f\"{h:02d}:{m:02d}:{int(s):02d},{int(round((s-int(s))*1000)):03d}\"\n",
        "def verify_wav_ok(path: Path)->bool:\n",
        "    try:\n",
        "        info = sf.info(str(path))\n",
        "        return info.samplerate > 0 and info.channels in (1, 2)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# OpenCC converter setup\n",
        "def build_opencc_pipeline(choice:str):\n",
        "    if choice.startswith(\"臺灣\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2tw')]\n",
        "    if choice.startswith(\"香港\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2hk')]\n",
        "    if choice.startswith(\"大陸\"):\n",
        "        return [OpenCC('t2s')]\n",
        "    return []  # Disable\n",
        "\n",
        "def apply_opencc(text:str, pipeline)->str:\n",
        "    for cc in pipeline:\n",
        "        text = cc.convert(text)\n",
        "    return text\n",
        "\n",
        "def ytdl(yturl:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting YouTube video ...\")\n",
        "    # Use sp.run instead of subprocess.run directly\n",
        "    cmd = [\"yt-dlp\", \"-f\", \"mp4\", \"-o\", str(tmp / \"%(title)s.%(ext)s\")]\n",
        "    if youtube_cookies_txt_path.strip():\n",
        "        cookies_abs = to_abs_mydrive(youtube_cookies_txt_path.strip())\n",
        "        if cookies_abs.exists():\n",
        "            cmd += [\"--cookies\", str(cookies_abs)]\n",
        "        else:\n",
        "            if DEBUG_MODE: print(f\"⚠️ 找不到 cookies 檔：{cookies_abs}（改為不帶 cookies）\")\n",
        "    cmd.append(yturl)\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        if \"Sign in to confirm\" in (p.stdout or \"\"):\n",
        "            print(\"\\n❗YouTube 要求登入/驗證，請提供 cookies 或先自行下載到雲端硬碟。\")\n",
        "        print(\"🔄 若多次失敗，請刪除執行階段並重啟後重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise RuntimeError(\"yt-dlp 下載失敗\")\n",
        "    files = list(tmp.glob(\"*\"))\n",
        "    if not files:\n",
        "        print(\"🔄 下載為空，建議刪除執行階段再重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise FileNotFoundError(\"YouTube 下載失敗：/tmp/dl 為空\")\n",
        "    f = files[0]\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(f, WHISPER_DIR / f.name)\n",
        "    return f\n",
        "\n",
        "def http_dl(url:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting HTTP(S) video ...\")\n",
        "    run_cmd([\"curl\", \"-L\", \"-o\", str(out), url])\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(out, WHISPER_DIR / out.name)\n",
        "    return out\n",
        "\n",
        "# Extract audio: ffmpeg -> 16k/mono WAV\n",
        "def ffmpeg_extract_wav(in_path:Path, out_wav:Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-vn\",\"-ac\",\"1\",\"-ar\",str(sr),\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 轉 WAV 失敗\")\n",
        "\n",
        "# CPU Denoising: ffmpeg afftdn\n",
        "def ffmpeg_afftdn(in_wav: Path, out_wav: Path, noise_floor_db=DENOISE_NOISE_FLOOR_DB):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-af\",f\"afftdn=nf={noise_floor_db}\",\n",
        "           \"-ac\",\"1\",\"-ar\",\"16000\",\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg afftdn 失敗\")\n",
        "\n",
        "# Safeguard: Repack WAV header if format is strange\n",
        "def ffmpeg_repack_wav(in_wav: Path, out_wav: Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-acodec\",\"pcm_s16le\",\"-ac\",\"1\",\"-ar\",str(sr),str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 重包 WAV 失敗\")\n",
        "\n",
        "# [4/8] Parse Source (Transcription) - Uses 'filename' and 'save_video_to_google_drive'\n",
        "if DEBUG_MODE: print(\"[4/8] Parsing input source ...\")\n",
        "try:\n",
        "    if is_youtube_url(filename):\n",
        "        src_path = ytdl(filename); out_base_dir = WHISPER_DIR\n",
        "    elif is_http_url(filename):\n",
        "        src_path = http_dl(filename); out_base_dir = WHISPER_DIR\n",
        "    else:\n",
        "        src_path = to_abs_mydrive(filename)\n",
        "        if not src_path.exists(): raise FileNotFoundError(f\"找不到檔案：{src_path}\")\n",
        "        out_base_dir = src_path.parent\n",
        "except Exception as e:\n",
        "    print(f\"\\n⛔ 來源解析/下載失敗：{e}\")\n",
        "    print(\"🔄 請刪除執行階段並重新啟動後重跑。\"); suggest_runtime_reset(); raise\n",
        "\n",
        "print(f\"→ 來源檔：{src_path}\")\n",
        "print(f\"→ 輸出資料夾：{out_base_dir}\")\n",
        "\n",
        "# [5/8] Extract Audio & CPU Denoising (Transcription) - Uses 'denoise_method' and 'DENOISE_NOISE_FLOOR_DB'\n",
        "AUDIO_16K = Path(\"/tmp/audio_16k.wav\")\n",
        "if DEBUG_MODE: print(\"[5/8] Extracting audio (ffmpeg → 16k/mono WAV) ...\")\n",
        "ffmpeg_extract_wav(src_path, AUDIO_16K, sr=16000)\n",
        "\n",
        "if denoise_method.startswith(\"afftdn\"):\n",
        "    if DEBUG_MODE: print(\"[5.5/8] Denoising (ffmpeg afftdn, CPU) ...\")\n",
        "    DENOISED = Path(\"/tmp/audio_16k_denoised.wav\")\n",
        "    ffmpeg_afftdn(AUDIO_16K, DENOISED, noise_floor_db=DENOISE_NOISE_FLOOR_DB)\n",
        "    denoised_audio = DENOISED if verify_wav_ok(DENOISED) else AUDIO_16K\n",
        "else:\n",
        "    denoised_audio = AUDIO_16K\n",
        "\n",
        "if not verify_wav_ok(denoised_audio):\n",
        "    if DEBUG_MODE: print(\"  - 音訊格式異常；嘗試重包 WAV ...\")\n",
        "    FIXED = Path(\"/tmp/audio_16k_fixed.wav\")\n",
        "    ffmpeg_repack_wav(denoised_audio, FIXED, sr=16000)\n",
        "    denoised_audio = FIXED\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ 最終輸入音訊：{denoised_audio}\")\n",
        "\n",
        "# [6/8] Load faster-whisper (GPU enforced) - Uses 'model_size'\n",
        "if DEBUG_MODE: print(\"[6/8] Loading faster-whisper model (GPU) ...\")\n",
        "device = \"cuda\"  # Enforce GPU\n",
        "model = None; last_err = None\n",
        "for ctype in [\"int8_float16\", \"float16\", \"int8\"]:\n",
        "    try:\n",
        "        if DEBUG_MODE: print(f\"  - Trying compute_type={ctype}\")\n",
        "        model = WhisperModel(model_size, device=device, compute_type=ctype)\n",
        "        if DEBUG_MODE: print(\"  - Model loaded successfully\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        last_err = e\n",
        "        if DEBUG_MODE: print(f\"  - Load failed: {e}\")\n",
        "if model is None:\n",
        "    print(\"\\n⛔ GPU 模型載入失敗。請確認『變更執行階段類型』選了 GPU（T4/A100），或刪除執行階段後重試。\")\n",
        "    suggest_runtime_reset()\n",
        "    raise RuntimeError(f\"無法載入模型：{last_err}\")\n",
        "\n",
        "gc.collect()  # Clean up before transcription (safety)\n",
        "\n",
        "# [7/8] Transcribe (GPU; real-time progress per segment) - Uses 'language_code', 'TRANSCRIPTION_BEAM_SIZE_PRIMARY', 'TRANSCRIPTION_CHUNK_LENGTH_PRIMARY', 'TRANSCRIPTION_BEAM_SIZE_FALLBACK', 'TRANSCRIPTION_CHUNK_LENGTH_FALLBACK'\n",
        "if DEBUG_MODE: print(f\"[7/8] Starting transcription (GPU: beam={TRANSCRIPTION_BEAM_SIZE_PRIMARY} / chunk={TRANSCRIPTION_CHUNK_LENGTH_PRIMARY}s / no VAD) ...\")\n",
        "\n",
        "def transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY):\n",
        "    return model.transcribe(\n",
        "        str(denoised_audio),\n",
        "        task=\"transcribe\",\n",
        "        language=language_code,\n",
        "        temperature=0.0,\n",
        "        condition_on_previous_text=False,\n",
        "        compression_ratio_threshold=2.4,\n",
        "        log_prob_threshold=-1.0,\n",
        "        no_speech_threshold=0.6,\n",
        "        beam_size=_beam,\n",
        "        chunk_length=_chunk,\n",
        "        vad_filter=False,\n",
        "        word_timestamps=False\n",
        "    )\n",
        "\n",
        "try:\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY)\n",
        "except Exception as e:\n",
        "    if DEBUG_MODE: print(f\"  - First transcription failed: {e}\\n    → Trying more conservative (beam={TRANSCRIPTION_BEAM_SIZE_FALLBACK}, chunk={TRANSCRIPTION_CHUNK_LENGTH_FALLBACK}) ...\")\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_FALLBACK, _chunk=TRANSCRIPTION_CHUNK_LENGTH_FALLBACK)\n",
        "\n",
        "# Display percentage based on total video duration\n",
        "duration = float(getattr(info, \"duration\", 0.0) or 0.0)\n",
        "if duration <= 0: duration = 1.0\n",
        "\n",
        "segments = []\n",
        "filtered = []\n",
        "\n",
        "if DEBUG_MODE:\n",
        "    print(f\"  - Detected language: {getattr(info,'language','未知')} (p={getattr(info,'language_probability',0):.2f})\")\n",
        "    print(f\"  - Audio length: {duration:.2f}s\")\n",
        "\n",
        "for s in seg_iter:\n",
        "    pct = int(min(100, round((s.end / duration) * 100)))\n",
        "    print(f\"[{pct:3d}%] {fmt_ts_srt(s.start)} → {fmt_ts_srt(s.end)}  {s.text.strip()}\", flush=True)\n",
        "    segments.append(s)\n",
        "\n",
        "    # Low confidence/high no-speech short segment filtering (no blacklist) - Uses FILTER_* parameters\n",
        "    keep = True\n",
        "    seg_dur = float(s.end - s.start)\n",
        "    if seg_dur < FILTER_MIN_DURATION_SHORT and getattr(s, \"avg_logprob\", None) is not None and s.avg_logprob < FILTER_AVG_LOGPROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if seg_dur < FILTER_MIN_DURATION_SPEECH_PROB and getattr(s, \"no_speech_prob\", None) is not None and s.no_speech_prob > FILTER_NO_SPEECH_PROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if keep:\n",
        "        filtered.append(s)\n",
        "\n",
        "if DEBUG_MODE: print(f\"  - Number of segments: Before filtering {len(segments)} → After filtering {len(filtered)}\")\n",
        "\n",
        "# ---- OpenCC Normalization (for output text) ---- - Uses 'text_postprocess'\n",
        "pipeline = build_opencc_pipeline(text_postprocess)\n",
        "def norm(txt: str) -> str:\n",
        "    return apply_opencc(txt, pipeline) if pipeline else txt\n",
        "\n",
        "# [8/8] Output (text after OpenCC) - Uses 'out_base_dir' (derived from 'filename')\n",
        "print(\"[8/8] 輸出 SRT / TXT ...\")\n",
        "# Determine the output directory for transcription based on input type\n",
        "# If input is a network source, output to WHISPER_DIR\n",
        "# If input is a local file, output to the same directory as the input file\n",
        "if is_youtube_url(filename) or is_http_url(filename):\n",
        "    out_base_dir = WHISPER_DIR\n",
        "else:\n",
        "    src_path_abs = to_abs_mydrive(filename)\n",
        "    out_base_dir = src_path_abs.parent\n",
        "\n",
        "# Create the transcription output directory if it doesn't exist\n",
        "out_dir = out_base_dir\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Determine the stem from the original source file path\n",
        "stem = Path(src_path).stem\n",
        "SRT = out_dir / f\"{stem}.srt\"\n",
        "TXT = out_dir / f\"{stem}.txt\"\n",
        "\n",
        "with open(SRT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, s in enumerate(filtered, 1):\n",
        "        text_out = norm(s.text.strip())\n",
        "        f.write(f\"{i}\\n{fmt_ts_srt(s.start)} --> {fmt_ts_srt(s.end)}\\n{text_out}\\n\\n\")\n",
        "\n",
        "with open(TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in filtered:\n",
        "        f.write(norm(s.text.strip()) + \"\\n\")  # Each segment on a new line\n",
        "\n",
        "print(f\"→ 完成！\\n  SRT: {SRT}\\n  TXT: {TXT}\")\n",
        "\n",
        "# Release model (release GPU memory)\n",
        "try: del model\n",
        "except: pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"→ Model released; can run again directly if needed.\")\n",
        "\n",
        "\n",
        "# ===== Summarization Logic Starts Here =====\n",
        "\n",
        "# Determine the SRT input path for summarization - Uses 'summary_srt_path' and 'SRT' from transcription\n",
        "if not summary_srt_path:\n",
        "    # If summary_srt_path is empty, use the SRT generated by the transcription step\n",
        "    summary_srt_path_abs = SRT\n",
        "    if DEBUG_MODE: print(f\"Using SRT from transcription step: {summary_srt_path_abs}\")\n",
        "else:\n",
        "    # If summary_srt_path is provided, convert it to an absolute path relative to MyDrive\n",
        "    summary_srt_path_abs = to_abs_mydrive(summary_srt_path)\n",
        "\n",
        "# Ensure the input SRT file for summarization exists\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "\n",
        "\n",
        "# ===== Summary 1/6) Check GPU and Install Dependencies (llama-cpp-python specific) =====\n",
        "# llama-cpp-python installation logic - Keep this separate as it has specific CUDA requirements\n",
        "if DEBUG_MODE: print(\"[Summary 1/6] Checking GPU and installing llama-cpp-python ...\")\n",
        "\n",
        "def detect_cuda_tag():\n",
        "    try:\n",
        "        out = sp.check_output([\"nvidia-smi\"], text=True)\n",
        "        m = re.search(r\"CUDA Version:\\s*([\\d.]+)\", out)\n",
        "        if not m:\n",
        "            return \"cu124\"\n",
        "        major, minor = [int(x) for x in m.group(1).split(\".\")[:2]]\n",
        "        if major > 12 or (major == 12 and minor >= 5):\n",
        "            return \"cu125\"\n",
        "        return \"cu124\"\n",
        "    except Exception:\n",
        "        return \"cu124\"\n",
        "\n",
        "cuda_tag = detect_cuda_tag()\n",
        "if DEBUG_MODE: print(f\"GPU 0: Detected CUDA version tag {cuda_tag}\")\n",
        "\n",
        "def try_import_llama():\n",
        "    try:\n",
        "        from llama_cpp import Llama\n",
        "        return Llama\n",
        "    except ModuleNotFoundError:\n",
        "        return None\n",
        "\n",
        "Llama = try_import_llama()\n",
        "if Llama is None:\n",
        "    # Keep your existing installation strategy: extra-index -> fallback to source compilation on failure\n",
        "    candidates = [cuda_tag, \"cu125\", \"cu124\", \"cu122\", \"cu121\"]\n",
        "    ok = False\n",
        "    for tag in candidates:\n",
        "        idx = f\"https://abetlen.github.io/llama-cpp-python/whl/{tag}\"\n",
        "        if DEBUG_MODE: print(f\"→ Attempting to install llama-cpp-python ({tag}) ...\")\n",
        "        r = pip_install([\"llama-cpp-python\"], extra_args=[\"--extra-index-url\", idx])\n",
        "        if r.returncode == 0:\n",
        "            Llama = try_import_llama()\n",
        "            if Llama is not None:\n",
        "                ok = True\n",
        "                break\n",
        "        else:\n",
        "            if DEBUG_MODE: print(\"  ✗ Installation failed (summary):\", \"\\n\".join(r.stdout.splitlines()[-5:]))\n",
        "    if not ok:\n",
        "        if DEBUG_MODE: print(\"→ Pre-compiled wheels not available, switching to 'source compilation (CUDA=ON)' ... (takes longer)\")\n",
        "        try:\n",
        "            import ninja # noqa: F401 # Import ninja to check if installed\n",
        "        except ModuleNotFoundError:\n",
        "            if DEBUG_MODE: print(\"→ Installing missing package: ninja\")\n",
        "            r = pip_install([\"ninja\"])\n",
        "            if r.returncode != 0:\n",
        "                if DEBUG_MODE: print(r.stdout)\n",
        "                raise RuntimeError(\"安裝 ninja 失敗。請重啟後重試。\")\n",
        "        env = os.environ.copy()\n",
        "        env[\"CMAKE_ARGS\"] = \"-DGGML_CUDA=on -DLLAMA_CUBLAS=on\"\n",
        "        env[\"FORCE_CMAKE\"] = \"1\"\n",
        "        r = pip_install([\"llama-cpp-python\"], env=env)\n",
        "        if r.returncode != 0:\n",
        "            if DEBUG_MODE: print(r.stdout)\n",
        "            raise RuntimeError(\"無法安裝 GPU 版 llama-cpp-python。\")\n",
        "        Llama = try_import_llama()\n",
        "\n",
        "# ===== Summary 2/6) Read SRT (Summary) - Uses 'summary_srt_path_abs'\n",
        "if DEBUG_MODE: print(\"[Summary 2/6] Reading SRT ...\")\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "with open(summary_srt_path_abs, \"r\", encoding=\"utf-8\") as f:\n",
        "    srt_text = f.read()\n",
        "subs = list(_srt.parse(srt_text)) # Use _srt as srt module was imported as _srt\n",
        "def td2s(td): return td.total_seconds()\n",
        "segments = []\n",
        "for it in subs:\n",
        "    txt = it.content.strip()\n",
        "    if not txt: continue\n",
        "    segments.append((td2s(it.start), td2s(it.end), txt))\n",
        "total_secs = (segments[-1][1] - segments[0][0]) if segments else 0\n",
        "if DEBUG_MODE: print(f\"→ Number of subtitle segments: {len(segments)}；Video length (est): {total_secs/60:.1f} minutes\")\n",
        "\n",
        "\n",
        "# ===== Summary 3/6) Download and Load GGUF Model (Summary) - Uses summary model parameters (REPO_ID, GGUF_FILE, ctx_window, etc.)\n",
        "if DEBUG_MODE: print(\"[Summary 3/6] Loading GPT-OSS-20B (GGUF, CUDA) ...\")\n",
        "local_repo = snapshot_download(REPO_ID, allow_patterns=[GGUF_FILE])\n",
        "gguf_path = str(Path(local_repo)/GGUF_FILE)\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=gguf_path,\n",
        "    n_ctx=ctx_window,\n",
        "    n_gpu_layers=-1,\n",
        "    seed=0,\n",
        "    logits_all=False,\n",
        "    verbose=True,          # Display the actual chat format used\n",
        "    chat_format=\"chatml\",  # Directly override the GGUF built-in Unsloth template to avoid outputting <|channel|> tags\n",
        ")\n",
        "if DEBUG_MODE: print(\"→ Model loaded successfully (GPU)\")\n",
        "\n",
        "# ===== Summary 4/6) Token-aware Segmentation (Summary) - Uses ctx_window, map_max_new_tokens, prompt_overhead\n",
        "if DEBUG_MODE: print(\"[Summary 4/6] Generating segments (token-aware; single segment ≤ safety limit) ...\")\n",
        "\n",
        "def count_tokens_text(text: str) -> int:\n",
        "    # Check if llm is initialized before using it\n",
        "    if 'llm' not in locals() or llm is None:\n",
        "         raise RuntimeError(\"LLM model is not loaded. Cannot count tokens.\")\n",
        "    return len(llm.tokenize(text.encode(\"utf-8\")))\n",
        "\n",
        "SYSTEM_INSTR = (\n",
        "  \"你是一個會議總結機器人。根據使用者提供的逐字稿（可能雜訊、重複、錯字），\"\n",
        "  \"請去除雜訊與重複、嚴守事實、不腦補。遇到不明確資訊以「待補充／未明確」標註。\"\n",
        "  \"輸出為 Markdown（繁體中文），不要輸出任何系統／思考標記。\"\n",
        ")\n",
        "\n",
        "# — Segment Summary Prompt: More concise request, avoid verbosity and system language - Uses 'topic_hint'\n",
        "MAP_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是逐字稿片段（非完整全文）：\n",
        "{chunk}\n",
        "\n",
        "請就此片段輸出「條列式重點摘要」（500–900 字，繁體中文），注意：\n",
        "- 只寫最終內容，不要寫解題想法、不要出現任何系統提示或中英括號標記。\n",
        "- 聚焦可驗證事實（時間、人物、任務、結論、未決事項、行動）。\n",
        "- 結構：可用小標題＋項目符號，語句務必短、準確、無贅詞。\n",
        "\"\"\")\n",
        "\n",
        "# — Summary Prompt: Maintain your three-section output structure - Uses 'topic_hint'\n",
        "REDUCE_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是所有片段的重點摘要彙整（仍可能有重疊）：\n",
        "{maps}\n",
        "\n",
        "請整合為一份會議筆記（Markdown，繁體）：\n",
        "1) **整體提要**（3–6 句，避免冗言）\n",
        "2) **章節要點（含時間脈絡）**：條列呈現，每點一行，可附粗略時間\n",
        "3) **可執行重點**：具體待辦（每條以動詞開頭）\n",
        "請只輸出最終筆記，不要出現系統或思考標記，不要加入未出現的新資訊。\n",
        "\"\"\")\n",
        "\n",
        "# Single segment token budget (reserve space for prompt and generation)\n",
        "prompt_overhead = 700\n",
        "chunk_target    = max(1024, min(3072, ctx_window - prompt_overhead - map_max_new_tokens))\n",
        "\n",
        "chunks: List[Tuple[float,float,str]] = []\n",
        "buf, t0, t1, cur = [], None, None, 0\n",
        "for (s, e, txt) in segments:\n",
        "    t = count_tokens_text(txt)\n",
        "    if not buf:\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "        continue\n",
        "    if cur + t <= chunk_target:\n",
        "        buf.append(txt); t1 = e; cur += t\n",
        "    else:\n",
        "        chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "if buf:\n",
        "    chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ Generated {len(chunks)} segments (target ~{chunk_target} tokens per segment)\")\n",
        "\n",
        "# ===== Common: Streaming Tools (No regex cleaning; use correct stop sequence) - Uses temperature, top_p, repeat_penalty, map_max_new_tokens, reduce_max_new_tokens\n",
        "def llm_stream(messages, max_tokens):\n",
        "    # Check if llm is initialized before using it\n",
        "    if 'llm' not in locals() or llm is None:\n",
        "         raise RuntimeError(\"LLM model is not loaded. Cannot stream generation.\")\n",
        "    # ChatML messages end with <|im_end|>; use stop to cut off, preventing the closing tag from being written to the file\n",
        "    gen = llm.create_chat_completion(\n",
        "        messages=messages,\n",
        "        temperature=float(temperature),\n",
        "        top_p=float(top_p),\n",
        "        repeat_penalty=float(repeat_penalty),\n",
        "        max_tokens=int(max_tokens),\n",
        "        stream=True,\n",
        "        stop=[\"<|im_end|>\"],  # Key: Prevent outputting the ending template\n",
        "    )\n",
        "    for ev in gen:\n",
        "        # Compatible with different fields\n",
        "        piece = \"\"\n",
        "        try:\n",
        "            piece = ev[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "        except Exception:\n",
        "            piece = ev[\"choices\"][0].get(\"text\", \"\")\n",
        "        if piece:\n",
        "            yield piece\n",
        "\n",
        "# ===== Summary 5/6) Segment Summary (map) - Uses map_max_new_tokens, ctx_window, prompt_overhead, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 5/6] Segment summarization (map) ...\")\n",
        "live = display(Markdown(\"\"), display_id=True)\n",
        "maps: List[str] = []\n",
        "\n",
        "for i, (s, e, body) in enumerate(chunks, 1):\n",
        "    pct = i / max(len(chunks),1) * 100\n",
        "    sys.stdout.write(f\"  - 處理分段 {i}/{len(chunks)}（~{pct:.1f}%）\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Shrink to safe budget before sending (prevent prompt+segment from exceeding window and causing model to terminate early)\n",
        "    budget_tokens = max(512, ctx_window - map_max_new_tokens - prompt_overhead)\n",
        "    def shrink_to_budget(text: str, budget_tokens: int) -> str:\n",
        "        cur = text\n",
        "        for _ in range(6):\n",
        "            if count_tokens_text(cur) <= budget_tokens:\n",
        "                return cur\n",
        "            keep = max(800, int(len(cur) * 0.85))\n",
        "            cur = cur[:keep]\n",
        "        return cur\n",
        "    body2 = shrink_to_budget(body, budget_tokens)\n",
        "\n",
        "    user_txt = MAP_USER_TMPL.format(topic=(topic_hint or \"（無）\"), chunk=body2)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n",
        "        {\"role\": \"user\",   \"content\": user_txt},\n",
        "    ]\n",
        "\n",
        "    part_buf = [] # Reset part_buf for each segment\n",
        "    for token in llm_stream(messages, map_max_new_tokens):\n",
        "        part_buf.append(token)\n",
        "        # Update live display and terminal character count periodically\n",
        "        if len(part_buf) % 24 == 0:\n",
        "            cur_txt = \"\".join(part_buf)\n",
        "            live.update(Markdown(cur_txt))\n",
        "            sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "    cur_txt = \"\".join(part_buf)\n",
        "    live.update(Markdown(cur_txt))\n",
        "    sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Include the model's final output directly, no regex cleaning\n",
        "    maps.append(cur_txt.strip())\n",
        "\n",
        "if DEBUG_MODE: print(\"→ Segment summarization complete\")\n",
        "\n",
        "# ===== Summary 6/6) Consolidate (reduce) & Only write .md (Summary) - Uses summary_output_dir, summary_srt_path_abs, reduce_max_new_tokens, ctx_window, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 6/6] Consolidating summary (reduce) ...\")\n",
        "maps_md = \"\\n\\n---\\n\\n\".join(f\"### 片段 {i+1} 要點\\n\\n{m}\" for i, m in enumerate(maps))\n",
        "\n",
        "# If combined text exceeds window, truncate proportionally first (without changing text within segments to avoid breaking meaning)\n",
        "def fit_reduce_payload(md_text: str, max_ctx_tokens: int) -> str:\n",
        "    for _ in range(8):\n",
        "        need = count_tokens_text(md_text)\n",
        "        if need + reduce_max_new_tokens + 400 <= max_ctx_tokens:\n",
        "            return md_text\n",
        "        md_text = md_text[: int(len(md_text) * 0.9)]\n",
        "    return md_text\n",
        "\n",
        "md_cur = fit_reduce_payload(maps_md, ctx_window)\n",
        "\n",
        "user_txt = REDUCE_USER_TMPL.format(topic=(topic_hint or \"（無）\"), maps=md_cur)\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_INSTR},\n",
        "            {\"role\":\"user\",\"content\":user_txt}]\n",
        "\n",
        "live2 = display(Markdown(\"\"), display_id=True)\n",
        "final_buf = []\n",
        "for token in llm_stream(messages, reduce_max_new_tokens):\n",
        "    final_buf.append(token)\n",
        "    if len(final_buf) % 24 == 0:\n",
        "        live2.update(Markdown(\"\".join(final_buf)))\n",
        "        sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "live2.update(Markdown(\"\".join(final_buf)))\n",
        "sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "\n",
        "final_text = \"\".join(final_buf).strip()\n",
        "\n",
        "# Determine and create the summary output directory\n",
        "summary_output_dir_abs = to_abs_mydrive(summary_output_dir)\n",
        "summary_output_dir_abs.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Determine the summary output file path using the stem of the input SRT\n",
        "out_md = summary_output_dir_abs / f\"{Path(summary_srt_path_abs).stem}_summary.md\"\n",
        "\n",
        "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_text)\n",
        "\n",
        "print(f\"→ 完成 ✅  {out_md}\")\n",
        "try:\n",
        "    del llm\n",
        "except Exception:\n",
        "    pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"（顯存已釋放，如需重跑可直接再次執行）\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "→ 當前工作目錄：/content/gdrive/MyDrive\n",
            "→ 來源檔：/content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\n",
            "→ 輸出資料夾：/content/gdrive/MyDrive/whisper\n",
            "[  1%] 00:00:00,000 → 00:00:29,980  Teksting av Nicolai Winther\n",
            "[  1%] 00:00:20,000 → 00:00:49,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:00:40,000 → 00:01:09,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:00,000 → 00:01:29,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:20,000 → 00:01:49,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:01:40,000 → 00:02:09,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:02:00,000 → 00:02:29,980  Teksting av Nicolai Winther\n",
            "[  4%] 00:02:20,000 → 00:02:49,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:00,000 → 00:03:29,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:20,000 → 00:03:49,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:03:40,000 → 00:04:09,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:04:00,000 → 00:04:18,900  聽得到聲音嗎?\n",
            "[  6%] 00:04:20,000 → 00:04:24,000  Ok,ok\n",
            "[  6%] 00:04:24,000 → 00:04:28,000  Ok,那我想先確定\n",
            "[  6%] 00:04:28,000 → 00:04:32,000  威神你那邊在看完教證手冊之後\n",
            "[  6%] 00:04:32,000 → 00:04:36,000  你目前有任何的想法嗎?\n",
            "[  6%] 00:04:36,000 → 00:04:40,000  我覺得因為那時候是說\n",
            "[  6%] 00:04:40,000 → 00:04:45,240  八月底先寫完那個內容的部分嘛\n",
            "[  6%] 00:04:45,240 → 00:04:48,440  但是我覺得看完之後應該要大概\n",
            "[  6%] 00:04:48,440 → 00:04:51,180  我覺得八月底前應該沒辦法寫完\n",
            "[  7%] 00:04:51,180 → 00:04:54,040  那你覺得你什麼時候可以完成得了\n",
            "[  7%] 00:04:54,040 → 00:04:56,480  十月左右嗎\n",
            "[  7%] 00:04:56,480 → 00:04:58,400  你是說單子內容嗎\n",
            "[  7%] 00:05:00,000 → 00:05:06,000  嗯,對。\n",
            "[  7%] 00:05:06,000 → 00:05:09,500  呃,十月底。\n",
            "[  7%] 00:05:09,500 → 00:05:11,580  十月底。\n",
            "[  7%] 00:05:11,580 → 00:05:12,160  好。\n",
            "[  7%] 00:05:12,160 → 00:05:14,780  前,看看吧。\n",
            "[  7%] 00:05:14,780 → 00:05:20,040  因為我也還沒有開始,就是,照他的那個方向去改,所以我...\n",
            "[  7%] 00:05:20,000 → 00:05:23,000  I don't know how long it will take.\n",
            "[  7%] 00:05:23,000 → 00:05:25,000  Ok, ok, I got it.\n",
            "[  7%] 00:05:25,000 → 00:05:27,000  Ok, then I would like to...\n",
            "[  7%] 00:05:27,000 → 00:05:29,000  If you can speak now,\n",
            "[  7%] 00:05:29,000 → 00:05:32,000  you can briefly introduce to Wei-Chen\n",
            "[  7%] 00:05:32,000 → 00:05:35,000  the anti-epidemic prevention method.\n",
            "[  8%] 00:05:40,000 → 00:06:00,000  你要先跟他講一下,就是...\n",
            "[  8%] 00:06:00,000 → 00:06:05,000  我覺得這是一個知識存在的方面嘛 就是框架然後核心特色這樣子\n",
            "[  8%] 00:06:05,000 → 00:06:09,000  好,我發現我只要轉手機跟電腦\n",
            "[  8%] 00:06:09,000 → 00:06:13,000  你們剛剛是問到說就是未成什麼時候可以完成這本書\n",
            "[  8%] 00:06:13,000 → 00:06:18,000  然後是說是十月,十月但是不確定是什麼時候是嗎?\n",
            "[  8%] 00:06:18,000 → 00:06:20,000  Yes\n",
            "[  9%] 00:06:20,000 → 00:06:35,000  我做出這個交戰手冊主要是想說我不知道能不能去陪軍做一些類似跟AI相關的工具\n",
            "[  9%] 00:06:35,000 → 00:06:40,000  因為我的經驗會是如果有了一個標準的準則\n",
            "[  9%] 00:06:40,000 → 00:06:43,600  算是這種抽象的邏輯的話\n",
            "[  9%] 00:06:43,600 → 00:06:48,800  就能夠讓實際在寫獎益的時候\n",
            "[  9%] 00:06:48,800 → 00:06:53,200  可能就可以搭配給AI去自動生成一些類似的東西\n",
            "[  9%] 00:06:53,200 → 00:06:57,600  或是甚至可以去檢驗說這份獎益有沒有包含到\n",
            "[  9%] 00:06:57,600 → 00:07:00,000  這個交戰手冊裡面鎖定\n",
            "[  9%] 00:07:00,000 → 00:07:08,000  我覺得這可能也會讓微塵在寫講義的時候再更快一點。\n",
            "[ 10%] 00:07:08,000 → 00:07:15,000  然後具體來說這裡面的這些校章手冊裡面的所有東西,\n",
            "[ 10%] 00:07:15,000 → 00:07:20,000  玉茜你剛是問我說\n",
            "[ 10%] 00:07:20,000 → 00:07:21,200  我要講什麼\n",
            "[ 10%] 00:07:21,200 → 00:07:24,040  就你可能要稍微跟他說明一下\n",
            "[ 10%] 00:07:24,040 → 00:07:25,240  然後介紹一下\n",
            "[ 10%] 00:07:27,240 → 00:07:28,040  很多耶\n",
            "[ 10%] 00:07:32,500 → 00:07:35,240  維承目前我有幫你按照那個\n",
            "[ 10%] 00:07:35,240 → 00:07:37,400  我覺得的優先順序去排\n",
            "[ 10%] 00:07:37,400 → 00:07:39,600  就是第一個姿勢框架的話\n",
            "[ 10%] 00:07:39,600 → 00:07:40,400  就是我覺得\n",
            "[ 10%] 00:07:40,000 → 00:07:44,000  我覺得這份獎益會最迫切需要的東西\n",
            "[ 10%] 00:07:44,000 → 00:07:47,000  然後所謂的知識框架你可以把它想像成\n",
            "[ 10%] 00:07:47,000 → 00:07:51,000  或寫一個法律系的那個解題的東西\n",
            "[ 11%] 00:07:51,000 → 00:07:55,000  就是我好像記得你有學過民法\n",
            "[ 11%] 00:07:55,000 → 00:07:58,000  還是其他的法律相關的東西\n",
            "[ 11%] 00:07:58,000 → 00:08:00,000  但你也大概可以知道\n",
            "[ 11%] 00:08:00,000 → 00:08:14,980  當你面對一個複雜的案件的時候,你一定要有一套固定的思考方式跟答題方式,你才能夠快速進入到那個理解的框架裡面,然後按照這些步驟去解那個題。\n",
            "[ 11%] 00:08:14,980 → 00:08:20,000  那即便這個步驟可能有一些是形同虛設的,有一些可能在...\n",
            "[ 11%] 00:08:20,000 → 00:08:23,340  在某些題目當中其實根本就是非必要的\n",
            "[ 11%] 00:08:23,340 → 00:08:26,880  可是一旦你有了一個固定的解題框\n",
            "[ 11%] 00:08:26,880 → 00:08:28,000  這樣的思考流程\n",
            "[ 11%] 00:08:28,000 → 00:08:30,440  你在解題的時候就會更有確定感\n",
            "[ 11%] 00:08:30,440 → 00:08:34,580  然後一方面是讓學生能夠感覺自己學到\n",
            "[ 11%] 00:08:34,580 → 00:08:37,660  很具體的感受到自己有學到一套策略\n",
            "[ 12%] 00:08:37,660 → 00:08:40,000  另外一方面也是我們在行銷的\n",
            "[ 12%] 00:08:40,000 → 00:08:46,000  也會更能夠拿這一個策略,這套方法論去推廣出去。\n",
            "[ 12%] 00:08:46,000 → 00:08:54,000  所以我自己是有幫你舉的一個物理上面的例子是先聚焦再發散。\n",
            "[ 12%] 00:08:54,000 → 00:09:00,000  然後我就直接幫你寫了先聚焦再發散這個東西的\n",
            "[ 12%] 00:09:00,000 → 00:09:03,000  This is...wait a minute, the jade line is sliding down\n",
            "[ 12%] 00:09:03,000 → 00:09:06,000  Sliding down, sliding down, sliding down\n",
            "[ 12%] 00:09:06,000 → 00:09:08,000  Hey, this is the correct one\n",
            "[ 12%] 00:09:08,000 → 00:09:11,000  I forgot to delete the top\n",
            "[ 12%] 00:09:11,000 → 00:09:15,000  And then there is a physical demonstration down there\n",
            "[ 12%] 00:09:15,000 → 00:09:20,000  I will want to see that the microcosm may be speaking again\n",
            "[ 13%] 00:09:20,000 → 00:09:28,000  內容的部分先去告訴學生說所謂的先聚焦再發散這個答題策略的核心觀念是什麼\n",
            "[ 13%] 00:09:28,000 → 00:09:34,000  就是什麼是聚焦什麼是發散為什麼聚焦什麼發散然後如何聚焦如何發散\n",
            "[ 13%] 00:09:34,000 → 00:09:40,000  接下來就是透過各種抽象的步驟整理各種抽象的策略\n",
            "[ 13%] 00:09:40,000 → 00:09:46,000  一步一步的去告訴學生說這一個知識框架到底想要傳達的是什麼\n",
            "[ 13%] 00:09:46,000 → 00:09:49,000  然後進到你的題目部分\n",
            "[ 13%] 00:09:49,000 → 00:09:53,000  題目我們等下還會討論說它是要做成就是多少頁數\n",
            "[ 13%] 00:09:53,000 → 00:09:55,000  然後要不要做成電子檔\n",
            "[ 13%] 00:09:55,000 → 00:09:59,000  然後等下育前也會補充說學生對於電子檔的看法這些的\n",
            "[ 14%] 00:10:00,000 → 00:10:12,760  不論如何把題目每一題的解題過程還有每一個詳節都去套用這個不管是三步驟的發賽也好還是先聚焦的發賽\n",
            "[ 14%] 00:10:12,760 → 00:10:19,760  只要固定有一個解題的框架固定的一個算是一個噱頭或是一個包裝\n",
            "[ 14%] 00:10:20,000 → 00:10:22,560  它都可以讓學生更有一個確定感\n",
            "[ 14%] 00:10:22,560 → 00:10:25,760  所以我就會希望這本書最少最少最少最少最少\n",
            "[ 14%] 00:10:25,760 → 00:10:28,000  其他可以慢慢再補上\n",
            "[ 14%] 00:10:28,000 → 00:10:33,000  但是我覺得這個是我會希望可以加進去書\n",
            "[ 14%] 00:10:33,000 → 00:10:34,600  然後再出版會比較好\n",
            "[ 14%] 00:10:34,600 → 00:10:37,000  看我講完了\n",
            "[ 14%] 00:10:40,000 → 00:10:44,000  你目前對這部分有任何的問題嗎?\n",
            "[ 15%] 00:10:49,000 → 00:10:59,000  我要再想就是怎麼具體去把它落實到書的每個章節裡面\n",
            "[ 15%] 00:11:00,000 → 00:11:04,000  OK\n",
            "[ 15%] 00:11:04,000 → 00:11:10,000  我可以問你你自己在打題的時候也會有這樣子的\n",
            "[ 15%] 00:11:10,000 → 00:11:16,000  它會給你一種感覺嗎?就是說物理每個題目好像都有一個感覺\n",
            "[ 15%] 00:11:16,000 → 00:11:20,000  還是你是每個題目有不同的感覺?\n",
            "[ 15%] 00:11:20,000 → 00:11:24,000  好像沒有一個固定的流程\n",
            "[ 15%] 00:11:24,000 → 00:11:31,000  就是覺得可能是\n",
            "[ 15%] 00:11:31,000 → 00:11:33,000  我不會啊\n",
            "[ 15%] 00:11:33,000 → 00:11:35,000  但我覺得他們可能要先\n",
            "[ 15%] 00:11:35,000 → 00:11:37,000  抓到情況再說什麼\n",
            "[ 15%] 00:11:37,000 → 00:11:39,000  但是我就\n",
            "[ 16%] 00:11:40,000 → 00:11:44,000  我覺得我可以抓到,但我覺得他們可能是沒辦法抓到,所以寫不出來。\n",
            "[ 16%] 00:11:46,000 → 00:11:51,000  所以我覺得要先教他們怎麼把題目的點抓出來。\n",
            "[ 16%] 00:11:53,000 → 00:12:00,000  還是我在想會不會你可以跟TradeGVD聊,就你把你看的那些,你可能跟...\n",
            "[ 16%] 00:12:00,000 → 00:12:04,000  跟ChangeGPT聊個十個題目到二十個題目\n",
            "[ 16%] 00:12:04,000 → 00:12:07,000  然後你可能就請他幫你總結一下你這套思路\n",
            "[ 16%] 00:12:07,000 → 00:12:12,000  它背後的核心的步驟\n",
            "[ 16%] 00:12:12,000 → 00:12:15,000  還有你關注的重點\n",
            "[ 16%] 00:12:15,000 → 00:12:18,000  怎麼樣變成一套固定的策略\n",
            "[ 16%] 00:12:18,000 → 00:12:20,000  你可以試試看這個\n",
            "[ 16%] 00:12:20,000 → 00:12:20,500  Ok\n",
            "[ 17%] 00:12:40,000 → 00:12:43,000  你這本書最主要的核心的點是什麼東西 你這本書最主要的核心的點是什麼東西\n",
            "[ 17%] 00:12:47,000 → 00:12:52,000  如果以英文英文的書去舉例的話 就會像是作文書的話\n",
            "[ 17%] 00:12:52,000 → 00:12:58,000  雖然說它有很多很多的內容 但是我們會推出一個最主要的基點 就是它的八條公式\n",
            "[ 17%] 00:12:58,000 → 00:13:00,000  然後這個八條公式也是我們\n",
            "[ 17%] 00:13:00,000 → 00:13:04,500  主要不管是拿在書籍的生存或在社群的行銷上\n",
            "[ 17%] 00:13:04,500 → 00:13:06,700  我們都會拿著八條公式去主打\n",
            "[ 18%] 00:13:06,700 → 00:13:10,580  所以它對於學生的記憶或是這本書的整體\n",
            "[ 18%] 00:13:10,580 → 00:13:14,060  它就會有一個固定的記憶格式\n",
            "[ 18%] 00:13:14,060 → 00:13:16,040  就是大家對於這本書就會是\n",
            "[ 18%] 00:13:16,040 → 00:13:18,900  這個就是那個八條公式就是那個很屌\n",
            "[ 18%] 00:13:18,900 → 00:13:19,980  然後一模獨創的那個\n",
            "[ 18%] 00:13:20,000 → 00:13:24,640  所以也會需要你在幫我寫這本書的時候\n",
            "[ 18%] 00:13:24,640 → 00:13:27,700  也去稍微想一下你這本書的核心特色\n",
            "[ 18%] 00:13:27,700 → 00:13:29,160  最主要的那個點會是什麼\n",
            "[ 18%] 00:13:29,160 → 00:13:30,840  然後是什麼東西是可以對\n",
            "[ 18%] 00:13:30,840 → 00:13:33,760  拿出去打給社群媒體的\n",
            "[ 18%] 00:13:33,760 → 00:13:35,900  這部分有問題嗎\n",
            "[ 18%] 00:13:35,900 → 00:13:37,900  OK\n",
            "[ 18%] 00:13:37,900 → 00:13:39,220  好\n",
            "[ 18%] 00:13:40,000 → 00:13:44,960  好 子明請說\n",
            "[ 18%] 00:13:44,960 → 00:13:48,960  好 我剛剛的那個核心特色\n",
            "[ 18%] 00:13:48,960 → 00:13:53,020  如果我以前在寫物理的內容跟題目的時候\n",
            "[ 18%] 00:13:53,020 → 00:13:54,920  想不到這個特色的話\n",
            "[ 19%] 00:13:54,920 → 00:13:57,340  其實也可以就是照個路\n",
            "[ 19%] 00:13:57,340 → 00:13:59,980  把它變成說是在讀物\n",
            "[ 19%] 00:14:00,000 → 00:14:03,000  你覺得物理這個科目上面的策略\n",
            "[ 19%] 00:14:03,000 → 00:14:05,000  可能就可以想一個什麼循環圖啊\n",
            "[ 19%] 00:14:05,000 → 00:14:09,000  還是什麼正面加強的理論啊什麼的\n",
            "[ 19%] 00:14:09,000 → 00:14:13,000  但就是不一定要是物理的那些章節\n",
            "[ 19%] 00:14:13,000 → 00:14:16,000  你也可以是講你的讀書方法或筆記方法\n",
            "[ 19%] 00:14:16,000 → 00:14:18,000  它也可以變成是一個核心特色\n",
            "[ 19%] 00:14:20,000 → 00:14:23,000  我再想想。\n",
            "[ 19%] 00:14:25,000 → 00:14:35,000  那我也想順便確認一下,你有預計什麼時候可能會確定這本書的整個核心特色嗎?\n",
            "[ 19%] 00:14:35,000 → 00:14:40,000  會需要等你內容寫完嗎?還是你在這中間的過程中你可以先...\n",
            "[ 20%] 00:14:40,000 → 00:14:41,920  跟我確定\n",
            "[ 20%] 00:14:41,920 → 00:14:47,960  應該可以比內容早確定\n",
            "[ 20%] 00:14:47,960 → 00:14:49,680  但是我現在還沒有\n",
            "[ 20%] 00:14:49,680 → 00:14:52,060  就是想出來它是什麼\n",
            "[ 20%] 00:14:52,060 → 00:14:54,940  OK好沒有問題\n",
            "[ 20%] 00:14:54,940 → 00:14:58,180  然後再來下一個的話\n",
            "[ 20%] 00:14:58,180 → 00:14:59,980  會是學習方式跟記憶策略\n",
            "[ 20%] 00:15:00,000 → 00:15:08,000  因為我知道你有先看過整個的內容,所以我想確認你對於這部分有任何問題嗎?\n",
            "[ 20%] 00:15:08,000 → 00:15:17,000  或是有特別想詢問的點嗎?如果沒有的話我們就加快進度,就不用這樣一個一個特別的去講解。\n",
            "[ 21%] 00:15:20,000 → 00:15:27,000  因為就是這邊看起來比較想要說就是要理解\n",
            "[ 21%] 00:15:27,000 → 00:15:35,000  但是我不確定就是他們要理解全盤理解的話會耗費的成本要多少\n",
            "[ 21%] 00:15:35,000 → 00:15:40,000  還是有些人是不是只是想要把它把固定的流程背起來\n",
            "[ 21%] 00:15:40,000 → 00:15:42,800  然後就可以去解題\n",
            "[ 21%] 00:15:42,800 → 00:15:46,200  所以我要著重在\n",
            "[ 21%] 00:15:46,200 → 00:15:48,000  就是不用全盤理解\n",
            "[ 21%] 00:15:48,000 → 00:15:49,200  但是比較好解題\n",
            "[ 21%] 00:15:49,200 → 00:15:51,600  還是希望他們比較好理解\n",
            "[ 21%] 00:15:51,600 → 00:15:56,100  然後就是底子很穩這樣\n",
            "[ 21%] 00:15:56,100 → 00:15:58,400  方向應該在那邊\n",
            "[ 21%] 00:15:58,400 → 00:16:00,000  我覺得會比較看\n",
            "[ 21%] 00:16:00,000 → 00:16:04,200  你這本書的定位點在哪裡?\n",
            "[ 21%] 00:16:04,200 → 00:16:09,800  子民剛說有要講話,我有看到你那個框框。\n",
            "[ 22%] 00:16:09,800 → 00:16:14,000  好像上次跟維城討論的時候你是說,\n",
            "[ 22%] 00:16:14,000 → 00:16:20,000  你希望事實上不知道怎麼開始讀物理的人也可以找到一個方向。\n",
            "[ 22%] 00:16:20,000 → 00:16:25,440  所以你可能打的比較算是中間的族群,是嗎?\n",
            "[ 22%] 00:16:25,440 → 00:16:27,240  算是。\n",
            "[ 22%] 00:16:27,240 → 00:16:28,240  喔。\n",
            "[ 22%] 00:16:34,900 → 00:16:40,000  我會去做這個學習策略的這個地方其實是想說你...\n",
            "[ 22%] 00:16:40,000 → 00:16:48,220  你如果在傳達你的想法跟知識的時候,能夠不要做任何的刪減,\n",
            "[ 23%] 00:16:49,040 → 00:16:58,500  而是你就把最難的東西端出來給學生,可是呢,你還是可以面對初級跟總級的學生,\n",
            "[ 23%] 00:16:58,500 → 00:17:00,500  但是你的...\n",
            "[ 23%] 00:17:00,000 → 00:17:20,120  實施卻是最難的,那這中間的那個gap,中間的那個就是轟溝,你就要透過這些學習方式跟記憶策略的引導,就是如果你的觀念越難,你中間就要解釋越多這樣子的學習策略,然後讓這些重等到初級的學生,\n",
            "[ 23%] 00:17:20,000 → 00:17:22,000  學生也能夠學起來\n",
            "[ 23%] 00:17:22,000 → 00:17:26,000  我當初設計就有這樣的想法\n",
            "[ 23%] 00:17:26,000 → 00:17:36,000  所以我就先把全部東西都最難的部分也寫出來\n",
            "[ 23%] 00:17:36,000 → 00:17:40,000  然後我想往後面再做一個\n",
            "[ 24%] 00:17:40,000 → 00:17:58,260  比較重點的整理,這樣,就是如果你對前面的深入學習沒有興趣的話,那你就直接看重點就好了,這樣應該比較好,就是兩邊都照顧到,也可以,又或者是說你其實也可以,\n",
            "[ 24%] 00:18:00,000 → 00:18:01,840  這點我可能還是會存疑啦\n",
            "[ 24%] 00:18:01,840 → 00:18:03,760  我其實也沒有很確定\n",
            "[ 24%] 00:18:03,760 → 00:18:07,900  就是因為我自己的作文書也是寫到最難\n",
            "[ 24%] 00:18:07,900 → 00:18:10,800  確實也是有學生會覺得太難\n",
            "[ 24%] 00:18:10,800 → 00:18:14,840  但我會傾向是說如果你能夠用這些\n",
            "[ 24%] 00:18:14,840 → 00:18:17,460  就是我有給你一個檔案\n",
            "[ 24%] 00:18:17,460 → 00:18:20,000  就是在這個頁面裡面還有一個連接\n",
            "[ 24%] 00:18:20,000 → 00:18:23,000  我有一個可以出去的檔案叫核心學習策略\n",
            "[ 24%] 00:18:23,000 → 00:18:25,000  你有看過這個嗎?一個\n",
            "[ 25%] 00:18:25,000 → 00:18:28,000  對對對對現在有打開了這個\n",
            "[ 25%] 00:18:28,000 → 00:18:33,000  就是你就可以把一些這裡面的讀書策略跟技巧\n",
            "[ 25%] 00:18:37,000 → 00:18:39,000  這個檔案我還沒看過\n",
            "[ 25%] 00:18:40,000 → 00:18:43,000  你可以先把它看一下。\n",
            "[ 25%] 00:18:43,000 → 00:18:54,000  我自己教學的經驗是讓我發現說這些策略它其實不是只用在英文。\n",
            "[ 25%] 00:18:54,000 → 00:18:59,000  我昨天也是用這個東西去跟學生講數學什麼學。\n",
            "[ 25%] 00:19:00,000 → 00:19:07,000  我想說這東西其實可以一定程度幫助學生理解一些太複雜或太困難的觀念。\n",
            "[ 26%] 00:19:07,000 → 00:19:16,000  然後我就會覺得你跟他解釋越多這些學習策略,他們可能就會越能夠理解你想要傳達的物理專業知識。\n",
            "[ 26%] 00:19:16,000 → 00:19:20,000  所以就是取決於你想要寫多難的東西,然後就加多少。\n",
            "[ 26%] 00:19:20,000 → 00:19:25,000  好,講完嘅。\n",
            "[ 26%] 00:19:25,000 → 00:19:29,000  威神那邊有問題嗎?\n",
            "[ 26%] 00:19:29,000 → 00:19:31,000  暫時沒有。\n",
            "[ 26%] 00:19:31,000 → 00:19:35,000  到時候再麻煩你會後花一些時間幫我看過,\n",
            "[ 26%] 00:19:35,000 → 00:19:39,000  然後如果有不懂的地方可以再隨時跟我們講。\n",
            "[ 26%] 00:19:39,000 → 00:19:40,000  好。\n",
            "[ 26%] 00:19:40,000 → 00:19:45,100  再嚟嘅話就會系梳集咗一個大嘅架構,\n",
            "[ 26%] 00:19:45,100 → 00:19:51,880  佢就跟其實就跟你現在嗰個章節都系很像,\n",
            "[ 26%] 00:19:52,160 → 00:19:55,420  但就系我哋嘅章節架構可能要再清楚明確一點,\n",
            "[ 27%] 00:19:57,760 → 00:19:59,960  然後像呢些可能\n",
            "[ 27%] 00:20:00,000 → 00:20:07,000  你可以先幫我列完,然後如果你需要一些圖示的話,這些我們都可以直接再幫你做。\n",
            "[ 27%] 00:20:11,000 → 00:20:20,000  所以大致上那個架構的話就會是講,就是可能這本書的蓋欄,然後跟這本書的使用說明,然後第一個的大張點。\n",
            "[ 27%] 00:20:20,000 → 00:20:39,000  第二個大章節,然後可能你大章節完之後你會有一個小的,你會先有一個小的總結,然後你的小章節一樣會有一個小的總結,然後才會是這個小章節裡面的氣象,然後最後你還是需要再幫他附一個總結,這樣會是一個比較完整的架構,然後也比較能幫助學生達到一個比較好的學習方式。\n",
            "[ 27%] 00:20:40,000 → 00:20:42,000  所以書籍加關可以參考這邊\n",
            "[ 28%] 00:20:42,000 → 00:20:44,000  好 子明起說\n",
            "[ 28%] 00:20:44,000 → 00:20:46,000  我喔 我又有話要說了\n",
            "[ 28%] 00:20:46,000 → 00:20:48,000  就是你除了\n",
            "[ 28%] 00:20:48,000 → 00:20:50,000  我要說什麼\n",
            "[ 28%] 00:20:50,000 → 00:20:52,000  你的大架構裡面\n",
            "[ 28%] 00:20:52,000 → 00:20:54,000  其實可以多加入一些些\n",
            "[ 28%] 00:20:54,000 → 00:20:56,000  就是比較感性一點的東西\n",
            "[ 28%] 00:20:56,000 → 00:20:58,000  就是你在書籍的可能\n",
            "[ 28%] 00:20:58,000 → 00:21:00,000  在那個章節的開頭\n",
            "[ 28%] 00:21:00,000 → 00:21:03,400  會需要先有一個簡單的總結或是一個概覽\n",
            "[ 28%] 00:21:03,400 → 00:21:05,100  然後讓學生可以進入這個章節\n",
            "[ 28%] 00:21:05,100 → 00:21:07,560  那章節的最後結束也會有一個總結\n",
            "[ 28%] 00:21:07,560 → 00:21:10,480  只是你的那個開始跟那個總結\n",
            "[ 28%] 00:21:10,480 → 00:21:13,220  就是不一定要是很理性\n",
            "[ 28%] 00:21:13,220 → 00:21:18,420  然後很踏實的那種知識上面的整理\n",
            "[ 28%] 00:21:18,420 → 00:21:19,980  你也可以在這邊加一些\n",
            "[ 28%] 00:21:20,000 → 00:21:22,500  讓學生可以心情好一點的東西\n",
            "[ 28%] 00:21:22,500 → 00:21:24,500  譬如說剛開始就是\n",
            "[ 28%] 00:21:24,500 → 00:21:26,500  在章節開始的時候就說\n",
            "[ 29%] 00:21:26,500 → 00:21:29,500  這張適合有哪一些問題的學生\n",
            "[ 29%] 00:21:29,500 → 00:21:31,500  然後就列很多學生常見的問題\n",
            "[ 29%] 00:21:31,500 → 00:21:34,500  那學生可能就會自己跳進去對號入座\n",
            "[ 29%] 00:21:34,500 → 00:21:36,500  就領了一個身份標籤之後\n",
            "[ 29%] 00:21:36,500 → 00:21:38,000  就開始讀這個章節的時候\n",
            "[ 29%] 00:21:38,000 → 00:21:40,000  就會覺得自己的\n",
            "[ 29%] 00:21:40,000 → 00:21:42,000  問題就可以被妥善的解決\n",
            "[ 29%] 00:21:42,000 → 00:21:44,000  然後你到總結的地方再跟他說\n",
            "[ 29%] 00:21:44,000 → 00:21:48,000  恭喜你就是已經解決了這樣子的問題\n",
            "[ 29%] 00:21:48,000 → 00:21:50,000  你一定會越來越好啊什麼的\n",
            "[ 29%] 00:21:50,000 → 00:21:52,000  就可以給一些情緒上面的\n",
            "[ 29%] 00:21:52,000 → 00:21:53,000  給一些情緒價值\n",
            "[ 29%] 00:21:53,000 → 00:21:55,000  學生讀起來會比較\n",
            "[ 29%] 00:21:55,000 → 00:21:57,000  算是堅持得下去吧\n",
            "[ 29%] 00:21:57,000 → 00:22:00,000  如果你會把內容加得深入一點點的話\n",
            "[ 29%] 00:22:00,000 → 00:22:02,000  還有腳外的\n",
            "[ 29%] 00:22:02,000 → 00:22:04,000  咚\n",
            "[ 29%] 00:22:04,000 → 00:22:06,000  好\n",
            "[ 29%] 00:22:06,000 → 00:22:08,000  再來的話就是說幾個小架構\n",
            "[ 29%] 00:22:08,000 → 00:22:10,000  那個小架構就是偏\n",
            "[ 29%] 00:22:10,000 → 00:22:12,000  理論跟案例\n",
            "[ 30%] 00:22:12,000 → 00:22:14,000  這個的話前面其實也有提到\n",
            "[ 30%] 00:22:14,000 → 00:22:16,000  然後這個你可以\n",
            "[ 30%] 00:22:16,000 → 00:22:18,000  如果你沒有很懂的話可以再問我\n",
            "[ 30%] 00:22:18,000 → 00:22:20,000  然後\n",
            "[ 30%] 00:22:20,000 → 00:22:25,000  理論的主要呈現原則就是你要以系統性的東西去取代流水帳\n",
            "[ 30%] 00:22:25,000 → 00:22:30,000  就是系統性就比較像是可能第一步第二步然後原則一原則二原則三\n",
            "[ 30%] 00:22:30,000 → 00:22:34,000  然後或者是你可以用一個表格呈現可以用流程圖可以用矩陣都可以\n",
            "[ 30%] 00:22:34,000 → 00:22:40,000  然後這種方式會比起你只是跟他講說我今天去買了蘋果\n",
            "[ 30%] 00:22:40,000 → 00:22:44,500  如果怎麼樣怎麼樣,這種流水的方式好很多很多很多。\n",
            "[ 30%] 00:22:44,500 → 00:22:46,500  然後再來是案例的呈現原則。\n",
            "[ 30%] 00:22:46,500 → 00:22:50,800  你要盡量讓,就是用故事的方式去讓理論去落地。\n",
            "[ 30%] 00:22:50,800 → 00:22:56,000  就是你可以去多講幾個例子,然後但是你不能只是單純的講例子。\n",
            "[ 31%] 00:22:56,000 → 00:23:00,000  你要去刻意的選擇可以提出這些理論的關鍵點的案例。\n",
            "[ 31%] 00:23:00,000 → 00:23:03,820  然後讓案例的順序跟理論的分點是一致的\n",
            "[ 31%] 00:23:03,820 → 00:23:05,620  就是學生他可以互相對照\n",
            "[ 31%] 00:23:05,620 → 00:23:07,800  他不會覺得我現在看了這個理論\n",
            "[ 31%] 00:23:07,800 → 00:23:09,500  但是我找不到對應的案例\n",
            "[ 31%] 00:23:09,500 → 00:23:10,720  或者是我現在看了這個案例\n",
            "[ 31%] 00:23:10,720 → 00:23:12,820  但我也不知道你在講哪一個理論這樣子\n",
            "[ 31%] 00:23:12,820 → 00:23:15,740  目前這邊是OK的\n",
            "[ 31%] 00:23:15,740 → 00:23:16,920  OK\n",
            "[ 31%] 00:23:16,920 → 00:23:17,980  好\n",
            "[ 31%] 00:23:17,980 → 00:23:20,020  然後因為我們收集的內容\n",
            "[ 31%] 00:23:20,000 → 00:23:22,260  我们会以黑白色为主\n",
            "[ 31%] 00:23:22,260 → 00:23:25,540  所以如果你今天在帮我写里面的内容\n",
            "[ 31%] 00:23:25,540 → 00:23:28,920  然后有些比较想要让他们强调的重点\n",
            "[ 31%] 00:23:28,920 → 00:23:31,640  你可能需要帮我使用色块或是粗体\n",
            "[ 31%] 00:23:31,640 → 00:23:34,860  或是一些其他的框框标记都可以\n",
            "[ 31%] 00:23:34,860 → 00:23:37,840  但是你需要有一个让他们可以很好get到说\n",
            "[ 31%] 00:23:37,840 → 00:23:39,980  这里可能是相对于其他内容性\n",
            "[ 31%] 00:23:40,000 → 00:23:42,000  較為重要的地方\n",
            "[ 32%] 00:23:44,000 → 00:23:45,000  好\n",
            "[ 32%] 00:23:45,000 → 00:23:48,000  然後下面你應該也都有看過\n",
            "[ 32%] 00:23:48,000 → 00:23:50,000  那你有什麼地方有不了解\n",
            "[ 32%] 00:23:50,000 → 00:23:52,000  然後有想問的嗎\n",
            "[ 32%] 00:23:56,000 → 00:23:58,000  看起來沒有\n",
            "[ 32%] 00:23:58,000 → 00:23:59,000  好\n",
            "[ 32%] 00:23:59,000 → 00:24:00,000  線上話\n",
            "[ 32%] 00:24:00,000 → 00:24:01,200  與配套工具\n",
            "[ 32%] 00:24:01,200 → 00:24:05,040  啊沒事\n",
            "[ 32%] 00:24:05,040 → 00:24:05,720  在下面\n",
            "[ 32%] 00:24:05,720 → 00:24:08,000  對不起我插嘴了\n",
            "[ 32%] 00:24:08,000 → 00:24:08,420  對不起\n",
            "[ 32%] 00:24:08,420 → 00:24:10,940  好然後順便跟維成提\n",
            "[ 32%] 00:24:10,940 → 00:24:13,260  就是因為我知道你有做那個\n",
            "[ 32%] 00:24:13,260 → 00:24:14,180  就是\n",
            "[ 32%] 00:24:14,180 → 00:24:16,440  立貼題目\n",
            "[ 32%] 00:24:16,440 → 00:24:16,840  然後\n",
            "[ 32%] 00:24:16,840 → 00:24:18,660  就是他如果\n",
            "[ 32%] 00:24:18,660 → 00:24:20,000  如果你今天還是要把他寫在\n",
            "[ 32%] 00:24:20,000 → 00:24:27,180  你在書裡面或是你今天在書本裡面有提到,然後你不知道怎麼拍板的話,就是知名右相有一個是比較好的方式。\n",
            "[ 33%] 00:24:27,180 → 00:24:40,000  如果你今天想要讓學生,他是可以先看完題目,然後先有一個答案,然後再繼續看詳解的話,你可以變成說第一頁他有三題的題目,然後你翻頁之後是那三題的講解。\n",
            "[ 33%] 00:24:40,000 → 00:25:00,000  然後就稍微對一下拍板,才不會讓他們馬上就可以找到答案,然後也沒有,就如果直接讓他們看到答案,他們就會不去思考,所以你可以先讓他們思考完之後,然後再去翻譯了,去對照那個答案,然後去看你的想解步都是什麼,然後這樣子,一方面是它有一個比較好的拍板格式,另外一方面是可以主動去引導他們去思考。\n",
            "[ 33%] 00:25:00,000 → 00:25:02,940  而不是直接仰賴你的解答\n",
            "[ 33%] 00:25:02,940 → 00:25:04,940  OK\n",
            "[ 33%] 00:25:04,940 → 00:25:05,500  OK\n",
            "[ 33%] 00:25:05,500 → 00:25:09,540  但是上次不是說那個解答要用呈現上嗎\n",
            "[ 33%] 00:25:09,540 → 00:25:11,680  不然頁數就已經爆了\n",
            "[ 33%] 00:25:11,680 → 00:25:12,540  對\n",
            "[ 34%] 00:25:12,540 → 00:25:15,040  就只是如果你今天有在內容裡面\n",
            "[ 34%] 00:25:15,040 → 00:25:16,620  有稍微稍稍的提到\n",
            "[ 34%] 00:25:16,620 → 00:25:19,260  就是你可以有一兩題或是三四題的話\n",
            "[ 34%] 00:25:19,260 → 00:25:19,960  是可以用這樣的\n",
            "[ 34%] 00:25:20,000 → 00:25:39,940  然後關於題目答案線上話這個點,我們需要,好我先跟你抓出來討論這個點好了,因為我們有收到學生的回饋是說他們的父母其實沒有很希望讓他們嘗試這樣用平板手機或是電腦,所以關於\n",
            "[ 35%] 00:25:40,000 → 00:25:59,960  解答線上話這一點,我們可能需要再思考一下,因為不是所有的學生都可以達到很好的學習效果,也不是所有的學生都可以這樣做自由,所以我們需要想一個解決方法,讓他們不是只能完全的仰賴這個AI工具,而是AI工具會變成是輔助他們的學習效果,而不是讓他們去\n",
            "[ 35%] 00:26:00,000 → 00:26:02,000  從AI工具中\n",
            "[ 35%] 00:26:02,000 → 00:26:04,000  就他們不能只是用AI工具找到答案\n",
            "[ 35%] 00:26:04,000 → 00:26:06,000  他們應該要從其他地方也可以找到答案\n",
            "[ 35%] 00:26:06,000 → 00:26:08,000  AI工具只是一個輔助\n",
            "[ 35%] 00:26:08,000 → 00:26:10,000  所以我們可能要先解決這個\n",
            "[ 35%] 00:26:10,000 → 00:26:12,000  點\n",
            "[ 35%] 00:26:16,000 → 00:26:18,000  然後我自己有稍微想了一下\n",
            "[ 35%] 00:26:18,000 → 00:26:20,000  如果說你今天是\n",
            "[ 35%] 00:26:20,000 → 00:26:40,000  因為如果有太多業績的話,其實它是可以用一個比較簡略版的複測,就是它反正只是西馬丁,然後完完全全就是黑白印刷,那他們的題目跟解析是可以分開來的,然後當然對於印刷成本也不會跟原本一樣那麼高,然後學生也不會說如果我今天不能用手機,要不能用手機,\n",
            "[ 35%] 00:26:40,000 → 00:26:42,700  我就完全沒有辦法找到這題的答案\n",
            "[ 36%] 00:26:42,700 → 00:26:45,780  或是我也沒辦法找到這題的相接是什麼東西\n",
            "[ 36%] 00:26:45,780 → 00:26:46,640  對\n",
            "[ 36%] 00:26:46,640 → 00:26:50,020  所以想順便問問看你那邊有任何的想法嗎\n",
            "[ 36%] 00:26:50,020 → 00:26:54,780  所以\n",
            "[ 36%] 00:26:54,780 → 00:26:55,780  嗯\n",
            "[ 36%] 00:26:55,780 → 00:26:59,920  就是解答還是要包含在\n",
            "[ 36%] 00:27:00,000 → 00:27:04,000  裡面,就是包含在整份裡面嘛\n",
            "[ 36%] 00:27:04,000 → 00:27:08,900  這樣頁數不是還是一樣,只是超出\n",
            "[ 36%] 00:27:08,900 → 00:27:13,740  就會變成是以主側跟副側的方式去呈現\n",
            "[ 36%] 00:27:13,740 → 00:27:16,580  那副側的話我們的印刷品質就會是比較\n",
            "[ 36%] 00:27:16,580 → 00:27:19,260  沒有到跟主側一樣那麼好的\n",
            "[ 36%] 00:27:19,260 → 00:27:19,960  那它的印刷\n",
            "[ 36%] 00:27:20,000 → 00:27:25,000  雖然說會增加,但是不會像原本高的那麼誇張。\n",
            "[ 37%] 00:27:28,000 → 00:27:30,000  或者是有如果...\n",
            "[ 37%] 00:27:30,000 → 00:27:31,000  請說。\n",
            "[ 37%] 00:27:31,000 → 00:27:35,000  我想題目分享解葉樹很多耶,比較不像作文那樣子。\n",
            "[ 37%] 00:27:35,000 → 00:27:38,000  只有少少的就是葉。\n",
            "[ 37%] 00:27:40,000 → 00:27:53,000  因為它如果現在是要寫成題目一頁相接一頁,或是一頁三個題目,然後相接三頁的話,那個頁數應該都會比作文還要多很多。\n",
            "[ 37%] 00:28:00,000 → 00:28:05,360  但我哋冇辦法完全就把佢現場化\n",
            "[ 37%] 00:28:05,360 → 00:28:11,900  因為學生也確實冇辦法讓佢哋有個好的學習方式\n",
            "[ 38%] 00:28:11,900 → 00:28:17,060  那我哋現在壓業數是因為硬抓成本跟定價嗎?\n",
            "[ 38%] 00:28:17,060 → 00:28:20,000  就是說我哋定價如果就是要定在\n",
            "[ 38%] 00:28:20,000 → 00:28:26,000  500塊以內,業數就是不可以到300,350到400\n",
            "[ 38%] 00:28:26,000 → 00:28:27,000  對\n",
            "[ 38%] 00:28:31,000 → 00:28:34,000  你如果今天要到,就是真的業數要到三四百\n",
            "[ 38%] 00:28:34,000 → 00:28:38,000  其實是,就是沒有什麼關係啦\n",
            "[ 38%] 00:28:38,000 → 00:28:40,000  但是一方面\n",
            "[ 38%] 00:28:40,000 → 00:28:45,020  因為成本很高,所以我們分下來的利潤可能覺得是不多的。\n",
            "[ 38%] 00:28:45,020 → 00:28:58,020  第二方面是,如果我們今天是推一個他可以很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:28:58,020 → 00:29:09,980  然後這就會延伸到,如果我們今天是推一個很快速學習的獎益,但是我們給他的業數卻是很多很多,我自己會覺得學生是沒有那麼多耐心可以把他認真地看完。\n",
            "[ 39%] 00:29:00,000 → 00:29:20,000  如果我們今天把排板放大,如果以A4尺寸去製作的話,A4它很吃排板功力,所以如果說你今天有任何一個排板點沒有排板好,或者是你的圖示效果不是那麼好的話,其實對於學生的學習狀況也不是到很良好。\n",
            "[ 39%] 00:29:20,000 → 00:29:22,000  如果你今天是一頁密密麻麻的文字\n",
            "[ 39%] 00:29:22,000 → 00:29:24,000  他們可能看到一半也不會想看\n",
            "[ 39%] 00:29:24,000 → 00:29:26,000  所以對於他們學習長相之後\n",
            "[ 39%] 00:29:26,000 → 00:29:28,000  不是那麼的佳\n",
            "[ 39%] 00:29:28,000 → 00:29:31,000  所以這個點我們可能要稍微想一下\n",
            "[ 39%] 00:29:31,000 → 00:29:33,000  我們去解決\n",
            "[ 39%] 00:29:35,000 → 00:29:40,000  以前如果你說學生有些會不想要用電子廠\n",
            "[ 40%] 00:29:40,000 → 00:29:46,000  那就代表之前說想借跟題目要做成線上資料庫\n",
            "[ 40%] 00:29:46,000 → 00:29:48,000  這個就等於是不可行的\n",
            "[ 40%] 00:29:48,000 → 00:29:51,000  對,會變成說如果真的要做的話\n",
            "[ 40%] 00:29:51,000 → 00:29:55,000  它更像是一個我給你一個更好的輔助工具\n",
            "[ 40%] 00:29:55,000 → 00:29:56,000  然後你如果今天想要\n",
            "[ 40%] 00:29:56,000 → 00:29:58,000  就你如果今天書籍沒有帶在身上的話\n",
            "[ 40%] 00:29:58,000 → 00:30:00,000  你也可以有一個\n",
            "[ 40%] 00:30:00,000 → 00:30:02,000  可以學習的地方\n",
            "[ 40%] 00:30:02,000 → 00:30:04,000  但現在問題點就是\n",
            "[ 40%] 00:30:04,000 → 00:30:06,000  很多家長他不願意讓學生\n",
            "[ 40%] 00:30:06,000 → 00:30:08,000  這樣去做\n",
            "[ 40%] 00:30:08,000 → 00:30:10,000  那如果\n",
            "[ 40%] 00:30:10,000 → 00:30:12,000  我們今天變成是\n",
            "[ 40%] 00:30:12,000 → 00:30:14,000  把題目跟\n",
            "[ 40%] 00:30:14,000 → 00:30:16,000  相借獨立成一本\n",
            "[ 40%] 00:30:16,000 → 00:30:18,000  複冊 然後\n",
            "[ 40%] 00:30:18,000 → 00:30:20,000  這本複冊的話\n",
            "[ 41%] 00:30:20,000 → 00:30:39,000  如果是買這本物理書,我們就會只給電子檔的複測,就是複測是用電子檔去給,然後他們可以自己印,又或是我們可以,他可以再加購,然後我們再把它印。\n",
            "[ 41%] 00:30:40,000 → 00:30:44,200  我覺得可能會以他們架構然後我們幫他印的方式\n",
            "[ 41%] 00:30:44,200 → 00:30:48,700  然後主要的話就是會印出的地方出去\n",
            "[ 41%] 00:30:48,700 → 00:30:53,000  不然我們成本一方面會拉高\n",
            "[ 41%] 00:30:53,000 → 00:30:57,900  另外一方面是他們好像不太擅長自己去印書\n",
            "[ 42%] 00:31:00,000 → 00:31:17,000  Ok,所以會需要麻煩維城,他可能還是要幫我把題目跟相機的都一樣有,就是可以有資本化的方式,就是你需要幫我拆開來寫,因為我們到時候會是以兩本書的形式推出去。\n",
            "[ 42%] 00:31:20,000 → 00:31:22,000  好,我可以提一個點嗎?\n",
            "[ 42%] 00:31:22,000 → 00:31:23,000  嗯。\n",
            "[ 42%] 00:31:23,000 → 00:31:36,000  就是微塵你可能現階段在做題目跟詳解的時候,你可能不要直接把它寫到 Word 檔,就是不要直接寫到你最後要出版的那個書上面。\n",
            "[ 42%] 00:31:36,000 → 00:31:40,000  而是你先用一個第三方的\n",
            "[ 42%] 00:31:40,000 → 00:31:43,000  另外一個的編輯的平台\n",
            "[ 42%] 00:31:43,000 → 00:31:47,000  你可能就先做在Notion上面\n",
            "[ 42%] 00:31:47,000 → 00:31:51,000  然後你把這些題目跟小節都做在Notion上面的時候\n",
            "[ 42%] 00:31:51,000 → 00:31:56,000  你一方面就是確保了我們剛剛講到的一個點是說\n",
            "[ 43%] 00:31:56,000 → 00:32:00,000  我們實體的東西要讓學生光看實體就看得懂\n",
            "[ 43%] 00:32:00,000 → 00:32:03,240  但是我們還是可以提供線上的輔助\n",
            "[ 43%] 00:32:03,240 → 00:32:06,340  這樣如果他們可能沒有帶到輔助\n",
            "[ 43%] 00:32:06,340 → 00:32:08,240  或是出了哪些狀況\n",
            "[ 43%] 00:32:08,240 → 00:32:10,340  或是他們想要用電子的方式去學\n",
            "[ 43%] 00:32:10,340 → 00:32:12,540  他們還是可以用電子的方式去做\n",
            "[ 43%] 00:32:12,540 → 00:32:14,840  所以就會變成說\n",
            "[ 43%] 00:32:14,840 → 00:32:17,000  利益\n",
            "[ 43%] 00:32:17,000 → 00:32:20,000  玉千你可不可以幫我開那個\n",
            "[ 43%] 00:32:20,000 → 00:32:25,000  英文共筆 英文選擇的那個檔案\n",
            "[ 43%] 00:32:25,000 → 00:32:27,000  對對對對\n",
            "[ 43%] 00:32:27,000 → 00:32:29,000  就是像現在的這個畫面\n",
            "[ 43%] 00:32:29,000 → 00:32:31,000  它就是一個英文的\n",
            "[ 43%] 00:32:31,000 → 00:32:33,000  英文選擇題的講義裡面的\n",
            "[ 43%] 00:32:33,000 → 00:32:36,000  線上的一個資料庫\n",
            "[ 43%] 00:32:36,000 → 00:32:39,000  你在寫你的那個題目跟詳解的時候\n",
            "[ 43%] 00:32:39,000 → 00:32:40,000  就建議你可以\n",
            "[ 44%] 00:32:40,000 → 00:33:00,000  寫在線上,然後就是在線上是一個已經有整理過的,有系統化的一個地方,然後這一個連結就可以直接分享給學生,然後學生就會有更多的自由度可以去在實體和電子上面同時的閱讀,就他們讀電子也得讀得懂,然後讀實體\n",
            "[ 44%] 00:33:00,000 → 00:33:11,060  你可以讀得懂,那你再把這個現在資料庫上面的東西再轉成實際書的排版跟內容就可以了,你這樣能聽得懂嗎?\n",
            "[ 44%] 00:33:13,860 → 00:33:19,940  我就是,因為我現在是把它拆在\n",
            "[ 44%] 00:33:20,000 → 00:33:29,000  因為我拿其他檔案,我的檔案,所以我之後寫完的話我再把它弄到 Notion上面。\n",
            "[ 45%] 00:33:29,000 → 00:33:31,000  這樣可以吧。\n",
            "[ 45%] 00:33:31,000 → 00:33:36,000  我覺得這樣應該會好一點,因為你我的檔不是會比較零散嗎?\n",
            "[ 45%] 00:33:40,000 → 00:33:44,000  欸可是notion上面就不能做那個公司那些咧?\n",
            "[ 45%] 00:33:46,000 → 00:33:48,000  Notion上可以做公司的\n",
            "[ 45%] 00:33:48,000 → 00:33:49,000  喔真的喔?\n",
            "[ 45%] 00:33:49,000 → 00:33:51,000  用Datex寫\n",
            "[ 45%] 00:33:53,000 → 00:33:55,000  你搜尋LATEX\n",
            "[ 45%] 00:34:00,000 → 00:34:02,000  等下等下等下\n",
            "[ 45%] 00:34:05,200 → 00:34:07,200  它是一個特定的滴刷\n",
            "[ 46%] 00:34:14,560 → 00:34:16,560  上面那個\n",
            "[ 46%] 00:34:20,000 → 00:34:30,340  就變成翅方,然後就要打一個固定的,就是一個字串進去,它就會變成翅方。\n",
            "[ 46%] 00:34:30,340 → 00:34:33,400  對,對,差不多了。\n",
            "[ 46%] 00:34:33,400 → 00:34:36,500  沃德裡面的公司應該是可以轉成這種模式的。\n",
            "[ 46%] 00:34:40,000 → 00:34:48,000  好,如果這方面維生不太會用的話,可以再問我,或是直接問培鈞也可以。\n",
            "[ 46%] 00:34:48,000 → 00:34:54,000  或是你也可以就直接在 Word 檔上面編輯,但是你截圖截到 Notion。\n",
            "[ 46%] 00:34:54,000 → 00:34:55,000  對。\n",
            "[ 46%] 00:34:55,000 → 00:34:59,000  因為 Notion 會有這種資料庫,就會比 Word 還要清楚一點。\n",
            "[ 47%] 00:35:00,000 → 00:35:05,000  好,那我就先在我的上面寫好了。\n",
            "[ 47%] 00:35:05,000 → 00:35:09,000  好,沒有問題。\n",
            "[ 47%] 00:35:09,000 → 00:35:20,000  然後這個的話其實剛剛子明就講到,你可以寫一個很深很深的關鍵,但是你要想辦法也要教會可能不是成都的嗎?\n",
            "[ 47%] 00:35:20,000 → 00:35:20,720  好的學生\n",
            "[ 47%] 00:35:20,720 → 00:35:26,800  那這部分剛剛你在聽的時候有問題嗎\n",
            "[ 47%] 00:35:26,800 → 00:35:34,340  你是說線上化跟配套工具\n",
            "[ 47%] 00:35:34,340 → 00:35:34,900  對\n",
            "[ 47%] 00:35:34,900 → 00:35:38,620  就是我們剛剛\n",
            "[ 47%] 00:35:40,000 → 00:35:45,000  我想講到自信框架的地方還有學習方式跟記憶策略的選擇\n",
            "[ 48%] 00:35:45,000 → 00:35:49,000  前面全部嗎?\n",
            "[ 48%] 00:35:49,000 → 00:35:52,000  對,它其實就是一樣的東西\n",
            "[ 48%] 00:35:52,000 → 00:35:55,000  就是教學理念的話我們希望它是以不間隔的方式\n",
            "[ 48%] 00:35:55,000 → 00:36:00,000  就是你要是寫好寫滿但是你要需要用方式讓可能\n",
            "[ 48%] 00:36:00,000 → 00:36:06,080  我比較沒有程度那麼高的學生去理解一個比較深奧的觀念\n",
            "[ 48%] 00:36:06,080 → 00:36:16,500  然後如果延續到前面剛剛提到的說\n",
            "[ 48%] 00:36:16,500 → 00:36:18,380  你要怎麼樣有一個很深奧的觀念\n",
            "[ 48%] 00:36:18,380 → 00:36:20,000  但是你卻不是只針對聰明\n",
            "[ 48%] 00:36:20,000 → 00:36:25,000  你只要把這個東西插成一個很碎片化的東西可以呈現。\n",
            "[ 48%] 00:36:25,000 → 00:36:28,000  它可能是三到五個獨立然後可以理解的小單元。\n",
            "[ 49%] 00:36:28,000 → 00:36:33,000  就你小單元小單元小單元讓他們去吸收,他們就比較可以接受。\n",
            "[ 49%] 00:36:33,000 → 00:36:37,000  然後再來的話是你每個單元只要專注一個最核心核心的點就好。\n",
            "[ 49%] 00:36:37,000 → 00:36:40,000  然後你可以搭配一些立體跟一些互動練習。\n",
            "[ 49%] 00:36:40,000 → 00:36:54,000  另外就是你要把那個包裝把它簡化簡化得很簡單,就是你可以用可能比較生物化的方式去解釋,或者是你可以用剩下一些視覺化的工具。\n",
            "[ 49%] 00:36:54,000 → 00:37:00,000  對,然後再來的話就是視超化落地,就是你這樣每個觀念都可以搭配一個可以讓它\n",
            "[ 49%] 00:37:00,000 → 00:37:12,000  所以我剛才會提到說你可能一個章節裡面你可能會有二到三題的練習題,你就可以搭配到視察化落地的這個部分。\n",
            "[ 50%] 00:37:12,000 → 00:37:20,000  好,然後再來的話就是剛其實就有稍微提到配套工具。\n",
            "[ 50%] 00:37:20,000 → 00:37:24,600  這幾個是我們覺得也可以用在物理講義裡面的配套工具\n",
            "[ 50%] 00:37:24,600 → 00:37:26,600  第一個就是Notion的筆記模板\n",
            "[ 50%] 00:37:26,600 → 00:37:28,600  然後再來的話就是SharedGPC的機器人\n",
            "[ 50%] 00:37:28,600 → 00:37:31,900  這個的話會是就是你先跟他聊聊聊\n",
            "[ 50%] 00:37:31,900 → 00:37:33,500  然後聊到說有一定的格式\n",
            "[ 50%] 00:37:33,500 → 00:37:37,100  然後之後我們再去轉成我們自己寫的機器人\n",
            "[ 50%] 00:37:37,100 → 00:37:40,100  就會是可能當學生輸入哪一些提示詞\n",
            "[ 50%] 00:37:40,000 → 00:37:44,420  他可以按照我們一開始就規定好的格式 然後產出相對應的內容\n",
            "[ 50%] 00:37:44,420 → 00:37:46,400  然後再來是Notebook LN\n",
            "[ 50%] 00:37:46,400 → 00:37:52,320  Notebook LN的話會比較偏向是我們一開始就先把我們的講義就先都上傳好\n",
            "[ 50%] 00:37:52,320 → 00:37:54,400  然後讓他的觀念是完整清楚的\n",
            "[ 50%] 00:37:54,400 → 00:37:56,780  那當學生他有什麼問題想要問的時候\n",
            "[ 50%] 00:37:56,780 → 00:37:59,020  他可以直接上Notebook LN然後問一個問題\n",
            "[ 50%] 00:37:59,020 → 00:37:59,300  然後\n",
            "[ 51%] 00:38:00,000 → 00:38:04,000  機器人就會想把相對應講義的內容輸出給他\n",
            "[ 51%] 00:38:04,000 → 00:38:07,000  就是一個很即時的問答\n",
            "[ 51%] 00:38:07,000 → 00:38:11,000  然後再來的話就是剛剛有給你看過的那個共編檔案\n",
            "[ 51%] 00:38:11,000 → 00:38:13,000  物理也可以這樣子做\n",
            "[ 51%] 00:38:13,000 → 00:38:17,000  但是這個的話就會很仰賴說\n",
            "[ 51%] 00:38:17,000 → 00:38:20,000  如果今天學生真的有上來留言\n",
            "[ 51%] 00:38:20,000 → 00:38:40,000  然後問問題的話,我們會需要很,就是至少在一定的時間內就可以幫他解完這樣的問題,然後並把這樣的東西再重新整理成新的內容,然後放上來,所以那個沒有到這麼急迫,但是我們還是會希望未來可以。\n",
            "[ 51%] 00:38:40,000 → 00:38:41,000  做\n",
            "[ 51%] 00:38:41,000 → 00:38:45,740  然後再來就是Notion的問答會診區\n",
            "[ 52%] 00:38:45,740 → 00:38:47,520  這個的話會是\n",
            "[ 52%] 00:38:47,520 → 00:38:49,900  譬如說我們有在IG啊\n",
            "[ 52%] 00:38:49,900 → 00:38:51,940  或者是在LINE的社群裡面\n",
            "[ 52%] 00:38:51,940 → 00:38:54,760  如果有任何人提到物理檢驗裡面的問題\n",
            "[ 52%] 00:38:54,760 → 00:38:57,020  我們都可以把它統整起來\n",
            "[ 52%] 00:38:57,020 → 00:38:58,500  然後就是你回答完之後\n",
            "[ 52%] 00:38:58,500 → 00:38:59,580  我們再把它統整起來\n",
            "[ 52%] 00:38:59,580 → 00:39:00,000  然後之後\n",
            "[ 52%] 00:39:00,000 → 00:39:03,320  有遇到一样的问题的时候学生就可以直接上来这边看\n",
            "[ 52%] 00:39:03,320 → 00:39:09,040  好那以上现在有问题吗\n",
            "[ 52%] 00:39:09,040 → 00:39:12,440  刚刚有说到那个notebook\n",
            "[ 52%] 00:39:12,440 → 00:39:16,140  它是就是上次是说它提供上来\n",
            "[ 52%] 00:39:16,140 → 00:39:17,700  然后它就会呈现解答\n",
            "[ 52%] 00:39:17,700 → 00:39:19,800  所以它是一个\n",
            "[ 52%] 00:39:20,000 → 00:39:25,020  它是AI嗎?還是它只是單純的查找的工具?\n",
            "[ 52%] 00:39:25,640 → 00:39:27,920  還是它是會生內容的那種AI?\n",
            "[ 53%] 00:39:30,120 → 00:39:33,000  它是一個幫助你去...\n",
            "[ 53%] 00:39:33,000 → 00:39:37,760  它是會自己生內容嗎?\n",
            "[ 53%] 00:39:38,360 → 00:39:39,980  還是它是拿出...\n",
            "[ 53%] 00:39:40,000 → 00:39:59,220  他會自己按照你給他的觀念格式,還有你給他的內容,然後去升,他裡面知道既有的內容,所以他不會去延伸說那些其實你並沒有輸入給他的東西,因為像ShareGP的話,他就很有可能是輸出一些\n",
            "[ 53%] 00:40:00,000 → 00:40:02,300  並唔係嗰麼正確性嘅嘢\n",
            "[ 53%] 00:40:02,300 → 00:40:06,400  但係NOPLM 佢就係完全按照你輸入乜嘢給佢\n",
            "[ 53%] 00:40:06,400 → 00:40:09,100  佢就會輸出相對應嘅嘢給學生\n",
            "[ 53%] 00:40:09,100 → 00:40:12,400  所以佢能確保佢裡面輸出嘅嘢一定係完整嘅\n",
            "[ 53%] 00:40:12,400 → 00:40:13,400  而且係正確嘅\n",
            "[ 53%] 00:40:15,600 → 00:40:16,400  好\n",
            "[ 54%] 00:40:16,400 → 00:40:19,900  對 所以會需要你完成獎益跟一些\n",
            "[ 54%] 00:40:20,000 → 00:40:23,000  我们再喂进去给那部LA\n",
            "[ 54%] 00:40:23,000 → 00:40:26,080  那到时候再用好\n",
            "[ 54%] 00:40:26,080 → 00:40:27,220  因为我现在也不会用它\n",
            "[ 54%] 00:40:27,220 → 00:40:29,160  好没有问题\n",
            "[ 54%] 00:40:29,160 → 00:40:32,440  然后善用比喻的话\n",
            "[ 54%] 00:40:32,440 → 00:40:34,380  上面也有讲过\n",
            "[ 54%] 00:40:34,380 → 00:40:35,780  然后你自己也有稍微看过\n",
            "[ 54%] 00:40:35,780 → 00:40:38,260  那这部分你有问题想询问的吗\n",
            "[ 54%] 00:40:40,000 → 00:40:44,000  應該比較還好,這部分應該比較簡單。\n",
            "[ 54%] 00:40:44,000 → 00:40:48,000  OK,那關於立場切換的部分呢?\n",
            "[ 54%] 00:40:51,000 → 00:41:00,000  這個就是子明剛剛跟你講到說,如果你今天是一個蓋籃的時候,你可以不要那麼的過於理性,或是就是一些文綽綽的\n",
            "[ 55%] 00:41:00,000 → 00:41:11,000  你可以是給他們一個對號入座的感覺,或是給他們一個比較偏向感性上面的支持,或是一些情緒支持這樣子,這就是舉例。\n",
            "[ 55%] 00:41:11,000 → 00:41:20,000  然後這個的話也是用在作文上的一個小小的行銷手段,它就是讓學生自己去想他們有什麼想法。\n",
            "[ 55%] 00:41:20,000 → 00:41:24,500  然後我們引導牠去對號入座到你真的有這個症狀\n",
            "[ 55%] 00:41:24,500 → 00:41:26,180  然後其實你很需要這個書\n",
            "[ 55%] 00:41:26,180 → 00:41:29,280  就是物理也可以用這樣的方式呈現\n",
            "[ 55%] 00:41:29,280 → 00:41:35,160  然後下面這些你在看的時候你有任何的問題嗎\n",
            "[ 55%] 00:41:35,160 → 00:41:37,300  或是有不太懂的地方嗎\n",
            "[ 56%] 00:41:40,000 → 00:42:00,000  應該都還好,剛剛前面說要給他們一些標籤,讓他們對好入座,我現在是沒想到有什麼啦,我想問你們,在寫物理的時候。\n",
            "[ 56%] 00:42:00,000 → 00:42:01,240  會有什麼問題嗎?\n",
            "[ 56%] 00:42:01,240 → 00:42:03,500  還是平常沒有在寫物理?\n",
            "[ 56%] 00:42:06,840 → 00:42:07,800  我有寫過\n",
            "[ 56%] 00:42:09,000 → 00:42:10,160  那你有什麼問題嗎?\n",
            "[ 56%] 00:42:11,540 → 00:42:12,660  我覺得從\n",
            "[ 56%] 00:42:13,660 → 00:42:16,560  如果是緯程那邊要整理這些問題的話\n",
            "[ 56%] 00:42:16,560 → 00:42:17,800  我反而會覺得\n",
            "[ 56%] 00:42:18,500 → 00:42:19,960  育謙那邊可能可以看\n",
            "[ 57%] 00:42:20,000 → 00:42:38,000  開一個物理的問答,限動的問答,然後藉由這樣子蒐集問題去知道學生的症節點在哪邊,然後就把那些問題全部灌到 CheckGPT,然後請CheckGPT整理學生有哪些類型,這樣應該就很快就可以找到那些問題。\n",
            "[ 57%] 00:42:38,000 → 00:42:40,000  但是問完那些問題之後……\n",
            "[ 57%] 00:42:40,000 → 00:42:47,000  可能未曾要幫忙簡單回答一下 因為育成可能沒辦法自己去回答物理的專業問題\n",
            "[ 57%] 00:42:47,000 → 00:42:52,000  被問問了但是沒有打算回答 這樣過分\n",
            "[ 57%] 00:42:52,000 → 00:43:00,000  我想舉一個例子就是我覺得我自己寫物理最大的祕訣是腦中藥\n",
            "[ 58%] 00:43:00,000 → 00:43:20,000  老公要有畫面,老公要有那個東西在跑的畫面,所以就可以把它當成是一個技巧,比如說看的那些物理的公式,看的那些數字,它沒有感覺怎麼樣,就可以去提。\n",
            "[ 58%] 00:43:20,000 → 00:43:28,000  提供他一些,譬如說像我剛剛講的那種讓自己比較有感覺的技巧這樣\n",
            "[ 58%] 00:43:28,000 → 00:43:30,000  類似這種方向\n",
            "[ 58%] 00:43:32,000 → 00:43:37,000  我有想過就是腦中要有畫面這件事情\n",
            "[ 58%] 00:43:37,000 → 00:43:40,000  但我後來發現就是好像不是每個人都可以做\n",
            "[ 58%] 00:43:40,000 → 00:43:44,000  就有些人特別沒有想像力\n",
            "[ 58%] 00:43:44,000 → 00:43:48,000  我要想一下就是要給我給他這個想像力\n",
            "[ 58%] 00:43:48,000 → 00:43:50,000  你要引導他去構思\n",
            "[ 58%] 00:43:50,000 → 00:43:52,000  對引導他去構思這個想像力\n",
            "[ 58%] 00:43:52,000 → 00:44:00,000  或是你也可以找一些線上的視覺化\n",
            "[ 59%] 00:44:00,000 → 00:44:04,000  現在有一些線上的物理方面的視覺化的工具\n",
            "[ 59%] 00:44:04,000 → 00:44:07,000  也可以引導他們去使用這些工具\n",
            "[ 59%] 00:44:07,000 → 00:44:10,000  然後自己去拉拉看那個訊息之類的\n",
            "[ 59%] 00:44:12,000 → 00:44:14,000  我可以稍微跟你提一個\n",
            "[ 59%] 00:44:14,000 → 00:44:17,000  可能比較像是聯想或者一個小技巧\n",
            "[ 59%] 00:44:17,000 → 00:44:20,000  像英文作文裡那個字名它就會\n",
            "[ 59%] 00:44:20,000 → 00:44:23,660  用break pin去講一些公式跟觀念\n",
            "[ 59%] 00:44:23,660 → 00:44:28,960  讓學生他們的想像畫面是以他們熟悉的東西去帶入\n",
            "[ 59%] 00:44:28,960 → 00:44:32,860  那他們就會比較好聯想到你要跟他們講什麼\n",
            "[ 59%] 00:44:32,860 → 00:44:38,020  然後當他們真的對於那個畫面沒有太大的感受的時候\n",
            "[ 59%] 00:44:38,020 → 00:44:39,900  他們也可以因為這個東西是他們比較\n",
            "[ 59%] 00:44:40,000 → 00:44:42,400  日常生活化就有在接觸的東西。\n",
            "[ 59%] 00:44:42,400 → 00:44:45,200  所以進而聯想到那個很抽象的畫面。\n",
            "[ 60%] 00:44:47,200 → 00:44:49,100  這就會是我們剛剛上面有講到的,\n",
            "[ 60%] 00:44:49,100 → 00:44:51,700  就是你可能要再多運用一些生活化\n",
            "[ 60%] 00:44:51,700 → 00:44:55,300  或是很日常的東西去做比喻,\n",
            "[ 60%] 00:44:55,300 → 00:44:57,100  然後去做例子的講解。\n",
            "[ 60%] 00:45:00,000 → 00:45:09,300  好,然後再來的話,學生需要會有一個固定的,固定默契的emoji,\n",
            "[ 60%] 00:45:09,460 → 00:45:13,680  因為它會是讓學生知道,我今天看到這個圖示的時候,\n",
            "[ 60%] 00:45:13,900 → 00:45:18,000  我就是接下來會看到什麼樣的內容,讓他們有一個小小的概念點。\n",
            "[ 61%] 00:45:20,000 → 00:45:40,000  但是如果以英文中文來講的話,這個東西就會是對應到總結的重點,然後小燈泡的話就會是一個口訣或是一個記憶法,然後如果你今天是一個手加一個筆的話,那就是你的動手練習,就是你可以稍微去幫他設計一個固定的符號,讓他們有一個小概念,他們才不會覺得...\n",
            "[ 61%] 00:45:40,000 → 00:45:44,000  看起來很亂,然後台板上我們也會比較整齊一點點。\n",
            "[ 61%] 00:45:44,000 → 00:45:48,140  然後如果今天是你想要自己跟學生講的話,\n",
            "[ 61%] 00:45:48,240 → 00:45:53,320  你也可以用一個可能老師的符號,或者是一個男生的符號,\n",
            "[ 61%] 00:45:53,500 → 00:45:56,440  然後跟他們講說這比較像是你心裡的話,\n",
            "[ 61%] 00:45:56,600 → 00:45:59,000  那他就不用那麼文綴綴,他就是真的可以很...\n",
            "[ 61%] 00:46:00,000 → 00:46:03,000  就是比較日常口語化的東西就可以了\n",
            "[ 61%] 00:46:03,000 → 00:46:06,000  然後再來就是上次就有提到的東西\n",
            "[ 61%] 00:46:06,000 → 00:46:08,000  就是說表達高用AI論搞過\n",
            "[ 61%] 00:46:08,000 → 00:46:11,000  因為現在的物理講義內容比較像是\n",
            "[ 61%] 00:46:11,000 → 00:46:13,000  你真的想到什麼然後就打什麼出來\n",
            "[ 61%] 00:46:13,000 → 00:46:15,000  它沒有一個固定的格式\n",
            "[ 62%] 00:46:15,000 → 00:46:18,000  然後甚至這樣的內容可能比較像是\n",
            "[ 62%] 00:46:18,000 → 00:46:20,000  只有你自己看得懂\n",
            "[ 62%] 00:46:20,000 → 00:46:22,000  所有的表達我們都可以丟到TradeGPT\n",
            "[ 62%] 00:46:22,000 → 00:46:24,000  就你只要把你的想法丟上去\n",
            "[ 62%] 00:46:24,000 → 00:46:26,000  然後剛才你說你可以幫我run稿嗎\n",
            "[ 62%] 00:46:26,000 → 00:46:28,000  或是你可以幫我修飾成\n",
            "[ 62%] 00:46:28,000 → 00:46:30,000  可能高中生也看得懂的話語\n",
            "[ 62%] 00:46:30,000 → 00:46:32,000  它就會直接幫你寫出來\n",
            "[ 62%] 00:46:32,000 → 00:46:34,000  但是它生成的內容\n",
            "[ 62%] 00:46:34,000 → 00:46:36,000  你還是需要再去檢查過\n",
            "[ 62%] 00:46:36,000 → 00:46:38,000  因為它有時候不一定是那麼正確\n",
            "[ 62%] 00:46:38,000 → 00:46:40,000  或是不一定那麼貼近你想要表達的\n",
            "[ 62%] 00:46:40,000 → 00:46:45,000  所以你就跟他多聊幾次就可以了。\n",
            "[ 62%] 00:46:45,000 → 00:46:47,000  好,以上是知識存在的方面。\n",
            "[ 62%] 00:46:47,000 → 00:46:51,000  然後如果是使用者體驗方面的話,\n",
            "[ 62%] 00:46:51,000 → 00:46:54,000  像是AI化、線上化跟連結種整理,\n",
            "[ 62%] 00:46:54,000 → 00:46:58,000  就會需要麻煩你在編寫獎益的內容之後,\n",
            "[ 62%] 00:46:58,000 → 00:47:00,000  在編寫獎益內容的之中,\n",
            "[ 62%] 00:47:00,000 → 00:47:02,800  我就邊想還有哪些東西可以去製作\n",
            "[ 63%] 00:47:02,800 → 00:47:04,900  然後在你撰寫的過程中\n",
            "[ 63%] 00:47:04,900 → 00:47:07,500  也可以邊製作一些AI工具\n",
            "[ 63%] 00:47:07,500 → 00:47:09,000  或是把東西線上畫\n",
            "[ 63%] 00:47:10,500 → 00:47:14,200  然後全球地圖廣告頁跟意見回饋購買東西調查\n",
            "[ 63%] 00:47:14,200 → 00:47:16,600  這些都會由e-mall這邊直接處理\n",
            "[ 63%] 00:47:18,000 → 00:47:19,500  然後再來是格式的話\n",
            "[ 63%] 00:47:20,000 → 00:47:30,000  因為我知道你現在跟小助手的方式 好像是你會先把他整理過 然後再傳檔案給他 對嗎?\n",
            "[ 63%] 00:47:32,000 → 00:47:33,000  對\n",
            "[ 63%] 00:47:33,000 → 00:47:38,000  對 所以格式的話可能要 就是從你那邊一開始打的時候\n",
            "[ 63%] 00:47:38,000 → 00:47:40,000  就是你開始編輯這個書的時候\n",
            "[ 63%] 00:47:40,000 → 00:47:42,240  你可能就要稍微幫我注意一下格式\n",
            "[ 63%] 00:47:42,240 → 00:47:43,980  我們就是以B5為主\n",
            "[ 63%] 00:47:43,980 → 00:47:46,060  然後那個初期線要稍微注意\n",
            "[ 64%] 00:47:46,060 → 00:47:48,780  至少邊邊要預留三面面\n",
            "[ 64%] 00:47:48,780 → 00:47:49,500  它會比較\n",
            "[ 64%] 00:47:49,500 → 00:47:53,520  就硬刷的時候才會比較不會卡到板\n",
            "[ 64%] 00:47:53,520 → 00:47:54,420  然後需要\n",
            "[ 64%] 00:47:54,420 → 00:47:55,620  預留多少\n",
            "[ 64%] 00:47:55,620 → 00:47:58,560  就是你開word\n",
            "[ 64%] 00:47:58,560 → 00:48:00,000  然後它會有那個\n",
            "[ 64%] 00:48:00,000 → 00:48:02,000  至少要窄\n",
            "[ 64%] 00:48:02,000 → 00:48:04,000  它有一個版面配飾\n",
            "[ 64%] 00:48:04,000 → 00:48:06,000  然後你最多最多只能選擇窄\n",
            "[ 64%] 00:48:06,000 → 00:48:08,000  然後不能再往下縮\n",
            "[ 64%] 00:48:10,000 → 00:48:12,000  等一下我再開給你看好了\n",
            "[ 64%] 00:48:12,000 → 00:48:14,000  稍等我一下\n",
            "[ 65%] 00:48:20,000 → 00:48:39,240  好,就是你在用Word等的時候,它其實有一個版面配置,然後你就,你需要先一開始就先幫我把大小分到。\n",
            "[ 65%] 00:48:40,000 → 00:48:42,640  啊我冇覆好,稍等我\n",
            "[ 65%] 00:48:42,640 → 00:48:44,080  奈咦阿捏\n",
            "[ 65%] 00:48:44,080 → 00:48:50,540  這樣有咩\n",
            "[ 65%] 00:48:50,540 → 00:48:55,720  所以你一開始就需要幫我把大小\n",
            "[ 65%] 00:48:55,720 → 00:48:57,880  就直接先選成B5的大小\n",
            "[ 65%] 00:48:57,880 → 00:48:59,780  然後邊界這邊\n",
            "[ 65%] 00:49:00,000 → 00:49:02,000  最多最多就是以窄為主\n",
            "[ 65%] 00:49:02,000 → 00:49:04,000  就是盡量不要再往下縮\n",
            "[ 65%] 00:49:04,000 → 00:49:08,000  不然我們的印刷照片可能會踩到旁邊\n",
            "[ 65%] 00:49:08,000 → 00:49:10,000  這部分OK咩?\n",
            "[ 65%] 00:49:10,000 → 00:49:12,000  OK\n",
            "[ 65%] 00:49:12,000 → 00:49:14,000  再超出一點點\n",
            "[ 65%] 00:49:14,000 → 00:49:16,000  一點點\n",
            "[ 65%] 00:49:16,000 → 00:49:18,000  對對對就是一點點\n",
            "[ 66%] 00:49:18,000 → 00:49:20,000  但不要壓得太緊\n",
            "[ 66%] 00:49:20,000 → 00:49:22,000  你可以回去剛那個地方嗎?\n",
            "[ 66%] 00:49:22,000 → 00:49:26,000  你看它的右上角\n",
            "[ 66%] 00:49:26,000 → 00:49:29,000  右上角是不是有一個L形的東西?\n",
            "[ 66%] 00:49:32,000 → 00:49:36,000  在紙張上有一個L形的框架\n",
            "[ 66%] 00:49:36,000 → 00:49:38,000  對這個\n",
            "[ 66%] 00:49:38,000 → 00:49:40,000  就是它的那個死角的那個\n",
            "[ 66%] 00:49:40,000 → 00:49:42,000  你的字可以寫到那邊\n",
            "[ 66%] 00:49:42,000 → 00:49:47,000  然後如果你字真的想要在外面再延伸一點點的話\n",
            "[ 66%] 00:49:47,000 → 00:49:52,000  就是不可以超過那個L型的中端\n",
            "[ 66%] 00:49:52,000 → 00:49:55,000  就不可以寫出L型的外面\n",
            "[ 66%] 00:49:55,000 → 00:49:59,000  就會是不會被拆到的格式\n",
            "[ 67%] 00:50:00,000 → 00:50:07,000  但是今天還是幫我縮在L型裡面會比較保險一點點\n",
            "[ 67%] 00:50:07,000 → 00:50:15,000  然後再來的話其他目前都有講過\n",
            "[ 67%] 00:50:15,000 → 00:50:20,000  這個呼籲社群宣傳\n",
            "[ 67%] 00:50:20,000 → 00:50:22,700  比較會像是你寫書已經寫到後半段之後\n",
            "[ 67%] 00:50:22,700 → 00:50:24,700  我們可以再來進行的東西\n",
            "[ 67%] 00:50:24,700 → 00:50:27,800  所以這個我們可以之後在開會的時候跟你講一下\n",
            "[ 67%] 00:50:29,800 → 00:50:33,300  然後誓願內容商品化會\n",
            "[ 67%] 00:50:33,300 → 00:50:34,800  這個就是範例\n",
            "[ 67%] 00:50:34,800 → 00:50:38,200  我們以英文作文或是英文文法\n",
            "[ 67%] 00:50:38,200 → 00:50:39,400  或是英文單字說的話\n",
            "[ 67%] 00:50:39,400 → 00:50:40,000  我們可能都會\n",
            "[ 67%] 00:50:40,000 → 00:50:46,320  給他一個備單的機器人 然後拿這個機器人去推廣我們的作文書跟其他的產品\n",
            "[ 68%] 00:50:46,320 → 00:50:49,560  就是當你使用這個機器人的時候 它底下其實會生成\n",
            "[ 68%] 00:50:49,560 → 00:50:54,860  如果你想看更多完整的內容 或者如果你想要看什麼更完整的文法解說\n",
            "[ 68%] 00:50:54,860 → 00:50:58,640  你可以購買一模一模的那本書 然後會貼一個下一個連結給他\n",
            "[ 68%] 00:50:58,640 → 00:51:00,000  就是到時候物理也可以用\n",
            "[ 68%] 00:51:00,000 → 00:51:02,800  用這種方式去做一個行銷宣傳。\n",
            "[ 68%] 00:51:02,800 → 00:51:06,800  在這裡,就是想知道如果背一個單字補輸一個觀念,\n",
            "[ 68%] 00:51:06,800 → 00:51:09,800  然後這就會是我們完整的書籍內容宣傳。\n",
            "[ 68%] 00:51:12,800 → 00:51:18,800  好,那目前以上有任何問題或是有任何想問的嗎?\n",
            "[ 68%] 00:51:20,000 → 00:51:26,120  因為Himoji那邊現在的樹就有了,所以還好。\n",
            "[ 68%] 00:51:26,120 → 00:51:31,440  然後你有一個MBTI那個是沒有要理它嗎?\n",
            "[ 69%] 00:51:34,960 → 00:51:40,020  因為這個可能就是對於物理...\n",
            "[ 69%] 00:51:40,000 → 00:51:43,200  講義有點難運用\n",
            "[ 69%] 00:51:43,200 → 00:51:43,840  其實\n",
            "[ 69%] 00:51:43,840 → 00:51:45,960  哦好那我就不理他\n",
            "[ 69%] 00:51:45,960 → 00:51:47,340  好好\n",
            "[ 69%] 00:51:47,340 → 00:51:48,280  子明你可以說\n",
            "[ 69%] 00:51:48,280 → 00:51:53,080  我寫那個其實只是一個紀錄\n",
            "[ 69%] 00:51:53,080 → 00:51:54,980  它不一定要寫NBT\n",
            "[ 69%] 00:51:54,980 → 00:51:56,820  我想講的只是說\n",
            "[ 69%] 00:51:56,820 → 00:51:59,240  你可以去設想\n",
            "[ 69%] 00:52:00,000 → 00:52:02,000  學生有千千百百多\n",
            "[ 69%] 00:52:02,000 → 00:52:04,000  就是有一些人\n",
            "[ 69%] 00:52:04,000 → 00:52:08,000  因為你自己怎麼學物理\n",
            "[ 69%] 00:52:08,000 → 00:52:10,000  跟其他人怎麼學物理\n",
            "[ 69%] 00:52:10,000 → 00:52:11,000  一定是非常不同的\n",
            "[ 69%] 00:52:11,000 → 00:52:13,000  然後除了是專業知識\n",
            "[ 69%] 00:52:13,000 → 00:52:15,000  觀念上面的落差之外\n",
            "[ 69%] 00:52:15,000 → 00:52:17,000  其實他們在理解知識\n",
            "[ 70%] 00:52:17,000 → 00:52:20,000  還有如何讀完這本書上面\n",
            "[ 70%] 00:52:20,000 → 00:52:22,500  本身就會有很大的不同\n",
            "[ 70%] 00:52:22,500 → 00:52:24,500  像譬如說喻謙好了\n",
            "[ 70%] 00:52:24,500 → 00:52:26,500  他如果今天讀到一本書\n",
            "[ 70%] 00:52:26,500 → 00:52:28,500  然後事實上他覺得很用心\n",
            "[ 70%] 00:52:33,500 → 00:52:35,500  如果是那本書讓喻謙覺得很用心\n",
            "[ 70%] 00:52:35,500 → 00:52:37,500  然後很有溫度\n",
            "[ 70%] 00:52:37,500 → 00:52:39,500  然後是很想把學徒顧好\n",
            "[ 70%] 00:52:39,500 → 00:52:40,500  喻謙就會想\n",
            "[ 70%] 00:52:40,000 → 00:52:42,000  你想把它讀完,你說是不是?\n",
            "[ 70%] 00:52:42,000 → 00:52:44,000  對\n",
            "[ 70%] 00:52:44,000 → 00:52:46,000  但是我的個性可能就會是\n",
            "[ 70%] 00:52:46,000 → 00:52:48,000  我想要看到超級爆炸具體的東西\n",
            "[ 70%] 00:52:48,000 → 00:52:50,000  你不要給我扯一些有的沒的的\n",
            "[ 70%] 00:52:50,000 → 00:52:52,000  剛才跟我講的重點\n",
            "[ 70%] 00:52:52,000 → 00:52:57,000  然後其他學生有些可能會喜歡圖像化的解說\n",
            "[ 70%] 00:52:57,000 → 00:53:00,000  然後就是你比起用文字去寫\n",
            "[ 70%] 00:53:00,000 → 00:53:01,800  寫第一步驟第二步驟第三步驟\n",
            "[ 71%] 00:53:01,800 → 00:53:05,300  你還不如直接用一張圖片或Canva的字圖\n",
            "[ 71%] 00:53:05,300 → 00:53:07,300  去告訴他三步驟是什麼\n",
            "[ 71%] 00:53:07,300 → 00:53:09,500  那又會有一些可能又會喜歡\n",
            "[ 71%] 00:53:09,500 → 00:53:13,100  就是兩個人的對話去推進一個觀念\n",
            "[ 71%] 00:53:13,100 → 00:53:14,600  就大家都有不同學習方式\n",
            "[ 71%] 00:53:14,600 → 00:53:16,900  然後我覺得你不一定要用MVTI\n",
            "[ 71%] 00:53:16,900 → 00:53:19,100  去把16個全部都想過一次\n",
            "[ 71%] 00:53:19,100 → 00:53:19,900  而是你\n",
            "[ 71%] 00:53:20,000 → 00:53:21,640  至少在寫獎音的時候\n",
            "[ 71%] 00:53:21,640 → 00:53:25,760  你要先抓幾個學生的標籤跟概念出來\n",
            "[ 71%] 00:53:25,760 → 00:53:28,640  可能是圖像化學生、理論化學生\n",
            "[ 71%] 00:53:28,640 → 00:53:31,040  然後比較情緒化的學生\n",
            "[ 71%] 00:53:31,040 → 00:53:32,000  抓幾個標籤出來\n",
            "[ 71%] 00:53:32,000 → 00:53:35,240  然後去寫獎音的時候照顧到這些學生的需求\n",
            "[ 71%] 00:53:37,240 → 00:53:39,040  好,我講完了\n",
            "[ 71%] 00:53:40,000 → 00:53:43,000  Ok, this part, do you think it's ok?\n",
            "[ 71%] 00:53:44,000 → 00:53:45,000  Yes, it's ok.\n",
            "[ 71%] 00:53:46,000 → 00:53:48,000  Ok, and then...\n",
            "[ 72%] 00:53:51,000 → 00:53:56,000  If you are in the process of making it, or you need some AI tools to help you,\n",
            "[ 72%] 00:53:56,000 → 00:54:00,000  you can find Pei Jun, he is a very good...\n",
            "[ 72%] 00:54:00,000 → 00:54:04,200  所以如果你在這雙方沒有問題的話都可以問他\n",
            "[ 72%] 00:54:04,200 → 00:54:16,000  我們不是還有一個是要問Pedro的事情嗎\n",
            "[ 72%] 00:54:20,000 → 00:54:22,000  我可以分享我的畫面嗎?\n",
            "[ 72%] 00:54:22,000 → 00:54:24,000  欸等一下,物理那邊都講完了吧?\n",
            "[ 72%] 00:54:24,000 → 00:54:26,000  對\n",
            "[ 72%] 00:54:26,000 → 00:54:30,000  好,那我想要問一下裴娟一個東西\n",
            "[ 72%] 00:54:30,000 → 00:54:32,000  我分享一下我的畫面\n",
            "[ 73%] 00:54:40,000 → 00:54:59,920  我们刚刚有讲到很多写讲义上面的东西,只是如果我们这边有这套准则,但是像伟臣可能写的时候还是会需要时不时回去看交战手册,然后有时候可能还是会不小心漏掉一些东西,或不知道怎么去使用,然后我在想如果我们未来\n",
            "[ 73%] 00:55:00,000 → 00:55:06,000  可能會需要同時跑很多本書 很多個合作者一起寫這樣一個話\n",
            "[ 73%] 00:55:06,000 → 00:55:09,000  我們來回溝通可能會需要花很多時間\n",
            "[ 73%] 00:55:09,000 → 00:55:14,000  然後就想到說 之前我在學SEO的時候\n",
            "[ 73%] 00:55:14,000 → 00:55:17,000  有一個像這樣子的工具\n",
            "[ 74%] 00:55:17,000 → 00:55:20,000  就是它的左邊是你在寫書\n",
            "[ 74%] 00:55:20,000 → 00:55:40,000  文章的頁面,然後右邊他就會告訴你說你現在拿到多少分,就是你有做到多少需求之內的事情,然後他就會一直提醒你說你還要再寫什麼,你還要再寫什麼才會足夠完整,然後在想就是這樣子的一個工具他製作的難度。\n",
            "[ 74%] 00:55:40,000 → 00:55:59,100  我覺得應該,這個東西他看起來是有機會整合在Notion裡面,但是我覺得他看起來,因為我們獎勵的內容其實是非常多嘛,我覺得他看起來對於Token的開銷會非常大,就是\n",
            "[ 75%] 00:56:00,000 → 00:56:10,000  我覺得我們透過應用程式去跟AI做串接,它中間其實是以量計價的。\n",
            "[ 75%] 00:56:10,000 → 00:56:20,000  我覺得這東西它或許是可以嘗試看看來做,但是因為\n",
            "[ 75%] 00:56:20,000 → 00:56:27,000  另一方面講義的內容很多,另一方面教單手字的內容也蠻多的\n",
            "[ 75%] 00:56:27,000 → 00:56:32,000  我覺得這個可能使用量的部分會比較大一點點\n",
            "[ 75%] 00:56:32,000 → 00:56:36,000  但這個東西會越來越便宜啦\n",
            "[ 75%] 00:56:36,000 → 00:56:40,000  所以或許我可以嘗試看看用\n",
            "[ 75%] 00:56:40,000 → 00:56:45,640  比較之前的,應該說用量比較小比較便宜的模型來試試看\n",
            "[ 75%] 00:56:46,660 → 00:56:49,720  因為畢竟他這個東西他不會要求說\n",
            "[ 76%] 00:56:49,980 → 00:56:53,320  就是我AI傳出的內容要到多進去\n",
            "[ 76%] 00:56:55,360 → 00:56:59,960  我覺得可以研究看看有沒有機會把它整合在Notion裡面\n",
            "[ 76%] 00:57:00,000 → 00:57:02,760  可能他更新頻率不會到這麼的高\n",
            "[ 76%] 00:57:02,760 → 00:57:09,760  可能就是寫作者完成一整階段的工作之後\n",
            "[ 76%] 00:57:09,760 → 00:57:14,500  再去再用AI去做這個提醒這樣\n",
            "[ 76%] 00:57:18,240 → 00:57:19,000  那如果\n",
            "[ 76%] 00:57:20,000 → 00:57:29,300  如果把這個工具切成是很多個更小的工具 那如果把這個工具切成是很多個更小的工具\n",
            "[ 76%] 00:57:29,300 → 00:57:33,780  就是我們不一定要是一戰式的解決所有講義變形的問題\n",
            "[ 77%] 00:57:33,780 → 00:57:40,000  可能把剛剛教授的手冊細分成五個層面或三個層面\n",
            "[ 77%] 00:57:40,000 → 00:57:47,000  要分別套這樣子的工具,它的用量這樣子會再更大,還是可以節省一點。\n",
            "[ 77%] 00:58:00,000 → 00:58:07,000  要怎麼切我覺得後續可以再來想了,目前就是我覺得可能要再研究一下。\n",
            "[ 77%] 00:58:07,000 → 00:58:14,000  好,不然我也先用ChangeGPT做做看好了,我先打一張手冊寫ChangeGPT。\n",
            "[ 77%] 00:58:14,000 → 00:58:20,000  然後維城如果會,如果想要看看說自己有沒有\n",
            "[ 78%] 00:58:20,000 → 00:58:24,680  有一些東西漏掉的話,你就可以先把你的獎金丟進去,change your VT\n",
            "[ 78%] 00:58:24,680 → 00:58:27,680  但是你一次可能就只能丟個十頁\n",
            "[ 78%] 00:58:27,680 → 00:58:30,680  就不能一次丟那個幾百頁進去\n",
            "[ 78%] 00:58:30,680 → 00:58:34,680  然後他可能就會告訴你說你還有哪些地方需要再錄\n",
            "[ 78%] 00:58:34,680 → 00:58:40,680  現階段先這樣子,然後這個可以之後有研究出來\n",
            "[ 78%] 00:58:40,000 → 00:58:43,000  讓我們再拿出來討論看看。\n",
            "[ 78%] 00:58:45,000 → 00:58:47,000  好,我講完了。\n",
            "[ 78%] 00:58:47,000 → 00:58:49,000  好耶。\n",
            "[ 78%] 00:58:49,000 → 00:58:52,000  那目前維生有任何想問的嗎?\n",
            "[ 78%] 00:58:52,000 → 00:58:56,000  或者也想分享看看你的想法也都可以。\n",
            "[ 79%] 00:59:00,000 → 00:59:09,440  我問個問題,就是之前不是有說你要開另外一個物理的帳號嗎?\n",
            "[ 79%] 00:59:09,440 → 00:59:11,440  嗯\n",
            "[ 79%] 00:59:11,440 → 00:59:20,000  就是我覺得應該要開另外一個跟英文獨立的帳號會比較好,不管你之後有沒有要掛e-mail的問題\n",
            "[ 79%] 00:59:20,000 → 00:59:22,000  我覺得分開會比較好\n",
            "[ 79%] 00:59:22,000 → 00:59:24,000  有原因嗎?\n",
            "[ 79%] 00:59:24,000 → 00:59:26,000  就是覺得分開會比較好\n",
            "[ 79%] 00:59:26,000 → 00:59:28,000  因為emote本來就是文科嘛\n",
            "[ 79%] 00:59:28,000 → 00:59:30,000  然後如果突然變成理科的話\n",
            "[ 79%] 00:59:30,000 → 00:59:32,000  就是你如果發的內容都混在一起\n",
            "[ 80%] 00:59:40,000 → 00:59:59,000  至少理科跟文科一個比較專業的分別,我會傾向把它分開,至少我看到這個帳號的時候我也知道它的專業是英文,這個帳號的專業是什麼,雖然它背後的人可能是同一批人。\n",
            "[ 80%] 01:00:00,000 → 01:00:02,000  我覺得它好像是不同的處理邏輯\n",
            "[ 80%] 01:00:02,000 → 01:00:04,000  就是我們現在如果把物理\n",
            "[ 80%] 01:00:04,000 → 01:00:06,000  它是兩種都是正確的狀況\n",
            "[ 80%] 01:00:06,000 → 01:00:08,000  然後我可能先跟你分享看看\n",
            "[ 80%] 01:00:08,000 → 01:00:10,000  要看你會不會有不同想法\n",
            "[ 80%] 01:00:20,000 → 01:00:25,000  如果是把講義掛到英文帳號的話\n",
            "[ 80%] 01:00:25,000 → 01:00:33,000  那其實是變成我們是幫助你在私領域去找客人\n",
            "[ 81%] 01:00:33,000 → 01:00:37,000  就是我們的瀏覽\n",
            "[ 81%] 01:00:37,000 → 01:00:40,000  我有做過一張圖秀給你看一下\n",
            "[ 81%] 01:00:40,000 → 01:00:48,300  就是我們的流量入口 IG的那些貼文就不太會真的去做物理專業知識相關的東西\n",
            "[ 81%] 01:00:48,300 → 01:00:52,580  那個就是真的跟英文真的太不相關\n",
            "[ 81%] 01:00:52,580 → 01:00:56,840  然後那個內容這樣跳來跳去也比較不符合學生的習慣\n",
            "[ 81%] 01:00:56,840 → 01:00:59,880  所以物理的專業知識不會\n",
            "[ 81%] 01:01:00,000 → 01:01:09,000  作為流量入口,我們的流量入口都會是以內容為主,只是那些流量進來之後\n",
            "[ 81%] 01:01:14,000 → 01:01:16,000  這邊沒有斷掉\n",
            "[ 82%] 01:01:20,000 → 01:01:34,080  他們還會被導到像是我們的節目或Line群然後限動\n",
            "[ 82%] 01:01:34,080 → 01:01:37,940  等於說是可能有6萬個追蹤者是追我們的IG\n",
            "[ 82%] 01:01:37,940 → 01:01:39,980  但是可能進入到死領域的\n",
            "[ 82%] 01:01:40,000 → 01:01:41,000  可能就只有一萬個\n",
            "[ 82%] 01:01:41,000 → 01:01:44,000  然後一萬個當中我們再想辦法幫你推銷\n",
            "[ 82%] 01:01:44,000 → 01:01:46,000  最後推銷出來\n",
            "[ 82%] 01:01:46,000 → 01:01:51,000  成交的數量就會比英文還要少\n",
            "[ 82%] 01:01:51,000 → 01:01:53,000  這是比較正常的狀況\n",
            "[ 82%] 01:01:53,000 → 01:01:55,000  但是相對來說\n",
            "[ 82%] 01:01:55,000 → 01:01:57,000  如果我們今天就開個全新的帳號\n",
            "[ 82%] 01:01:57,000 → 01:02:00,000  那我們那個全新的帳號也必須達到一定的粉絲級\n",
            "[ 82%] 01:02:00,000 → 01:02:02,760  才可以去平衡掉我剛剛說\n",
            "[ 82%] 01:02:02,760 → 01:02:04,800  比如說導到死領域的可能有一萬個\n",
            "[ 83%] 01:02:04,800 → 01:02:06,980  那就代表如果我們要重開一個帳號\n",
            "[ 83%] 01:02:06,980 → 01:02:10,300  那個帳號可能至少就要光靠自然科\n",
            "[ 83%] 01:02:10,300 → 01:02:14,060  光靠物理可能就要至少達到一萬個粉絲\n",
            "[ 83%] 01:02:14,060 → 01:02:16,220  它才會比較有機率\n",
            "[ 83%] 01:02:16,220 → 01:02:18,480  可以達到跟英文一樣的宣傳效果\n",
            "[ 83%] 01:02:18,480 → 01:02:19,980  就有點像我這邊\n",
            "[ 83%] 01:02:20,000 → 01:02:22,000  我沒有做一個圖\n",
            "[ 83%] 01:02:22,000 → 01:02:27,000  就是打開熱量漏斗的地方其實是我們會用英文去做\n",
            "[ 83%] 01:02:27,000 → 01:02:29,000  但是其他的這個地方\n",
            "[ 83%] 01:02:29,000 → 01:02:31,000  YouTube 跟 IG 限動\n",
            "[ 83%] 01:02:31,000 → 01:02:34,000  還有專業的一些課程\n",
            "[ 83%] 01:02:34,000 → 01:02:35,000  就是講義啊\n",
            "[ 83%] 01:02:35,000 → 01:02:38,000  然後現在是沒有在做直播跟團課啦\n",
            "[ 83%] 01:02:38,000 → 01:02:40,000  但是其他的一些專業的\n",
            "[ 83%] 01:02:40,000 → 01:02:46,600  像私訊的問題回答還有Line群的問題回答都會幫你的物理數據倒流\n",
            "[ 83%] 01:02:46,600 → 01:02:49,000  這樣你要懂意思嗎\n",
            "[ 84%] 01:02:49,000 → 01:03:00,000  但我剛意思其實是說如果你要發物理的文章的話或什麼東西的話我覺得就是要有另外一個帳號\n",
            "[ 84%] 01:03:00,000 → 01:03:02,000  喔對啊確實\n",
            "[ 84%] 01:03:02,000 → 01:03:06,000  可是誰要來發物理的文章\n",
            "[ 84%] 01:03:06,000 → 01:03:08,000  你會想要發物理的文章嗎\n",
            "[ 84%] 01:03:08,000 → 01:03:10,000  如果我有寫的話\n",
            "[ 84%] 01:03:10,000 → 01:03:14,000  或者就是你之前不是說要做一些奇怪的實驗\n",
            "[ 84%] 01:03:14,000 → 01:03:16,000  所以我不知道你要做什麼實驗\n",
            "[ 84%] 01:03:16,000 → 01:03:20,000  喔對啊我之前不是有傳給你一個\n",
            "[ 84%] 01:03:20,000 → 01:03:23,000  你有看過這個嗎?\n",
            "[ 84%] 01:03:23,000 → 01:03:25,000  你有傳給我嗎?\n",
            "[ 84%] 01:03:25,000 → 01:03:28,000  我傳在 Slack 啦\n",
            "[ 84%] 01:03:28,000 → 01:03:30,000  就是我們會\n",
            "[ 84%] 01:03:30,000 → 01:03:33,000  如果是我幫你做內容的話\n",
            "[ 84%] 01:03:33,000 → 01:03:35,000  我理想上會是\n",
            "[ 85%] 01:03:35,000 → 01:03:37,000  我找一下那個\n",
            "[ 85%] 01:03:37,000 → 01:03:39,000  如果是專業的物理知識\n",
            "[ 85%] 01:03:39,000 → 01:03:41,000  就會是需要你來幫忙\n",
            "[ 85%] 01:03:40,000 → 01:03:45,000  如果是我們幫你做內容可能會做的比較類似這種\n",
            "[ 85%] 01:03:45,000 → 01:03:47,000  欸這個\n",
            "[ 85%] 01:03:51,000 → 01:03:53,000  喔我有看到這個\n",
            "[ 85%] 01:03:54,000 → 01:03:58,000  喔就只能做的比較娛樂化一點\n",
            "[ 85%] 01:03:59,000 → 01:04:00,000  然後再把你放寡\n",
            "[ 85%] 01:04:00,000 → 01:04:02,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:02,000 → 01:04:04,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:04,000 → 01:04:06,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:06,000 → 01:04:08,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:08,000 → 01:04:10,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:10,000 → 01:04:12,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:12,000 → 01:04:14,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:14,000 → 01:04:16,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:16,000 → 01:04:18,000  如果你是開一個全新的賬號\n",
            "[ 85%] 01:04:18,000 → 01:04:20,000  如果你是開一個全新的賬號\n",
            "[ 86%] 01:04:20,000 → 01:04:24,600  其實會需要有穩定的內容才處理\n",
            "[ 86%] 01:04:24,600 → 01:04:29,600  就是你可能不能是想到文章再發\n",
            "[ 86%] 01:04:29,600 → 01:04:33,000  然後我們這邊就會是需要\n",
            "[ 86%] 01:04:33,000 → 01:04:35,800  每次都就是幫你去做布林的帖文\n",
            "[ 86%] 01:04:40,000 → 01:05:00,000  如果是掛在英文上的話,有時候就可以像我之前有給你看單字數的ChangeGPT,有時候我覺得把那個ChangeGPT放在英文,然後讓它流傳下去的話,像現在的ChangeGPT就有三千多個對話,然後如果三千多個對話,每一次對話都會有三千多個對話,\n",
            "[ 86%] 01:05:00,000 → 01:05:02,000  如果有一個肯定的廣告的話\n",
            "[ 86%] 01:05:02,000 → 01:05:04,000  我覺得導流效果也蠻不錯的\n",
            "[ 86%] 01:05:04,000 → 01:05:06,000  所以這個可以再想想看\n",
            "[ 87%] 01:05:06,000 → 01:05:08,000  但如果你會希望\n",
            "[ 87%] 01:05:08,000 → 01:05:10,000  開個線上號\n",
            "[ 87%] 01:05:10,000 → 01:05:12,000  然後希望可以做一些\n",
            "[ 87%] 01:05:12,000 → 01:05:14,000  專門輸入的內容\n",
            "[ 87%] 01:05:14,000 → 01:05:16,000  我覺得也沒有問題\n",
            "[ 87%] 01:05:16,000 → 01:05:18,000  但是我們之後可以再一起把細節\n",
            "[ 87%] 01:05:18,000 → 01:05:20,000  就是我可以\n",
            "[ 87%] 01:05:20,000 → 01:05:22,500  直接先開帳號,然後可能先做做看\n",
            "[ 87%] 01:05:22,500 → 01:05:24,400  然後再告訴你有沒有困難的點\n",
            "[ 87%] 01:05:25,700 → 01:05:28,600  那如果你現在要發一個立刻的東西\n",
            "[ 87%] 01:05:28,600 → 01:05:29,800  你是要發在哪邊?\n",
            "[ 87%] 01:05:32,100 → 01:05:34,100  現在要發一個立刻的東西\n",
            "[ 87%] 01:05:34,800 → 01:05:38,100  就是如果你沒有打算再開一個行政帳號的話\n",
            "[ 87%] 01:05:38,700 → 01:05:40,100  啊,立刻的東西\n",
            "[ 88%] 01:05:40,000 → 01:05:59,380  我就會把他放在YouTube的影片,我會幫你講,然後再用IG去引導學生去YouTube的影片,然後會是IG行動,還有Threads的,在Threads上面我就不會教物理,而是我會直接\n",
            "[ 88%] 01:06:00,000 → 01:06:06,800  丟免費的工具給學生,然後讓那個免費的工具自己下去學生之間流傳。\n",
            "[ 88%] 01:06:06,800 → 01:06:16,360  比如說你的事業檔案,那就算是一種免費的工具。\n",
            "[ 88%] 01:06:16,360 → 01:06:17,240  大概理解。\n",
            "[ 88%] 01:06:20,000 → 01:06:27,000  還有你的商品掛在蝦皮機就會有一定的流量\n",
            "[ 88%] 01:06:27,000 → 01:06:33,000  因為我們賣場也會有既定的客源進來\n",
            "[ 89%] 01:06:33,000 → 01:06:38,000  還有LINE群\n",
            "[ 89%] 01:06:38,000 → 01:06:40,000  LINE群會有選手喔\n",
            "[ 89%] 01:06:40,000 → 01:06:42,760  喔對之前有講到Live群\n",
            "[ 89%] 01:06:42,760 → 01:06:46,940  所以現在是有學生在問物理的問題嗎\n",
            "[ 89%] 01:06:46,940 → 01:06:48,360  還是還沒有\n",
            "[ 89%] 01:06:48,360 → 01:06:49,620  還沒有\n",
            "[ 89%] 01:06:49,620 → 01:06:55,740  可能我們也還沒有引導他們去問物理的\n",
            "[ 89%] 01:06:55,740 → 01:06:59,980  你現在有在這個群組\n",
            "[ 89%] 01:07:00,000 → 01:07:14,400  還有其他問題呢?\n",
            "[ 89%] 01:07:18,400 → 01:07:20,400  這部分應該就到這裡了\n",
            "[ 90%] 01:07:20,000 → 01:07:26,100  然後我提問一下,這是你的公司名稱嗎?\n",
            "[ 90%] 01:07:27,140 → 01:07:31,000  公司名稱是成學文教有限公司,\n",
            "[ 90%] 01:07:31,600 → 01:07:33,840  陰謀比較像是品牌名稱。\n",
            "[ 90%] 01:07:33,840 → 01:07:36,540  所以那你的陰謀是申請商標嗎?\n",
            "[ 90%] 01:07:37,420 → 01:07:38,000  我是好奇。\n",
            "[ 90%] 01:07:40,000 → 01:07:42,000  喔好\n",
            "[ 90%] 01:07:42,000 → 01:07:45,820  你要搶住嗎\n",
            "[ 90%] 01:07:45,820 → 01:07:47,420  我都沒想到\n",
            "[ 90%] 01:07:47,420 → 01:07:49,880  惡意搶住\n",
            "[ 90%] 01:07:49,880 → 01:07:53,340  你是學了民法之後學壞了是不是\n",
            "[ 90%] 01:07:53,340 → 01:07:57,720  我好像記得有的是法律系\n",
            "[ 90%] 01:07:57,720 → 01:08:00,000  我是法律系\n",
            "[ 90%] 01:08:00,000 → 01:08:05,000  好\n",
            "[ 91%] 01:08:05,000 → 01:08:07,700  那應該沒有其他問題耶\n",
            "[ 91%] 01:08:07,700 → 01:08:08,940  好\n",
            "[ 91%] 01:08:08,940 → 01:08:10,620  你應該沒有\n",
            "[ 91%] 01:08:10,620 → 01:08:12,160  打算先註冊對吧\n",
            "[ 91%] 01:08:12,160 → 01:08:12,660  沒有沒有\n",
            "[ 91%] 01:08:12,660 → 01:08:13,460  OKOK\n",
            "[ 91%] 01:08:13,460 → 01:08:15,180  有點麻煩\n",
            "[ 91%] 01:08:15,180 → 01:08:16,300  沒有想要做這種事\n",
            "[ 91%] 01:08:20,000 → 01:08:28,000  如果沒有的話,我們今天會先到這邊喔。\n",
            "[ 91%] 01:08:28,000 → 01:08:30,000  好。\n",
            "[ 91%] 01:08:30,000 → 01:08:32,000  好,辛苦了,謝謝你。\n",
            "[ 91%] 01:08:32,000 → 01:08:34,000  掰掰。\n",
            "[ 91%] 01:08:34,000 → 01:08:36,000  掰掰。\n",
            "[ 91%] 01:08:40,000 → 01:08:49,860  我要影片嗎?想要影片?\n",
            "[ 91%] 01:08:50,000 → 01:08:51,440  我有,好,我再傳\n",
            "[ 92%] 01:08:51,440 → 01:08:53,280  做完可以改AI\n",
            "[ 92%] 01:08:53,280 → 01:08:54,060  OK\n",
            "[ 92%] 01:08:54,060 → 01:08:57,760  為什麼我媽留著?\n",
            "[ 92%] 01:08:57,860 → 01:08:59,320  我媽有什麼事情要討論嗎?\n",
            "[ 92%] 01:09:00,000 → 01:09:02,000  沒有啊\n",
            "[ 92%] 01:09:02,000 → 01:09:04,000  那我先撤囉\n",
            "[ 92%] 01:09:04,000 → 01:09:05,000  好嘞\n",
            "[ 92%] 01:09:05,000 → 01:09:08,000  我會去玩國粹職之後再去你那邊喔\n",
            "[ 92%] 01:09:08,000 → 01:09:09,000  好喔沒問題\n",
            "[ 92%] 01:09:09,000 → 01:09:10,000  你就直接進來就好\n",
            "[ 92%] 01:09:10,000 → 01:09:11,000  我會穿褲子\n",
            "[ 92%] 01:09:11,000 → 01:09:12,000  好掰掰\n",
            "[ 92%] 01:09:12,000 → 01:09:14,000  好掰掰\n",
            "[ 92%] 01:09:16,000 → 01:09:17,000  拜啦老孫\n",
            "[ 92%] 01:09:17,000 → 01:09:19,000  你剛聽起來有什麼問題嗎\n",
            "[ 92%] 01:09:20,000 → 01:09:26,000  沒有,但是我想到有很嚴重的事情要做\n",
            "[ 92%] 01:09:26,000 → 01:09:27,400  你說?\n",
            "[ 92%] 01:09:27,400 → 01:09:32,240  就是那個那個那個那個常常需要驗證的問題\n",
            "[ 92%] 01:09:32,240 → 01:09:35,760  我們現在把它解決掉了嘛\n",
            "[ 92%] 01:09:35,760 → 01:09:37,360  會很久嗎?\n",
            "[ 93%] 01:09:37,360 → 01:09:39,960  不會不會\n",
            "[ 93%] 01:09:40,000 → 01:09:50,000  比較就是我開個分享的分享分享\n",
            "[ 93%] 01:09:50,000 → 01:09:54,000  我的IG快快的\n",
            "[ 93%] 01:09:54,000 → 01:09:58,000  你的IG快快的\n",
            "[ 93%] 01:09:58,000 → 01:10:00,000  等一下你說\n",
            "[ 93%] 01:10:00,000 → 01:10:19,940  我來新增一下,因為目前都是要發去你的手機,然後\n",
            "[ 93%] 01:10:20,000 → 01:10:23,000  你的手機去做驗證嗎?\n",
            "[ 94%] 01:10:23,000 → 01:10:24,000  嗯\n",
            "[ 94%] 01:10:24,000 → 01:10:29,000  對 然後我是想說就是我們直接來進入這個\n",
            "[ 94%] 01:10:29,000 → 01:10:33,000  就是我們直接弄一個這個動態驗證嘛\n",
            "[ 94%] 01:10:33,000 → 01:10:34,000  就是它可以\n",
            "[ 94%] 01:10:34,000 → 01:10:35,000  原來我們有這個東西啊\n",
            "[ 94%] 01:10:35,000 → 01:10:36,000  蛤?\n",
            "[ 94%] 01:10:36,000 → 01:10:38,000  我們有這個東西啊\n",
            "[ 94%] 01:10:38,000 → 01:10:40,000  你們有這個東西\n",
            "[ 94%] 01:10:40,000 → 01:10:44,000  不是不是不是 不是我們有動態驗證碼\n",
            "[ 94%] 01:10:44,000 → 01:10:48,000  你們有動態驗證碼 可是我在帳號裡面沒看到你\n",
            "[ 94%] 01:10:48,000 → 01:10:52,000  因為我們是綁openai跟ig消息\n",
            "[ 94%] 01:10:52,000 → 01:10:56,000  那你這個要不要綁一下 可以可以 四十嗎\n",
            "[ 94%] 01:10:56,000 → 01:11:00,000  不然我每次半夜在搞東西\n",
            "[ 94%] 01:11:00,000 → 01:11:02,000  都會卡住\n",
            "[ 94%] 01:11:02,000 → 01:11:04,000  好有嗎?\n",
            "[ 94%] 01:11:04,000 → 01:11:06,000  有啊它進去了\n",
            "[ 94%] 01:11:06,000 → 01:11:08,000  等等等\n",
            "[ 95%] 01:11:08,000 → 01:11:10,000  那我現在新增一個然後截圖給你們\n",
            "[ 95%] 01:11:10,000 → 01:11:12,000  沒有好等一下我直接\n",
            "[ 95%] 01:11:12,000 → 01:11:14,000  我只新增\n",
            "[ 95%] 01:11:14,000 → 01:11:16,000  沒有我是截個圖啊\n",
            "[ 95%] 01:11:16,000 → 01:11:18,000  它不是會一直跑嗎?\n",
            "[ 95%] 01:11:18,000 → 01:11:20,000  它一直都會跑啊\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  沒有沒有這個不會\n",
            "[ 95%] 01:11:20,000 → 01:11:22,000  這個圖不會\n",
            "[ 95%] 01:11:22,000 → 01:11:24,000  這個圖不會 為什麼\n",
            "[ 95%] 01:11:24,000 → 01:11:26,000  因為它跑的不是這個圖\n",
            "[ 95%] 01:11:26,000 → 01:11:28,000  它跑的是這個圖裡面有精藥\n",
            "[ 95%] 01:11:28,000 → 01:11:30,000  然後它會根據這個精藥\n",
            "[ 95%] 01:11:30,000 → 01:11:32,000  加上時間\n",
            "[ 95%] 01:11:32,000 → 01:11:34,000  那個數字不是一直都會跑嗎\n",
            "[ 95%] 01:11:34,000 → 01:11:36,000  對 但是這個圖不會跑\n",
            "[ 95%] 01:11:38,000 → 01:11:40,000  對 它是用這個圖加上時間去\n",
            "[ 95%] 01:11:40,000 → 01:11:42,000  你去算出那個數字\n",
            "[ 95%] 01:11:42,000 → 01:11:44,000  這樣這樣\n",
            "[ 95%] 01:11:45,120 → 01:11:47,120  那我要放在notion裡面了\n",
            "[ 95%] 01:11:48,580 → 01:11:50,580  這樣會太危險嗎\n",
            "[ 95%] 01:11:50,580 → 01:11:52,580  你直接幫我查個指名好不好\n",
            "[ 96%] 01:11:54,840 → 01:11:56,840  等等等等等等\n",
            "[ 96%] 01:11:56,840 → 01:11:58,840  等等喔\n",
            "[ 96%] 01:11:58,840 → 01:12:00,840  我要建個頻道\n",
            "[ 96%] 01:12:00,000 → 01:12:02,000  你用平常名稱叫什麼?\n",
            "[ 96%] 01:12:04,000 → 01:12:06,000  工程部門\n",
            "[ 96%] 01:12:15,000 → 01:12:18,000  為什麼你現在用的那個Gmail是你自己的嗎?\n",
            "[ 96%] 01:12:18,000 → 01:12:20,000  你幫我貼在那個工程部門\n",
            "[ 97%] 01:12:20,000 → 01:12:40,000  我哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋哋\n",
            "[ 97%] 01:12:40,000 → 01:12:40,840  還是你本來就有在用?\n",
            "[ 97%] 01:12:40,840 → 01:12:41,340  沒有啊\n",
            "[ 97%] 01:12:42,000 → 01:12:43,840  那是我的主力帳號啊\n",
            "[ 97%] 01:12:43,840 → 01:12:45,160  因為這個帳號\n",
            "[ 97%] 01:12:45,160 → 01:12:46,460  幼稚園的時候就創了\n",
            "[ 97%] 01:12:46,460 → 01:12:48,500  所以那個名字是亂打的\n",
            "[ 97%] 01:12:49,340 → 01:12:50,000  打動了\n",
            "[ 97%] 01:12:55,800 → 01:12:58,500  啊你剛剛那個婚姻紀錄有開完嗎?\n",
            "[ 97%] 01:12:58,840 → 01:12:59,340  你有打動嗎?\n",
            "[ 97%] 01:12:59,340 → 01:12:59,840  有有有\n",
            "[ 97%] 01:13:00,000 → 01:13:04,600  你可能要跟他講一下那個東西是幹嘛的\n",
            "[ 97%] 01:13:04,600 → 01:13:09,700  就是你傳到工程部門那個東西是幹嘛的\n",
            "[ 97%] 01:13:09,700 → 01:13:10,760  他可能不太知道\n",
            "[ 97%] 01:13:10,760 → 01:13:14,520  他拿iPhone還安儲\n",
            "[ 97%] 01:13:14,520 → 01:13:16,060  他拿iPhone\n",
            "[ 98%] 01:13:20,000 → 01:13:24,000  好了,我們要去尿尿,然後我要出發了,bye!\n",
            "[ 98%] 01:13:25,280 → 01:13:25,520  好\n",
            "[ 98%] 01:13:25,520 → 01:13:29,780  下午的會議如果需要你,我再call你進來可以嗎?\n",
            "[ 98%] 01:13:34,400 → 01:13:35,080  可以嗎?\n",
            "[ 98%] 01:13:37,020 → 01:13:39,540  哇,那我怎麼知道你什麼時候要call我進來?\n",
            "[ 98%] 01:13:40,000 → 01:13:42,800  好吧,那你就去忙,你就去做你自己的生意\n",
            "[ 98%] 01:13:42,800 → 01:13:43,800  如果你剛好有\n",
            "[ 98%] 01:13:43,800 → 01:13:45,600  我可以進來沒關係啊\n",
            "[ 98%] 01:13:45,600 → 01:13:47,100  好,那你就順便停\n",
            "[ 98%] 01:13:47,100 → 01:13:49,140  OK,好,Bye\n",
            "[ 98%] 01:13:49,140 → 01:13:52,360  2點啊,2點到4點\n",
            "[ 98%] 01:13:52,360 → 01:13:53,180  好\n",
            "[ 98%] 01:13:53,180 → 01:13:53,840  再見\n",
            "[ 99%] 01:14:00,000 → 01:14:29,980  Teksting av Nicolai Winther\n",
            "[ 99%] 01:14:20,000 → 01:14:49,980  Takk for att du så med.\n",
            "[100%] 01:14:40,000 → 01:15:09,980  Teksting av Nicolai Winther\n",
            "[100%] 01:15:00,000 → 01:15:29,980  Teksting av Nicolai Winther\n",
            "[8/8] 輸出 SRT / TXT ...\n",
            "→ 完成！\n",
            "  SRT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).srt\n",
            "  TXT: /content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).txt\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae82c25f33084774bf7b06bde73c997d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_load_from_file_impl: using device CUDA0 (Tesla T4) - 14974 MiB free\n",
            "llama_model_loader: loaded meta data with 37 key-value pairs and 459 tensors from /root/.cache/huggingface/hub/models--unsloth--gpt-oss-20b-GGUF/snapshots/c6cedd4259adbfe7e4d4d983a0400bf4cc38e7db/gpt-oss-20b-Q4_K_M.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = gpt-oss\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   3:                           general.basename str              = Gpt-Oss-20B\n",
            "llama_model_loader: - kv   4:                       general.quantized_by str              = Unsloth\n",
            "llama_model_loader: - kv   5:                         general.size_label str              = 20B\n",
            "llama_model_loader: - kv   6:                            general.license str              = apache-2.0\n",
            "llama_model_loader: - kv   7:                           general.repo_url str              = https://huggingface.co/unsloth\n",
            "llama_model_loader: - kv   8:                               general.tags arr[str,2]       = [\"vllm\", \"text-generation\"]\n",
            "llama_model_loader: - kv   9:                        gpt-oss.block_count u32              = 24\n",
            "llama_model_loader: - kv  10:                     gpt-oss.context_length u32              = 131072\n",
            "llama_model_loader: - kv  11:                   gpt-oss.embedding_length u32              = 2880\n",
            "llama_model_loader: - kv  12:                gpt-oss.feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  13:               gpt-oss.attention.head_count u32              = 64\n",
            "llama_model_loader: - kv  14:            gpt-oss.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  15:                     gpt-oss.rope.freq_base f32              = 150000.000000\n",
            "llama_model_loader: - kv  16:   gpt-oss.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  17:                       gpt-oss.expert_count u32              = 32\n",
            "llama_model_loader: - kv  18:                  gpt-oss.expert_used_count u32              = 4\n",
            "llama_model_loader: - kv  19:               gpt-oss.attention.key_length u32              = 64\n",
            "llama_model_loader: - kv  20:             gpt-oss.attention.value_length u32              = 64\n",
            "llama_model_loader: - kv  21:           gpt-oss.attention.sliding_window u32              = 128\n",
            "llama_model_loader: - kv  22:         gpt-oss.expert_feed_forward_length u32              = 2880\n",
            "llama_model_loader: - kv  23:                  gpt-oss.rope.scaling.type str              = yarn\n",
            "llama_model_loader: - kv  24:                gpt-oss.rope.scaling.factor f32              = 32.000000\n",
            "llama_model_loader: - kv  25: gpt-oss.rope.scaling.original_context_length u32              = 4096\n",
            "llama_model_loader: - kv  26:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  27:                         tokenizer.ggml.pre str              = gpt-4o\n",
            "llama_model_loader: - kv  28:                      tokenizer.ggml.tokens arr[str,201088]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  29:                  tokenizer.ggml.token_type arr[i32,201088]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  30:                      tokenizer.ggml.merges arr[str,446189]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  31:                tokenizer.ggml.bos_token_id u32              = 199998\n",
            "llama_model_loader: - kv  32:                tokenizer.ggml.eos_token_id u32              = 200002\n",
            "llama_model_loader: - kv  33:            tokenizer.ggml.padding_token_id u32              = 200017\n",
            "llama_model_loader: - kv  34:                    tokenizer.chat_template str              = {# Chat template fixes by Unsloth #}\\n...\n",
            "llama_model_loader: - kv  35:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  36:                          general.file_type u32              = 15\n",
            "llama_model_loader: - type  f32:  289 tensors\n",
            "llama_model_loader: - type q5_0:   61 tensors\n",
            "llama_model_loader: - type q8_0:   13 tensors\n",
            "llama_model_loader: - type q4_K:   24 tensors\n",
            "llama_model_loader: - type mxfp4:   72 tensors\n",
            "print_info: file format = GGUF V3 (latest)\n",
            "print_info: file type   = Q4_K - Medium\n",
            "print_info: file size   = 10.81 GiB (4.44 BPW) \n",
            "init_tokenizer: initializing tokenizer for type 2\n",
            "load: control token: 200017 '<|reserved_200017|>' is not marked as EOG\n",
            "load: control token: 200014 '<|reserved_200014|>' is not marked as EOG\n",
            "load: control token: 200011 '<|reserved_200011|>' is not marked as EOG\n",
            "load: control token: 200009 '<|reserved_200009|>' is not marked as EOG\n",
            "load: control token: 200008 '<|message|>' is not marked as EOG\n",
            "load: control token: 200006 '<|start|>' is not marked as EOG\n",
            "load: control token: 200004 '<|reserved_200004|>' is not marked as EOG\n",
            "load: control token: 200003 '<|constrain|>' is not marked as EOG\n",
            "load: control token: 200000 '<|reserved_200000|>' is not marked as EOG\n",
            "load: control token: 200005 '<|channel|>' is not marked as EOG\n",
            "load: control token: 200010 '<|reserved_200010|>' is not marked as EOG\n",
            "load: control token: 200016 '<|reserved_200016|>' is not marked as EOG\n",
            "load: control token: 200013 '<|reserved_200013|>' is not marked as EOG\n",
            "load: control token: 199998 '<|startoftext|>' is not marked as EOG\n",
            "load: control token: 200018 '<|endofprompt|>' is not marked as EOG\n",
            "load: control token: 200001 '<|reserved_200001|>' is not marked as EOG\n",
            "load: control token: 200015 '<|reserved_200015|>' is not marked as EOG\n",
            "load: printing all EOG tokens:\n",
            "load:   - 199999 ('<|endoftext|>')\n",
            "load:   - 200002 ('<|return|>')\n",
            "load:   - 200007 ('<|end|>')\n",
            "load:   - 200012 ('<|call|>')\n",
            "load: special_eog_ids contains both '<|return|>' and '<|call|>' tokens, removing '<|end|>' token from EOG list\n",
            "load: special tokens cache size = 21\n",
            "load: token to piece cache size = 1.3332 MB\n",
            "print_info: arch             = gpt-oss\n",
            "print_info: vocab_only       = 0\n",
            "print_info: n_ctx_train      = 131072\n",
            "print_info: n_embd           = 2880\n",
            "print_info: n_layer          = 24\n",
            "print_info: n_head           = 64\n",
            "print_info: n_head_kv        = 8\n",
            "print_info: n_rot            = 64\n",
            "print_info: n_swa            = 128\n",
            "print_info: is_swa_any       = 1\n",
            "print_info: n_embd_head_k    = 64\n",
            "print_info: n_embd_head_v    = 64\n",
            "print_info: n_gqa            = 8\n",
            "print_info: n_embd_k_gqa     = 512\n",
            "print_info: n_embd_v_gqa     = 512\n",
            "print_info: f_norm_eps       = 0.0e+00\n",
            "print_info: f_norm_rms_eps   = 1.0e-05\n",
            "print_info: f_clamp_kqv      = 0.0e+00\n",
            "print_info: f_max_alibi_bias = 0.0e+00\n",
            "print_info: f_logit_scale    = 0.0e+00\n",
            "print_info: f_attn_scale     = 0.0e+00\n",
            "print_info: n_ff             = 2880\n",
            "print_info: n_expert         = 32\n",
            "print_info: n_expert_used    = 4\n",
            "print_info: causal attn      = 1\n",
            "print_info: pooling type     = 0\n",
            "print_info: rope type        = 2\n",
            "print_info: rope scaling     = yarn\n",
            "print_info: freq_base_train  = 150000.0\n",
            "print_info: freq_scale_train = 0.03125\n",
            "print_info: n_ctx_orig_yarn  = 4096\n",
            "print_info: rope_finetuned   = unknown\n",
            "print_info: model type       = ?B\n",
            "print_info: model params     = 20.91 B\n",
            "print_info: general.name     = Gpt-Oss-20B\n",
            "print_info: n_ff_exp         = 2880\n",
            "print_info: vocab type       = BPE\n",
            "print_info: n_vocab          = 201088\n",
            "print_info: n_merges         = 446189\n",
            "print_info: BOS token        = 199998 '<|startoftext|>'\n",
            "print_info: EOS token        = 200002 '<|return|>'\n",
            "print_info: EOT token        = 199999 '<|endoftext|>'\n",
            "print_info: PAD token        = 200017 '<|reserved_200017|>'\n",
            "print_info: LF token         = 198 'Ċ'\n",
            "print_info: EOG token        = 199999 '<|endoftext|>'\n",
            "print_info: EOG token        = 200002 '<|return|>'\n",
            "print_info: EOG token        = 200012 '<|call|>'\n",
            "print_info: max token length = 256\n",
            "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
            "load_tensors: layer   0 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   1 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   2 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   3 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   4 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   5 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   6 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   7 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer   8 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer   9 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  10 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  11 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  12 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  13 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  14 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  15 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  16 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  17 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  18 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  19 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  20 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  21 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  22 assigned to device CUDA0, is_swa = 1\n",
            "load_tensors: layer  23 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: layer  24 assigned to device CUDA0, is_swa = 0\n",
            "load_tensors: tensor 'token_embd.weight' (q5_0) (and 0 others) cannot be used with preferred buffer type CUDA_Host, using CPU instead\n",
            "load_tensors: offloading 24 repeating layers to GPU\n",
            "load_tensors: offloading output layer to GPU\n",
            "load_tensors: offloaded 25/25 layers to GPU\n",
            "load_tensors:        CUDA0 model buffer size = 10694.15 MiB\n",
            "load_tensors:   CPU_Mapped model buffer size =   379.71 MiB\n",
            "...............................................................................\n",
            "llama_context: constructing llama_context\n",
            "llama_context: n_seq_max     = 1\n",
            "llama_context: n_ctx         = 8192\n",
            "llama_context: n_ctx_per_seq = 8192\n",
            "llama_context: n_batch       = 512\n",
            "llama_context: n_ubatch      = 512\n",
            "llama_context: causal_attn   = 1\n",
            "llama_context: flash_attn    = 0\n",
            "llama_context: kv_unified    = false\n",
            "llama_context: freq_base     = 150000.0\n",
            "llama_context: freq_scale    = 0.03125\n",
            "llama_context: n_ctx_per_seq (8192) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "set_abort_callback: call\n",
            "llama_context:  CUDA_Host  output buffer size =     0.77 MiB\n",
            "create_memory: n_ctx = 8192 (padded)\n",
            "llama_kv_cache_unified_iswa: using full-size SWA cache (ref: https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)\n",
            "llama_kv_cache_unified_iswa: creating non-SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: skipped\n",
            "llama_kv_cache_unified: layer   1: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   2: skipped\n",
            "llama_kv_cache_unified: layer   3: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   4: skipped\n",
            "llama_kv_cache_unified: layer   5: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   6: skipped\n",
            "llama_kv_cache_unified: layer   7: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   8: skipped\n",
            "llama_kv_cache_unified: layer   9: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  10: skipped\n",
            "llama_kv_cache_unified: layer  11: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  12: skipped\n",
            "llama_kv_cache_unified: layer  13: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  14: skipped\n",
            "llama_kv_cache_unified: layer  15: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  16: skipped\n",
            "llama_kv_cache_unified: layer  17: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  18: skipped\n",
            "llama_kv_cache_unified: layer  19: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  20: skipped\n",
            "llama_kv_cache_unified: layer  21: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  22: skipped\n",
            "llama_kv_cache_unified: layer  23: dev = CUDA0\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_kv_cache_unified_iswa: creating     SWA KV cache, size = 8192 cells\n",
            "llama_kv_cache_unified: layer   0: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   1: skipped\n",
            "llama_kv_cache_unified: layer   2: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   3: skipped\n",
            "llama_kv_cache_unified: layer   4: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   5: skipped\n",
            "llama_kv_cache_unified: layer   6: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   7: skipped\n",
            "llama_kv_cache_unified: layer   8: dev = CUDA0\n",
            "llama_kv_cache_unified: layer   9: skipped\n",
            "llama_kv_cache_unified: layer  10: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  11: skipped\n",
            "llama_kv_cache_unified: layer  12: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  13: skipped\n",
            "llama_kv_cache_unified: layer  14: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  15: skipped\n",
            "llama_kv_cache_unified: layer  16: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  17: skipped\n",
            "llama_kv_cache_unified: layer  18: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  19: skipped\n",
            "llama_kv_cache_unified: layer  20: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  21: skipped\n",
            "llama_kv_cache_unified: layer  22: dev = CUDA0\n",
            "llama_kv_cache_unified: layer  23: skipped\n",
            "llama_kv_cache_unified:      CUDA0 KV buffer size =   192.00 MiB\n",
            "llama_kv_cache_unified: size =  192.00 MiB (  8192 cells,  12 layers,  1/1 seqs), K (f16):   96.00 MiB, V (f16):   96.00 MiB\n",
            "llama_context: enumerating backends\n",
            "llama_context: backend_ptrs.size() = 2\n",
            "llama_context: max_nodes = 3672\n",
            "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
            "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
            "llama_context:      CUDA0 compute buffer size =  1087.26 MiB\n",
            "llama_context:  CUDA_Host compute buffer size =    41.64 MiB\n",
            "llama_context: graph nodes  = 1446\n",
            "llama_context: graph splits = 2\n",
            "CUDA : ARCHS = 500,520,530,600,610,620,700,720,750,800,860,870,890,900 | FORCE_MMQ = 1 | USE_GRAPHS = 1 | PEER_MAX_BATCH_SIZE = 128 | CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | BMI2 = 1 | LLAMAFILE = 1 | OPENMP = 1 | REPACK = 1 | \n",
            "Model metadata: {'general.file_type': '15', 'general.quantization_version': '2', 'tokenizer.chat_template': '{# Chat template fixes by Unsloth #}\\n{#-\\n  In addition to the normal inputs of `messages` and `tools`, this template also accepts the\\n  following kwargs:\\n  - \"builtin_tools\": A list, can contain \"browser\" and/or \"python\".\\n  - \"model_identity\": A string that optionally describes the model identity.\\n  - \"reasoning_effort\": A string that describes the reasoning effort, defaults to \"medium\".\\n #}\\n\\n{#- Tool Definition Rendering ============================================== #}\\n{%- macro render_typescript_type(param_spec, required_params, is_nullable=false) -%}\\n    {%- if param_spec.type == \"array\" -%}\\n        {%- if param_spec[\\'items\\'] -%}\\n            {%- if param_spec[\\'items\\'][\\'type\\'] == \"string\" -%}\\n                {{- \"string[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"number\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"integer\" -%}\\n                {{- \"number[]\" }}\\n            {%- elif param_spec[\\'items\\'][\\'type\\'] == \"boolean\" -%}\\n                {{- \"boolean[]\" }}\\n            {%- else -%}\\n                {%- set inner_type = render_typescript_type(param_spec[\\'items\\'], required_params) -%}\\n                {%- if inner_type == \"object | object\" or inner_type|length > 50 -%}\\n                    {{- \"any[]\" }}\\n                {%- else -%}\\n                    {{- inner_type + \"[]\" }}\\n                {%- endif -%}\\n            {%- endif -%}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- else -%}\\n            {{- \"any[]\" }}\\n            {%- if param_spec.nullable -%}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type is defined and param_spec.type is iterable and param_spec.type is not string and param_spec.type is not mapping and param_spec.type[0] is defined -%}\\n        {#- Handle array of types like [\"object\", \"object\"] from Union[dict, list] #}\\n        {%- if param_spec.type | length > 1 -%}\\n            {{- param_spec.type | join(\" | \") }}\\n        {%- else -%}\\n            {{- param_spec.type[0] }}\\n        {%- endif -%}\\n    {%- elif param_spec.oneOf -%}\\n        {#- Handle oneOf schemas - check for complex unions and fallback to any #}\\n        {%- set has_object_variants = false -%}\\n        {%- for variant in param_spec.oneOf -%}\\n            {%- if variant.type == \"object\" -%}\\n                {%- set has_object_variants = true -%}\\n            {%- endif -%}\\n        {%- endfor -%}\\n        {%- if has_object_variants and param_spec.oneOf|length > 1 -%}\\n            {{- \"any\" }}\\n        {%- else -%}\\n            {%- for variant in param_spec.oneOf -%}\\n                {{- render_typescript_type(variant, required_params) -}}\\n                {%- if variant.description %}\\n                    {{- \"// \" + variant.description }}\\n                {%- endif -%}\\n                {%- if variant.default is defined %}\\n                    {{ \"// default: \" + variant.default|tojson }}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \" | \" }}\\n                {% endif -%}\\n            {%- endfor -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"string\" -%}\\n        {%- if param_spec.enum -%}\\n            {{- \\'\"\\' + param_spec.enum|join(\\'\" | \"\\') + \\'\"\\' -}}\\n        {%- else -%}\\n            {{- \"string\" }}\\n            {%- if param_spec.nullable %}\\n                {{- \" | null\" }}\\n            {%- endif -%}\\n        {%- endif -%}\\n    {%- elif param_spec.type == \"number\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"integer\" -%}\\n        {{- \"number\" }}\\n    {%- elif param_spec.type == \"boolean\" -%}\\n        {{- \"boolean\" }}\\n\\n    {%- elif param_spec.type == \"object\" -%}\\n        {%- if param_spec.properties -%}\\n            {{- \"{\\\\n\" }}\\n            {%- for prop_name, prop_spec in param_spec.properties.items() -%}\\n                {{- prop_name -}}\\n                {%- if prop_name not in (param_spec.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{ render_typescript_type(prop_spec, param_spec.required or []) }}\\n                {%- if not loop.last -%}\\n                    {{-\", \" }}\\n                {%- endif -%}\\n            {%- endfor -%}\\n            {{- \"}\" }}\\n        {%- else -%}\\n            {{- \"object\" }}\\n        {%- endif -%}\\n    {%- else -%}\\n        {{- \"any\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{%- macro render_tool_namespace(namespace_name, tools) -%}\\n    {{- \"## \" + namespace_name + \"\\\\n\\\\n\" }}\\n    {{- \"namespace \" + namespace_name + \" {\\\\n\\\\n\" }}\\n    {%- for tool in tools %}\\n        {%- set tool = tool.function %}\\n        {{- \"// \" + tool.description + \"\\\\n\" }}\\n        {{- \"type \"+ tool.name + \" = \" }}\\n        {%- if tool.parameters and tool.parameters.properties %}\\n            {{- \"(_: {\\\\n\" }}\\n            {%- for param_name, param_spec in tool.parameters.properties.items() %}\\n                {%- if param_spec.description %}\\n                    {{- \"// \" + param_spec.description + \"\\\\n\" }}\\n                {%- endif %}\\n                {{- param_name }}\\n                {%- if param_name not in (tool.parameters.required or []) -%}\\n                    {{- \"?\" }}\\n                {%- endif -%}\\n                {{- \": \" }}\\n                {{- render_typescript_type(param_spec, tool.parameters.required or []) }}\\n                {%- if param_spec.default is defined -%}\\n                    {%- if param_spec.enum %}\\n                        {{- \", // default: \" + param_spec.default }}\\n                    {%- elif param_spec.oneOf %}\\n                        {{- \"// default: \" + param_spec.default }}\\n                    {%- else %}\\n                        {{- \", // default: \" + param_spec.default|tojson }}\\n                    {%- endif -%}\\n                {%- endif -%}\\n                {%- if not loop.last %}\\n                    {{- \",\\\\n\" }}\\n                {%- else %}\\n                    {{- \",\\\\n\" }}\\n                {%- endif -%}\\n            {%- endfor %}\\n            {{- \"}) => any;\\\\n\\\\n\" }}\\n        {%- else -%}\\n            {{- \"() => any;\\\\n\\\\n\" }}\\n        {%- endif -%}\\n    {%- endfor %}\\n    {{- \"} // namespace \" + namespace_name }}\\n{%- endmacro -%}\\n\\n{%- macro render_builtin_tools(browser_tool, python_tool) -%}\\n    {%- if browser_tool %}\\n        {{- \"## browser\\\\n\\\\n\" }}\\n        {{- \"// Tool for browsing.\\\\n\" }}\\n        {{- \"// The `cursor` appears in brackets before each browsing display: `[{cursor}]`.\\\\n\" }}\\n        {{- \"// Cite information from the tool using the following format:\\\\n\" }}\\n        {{- \"// `【{cursor}†L{line_start}(-L{line_end})?】`, for example: `【6†L9-L11】` or `【8†L3】`.\\\\n\" }}\\n        {{- \"// Do not quote more than 10 words directly from the tool output.\\\\n\" }}\\n        {{- \"// sources=web (default: web)\\\\n\" }}\\n        {{- \"namespace browser {\\\\n\\\\n\" }}\\n        {{- \"// Searches for information related to `query` and displays `topn` results.\\\\n\" }}\\n        {{- \"type search = (_: {\\\\n\" }}\\n        {{- \"query: string,\\\\n\" }}\\n        {{- \"topn?: number, // default: 10\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Opens the link `id` from the page indicated by `cursor` starting at line number `loc`, showing `num_lines` lines.\\\\n\" }}\\n        {{- \"// Valid link ids are displayed with the formatting: `【{id}†.*】`.\\\\n\" }}\\n        {{- \"// If `cursor` is not provided, the most recent page is implied.\\\\n\" }}\\n        {{- \"// If `id` is a string, it is treated as a fully qualified URL associated with `source`.\\\\n\" }}\\n        {{- \"// If `loc` is not provided, the viewport will be positioned at the beginning of the document or centered on the most relevant passage, if available.\\\\n\" }}\\n        {{- \"// Use this function without `id` to scroll to a new location of an opened page.\\\\n\" }}\\n        {{- \"type open = (_: {\\\\n\" }}\\n        {{- \"id?: number | string, // default: -1\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"loc?: number, // default: -1\\\\n\" }}\\n        {{- \"num_lines?: number, // default: -1\\\\n\" }}\\n        {{- \"view_source?: boolean, // default: false\\\\n\" }}\\n        {{- \"source?: string,\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"// Finds exact matches of `pattern` in the current page, or the page given by `cursor`.\\\\n\" }}\\n        {{- \"type find = (_: {\\\\n\" }}\\n        {{- \"pattern: string,\\\\n\" }}\\n        {{- \"cursor?: number, // default: -1\\\\n\" }}\\n        {{- \"}) => any;\\\\n\\\\n\" }}\\n        {{- \"} // namespace browser\\\\n\\\\n\" }}\\n    {%- endif -%}\\n\\n    {%- if python_tool %}\\n        {{- \"## python\\\\n\\\\n\" }}\\n        {{- \"Use this tool to execute Python code in your chain of thought. The code will not be shown to the user. This tool should be used for internal reasoning, but not for code that is intended to be visible to the user (e.g. when creating plots, tables, or files).\\\\n\\\\n\" }}\\n        {{- \"When you send a message containing Python code to python, it will be executed in a stateful Jupyter notebook environment. python will respond with the output of the execution or time out after 120.0 seconds. The drive at \\'/mnt/data\\' can be used to save and persist user files. Internet access for this session is UNKNOWN. Depends on the cluster.\\\\n\\\\n\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- System Message Construction ============================================ #}\\n{%- macro build_system_message() -%}\\n    {%- if model_identity is not defined %}\\n        {%- set model_identity = \"You are ChatGPT, a large language model trained by OpenAI.\" %}\\n    {%- endif %}\\n    {{- model_identity + \"\\\\n\" }}\\n    {{- \"Knowledge cutoff: 2024-06\\\\n\" }}\\n    {{- \"Current date: \" + strftime_now(\"%Y-%m-%d\") + \"\\\\n\\\\n\" }}\\n    {%- if reasoning_effort is not defined %}\\n        {%- set reasoning_effort = \"medium\" %}\\n    {%- endif %}\\n    {{- \"Reasoning: \" + reasoning_effort + \"\\\\n\\\\n\" }}\\n    {%- if builtin_tools is defined and builtin_tools is not none %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {%- set available_builtin_tools = namespace(browser=false, python=false) %}\\n        {%- for tool in builtin_tools %}\\n            {%- if tool == \"browser\" %}\\n                {%- set available_builtin_tools.browser = true %}\\n            {%- elif tool == \"python\" %}\\n                {%- set available_builtin_tools.python = true %}\\n            {%- endif %}\\n        {%- endfor %}\\n        {{- render_builtin_tools(available_builtin_tools.browser, available_builtin_tools.python) }}\\n    {%- endif -%}\\n    {{- \"# Valid channels: analysis, commentary, final. Channel must be included for every message.\" }}\\n    {%- if tools -%}\\n        {{- \"\\\\nCalls to these tools must go to the commentary channel: \\'functions\\'.\" }}\\n    {%- endif -%}\\n{%- endmacro -%}\\n\\n{#- Main Template Logic ================================================= #}\\n{#- Set defaults #}\\n\\n{#- Render system message #}\\n{{- \"<|start|>system<|message|>\" }}\\n{{- build_system_message() }}\\n{{- \"<|end|>\" }}\\n\\n{#- Extract developer message #}\\n{%- if developer_instructions is defined and developer_instructions is not none %}\\n    {%- set developer_message = developer_instructions %}\\n    {%- set loop_messages = messages %}\\n{%- elif messages[0].role == \"developer\" or messages[0].role == \"system\" %}\\n    {%- set developer_message = messages[0].content %}\\n    {%- set loop_messages = messages[1:] %}\\n{%- else %}\\n    {%- set developer_message = \"\" %}\\n    {%- set loop_messages = messages %}\\n{%- endif %}\\n\\n{#- Render developer message #}\\n{%- if developer_message or tools %}\\n    {{- \"<|start|>developer<|message|>\" }}\\n    {%- if developer_message %}\\n        {{- \"# Instructions\\\\n\\\\n\" }}\\n        {{- developer_message }}\\n    {%- endif %}\\n    {%- if tools -%}\\n        {%- if developer_message %}\\n            {{- \"\\\\n\\\\n\" }}\\n        {%- endif %}\\n        {{- \"# Tools\\\\n\\\\n\" }}\\n        {{- render_tool_namespace(\"functions\", tools) }}\\n    {%- endif -%}\\n    {{- \"<|end|>\" }}\\n{%- endif %}\\n\\n{#- Render messages #}\\n{%- set last_tool_call = namespace(name=none) %}\\n{%- for message in loop_messages -%}\\n    {#- At this point only assistant/user/tool messages should remain #}\\n    {%- if message.role == \\'assistant\\' -%}\\n        {#- Checks to ensure the messages are being passed in the format we expect #}\\n        {%- if \"thinking\" in message %}\\n            {%- if \"<|channel|>analysis<|message|>\" in message.thinking or \"<|channel|>final<|message|>\" in message.thinking %}\\n                {{- raise_exception(\"You have passed a message containing <|channel|> tags in the thinking field. Instead of doing this, you should pass analysis messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'thinking\\' field, and final messages (the string between \\'<|message|>\\' and \\'<|end|>\\') in the \\'content\\' field.\") }}\\n            {%- endif %}\\n        {%- endif %}\\n        {%- if \"tool_calls\" in message %}\\n            {#- We need very careful handling here - we want to drop the tool call analysis message if the model #}\\n            {#- has output a later <|final|> message, but otherwise we want to retain it. This is the only case #}\\n            {#- when we render CoT/analysis messages in inference. #}\\n            {%- set future_final_message = namespace(found=false) %}\\n            {%- for future_message in loop_messages[loop.index:] %}\\n                {%- if future_message.role == \\'assistant\\' and \"tool_calls\" not in future_message %}\\n                    {%- set future_final_message.found = true %}\\n                {%- endif %}\\n            {%- endfor %}\\n            {#- We assume max 1 tool call per message, and so we infer the tool call name #}\\n            {#- in \"tool\" messages from the most recent assistant tool call name #}\\n            {%- set tool_call = message.tool_calls[0] %}\\n            {%- if tool_call.function %}\\n                {%- set tool_call = tool_call.function %}\\n            {%- endif %}\\n            {%- if message.content and message.thinking %}\\n                {{- raise_exception(\"Cannot pass both content and thinking in an assistant message with tool calls! Put the analysis message in one or the other, but not both.\") }}\\n            {%- elif message.content and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- elif message.thinking and not future_final_message.found %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {{- \"<|start|>assistant to=\" }}\\n            {{- \"functions.\" + tool_call.name + \"<|channel|>commentary \" }}\\n            {{- (tool_call.content_type if tool_call.content_type is defined else \"json\") + \"<|message|>\" }}\\n            {%- if tool_call.arguments is string %}\\n                {{- tool_call.arguments }}\\n            {%- else %}\\n                {{- tool_call.arguments|tojson }}\\n            {%- endif %}\\n            {{- \"<|call|>\" }}\\n            {%- set last_tool_call.name = tool_call.name %}\\n        {%- elif loop.last and not add_generation_prompt %}\\n            {#- Only render the CoT if the final turn is an assistant turn and add_generation_prompt is false #}\\n            {#- This is a situation that should only occur in training, never in inference. #}\\n            {%- if \"thinking\" in message %}\\n                {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.thinking + \"<|end|>\" }}\\n            {%- endif %}\\n            {#- <|return|> indicates the end of generation, but <|end|> does not #}\\n            {#- <|return|> should never be an input to the model, but we include it as the final token #}\\n            {#- when training, so the model learns to emit it. #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- elif \"thinking\" in message %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>analysis<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- else %}\\n            {#- CoT is dropped during all previous turns, so we never render it for inference #}\\n            {{- \"<|start|>assistant<|channel|>final<|message|>\" + message.content + \"<|end|>\" }}\\n            {%- set last_tool_call.name = none %}\\n        {%- endif %}\\n    {%- elif message.role == \\'tool\\' -%}\\n        {%- if last_tool_call.name is none %}\\n            {{- raise_exception(\"Message has tool role, but there was no previous assistant message with a tool call!\") }}\\n        {%- endif %}\\n        {{- \"<|start|>functions.\" + last_tool_call.name }}\\n        {%- if message.content is string %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content + \"<|end|>\" }}\\n        {%- else %}\\n            {{- \" to=assistant<|channel|>commentary<|message|>\" + message.content|tojson + \"<|end|>\" }}\\n        {%- endif %}\\n    {%- elif message.role == \\'user\\' -%}\\n        {{- \"<|start|>user<|message|>\" + message.content + \"<|end|>\" }}\\n    {%- endif -%}\\n{%- endfor -%}\\n\\n{#- Generation prompt #}\\n{%- if add_generation_prompt -%}\\n<|start|>assistant\\n{%- endif -%}\\n{# Copyright 2025-present Unsloth. Apache 2.0 License. Unsloth chat template fixes. Edited from ggml-org & OpenAI #}', 'gpt-oss.attention.head_count': '64', 'gpt-oss.rope.scaling.original_context_length': '4096', 'gpt-oss.feed_forward_length': '2880', 'general.repo_url': 'https://huggingface.co/unsloth', 'general.license': 'apache-2.0', 'general.size_label': '20B', 'general.type': 'model', 'tokenizer.ggml.padding_token_id': '200017', 'gpt-oss.context_length': '131072', 'general.quantized_by': 'Unsloth', 'gpt-oss.embedding_length': '2880', 'gpt-oss.block_count': '24', 'gpt-oss.attention.sliding_window': '128', 'tokenizer.ggml.pre': 'gpt-4o', 'general.architecture': 'gpt-oss', 'gpt-oss.rope.freq_base': '150000.000000', 'gpt-oss.attention.head_count_kv': '8', 'gpt-oss.attention.layer_norm_rms_epsilon': '0.000010', 'gpt-oss.expert_count': '32', 'general.basename': 'Gpt-Oss-20B', 'gpt-oss.attention.key_length': '64', 'gpt-oss.expert_used_count': '4', 'gpt-oss.expert_feed_forward_length': '2880', 'gpt-oss.rope.scaling.type': 'yarn', 'tokenizer.ggml.eos_token_id': '200002', 'gpt-oss.rope.scaling.factor': '32.000000', 'tokenizer.ggml.model': 'gpt2', 'general.name': 'Gpt-Oss-20B', 'gpt-oss.attention.value_length': '64', 'tokenizer.ggml.bos_token_id': '199998'}\n",
            "Available chat formats from metadata: chat_template.default\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "LLM model is not loaded. Cannot count tokens.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-685043203.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    584\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msegments\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_tokens_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m         \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtxt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-685043203.py\u001b[0m in \u001b[0;36mcount_tokens_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;31m# Check if llm is initialized before using it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'llm'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mllm\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m          \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LLM model is not loaded. Cannot count tokens.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: LLM model is not loaded. Cannot count tokens."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8652407f"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback shows that the `llm` object is still not initialized when `count_tokens_text` is called within the token-aware segmentation section (`[Summary 4/6]`). This means that the steps to install `llama-cpp-python` and load the LLM model (`[Summary 1/6]` and `[Summary 3/6]`) did not execute before the code reached `[Summary 4/6]`. Looking at the code, these steps are indeed placed after the transcription output section (`[8/8]`) and the determination of `summary_srt_path_abs`, but before the tokenization and summarization logic. The LLM model must be loaded before any function that uses `llm` is called. I need to move the `llama-cpp-python` installation and model loading steps to just before the summarization logic begins (`[Summary 2/6] Read SRT`) since the `count_tokens_text` function is used within the loop that processes the SRT segments. I will regenerate the full code with this corrected order. I will also keep the check within `count_tokens_text` and `llm_stream` just in case, although the reordering should prevent this error.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "YNEXiqBqHoFS",
        "outputId": "57a84cc5-710b-477d-d56b-fd8521c67c54"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Whisper Automatic Subtitle Generation: GPU Transcription + CPU Denoising + OpenCC Post-processing (Traditional/Simplified Conversion)\n",
        "# And LLM Summarization (GPT-OSS-20B / llama.cpp / CUDA)\n",
        "# - Transcription: faster-whisper (CUDA, compute: int8_float16→float16→int8)\n",
        "# - Denoising: ffmpeg afftdn (CPU)\n",
        "# - Progress: Real-time printing of \"current sentence + video total length percentage\"\n",
        "# - Network source download and output: MyDrive/whisper; Files in Drive: Output to the same folder\n",
        "# - LLM Summary: llama.cpp + GPT-OSS-20B GGUF for summarizing transcription\n",
        "# - Prompts \"Delete runtime and restart\" if download is blocked or abnormal\n",
        "# =========================================================\n",
        "\n",
        "# Restrict multithreading (more stable)\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# [1/8] Mount Google Drive\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "except:\n",
        "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "# Consolidated Imports\n",
        "import sys, gc, shutil, datetime, subprocess as sp\n",
        "from pathlib import Path\n",
        "import re, math, time, importlib, textwrap\n",
        "from typing import List, Tuple\n",
        "from IPython.display import display, Markdown\n",
        "import soundfile as sf\n",
        "from faster_whisper import WhisperModel\n",
        "from opencc import OpenCC\n",
        "import srt as _srt # Import srt as _srt to avoid name conflict later with the module itself\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "ROOT = Path(\"/content/gdrive/MyDrive\")\n",
        "WHISPER_DIR = ROOT / \"whisper\"\n",
        "WHISPER_DIR.mkdir(exist_ok=True, parents=True)\n",
        "os.chdir(ROOT)\n",
        "print(f\"→ 當前工作目錄：{os.getcwd()}\")\n",
        "\n",
        "# [2/8] User Form Parameters (Unified)\n",
        "#@markdown # Whisper Transcription & LLM Summary Pipeline\n",
        "\n",
        "#@markdown ## Input & Transcription Settings\n",
        "#@markdown **Input Source:** Google Drive file (relative to MyDrive) or video URL (YouTube/HTTP).\n",
        "filename = \"whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\"  #@param {type:\"string\"}\n",
        "#@markdown **Download Option:** Check to save network source files to `MyDrive/whisper`.\n",
        "save_video_to_google_drive = True  #@param {type:\"boolean\"}\n",
        "#@markdown **Whisper Model Size:** Choose a model size. `large-v3` requires more GPU VRAM; `medium` is a good alternative if VRAM is limited.\n",
        "model_size = \"large-v3\"  #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\"]\n",
        "#@markdown **Language:** Select the language for transcription. \"自動偵測\" (Auto-detect) is usually sufficient.\n",
        "language = \"自動偵測\"  #@param [\"自動偵測\", \"中文\", \"英文\"]\n",
        "#@markdown **Denoising:** Apply CPU-based denoising to the audio before transcription. `afftdn` is recommended.\n",
        "denoise_method = \"afftdn (建議)\"  #@param [\"afftdn (建議)\", \"none\"]\n",
        "#@markdown **Text Post-processing (OpenCC):** Convert the transcribed text (SRT/TXT output) between Simplified and Traditional Chinese variants.\n",
        "text_postprocess = \"臺灣繁體中文（預設）\"  #@param [\"臺灣繁體中文（預設）\",\"香港繁體中文\",\"大陸簡體中文\",\"關閉\"]\n",
        "#@markdown **YouTube Cookies (Optional):** Path to a Netscape-format cookies file (relative to MyDrive) for accessing age-restricted or member-only YouTube videos (e.g., `cookies/youtube.txt`).\n",
        "youtube_cookies_txt_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Summarization Settings\n",
        "#@markdown **SRT Input:** Path to the SRT file for summarization (relative to MyDrive or absolute). Leave empty to use the SRT generated by the transcription step above.\n",
        "summary_srt_path = \"\"  #@param {type:\"string\"}\n",
        "#@markdown **Topic Hint (Optional):** Provide a brief hint about the topic to guide the summarization process.\n",
        "topic_hint = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Output Paths\n",
        "#@markdown **Transcription Output Directory:** Directory where the generated SRT and TXT files will be saved (relative to MyDrive or absolute). Default is the input file's directory for local files, or `MyDrive/whisper` for network sources. This is determined automatically.\n",
        "# (Note: filename's directory is used if local, otherwise WHISPER_DIR. This parameter is more of an indicator of the default output base.)\n",
        "#@markdown **Summary Output Directory:** Directory where the final summary Markdown file will be saved (relative to MyDrive or absolute).\n",
        "summary_output_dir = \"/content/gdrive/MyDrive/whisper\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "language_code_map = {\"自動偵測\": None, \"中文\":\"zh\", \"英文\":\"en\"}\n",
        "language_code = language_code_map[language]\n",
        "\n",
        "# =========================================================\n",
        "# Developer Options\n",
        "# Advanced users can fine-tune parameters in this section.\n",
        "# Modify only if you understand the impact.\n",
        "# =========================================================\n",
        "DEBUG_MODE = False # Set to True for more detailed logging\n",
        "\n",
        "# --- Transcription Parameters ---\n",
        "TRANSCRIPTION_BEAM_SIZE_PRIMARY = 3\n",
        "TRANSCRIPTION_CHUNK_LENGTH_PRIMARY = 20\n",
        "TRANSCRIPTION_BEAM_SIZE_FALLBACK = 1 # Used if primary fails\n",
        "TRANSCRIPTION_CHUNK_LENGTH_FALLBACK = 15 # Used if primary fails\n",
        "\n",
        "# --- Denoising Parameters ---\n",
        "DENOISE_NOISE_FLOOR_DB = -25\n",
        "\n",
        "# --- Filtering Parameters ---\n",
        "FILTER_MIN_DURATION_SHORT = 1.5 # Minimum duration for short segments\n",
        "FILTER_AVG_LOGPROB_THRESHOLD = -1.0 # Avg log probability threshold for short segments\n",
        "FILTER_MIN_DURATION_SPEECH_PROB = 2.0 # Minimum duration for speech probability filtering\n",
        "FILTER_NO_SPEECH_PROB_THRESHOLD = 0.6 # No speech probability threshold\n",
        "\n",
        "# --- Summary Model Parameters ---\n",
        "REPO_ID   = \"unsloth/gpt-oss-20b-GGUF\"   # GGUF Model Repository\n",
        "GGUF_FILE = \"gpt-oss-20b-Q4_K_M.gguf\"    # Approx. 10.8GiB, T4 can run\n",
        "\n",
        "# --- Summary Inference Parameters (Increase available generation space to avoid truncation) ---\n",
        "ctx_window            = 8192\n",
        "map_max_new_tokens    = 512   # Segment output: original 256 -> 512 (approx. 350-450 chars)\n",
        "reduce_max_new_tokens = 1024  # Summary output: original 512 -> 1024 (approx. 700-900+ chars)\n",
        "temperature           = 0.2\n",
        "top_p                 = 0.9\n",
        "repeat_penalty        = 1.05\n",
        "# =========================================================\n",
        "# End of Developer Options\n",
        "# =========================================================\n",
        "\n",
        "\n",
        "# [3/8] Install Dependencies\n",
        "# Combine installation steps from both original cells\n",
        "if DEBUG_MODE: print(\"[Install] faster-whisper / yt-dlp / soundfile / opencc / srt / huggingface_hub / llama-cpp-python ...\")\n",
        "\n",
        "def pip_install(pkgs, extra_args=None, env=None):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"]\n",
        "    if extra_args:\n",
        "        cmd += extra_args\n",
        "    cmd += pkgs\n",
        "    return sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True, env=env)\n",
        "\n",
        "# Install common dependencies first\n",
        "common_missing = []\n",
        "try: import srt # check srt module directly after import as _srt\n",
        "except ModuleNotFoundError: common_missing.append(\"srt>=3.5.3\")\n",
        "try: from huggingface_hub import snapshot_download # check huggingface_hub module directly\n",
        "except ModuleNotFoundError: common_missing.append(\"huggingface_hub>=0.23.0\")\n",
        "try: import soundfile # check soundfile\n",
        "except ModuleNotFoundError: common_missing.append(\"soundfile\")\n",
        "try: import opencc # check opencc\n",
        "except ModuleNotFoundError: common_missing.append(\"opencc-python-reimplemented\")\n",
        "\n",
        "if common_missing:\n",
        "    if DEBUG_MODE: print(\"→ Installing common missing packages:\", \", \".join(common_missing))\n",
        "    r = pip_install(common_missing)\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"基礎依賴安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "# Install faster-whisper and yt-dlp separately as they were in the first cell\n",
        "try: from faster_whisper import WhisperModel # check faster_whisper\n",
        "except ModuleNotFoundError:\n",
        "    if DEBUG_MODE: print(\"→ Installing missing package: faster-whisper yt-dlp\")\n",
        "    r = pip_install([\"faster-whisper\", \"yt-dlp\"])\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"faster-whisper / yt-dlp 安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "\n",
        "def suggest_runtime_reset():\n",
        "    print(\"\\n🧹 建議動作（Colab）\")\n",
        "    print(\"1) 依序：『執行階段 Runtime』 → 『刪除執行階段/還原出廠設定 Factory reset runtime』\")\n",
        "    print(\"2) 重新執行本 Notebook（從掛載雲端硬碟那格開始）\\n\", flush=True)\n",
        "\n",
        "def run_cmd(cmd:list, check=True):\n",
        "    if DEBUG_MODE: print(\"  $\", \" \".join(cmd))\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"命令失敗：{' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "def is_youtube_url(s:str)->bool:\n",
        "    return isinstance(s, str) and (\"youtu.be\" in s or \"youtube.com\" in s)\n",
        "def is_http_url(s:str)->bool:\n",
        "    return isinstance(s, str) and s.lower().startswith(\"http\")\n",
        "def to_abs_mydrive(p:str)->Path:\n",
        "    return (Path(p) if p.startswith(\"/\") else (ROOT / p)).resolve()\n",
        "def fmt_ts_srt(t:float)->str:\n",
        "    h = int(t//3600); m = int((t%3600)//60); s = t - h*3600 - m*60\n",
        "    return f\"{h:02d}:{m:02d}:{int(s):02d},{int(round((s-int(s))*1000)):03d}\"\n",
        "def verify_wav_ok(path: Path)->bool:\n",
        "    try:\n",
        "        info = sf.info(str(path))\n",
        "        return info.samplerate > 0 and info.channels in (1, 2)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# OpenCC converter setup\n",
        "def build_opencc_pipeline(choice:str):\n",
        "    if choice.startswith(\"臺灣\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2tw')]\n",
        "    if choice.startswith(\"香港\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2hk')]\n",
        "    if choice.startswith(\"大陸\"):\n",
        "        return [OpenCC('t2s')]\n",
        "    return []  # Disable\n",
        "\n",
        "def apply_opencc(text:str, pipeline)->str:\n",
        "    for cc in pipeline:\n",
        "        text = cc.convert(text)\n",
        "    return text\n",
        "\n",
        "def ytdl(yturl:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting YouTube video ...\")\n",
        "    # Use sp.run instead of subprocess.run directly\n",
        "    cmd = [\"yt-dlp\", \"-f\", \"mp4\", \"-o\", str(tmp / \"%(title)s.%(ext)s\")]\n",
        "    if youtube_cookies_txt_path.strip():\n",
        "        cookies_abs = to_abs_mydrive(youtube_cookies_txt_path.strip())\n",
        "        if cookies_abs.exists():\n",
        "            cmd += [\"--cookies\", str(cookies_abs)]\n",
        "        else:\n",
        "            if DEBUG_MODE: print(f\"⚠️ 找不到 cookies 檔：{cookies_abs}（改為不帶 cookies）\")\n",
        "    cmd.append(yturl)\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        if \"Sign in to confirm\" in (p.stdout or \"\"):\n",
        "            print(\"\\n❗YouTube 要求登入/驗證，請提供 cookies 或先自行下載到雲端硬碟。\")\n",
        "        print(\"🔄 若多次失敗，請刪除執行階段並重啟後重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise RuntimeError(\"yt-dlp 下載失敗\")\n",
        "    files = list(tmp.glob(\"*\"))\n",
        "    if not files:\n",
        "        print(\"🔄 下載為空，建議刪除執行階段再重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise FileNotFoundError(\"YouTube 下載失敗：/tmp/dl 為空\")\n",
        "    f = files[0]\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(f, WHISPER_DIR / f.name)\n",
        "    return f\n",
        "\n",
        "def http_dl(url:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting HTTP(S) video ...\")\n",
        "    run_cmd([\"curl\", \"-L\", \"-o\", str(out), url])\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(out, WHISPER_DIR / out.name)\n",
        "    return out\n",
        "\n",
        "# Extract audio: ffmpeg -> 16k/mono WAV\n",
        "def ffmpeg_extract_wav(in_path:Path, out_wav:Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-vn\",\"-ac\",\"1\",\"-ar\",str(sr),\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 轉 WAV 失敗\")\n",
        "\n",
        "# CPU Denoising: ffmpeg afftdn\n",
        "def ffmpeg_afftdn(in_wav: Path, out_wav: Path, noise_floor_db=DENOISE_NOISE_FLOOR_DB):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-af\",f\"afftdn=nf={noise_floor_db}\",\n",
        "           \"-ac\",\"1\",\"-ar\",\"16000\",\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg afftdn 失敗\")\n",
        "\n",
        "# Safeguard: Repack WAV header if format is strange\n",
        "def ffmpeg_repack_wav(in_wav: Path, out_wav: Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-acodec\",\"pcm_s16le\",\"-ac\",\"1\",\"-ar\",str(sr),str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 重包 WAV 失敗\")\n",
        "\n",
        "# [4/8] Parse Source (Transcription) - Uses 'filename' and 'save_video_to_google_drive'\n",
        "if DEBUG_MODE: print(\"[4/8] Parsing input source ...\")\n",
        "try:\n",
        "    if is_youtube_url(filename):\n",
        "        src_path = ytdl(filename); out_base_dir = WHISPER_DIR\n",
        "    elif is_http_url(filename):\n",
        "        src_path = http_dl(filename); out_base_dir = WHISPER_DIR\n",
        "    else:\n",
        "        src_path = to_abs_mydrive(filename)\n",
        "        if not src_path.exists(): raise FileNotFoundError(f\"找不到檔案：{src_path}\")\n",
        "        out_base_dir = src_path.parent\n",
        "except Exception as e:\n",
        "    print(f\"\\n⛔ 來源解析/下載失敗：{e}\")\n",
        "    print(\"🔄 請刪除執行階段並重新啟動後重跑。\"); suggest_runtime_reset(); raise\n",
        "\n",
        "print(f\"→ 來源檔：{src_path}\")\n",
        "print(f\"→ 輸出資料夾：{out_base_dir}\")\n",
        "\n",
        "# [5/8] Extract Audio & CPU Denoising (Transcription) - Uses 'denoise_method' and 'DENOISE_NOISE_FLOOR_DB'\n",
        "AUDIO_16K = Path(\"/tmp/audio_16k.wav\")\n",
        "if DEBUG_MODE: print(\"[5/8] Extracting audio (ffmpeg → 16k/mono WAV) ...\")\n",
        "ffmpeg_extract_wav(src_path, AUDIO_16K, sr=16000)\n",
        "\n",
        "if denoise_method.startswith(\"afftdn\"):\n",
        "    if DEBUG_MODE: print(\"[5.5/8] Denoising (ffmpeg afftdn, CPU) ...\")\n",
        "    DENOISED = Path(\"/tmp/audio_16k_denoised.wav\")\n",
        "    ffmpeg_afftdn(AUDIO_16K, DENOISED, noise_floor_db=DENOISE_NOISE_FLOOR_DB)\n",
        "    denoised_audio = DENOISED if verify_wav_ok(DENOISED) else AUDIO_16K\n",
        "else:\n",
        "    denoised_audio = AUDIO_16K\n",
        "\n",
        "if not verify_wav_ok(denoised_audio):\n",
        "    if DEBUG_MODE: print(\"  - 音訊格式異常；嘗試重包 WAV ...\")\n",
        "    FIXED = Path(\"/tmp/audio_16k_fixed.wav\")\n",
        "    ffmpeg_repack_wav(denoised_audio, FIXED, sr=16000)\n",
        "    denoised_audio = FIXED\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ 最終輸入音訊：{denoised_audio}\")\n",
        "\n",
        "# [6/8] Load faster-whisper (GPU enforced) - Uses 'model_size'\n",
        "if DEBUG_MODE: print(\"[6/8] Loading faster-whisper model (GPU) ...\")\n",
        "device = \"cuda\"  # Enforce GPU\n",
        "model = None; last_err = None\n",
        "for ctype in [\"int8_float16\", \"float16\", \"int8\"]:\n",
        "    try:\n",
        "        if DEBUG_MODE: print(f\"  - Trying compute_type={ctype}\")\n",
        "        model = WhisperModel(model_size, device=device, compute_type=ctype)\n",
        "        if DEBUG_MODE: print(\"  - Model loaded successfully\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        last_err = e\n",
        "        if DEBUG_MODE: print(f\"  - Load failed: {e}\")\n",
        "if model is None:\n",
        "    print(\"\\n⛔ GPU 模型載入失敗。請確認『變更執行階段類型』選了 GPU（T4/A100），或刪除執行階段後重試。\")\n",
        "    suggest_runtime_reset()\n",
        "    raise RuntimeError(f\"無法載入模型：{last_err}\")\n",
        "\n",
        "gc.collect()  # Clean up before transcription (safety)\n",
        "\n",
        "# [7/8] Transcribe (GPU; real-time progress per segment) - Uses 'language_code', 'TRANSCRIPTION_BEAM_SIZE_PRIMARY', 'TRANSCRIPTION_CHUNK_LENGTH_PRIMARY', 'TRANSCRIPTION_BEAM_SIZE_FALLBACK', 'TRANSCRIPTION_CHUNK_LENGTH_FALLBACK'\n",
        "if DEBUG_MODE: print(f\"[7/8] Starting transcription (GPU: beam={TRANSCRIPTION_BEAM_SIZE_PRIMARY} / chunk={TRANSCRIPTION_CHUNK_LENGTH_PRIMARY}s / no VAD) ...\")\n",
        "\n",
        "def transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY):\n",
        "    return model.transcribe(\n",
        "        str(denoised_audio),\n",
        "        task=\"transcribe\",\n",
        "        language=language_code,\n",
        "        temperature=0.0,\n",
        "        condition_on_previous_text=False,\n",
        "        compression_ratio_threshold=2.4,\n",
        "        log_prob_threshold=-1.0,\n",
        "        no_speech_threshold=0.6,\n",
        "        beam_size=_beam,\n",
        "        chunk_length=_chunk,\n",
        "        vad_filter=False,\n",
        "        word_timestamps=False\n",
        "    )\n",
        "\n",
        "try:\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY)\n",
        "except Exception as e:\n",
        "    if DEBUG_MODE: print(f\"  - First transcription failed: {e}\\n    → Trying more conservative (beam={TRANSCRIPTION_BEAM_SIZE_FALLBACK}, chunk={TRANSCRIPTION_CHUNK_LENGTH_FALLBACK}) ...\")\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_FALLBACK, _chunk=TRANSCRIPTION_CHUNK_LENGTH_FALLBACK)\n",
        "\n",
        "# Display percentage based on total video duration\n",
        "duration = float(getattr(info, \"duration\", 0.0) or 0.0)\n",
        "if duration <= 0: duration = 1.0\n",
        "\n",
        "segments = []\n",
        "filtered = []\n",
        "\n",
        "if DEBUG_MODE:\n",
        "    print(f\"  - Detected language: {getattr(info,'language','未知')} (p={getattr(info,'language_probability',0):.2f})\")\n",
        "    print(f\"  - Audio length: {duration:.2f}s\")\n",
        "\n",
        "for s in seg_iter:\n",
        "    pct = int(min(100, round((s.end / duration) * 100)))\n",
        "    print(f\"[{pct:3d}%] {fmt_ts_srt(s.start)} → {fmt_ts_srt(s.end)}  {s.text.strip()}\", flush=True)\n",
        "    segments.append(s)\n",
        "\n",
        "    # Low confidence/high no-speech short segment filtering (no blacklist) - Uses FILTER_* parameters\n",
        "    keep = True\n",
        "    seg_dur = float(s.end - s.start)\n",
        "    if seg_dur < FILTER_MIN_DURATION_SHORT and getattr(s, \"avg_logprob\", None) is not None and s.avg_logprob < FILTER_AVG_LOGPROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if seg_dur < FILTER_MIN_DURATION_SPEECH_PROB and getattr(s, \"no_speech_prob\", None) is not None and s.no_speech_prob > FILTER_NO_SPEECH_THRESHOLD:\n",
        "        keep = False\n",
        "    if keep:\n",
        "        filtered.append(s)\n",
        "\n",
        "if DEBUG_MODE: print(f\"  - Number of segments: Before filtering {len(segments)} → After filtering {len(filtered)}\")\n",
        "\n",
        "# ---- OpenCC Normalization (for output text) ---- - Uses 'text_postprocess'\n",
        "pipeline = build_opencc_pipeline(text_postprocess)\n",
        "def norm(txt: str) -> str:\n",
        "    return apply_opencc(txt, pipeline) if pipeline else txt\n",
        "\n",
        "# [8/8] Output (text after OpenCC) - Uses 'out_base_dir' (derived from 'filename')\n",
        "print(\"[8/8] 輸出 SRT / TXT ...\")\n",
        "# Determine the output directory for transcription based on input type\n",
        "# If input is a network source, output to WHISPER_DIR\n",
        "# If input is a local file, output to the same directory as the input file\n",
        "if is_youtube_url(filename) or is_http_url(filename):\n",
        "    out_base_dir = WHISPER_DIR\n",
        "else:\n",
        "    src_path_abs = to_abs_mydrive(filename)\n",
        "    out_base_dir = src_path_abs.parent\n",
        "\n",
        "# Create the transcription output directory if it doesn't exist\n",
        "out_dir = out_base_dir\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Determine the stem from the original source file path\n",
        "stem = Path(src_path).stem\n",
        "SRT = out_dir / f\"{stem}.srt\"\n",
        "TXT = out_dir / f\"{stem}.txt\"\n",
        "\n",
        "with open(SRT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, s in enumerate(filtered, 1):\n",
        "        text_out = norm(s.text.strip())\n",
        "        f.write(f\"{i}\\n{fmt_ts_srt(s.start)} --> {fmt_ts_srt(s.end)}\\n{text_out}\\n\\n\")\n",
        "\n",
        "with open(TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in filtered:\n",
        "        f.write(norm(s.text.strip()) + \"\\n\")  # Each segment on a new line\n",
        "\n",
        "print(f\"→ 完成！\\n  SRT: {SRT}\\n  TXT: {TXT}\")\n",
        "\n",
        "# Release model (release GPU memory)\n",
        "try: del model\n",
        "except: pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"→ Model released; can run again directly if needed.\")\n",
        "\n",
        "\n",
        "# ===== Summarization Logic Starts Here =====\n",
        "\n",
        "# Determine the SRT input path for summarization - Uses 'summary_srt_path' and 'SRT' from transcription\n",
        "if not summary_srt_path:\n",
        "    # If summary_srt_path is empty, use the SRT generated by the transcription step\n",
        "    summary_srt_path_abs = SRT\n",
        "    if DEBUG_MODE: print(f\"Using SRT from transcription step: {summary_srt_path_abs}\")\n",
        "else:\n",
        "    # If summary_srt_path is provided, convert it to an absolute path relative to MyDrive\n",
        "    summary_srt_path_abs = to_abs_mydrive(summary_srt_path)\n",
        "\n",
        "# Ensure the input SRT file for summarization exists\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "\n",
        "\n",
        "# ===== Summary 1/6) Check GPU and Install Dependencies (llama-cpp-python specific) =====\n",
        "# llama-cpp-python installation logic - Keep this separate as it has specific CUDA requirements\n",
        "# Moved this section to just before reading the SRT for summarization\n",
        "if DEBUG_MODE: print(\"[Summary 1/6] Checking GPU and installing llama-cpp-python ...\")\n",
        "\n",
        "def detect_cuda_tag():\n",
        "    try:\n",
        "        out = sp.check_output([\"nvidia-smi\"], text=True)\n",
        "        m = re.search(r\"CUDA Version:\\s*([\\d.]+)\", out)\n",
        "        if not m:\n",
        "            return \"cu124\"\n",
        "        major, minor = [int(x) for x in m.group(1).split(\".\")[:2]]\n",
        "        if major > 12 or (major == 12 and minor >= 5):\n",
        "            return \"cu125\"\n",
        "        return \"cu124\"\n",
        "    except Exception:\n",
        "        return \"cu124\"\n",
        "\n",
        "cuda_tag = detect_cuda_tag()\n",
        "if DEBUG_MODE: print(f\"GPU 0: Detected CUDA version tag {cuda_tag}\")\n",
        "\n",
        "def try_import_llama():\n",
        "    try:\n",
        "        from llama_cpp import Llama\n",
        "        return Llama\n",
        "    except ModuleNotFoundError:\n",
        "        return None\n",
        "\n",
        "Llama = try_import_llama()\n",
        "if Llama is None:\n",
        "    # Keep your existing installation strategy: extra-index -> fallback to source compilation on failure\n",
        "    candidates = [cuda_tag, \"cu125\", \"cu124\", \"cu122\", \"cu121\"]\n",
        "    ok = False\n",
        "    for tag in candidates:\n",
        "        idx = f\"https://abetlen.github.io/llama-cpp-python/whl/{tag}\"\n",
        "        if DEBUG_MODE: print(f\"→ Attempting to install llama-cpp-python ({tag}) ...\")\n",
        "        r = pip_install([\"llama-cpp-python\"], extra_args=[\"--extra-index-url\", idx])\n",
        "        if r.returncode == 0:\n",
        "            Llama = try_import_llama()\n",
        "            if Llama is not None:\n",
        "                ok = True\n",
        "                break\n",
        "        else:\n",
        "            if DEBUG_MODE: print(\"  ✗ Installation failed (summary):\", \"\\n\".join(r.stdout.splitlines()[-5:]))\n",
        "    if not ok:\n",
        "        if DEBUG_MODE: print(\"→ Pre-compiled wheels not available, switching to 'source compilation (CUDA=ON)' ... (takes longer)\")\n",
        "        try:\n",
        "            import ninja # noqa: F401 # Import ninja to check if installed\n",
        "        except ModuleNotFoundError:\n",
        "            if DEBUG_MODE: print(\"→ Installing missing package: ninja\")\n",
        "            r = pip_install([\"ninja\"])\n",
        "            if r.returncode != 0:\n",
        "                if DEBUG_MODE: print(r.stdout)\n",
        "                raise RuntimeError(\"安裝 ninja 失敗。請重啟後重試。\")\n",
        "        env = os.environ.copy()\n",
        "        env[\"CMAKE_ARGS\"] = \"-DGGML_CUDA=on -DLLAMA_CUBLAS=on\"\n",
        "        env[\"FORCE_CMAKE\"] = \"1\"\n",
        "        r = pip_install([\"llama-cpp-python\"], env=env)\n",
        "        if r.returncode != 0:\n",
        "            if DEBUG_MODE: print(r.stdout)\n",
        "            raise RuntimeError(\"無法安裝 GPU 版 llama-cpp-python。\")\n",
        "        Llama = try_import_llama()\n",
        "\n",
        "\n",
        "# ===== Summary 2/6) Read SRT (Summary) - Uses 'summary_srt_path_abs'\n",
        "if DEBUG_MODE: print(\"[Summary 2/6] Reading SRT ...\")\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "with open(summary_srt_path_abs, \"r\", encoding=\"utf-8\") as f:\n",
        "    srt_text = f.read()\n",
        "subs = list(_srt.parse(srt_text)) # Use _srt as srt module was imported as _srt\n",
        "def td2s(td): return td.total_seconds()\n",
        "segments = []\n",
        "for it in subs:\n",
        "    txt = it.content.strip()\n",
        "    if not txt: continue\n",
        "    segments.append((td2s(it.start), td2s(it.end), txt))\n",
        "total_secs = (segments[-1][1] - segments[0][0]) if segments else 0\n",
        "if DEBUG_MODE: print(f\"→ Number of subtitle segments: {len(segments)}；Video length (est): {total_secs/60:.1f} minutes\")\n",
        "\n",
        "\n",
        "# ===== Summary 3/6) Download and Load GGUF Model (Summary) - Uses summary model parameters (REPO_ID, GGUF_FILE, ctx_window, etc.)\n",
        "# Moved this section to just after installing llama-cpp-python\n",
        "if DEBUG_MODE: print(\"[Summary 3/6] Loading GPT-OSS-20B (GGUF, CUDA) ...\")\n",
        "local_repo = snapshot_download(REPO_ID, allow_patterns=[GGUF_FILE])\n",
        "gguf_path = str(Path(local_repo)/GGUF_FILE)\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=gguf_path,\n",
        "    n_ctx=ctx_window,\n",
        "    n_gpu_layers=-1,\n",
        "    seed=0,\n",
        "    logits_all=False,\n",
        "    verbose=True,          # Display the actual chat format used\n",
        "    chat_format=\"chatml\",  # Directly override the GGUF built-in Unsloth template to avoid outputting <|channel|> tags\n",
        ")\n",
        "if DEBUG_MODE: print(\"→ Model loaded successfully (GPU)\")\n",
        "\n",
        "\n",
        "# ===== Summary 4/6) Token-aware Segmentation (Summary) - Uses ctx_window, map_max_new_tokens, prompt_overhead\n",
        "if DEBUG_MODE: print(\"[Summary 4/6] Generating segments (token-aware; single segment ≤ safety limit) ...\")\n",
        "\n",
        "def count_tokens_text(text: str) -> int:\n",
        "    # Check if llm is initialized before using it\n",
        "    if 'llm' not in locals() or llm is None:\n",
        "         raise RuntimeError(\"LLM model is not loaded. Cannot count tokens.\")\n",
        "    return len(llm.tokenize(text.encode(\"utf-8\")))\n",
        "\n",
        "SYSTEM_INSTR = (\n",
        "  \"你是一個會議總結機器人。根據使用者提供的逐字稿（可能雜訊、重複、錯字），\"\n",
        "  \"請去除雜訊與重複、嚴守事實、不腦補。遇到不明確資訊以「待補充／未明確」標註。\"\n",
        "  \"輸出為 Markdown（繁體中文），不要輸出任何系統／思考標記。\"\n",
        ")\n",
        "\n",
        "# — Segment Summary Prompt: More concise request, avoid verbosity and system language - Uses 'topic_hint'\n",
        "MAP_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是逐字稿片段（非完整全文）：\n",
        "{chunk}\n",
        "\n",
        "請就此片段輸出「條列式重點摘要」（500–900 字，繁體中文），注意：\n",
        "- 只寫最終內容，不要寫解題想法、不要出現任何系統提示或中英括號標記。\n",
        "- 聚焦可驗證事實（時間、人物、任務、結論、未決事項、行動）。\n",
        "- 結構：可用小標題＋項目符號，語句務必短、準確、無贅詞。\n",
        "\"\"\")\n",
        "\n",
        "# — Summary Prompt: Maintain your three-section output structure - Uses 'topic_hint'\n",
        "REDUCE_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是所有片段的重點摘要彙整（仍可能有重疊）：\n",
        "{maps}\n",
        "\n",
        "請整合為一份會議筆記（Markdown，繁體）：\n",
        "1) **整體提要**（3–6 句，避免冗言）\n",
        "2) **章節要點（含時間脈絡）**：條列呈現，每點一行，可附粗略時間\n",
        "3) **可執行重點**：具體待辦（每條以動詞開頭）\n",
        "請只輸出最終筆記，不要出現系統或思考標記，不要加入未出現的新資訊。\n",
        "\"\"\")\n",
        "\n",
        "# Single segment token budget (reserve space for prompt and generation)\n",
        "prompt_overhead = 700\n",
        "chunk_target    = max(1024, min(3072, ctx_window - prompt_overhead - map_max_new_tokens))\n",
        "\n",
        "chunks: List[Tuple[float,float,str]] = []\n",
        "buf, t0, t1, cur = [], None, None, 0\n",
        "for (s, e, txt) in segments:\n",
        "    t = count_tokens_text(txt)\n",
        "    if not buf:\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "        continue\n",
        "    if cur + t <= chunk_target:\n",
        "        buf.append(txt); t1 = e; cur += t\n",
        "    else:\n",
        "        chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "if buf:\n",
        "    chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ Generated {len(chunks)} segments (target ~{chunk_target} tokens per segment)\")\n",
        "\n",
        "# ===== Common: Streaming Tools (No regex cleaning; use correct stop sequence) - Uses temperature, top_p, repeat_penalty, map_max_new_tokens, reduce_max_new_tokens\n",
        "def llm_stream(messages, max_tokens):\n",
        "    # Check if llm is initialized before using it\n",
        "    if 'llm' not in locals() or llm is None:\n",
        "         raise RuntimeError(\"LLM model is not loaded. Cannot stream generation.\")\n",
        "    # ChatML messages end with <|im_end|>; use stop to cut off, preventing the closing tag from being written to the file\n",
        "    gen = llm.create_chat_completion(\n",
        "        messages=messages,\n",
        "        temperature=float(temperature),\n",
        "        top_p=float(top_p),\n",
        "        repeat_penalty=float(repeat_penalty),\n",
        "        max_tokens=int(max_tokens),\n",
        "        stream=True,\n",
        "        stop=[\"<|im_end|>\"],  # Key: Prevent outputting the ending template\n",
        "    )\n",
        "    for ev in gen:\n",
        "        # Compatible with different fields\n",
        "        piece = \"\"\n",
        "        try:\n",
        "            piece = ev[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "        except Exception:\n",
        "            piece = ev[\"choices\"][0].get(\"text\", \"\")\n",
        "        if piece:\n",
        "            yield piece\n",
        "\n",
        "# ===== Summary 5/6) Segment Summary (map) - Uses map_max_new_tokens, ctx_window, prompt_overhead, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 5/6] Segment summarization (map) ...\")\n",
        "live = display(Markdown(\"\"), display_id=True)\n",
        "maps: List[str] = []\n",
        "\n",
        "for i, (s, e, body) in enumerate(chunks, 1):\n",
        "    pct = i / max(len(chunks),1) * 100\n",
        "    sys.stdout.write(f\"  - 處理分段 {i}/{len(chunks)}（~{pct:.1f}%）\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Shrink to safe budget before sending (prevent prompt+segment from exceeding window and causing model to terminate early)\n",
        "    budget_tokens = max(512, ctx_window - map_max_new_tokens - prompt_overhead)\n",
        "    def shrink_to_budget(text: str, budget_tokens: int) -> str:\n",
        "        cur = text\n",
        "        for _ in range(6):\n",
        "            if count_tokens_text(cur) <= budget_tokens:\n",
        "                return cur\n",
        "            keep = max(800, int(len(cur) * 0.85))\n",
        "            cur = cur[:keep]\n",
        "        return cur\n",
        "    body2 = shrink_to_budget(body, budget_tokens)\n",
        "\n",
        "    user_txt = MAP_USER_TMPL.format(topic=(topic_hint or \"（無）\"), chunk=body2)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n",
        "        {\"role\": \"user\",   \"content\": user_txt},\n",
        "    ]\n",
        "\n",
        "    part_buf = [] # Reset part_buf for each segment\n",
        "    for token in llm_stream(messages, map_max_new_tokens):\n",
        "        part_buf.append(token)\n",
        "        # Update live display and terminal character count periodically\n",
        "        if len(part_buf) % 24 == 0:\n",
        "            cur_txt = \"\".join(part_buf)\n",
        "            live.update(Markdown(cur_txt))\n",
        "            sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "    cur_txt = \"\".join(part_buf)\n",
        "    live.update(Markdown(cur_txt))\n",
        "    sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Include the model's final output directly, no regex cleaning\n",
        "    maps.append(cur_txt.strip())\n",
        "\n",
        "if DEBUG_MODE: print(\"→ Segment summarization complete\")\n",
        "\n",
        "# ===== Summary 6/6) Consolidate (reduce) & Only write .md (Summary) - Uses summary_output_dir, summary_srt_path_abs, reduce_max_new_tokens, ctx_window, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 6/6] Consolidating summary (reduce) ...\")\n",
        "maps_md = \"\\n\\n---\\n\\n\".join(f\"### 片段 {i+1} 要點\\n\\n{m}\" for i, m in enumerate(maps))\n",
        "\n",
        "# If combined text exceeds window, truncate proportionally first (without changing text within segments to avoid breaking meaning)\n",
        "def fit_reduce_payload(md_text: str, max_ctx_tokens: int) -> str:\n",
        "    for _ in range(8):\n",
        "        need = count_tokens_text(md_text)\n",
        "        if need + reduce_max_new_tokens + 400 <= max_ctx_tokens:\n",
        "            return md_text\n",
        "        md_text = md_text[: int(len(md_text) * 0.9)]\n",
        "    return md_text\n",
        "\n",
        "md_cur = fit_reduce_payload(maps_md, ctx_window)\n",
        "\n",
        "user_txt = REDUCE_USER_TMPL.format(topic=(topic_hint or \"（無）\"), maps=md_cur)\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_INSTR},\n",
        "            {\"role\":\"user\",\"content\":user_txt}]\n",
        "\n",
        "live2 = display(Markdown(\"\"), display_id=True)\n",
        "final_buf = []\n",
        "for token in llm_stream(messages, reduce_max_new_tokens):\n",
        "    final_buf.append(token)\n",
        "    if len(final_buf) % 24 == 0:\n",
        "        live2.update(Markdown(\"\".join(final_buf)))\n",
        "        sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "live2.update(Markdown(\"\".join(final_buf)))\n",
        "sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "\n",
        "final_text = \"\".join(final_buf).strip()\n",
        "\n",
        "# Determine and create the summary output directory\n",
        "summary_output_dir_abs = to_abs_mydrive(summary_output_dir)\n",
        "summary_output_dir_abs.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Determine the summary output file path using the stem of the input SRT\n",
        "out_md = summary_output_dir_abs / f\"{Path(summary_srt_path_abs).stem}_summary.md\"\n",
        "\n",
        "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_text)\n",
        "\n",
        "print(f\"→ 完成 ✅  {out_md}\")\n",
        "try:\n",
        "    del llm\n",
        "except Exception:\n",
        "    pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"（顯存已釋放，如需重跑可直接再次執行）\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "→ 當前工作目錄：/content/gdrive/MyDrive\n",
            "→ 來源檔：/content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\n",
            "→ 輸出資料夾：/content/gdrive/MyDrive/whisper\n",
            "[  1%] 00:00:00,000 → 00:00:29,980  Teksting av Nicolai Winther\n",
            "[  1%] 00:00:20,000 → 00:00:49,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:00:40,000 → 00:01:09,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:00,000 → 00:01:29,980  Teksting av Nicolai Winther\n",
            "[  2%] 00:01:20,000 → 00:01:49,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:01:40,000 → 00:02:09,980  Teksting av Nicolai Winther\n",
            "[  3%] 00:02:00,000 → 00:02:29,980  Teksting av Nicolai Winther\n",
            "[  4%] 00:02:20,000 → 00:02:49,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:00,000 → 00:03:29,980  Teksting av Nicolai Winther\n",
            "[  5%] 00:03:20,000 → 00:03:49,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:03:40,000 → 00:04:09,980  Teksting av Nicolai Winther\n",
            "[  6%] 00:04:00,000 → 00:04:18,900  聽得到聲音嗎?\n",
            "[  6%] 00:04:20,000 → 00:04:24,000  Ok,ok\n",
            "[  6%] 00:04:24,000 → 00:04:28,000  Ok,那我想先確定\n",
            "[  6%] 00:04:28,000 → 00:04:32,000  威神你那邊在看完教證手冊之後\n",
            "[  6%] 00:04:32,000 → 00:04:36,000  你目前有任何的想法嗎?\n",
            "[  6%] 00:04:36,000 → 00:04:40,000  我覺得因為那時候是說\n",
            "[  6%] 00:04:40,000 → 00:04:45,240  八月底先寫完那個內容的部分嘛\n",
            "[  6%] 00:04:45,240 → 00:04:48,440  但是我覺得看完之後應該要大概\n",
            "[  6%] 00:04:48,440 → 00:04:51,180  我覺得八月底前應該沒辦法寫完\n",
            "[  7%] 00:04:51,180 → 00:04:54,040  那你覺得你什麼時候可以完成得了\n",
            "[  7%] 00:04:54,040 → 00:04:56,480  十月左右嗎\n",
            "[  7%] 00:04:56,480 → 00:04:58,400  你是說單子內容嗎\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'FILTER_NO_SPEECH_THRESHOLD' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3362362750.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    376\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mseg_dur\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mFILTER_MIN_DURATION_SHORT\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"avg_logprob\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavg_logprob\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mFILTER_AVG_LOGPROB_THRESHOLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mseg_dur\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mFILTER_MIN_DURATION_SPEECH_PROB\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"no_speech_prob\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_speech_prob\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mFILTER_NO_SPEECH_THRESHOLD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m         \u001b[0mkeep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeep\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'FILTER_NO_SPEECH_THRESHOLD' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd62efaf"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback indicates a `NameError` because `FILTER_NO_SPEECH_THRESHOLD` is not defined when the transcription filtering logic is executed. Looking at the code, the \"Developer Options\" section where these filtering parameters are defined is placed *after* the transcription code block. This is incorrect; all variables must be defined *before* they are used. I need to move the \"Developer Options\" section, which contains all the filter and transcription parameters, to be immediately after the user form parameters section (`[2/8]`). I will regenerate the full code with this corrected placement.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "YG8Bfp_lIJw2",
        "outputId": "9a4c8a02-6d18-4b55-de0b-c456c161cb25"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Whisper Automatic Subtitle Generation: GPU Transcription + CPU Denoising + OpenCC Post-processing (Traditional/Simplified Conversion)\n",
        "# And LLM Summarization (GPT-OSS-20B / llama.cpp / CUDA)\n",
        "# - Transcription: faster-whisper (CUDA, compute: int8_float16→float16→int8)\n",
        "# - Denoising: ffmpeg afftdn (CPU)\n",
        "# - Progress: Real-time printing of \"current sentence + video total length percentage\"\n",
        "# - Network source download and output: MyDrive/whisper; Files in Drive: Output to the same folder\n",
        "# - LLM Summary: llama.cpp + GPT-OSS-20B GGUF for summarizing transcription\n",
        "# - Prompts \"Delete runtime and restart\" if download is blocked or abnormal\n",
        "# =========================================================\n",
        "\n",
        "# Restrict multithreading (more stable)\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# [1/8] Mount Google Drive\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "except:\n",
        "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "# Consolidated Imports\n",
        "import sys, gc, shutil, datetime, subprocess as sp\n",
        "from pathlib import Path\n",
        "import re, math, time, importlib, textwrap\n",
        "from typing import List, Tuple\n",
        "from IPython.display import display, Markdown\n",
        "import soundfile as sf\n",
        "from faster_whisper import WhisperModel\n",
        "from opencc import OpenCC\n",
        "import srt as _srt # Import srt as _srt to avoid name conflict later with the module itself\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "ROOT = Path(\"/content/gdrive/MyDrive\")\n",
        "WHISPER_DIR = ROOT / \"whisper\"\n",
        "WHISPER_DIR.mkdir(exist_ok=True, parents=True)\n",
        "os.chdir(ROOT)\n",
        "print(f\"→ 當前工作目錄：{os.getcwd()}\")\n",
        "\n",
        "# [2/8] User Form Parameters (Unified)\n",
        "#@markdown # Whisper Transcription & LLM Summary Pipeline\n",
        "\n",
        "#@markdown ## Input & Transcription Settings\n",
        "#@markdown **Input Source:** Google Drive file (relative to MyDrive) or video URL (YouTube/HTTP).\n",
        "filename = \"whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\"  #@param {type:\"string\"}\n",
        "#@markdown **Download Option:** Check to save network source files to `MyDrive/whisper`.\n",
        "save_video_to_google_drive = True  #@param {type:\"boolean\"}\n",
        "#@markdown **Whisper Model Size:** Choose a model size. `large-v3` requires more GPU VRAM; `medium` is a good alternative if VRAM is limited.\n",
        "model_size = \"large-v3\"  #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\"]\n",
        "#@markdown **Language:** Select the language for transcription. \"自動偵測\" (Auto-detect) is usually sufficient.\n",
        "language = \"自動偵測\"  #@param [\"自動偵測\", \"中文\", \"英文\"]\n",
        "#@markdown **Denoising:** Apply CPU-based denoising to the audio before transcription. `afftdn` is recommended.\n",
        "denoise_method = \"afftdn (建議)\"  #@param [\"afftdn (建議)\", \"none\"]\n",
        "#@markdown **Text Post-processing (OpenCC):** Convert the transcribed text (SRT/TXT output) between Simplified and Traditional Chinese variants.\n",
        "text_postprocess = \"臺灣繁體中文（預設）\"  #@param [\"臺灣繁體中文（預設）\",\"香港繁體中文\",\"大陸簡體中文\",\"關閉\"]\n",
        "#@markdown **YouTube Cookies (Optional):** Path to a Netscape-format cookies file (relative to MyDrive) for accessing age-restricted or member-only YouTube videos (e.g., `cookies/youtube.txt`).\n",
        "youtube_cookies_txt_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Summarization Settings\n",
        "#@markdown **SRT Input:** Path to the SRT file for summarization (relative to MyDrive or absolute). Leave empty to use the SRT generated by the transcription step above.\n",
        "summary_srt_path = \"\"  #@param {type:\"string\"}\n",
        "#@markdown **Topic Hint (Optional):** Provide a brief hint about the topic to guide the summarization process.\n",
        "topic_hint = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Output Paths\n",
        "#@markdown **Transcription Output Directory:** Directory where the generated SRT and TXT files will be saved (relative to MyDrive or absolute). Default is the input file's directory for local files, or `MyDrive/whisper` for network sources. This is determined automatically.\n",
        "# (Note: filename's directory is used if local, otherwise WHISPER_DIR. This parameter is more of an indicator of the default output base.)\n",
        "#@markdown **Summary Output Directory:** Directory where the final summary Markdown file will be saved (relative to MyDrive or absolute).\n",
        "summary_output_dir = \"/content/gdrive/MyDrive/whisper\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "language_code_map = {\"自動偵測\": None, \"中文\":\"zh\", \"英文\":\"en\"}\n",
        "language_code = language_code_map[language]\n",
        "\n",
        "# =========================================================\n",
        "# Developer Options\n",
        "# Advanced users can fine-tune parameters in this section.\n",
        "# Modify only if you understand the impact.\n",
        "# =========================================================\n",
        "DEBUG_MODE = False # Set to True for more detailed logging\n",
        "\n",
        "# --- Transcription Parameters ---\n",
        "TRANSCRIPTION_BEAM_SIZE_PRIMARY = 3\n",
        "TRANSCRIPTION_CHUNK_LENGTH_PRIMARY = 20\n",
        "TRANSCRIPTION_BEAM_SIZE_FALLBACK = 1 # Used if primary fails\n",
        "TRANSCRIPTION_CHUNK_LENGTH_FALLBACK = 15 # Used if primary fails\n",
        "\n",
        "# --- Denoising Parameters ---\n",
        "DENOISE_NOISE_FLOOR_DB = -25\n",
        "\n",
        "# --- Filtering Parameters ---\n",
        "FILTER_MIN_DURATION_SHORT = 1.5 # Minimum duration for short segments\n",
        "FILTER_AVG_LOGPROB_THRESHOLD = -1.0 # Avg log probability threshold for short segments\n",
        "FILTER_MIN_DURATION_SPEECH_PROB = 2.0 # Minimum duration for speech probability filtering\n",
        "FILTER_NO_SPEECH_PROB_THRESHOLD = 0.6 # No speech probability threshold\n",
        "\n",
        "# --- Summary Model Parameters ---\n",
        "REPO_ID   = \"unsloth/gpt-oss-20b-GGUF\"   # GGUF Model Repository\n",
        "GGUF_FILE = \"gpt-oss-20b-Q4_K_M.gguf\"    # Approx. 10.8GiB, T4 can run\n",
        "\n",
        "# --- Summary Inference Parameters (Increase available generation space to avoid truncation) ---\n",
        "ctx_window            = 8192\n",
        "map_max_new_tokens    = 512   # Segment output: original 256 -> 512 (approx. 350-450 chars)\n",
        "reduce_max_new_tokens = 1024  # Summary output: original 512 -> 1024 (approx. 700-900+ chars)\n",
        "temperature           = 0.2\n",
        "top_p                 = 0.9\n",
        "repeat_penalty        = 1.05\n",
        "# =========================================================\n",
        "# End of Developer Options\n",
        "# =========================================================\n",
        "\n",
        "\n",
        "# [3/8] Install Dependencies\n",
        "# Combine installation steps from both original cells\n",
        "if DEBUG_MODE: print(\"[Install] faster-whisper / yt-dlp / soundfile / opencc / srt / huggingface_hub / llama-cpp-python ...\")\n",
        "\n",
        "def pip_install(pkgs, extra_args=None, env=None):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"]\n",
        "    if extra_args:\n",
        "        cmd += extra_args\n",
        "    cmd += pkgs\n",
        "    return sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True, env=env)\n",
        "\n",
        "# Install common dependencies first\n",
        "common_missing = []\n",
        "try: import srt # check srt module directly after import as _srt\n",
        "except ModuleNotFoundError: common_missing.append(\"srt>=3.5.3\")\n",
        "try: from huggingface_hub import snapshot_download # check huggingface_hub module directly\n",
        "except ModuleNotFoundError: common_missing.append(\"huggingface_hub>=0.23.0\")\n",
        "try: import soundfile # check soundfile\n",
        "except ModuleNotFoundError: common_missing.append(\"soundfile\")\n",
        "try: import opencc # check opencc\n",
        "except ModuleNotFoundError: common_missing.append(\"opencc-python-reimplemented\")\n",
        "\n",
        "if common_missing:\n",
        "    if DEBUG_MODE: print(\"→ Installing common missing packages:\", \", \".join(common_missing))\n",
        "    r = pip_install(common_missing)\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"基礎依賴安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "# Install faster-whisper and yt-dlp separately as they were in the first cell\n",
        "try: from faster_whisper import WhisperModel # check faster_whisper\n",
        "except ModuleNotFoundError:\n",
        "    if DEBUG_MODE: print(\"→ Installing missing package: faster-whisper yt-dlp\")\n",
        "    r = pip_install([\"faster-whisper\", \"yt-dlp\"])\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"faster-whisper / yt-dlp 安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "\n",
        "def suggest_runtime_reset():\n",
        "    print(\"\\n🧹 建議動作（Colab）\")\n",
        "    print(\"1) 依序：『執行階段 Runtime』 → 『刪除執行階段/還原出廠設定 Factory reset runtime』\")\n",
        "    print(\"2) 重新執行本 Notebook（從掛載雲端硬碟那格開始）\\n\", flush=True)\n",
        "\n",
        "def run_cmd(cmd:list, check=True):\n",
        "    if DEBUG_MODE: print(\"  $\", \" \".join(cmd))\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"命令失敗：{' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "def is_youtube_url(s:str)->bool:\n",
        "    return isinstance(s, str) and (\"youtu.be\" in s or \"youtube.com\" in s)\n",
        "def is_http_url(s:str)->bool:\n",
        "    return isinstance(s, str) and s.lower().startswith(\"http\")\n",
        "def to_abs_mydrive(p:str)->Path:\n",
        "    return (Path(p) if p.startswith(\"/\") else (ROOT / p)).resolve()\n",
        "def fmt_ts_srt(t:float)->str:\n",
        "    h = int(t//3600); m = int((t%3600)//60); s = t - h*3600 - m*60\n",
        "    return f\"{h:02d}:{m:02d}:{int(s):02d},{int(round((s-int(s))*1000)):03d}\"\n",
        "def verify_wav_ok(path: Path)->bool:\n",
        "    try:\n",
        "        info = sf.info(str(path))\n",
        "        return info.samplerate > 0 and info.channels in (1, 2)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# OpenCC converter setup\n",
        "def build_opencc_pipeline(choice:str):\n",
        "    if choice.startswith(\"臺灣\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2tw')]\n",
        "    if choice.startswith(\"香港\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2hk')]\n",
        "    if choice.startswith(\"大陸\"):\n",
        "        return [OpenCC('t2s')]\n",
        "    return []  # Disable\n",
        "\n",
        "def apply_opencc(text:str, pipeline)->str:\n",
        "    for cc in pipeline:\n",
        "        text = cc.convert(text)\n",
        "    return text\n",
        "\n",
        "def ytdl(yturl:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting YouTube video ...\")\n",
        "    # Use sp.run instead of subprocess.run directly\n",
        "    cmd = [\"yt-dlp\", \"-f\", \"mp4\", \"-o\", str(tmp / \"%(title)s.%(ext)s\")]\n",
        "    if youtube_cookies_txt_path.strip():\n",
        "        cookies_abs = to_abs_mydrive(youtube_cookies_txt_path.strip())\n",
        "        if cookies_abs.exists():\n",
        "            cmd += [\"--cookies\", str(cookies_abs)]\n",
        "        else:\n",
        "            if DEBUG_MODE: print(f\"⚠️ 找不到 cookies 檔：{cookies_abs}（改為不帶 cookies）\")\n",
        "    cmd.append(yturl)\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        if \"Sign in to confirm\" in (p.stdout or \"\"):\n",
        "            print(\"\\n❗YouTube 要求登入/驗證，請提供 cookies 或先自行下載到雲端硬碟。\")\n",
        "        print(\"🔄 若多次失敗，請刪除執行階段並重啟後重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise RuntimeError(\"yt-dlp 下載失敗\")\n",
        "    files = list(tmp.glob(\"*\"))\n",
        "    if not files:\n",
        "        print(\"🔄 下載為空，建議刪除執行階段再重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise FileNotFoundError(\"YouTube 下載失敗：/tmp/dl 為空\")\n",
        "    f = files[0]\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(f, WHISPER_DIR / f.name)\n",
        "    return f\n",
        "\n",
        "def http_dl(url:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting HTTP(S) video ...\")\n",
        "    run_cmd([\"curl\", \"-L\", \"-o\", str(out), url])\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(out, WHISPER_DIR / out.name)\n",
        "    return out\n",
        "\n",
        "# Extract audio: ffmpeg -> 16k/mono WAV\n",
        "def ffmpeg_extract_wav(in_path:Path, out_wav:Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-vn\",\"-ac\",\"1\",\"-ar\",str(sr),\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 轉 WAV 失敗\")\n",
        "\n",
        "# CPU Denoising: ffmpeg afftdn\n",
        "def ffmpeg_afftdn(in_wav: Path, out_wav: Path, noise_floor_db=DENOISE_NOISE_FLOOR_DB):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-af\",f\"afftdn=nf={noise_floor_db}\",\n",
        "           \"-ac\",\"1\",\"-ar\",\"16000\",\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg afftdn 失敗\")\n",
        "\n",
        "# Safeguard: Repack WAV header if format is strange\n",
        "def ffmpeg_repack_wav(in_wav: Path, out_wav: Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-acodec\",\"pcm_s16le\",\"-ac\",\"1\",\"-ar\",str(sr),str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 重包 WAV 失敗\")\n",
        "\n",
        "# [4/8] Parse Source (Transcription) - Uses 'filename' and 'save_video_to_google_drive'\n",
        "if DEBUG_MODE: print(\"[4/8] Parsing input source ...\")\n",
        "try:\n",
        "    if is_youtube_url(filename):\n",
        "        src_path = ytdl(filename); out_base_dir = WHISPER_DIR\n",
        "    elif is_http_url(filename):\n",
        "        src_path = http_dl(filename); out_base_dir = WHISPER_DIR\n",
        "    else:\n",
        "        src_path = to_abs_mydrive(filename)\n",
        "        if not src_path.exists(): raise FileNotFoundError(f\"找不到檔案：{src_path}\")\n",
        "        out_base_dir = src_path.parent\n",
        "except Exception as e:\n",
        "    print(f\"\\n⛔ 來源解析/下載失敗：{e}\")\n",
        "    print(\"🔄 請刪除執行階段並重新啟動後重跑。\"); suggest_runtime_reset(); raise\n",
        "\n",
        "print(f\"→ 來源檔：{src_path}\")\n",
        "print(f\"→ 輸出資料夾：{out_base_dir}\")\n",
        "\n",
        "# [5/8] Extract Audio & CPU Denoising (Transcription) - Uses 'denoise_method' and 'DENOISE_NOISE_FLOOR_DB'\n",
        "AUDIO_16K = Path(\"/tmp/audio_16k.wav\")\n",
        "if DEBUG_MODE: print(\"[5/8] Extracting audio (ffmpeg → 16k/mono WAV) ...\")\n",
        "ffmpeg_extract_wav(src_path, AUDIO_16K, sr=16000)\n",
        "\n",
        "if denoise_method.startswith(\"afftdn\"):\n",
        "    if DEBUG_MODE: print(\"[5.5/8] Denoising (ffmpeg afftdn, CPU) ...\")\n",
        "    DENOISED = Path(\"/tmp/audio_16k_denoised.wav\")\n",
        "    ffmpeg_afftdn(AUDIO_16K, DENOISED, noise_floor_db=DENOISE_NOISE_FLOOR_DB)\n",
        "    denoised_audio = DENOISED if verify_wav_ok(DENOISED) else AUDIO_16K\n",
        "else:\n",
        "    denoised_audio = AUDIO_16K\n",
        "\n",
        "if not verify_wav_ok(denoised_audio):\n",
        "    if DEBUG_MODE: print(\"  - 音訊格式異常；嘗試重包 WAV ...\")\n",
        "    FIXED = Path(\"/tmp/audio_16k_fixed.wav\")\n",
        "    ffmpeg_repack_wav(denoised_audio, FIXED, sr=16000)\n",
        "    denoised_audio = FIXED\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ 最終輸入音訊：{denoised_audio}\")\n",
        "\n",
        "# [6/8] Load faster-whisper (GPU enforced) - Uses 'model_size'\n",
        "if DEBUG_MODE: print(\"[6/8] Loading faster-whisper model (GPU) ...\")\n",
        "device = \"cuda\"  # Enforce GPU\n",
        "model = None; last_err = None\n",
        "for ctype in [\"int8_float16\", \"float16\", \"int8\"]:\n",
        "    try:\n",
        "        if DEBUG_MODE: print(f\"  - Trying compute_type={ctype}\")\n",
        "        model = WhisperModel(model_size, device=device, compute_type=ctype)\n",
        "        if DEBUG_MODE: print(\"  - Model loaded successfully\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        last_err = e\n",
        "        if DEBUG_MODE: print(f\"  - Load failed: {e}\")\n",
        "if model is None:\n",
        "    print(\"\\n⛔ GPU 模型載入失敗。請確認『變更執行階段類型』選了 GPU（T4/A100），或刪除執行階段後重試。\")\n",
        "    suggest_runtime_reset()\n",
        "    raise RuntimeError(f\"無法載入模型：{last_err}\")\n",
        "\n",
        "gc.collect()  # Clean up before transcription (safety)\n",
        "\n",
        "# [7/8] Transcribe (GPU; real-time progress per segment) - Uses 'language_code', 'TRANSCRIPTION_BEAM_SIZE_PRIMARY', 'TRANSCRIPTION_CHUNK_LENGTH_PRIMARY', 'TRANSCRIPTION_BEAM_SIZE_FALLBACK', 'TRANSCRIPTION_CHUNK_LENGTH_FALLBACK'\n",
        "if DEBUG_MODE: print(f\"[7/8] Starting transcription (GPU: beam={TRANSCRIPTION_BEAM_SIZE_PRIMARY} / chunk={TRANSCRIPTION_CHUNK_LENGTH_PRIMARY}s / no VAD) ...\")\n",
        "\n",
        "def transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY):\n",
        "    return model.transcribe(\n",
        "        str(denoised_audio),\n",
        "        task=\"transcribe\",\n",
        "        language=language_code,\n",
        "        temperature=0.0,\n",
        "        condition_on_previous_text=False,\n",
        "        compression_ratio_threshold=2.4,\n",
        "        log_prob_threshold=-1.0,\n",
        "        no_speech_threshold=0.6,\n",
        "        beam_size=_beam,\n",
        "        chunk_length=_chunk,\n",
        "        vad_filter=False,\n",
        "        word_timestamps=False\n",
        "    )\n",
        "\n",
        "try:\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY)\n",
        "except Exception as e:\n",
        "    if DEBUG_MODE: print(f\"  - First transcription failed: {e}\\n    → Trying more conservative (beam={TRANSCRIPTION_BEAM_SIZE_FALLBACK}, chunk={TRANSCRIPTION_CHUNK_LENGTH_FALLBACK}) ...\")\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_FALLBACK, _chunk=TRANSCRIPTION_CHUNK_LENGTH_FALLBACK)\n",
        "\n",
        "# Display percentage based on total video duration\n",
        "duration = float(getattr(info, \"duration\", 0.0) or 0.0)\n",
        "if duration <= 0: duration = 1.0\n",
        "\n",
        "segments = []\n",
        "filtered = []\n",
        "\n",
        "if DEBUG_MODE:\n",
        "    print(f\"  - Detected language: {getattr(info,'language','未知')} (p={getattr(info,'language_probability',0):.2f})\")\n",
        "    print(f\"  - Audio length: {duration:.2f}s\")\n",
        "\n",
        "for s in seg_iter:\n",
        "    pct = int(min(100, round((s.end / duration) * 100)))\n",
        "    print(f\"[{pct:3d}%] {fmt_ts_srt(s.start)} → {fmt_ts_srt(s.end)}  {s.text.strip()}\", flush=True)\n",
        "    segments.append(s)\n",
        "\n",
        "    # Low confidence/high no-speech short segment filtering (no blacklist) - Uses FILTER_* parameters\n",
        "    keep = True\n",
        "    seg_dur = float(s.end - s.start)\n",
        "    if seg_dur < FILTER_MIN_DURATION_SHORT and getattr(s, \"avg_logprob\", None) is not None and s.avg_logprob < FILTER_AVG_LOGPROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if seg_dur < FILTER_MIN_DURATION_SPEECH_PROB and getattr(s, \"no_speech_prob\", None) is not None and s.no_speech_prob > FILTER_NO_SPEECH_PROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if keep:\n",
        "        filtered.append(s)\n",
        "\n",
        "if DEBUG_MODE: print(f\"  - Number of segments: Before filtering {len(segments)} → After filtering {len(filtered)}\")\n",
        "\n",
        "# ---- OpenCC Normalization (for output text) ---- - Uses 'text_postprocess'\n",
        "pipeline = build_opencc_pipeline(text_postprocess)\n",
        "def norm(txt: str) -> str:\n",
        "    return apply_opencc(txt, pipeline) if pipeline else txt\n",
        "\n",
        "# [8/8] Output (text after OpenCC) - Uses 'out_base_dir' (derived from 'filename')\n",
        "print(\"[8/8] 輸出 SRT / TXT ...\")\n",
        "# Determine the output directory for transcription based on input type\n",
        "# If input is a network source, output to WHISPER_DIR\n",
        "# If input is a local file, output to the same directory as the input file\n",
        "if is_youtube_url(filename) or is_http_url(filename):\n",
        "    out_base_dir = WHISPER_DIR\n",
        "else:\n",
        "    src_path_abs = to_abs_mydrive(filename)\n",
        "    out_base_dir = src_path_abs.parent\n",
        "\n",
        "# Create the transcription output directory if it doesn't exist\n",
        "out_dir = out_base_dir\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Determine the stem from the original source file path\n",
        "stem = Path(src_path).stem\n",
        "SRT = out_dir / f\"{stem}.srt\"\n",
        "TXT = out_dir / f\"{stem}.txt\"\n",
        "\n",
        "with open(SRT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, s in enumerate(filtered, 1):\n",
        "        text_out = norm(s.text.strip())\n",
        "        f.write(f\"{i}\\n{fmt_ts_srt(s.start)} --> {fmt_ts_srt(s.end)}\\n{text_out}\\n\\n\")\n",
        "\n",
        "with open(TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in filtered:\n",
        "        f.write(norm(s.text.strip()) + \"\\n\")  # Each segment on a new line\n",
        "\n",
        "print(f\"→ 完成！\\n  SRT: {SRT}\\n  TXT: {TXT}\")\n",
        "\n",
        "# Release model (release GPU memory)\n",
        "try: del model\n",
        "except: pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"→ Model released; can run again directly if needed.\")\n",
        "\n",
        "\n",
        "# ===== Summarization Logic Starts Here =====\n",
        "\n",
        "# Determine the SRT input path for summarization - Uses 'summary_srt_path' and 'SRT' from transcription\n",
        "if not summary_srt_path:\n",
        "    # If summary_srt_path is empty, use the SRT generated by the transcription step\n",
        "    summary_srt_path_abs = SRT\n",
        "    if DEBUG_MODE: print(f\"Using SRT from transcription step: {summary_srt_path_abs}\")\n",
        "else:\n",
        "    # If summary_srt_path is provided, convert it to an absolute path relative to MyDrive\n",
        "    summary_srt_path_abs = to_abs_mydrive(summary_srt_path)\n",
        "\n",
        "# Ensure the input SRT file for summarization exists\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "\n",
        "\n",
        "# ===== Summary 1/6) Check GPU and Install Dependencies (llama-cpp-python specific) =====\n",
        "# llama-cpp-python installation logic - Keep this separate as it has specific CUDA requirements\n",
        "# Moved this section to just before reading the SRT for summarization\n",
        "if DEBUG_MODE: print(\"[Summary 1/6] Checking GPU and installing llama-cpp-python ...\")\n",
        "\n",
        "def detect_cuda_tag():\n",
        "    try:\n",
        "        out = sp.check_output([\"nvidia-smi\"], text=True)\n",
        "        m = re.search(r\"CUDA Version:\\s*([\\d.]+)\", out)\n",
        "        if not m:\n",
        "            return \"cu124\"\n",
        "        major, minor = [int(x) for x in m.group(1).split(\".\")[:2]]\n",
        "        if major > 12 or (major == 12 and minor >= 5):\n",
        "            return \"cu125\"\n",
        "        return \"cu124\"\n",
        "    except Exception:\n",
        "        return \"cu124\"\n",
        "\n",
        "cuda_tag = detect_cuda_tag()\n",
        "if DEBUG_MODE: print(f\"GPU 0: Detected CUDA version tag {cuda_tag}\")\n",
        "\n",
        "def try_import_llama():\n",
        "    try:\n",
        "        from llama_cpp import Llama\n",
        "        return Llama\n",
        "    except ModuleNotFoundError:\n",
        "        return None\n",
        "\n",
        "Llama = try_import_llama()\n",
        "if Llama is None:\n",
        "    # Keep your existing installation strategy: extra-index -> fallback to source compilation on failure\n",
        "    candidates = [cuda_tag, \"cu125\", \"cu124\", \"cu122\", \"cu121\"]\n",
        "    ok = False\n",
        "    for tag in candidates:\n",
        "        idx = f\"https://abetlen.github.io/llama-cpp-python/whl/{tag}\"\n",
        "        if DEBUG_MODE: print(f\"→ Attempting to install llama-cpp-python ({tag}) ...\")\n",
        "        r = pip_install([\"llama-cpp-python\"], extra_args=[\"--extra-index-url\", idx])\n",
        "        if r.returncode == 0:\n",
        "            Llama = try_import_llama()\n",
        "            if Llama is not None:\n",
        "                ok = True\n",
        "                break\n",
        "        else:\n",
        "            if DEBUG_MODE: print(\"  ✗ Installation failed (summary):\", \"\\n\".join(r.stdout.splitlines()[-5:]))\n",
        "    if not ok:\n",
        "        if DEBUG_MODE: print(\"→ Pre-compiled wheels not available, switching to 'source compilation (CUDA=ON)' ... (takes longer)\")\n",
        "        try:\n",
        "            import ninja # noqa: F401 # Import ninja to check if installed\n",
        "        except ModuleNotFoundError:\n",
        "            if DEBUG_MODE: print(\"→ Installing missing package: ninja\")\n",
        "            r = pip_install([\"ninja\"])\n",
        "            if r.returncode != 0:\n",
        "                if DEBUG_MODE: print(r.stdout)\n",
        "                raise RuntimeError(\"安裝 ninja 失敗。請重啟後重試。\")\n",
        "        env = os.environ.copy()\n",
        "        env[\"CMAKE_ARGS\"] = \"-DGGML_CUDA=on -DLLAMA_CUBLAS=on\"\n",
        "        env[\"FORCE_CMAKE\"] = \"1\"\n",
        "        r = pip_install([\"llama-cpp-python\"], env=env)\n",
        "        if r.returncode != 0:\n",
        "            if DEBUG_MODE: print(r.stdout)\n",
        "            raise RuntimeError(\"無法安裝 GPU 版 llama-cpp-python。\")\n",
        "        Llama = try_import_llama()\n",
        "\n",
        "\n",
        "# ===== Summary 2/6) Read SRT (Summary) - Uses 'summary_srt_path_abs'\n",
        "if DEBUG_MODE: print(\"[Summary 2/6] Reading SRT ...\")\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "with open(summary_srt_path_abs, \"r\", encoding=\"utf-8\") as f:\n",
        "    srt_text = f.read()\n",
        "subs = list(_srt.parse(srt_text)) # Use _srt as srt module was imported as _srt\n",
        "def td2s(td): return td.total_seconds()\n",
        "segments = []\n",
        "for it in subs:\n",
        "    txt = it.content.strip()\n",
        "    if not txt: continue\n",
        "    segments.append((td2s(it.start), td2s(it.end), txt))\n",
        "total_secs = (segments[-1][1] - segments[0][0]) if segments else 0\n",
        "if DEBUG_MODE: print(f\"→ Number of subtitle segments: {len(segments)}；Video length (est): {total_secs/60:.1f} minutes\")\n",
        "\n",
        "\n",
        "# ===== Summary 3/6) Download and Load GGUF Model (Summary) - Uses summary model parameters (REPO_ID, GGUF_FILE, ctx_window, etc.)\n",
        "# Moved this section to just after installing llama-cpp-python\n",
        "if DEBUG_MODE: print(\"[Summary 3/6] Loading GPT-OSS-20B (GGUF, CUDA) ...\")\n",
        "local_repo = snapshot_download(REPO_ID, allow_patterns=[GGUF_FILE])\n",
        "gguf_path = str(Path(local_repo)/GGUF_FILE)\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=gguf_path,\n",
        "    n_ctx=ctx_window,\n",
        "    n_gpu_layers=-1,\n",
        "    seed=0,\n",
        "    logits_all=False,\n",
        "    verbose=True,          # Display the actual chat format used\n",
        "    chat_format=\"chatml\",  # Directly override the GGUF built-in Unsloth template to avoid outputting <|channel|> tags\n",
        ")\n",
        "if DEBUG_MODE: print(\"→ Model loaded successfully (GPU)\")\n",
        "\n",
        "\n",
        "# ===== Summary 4/6) Token-aware Segmentation (Summary) - Uses ctx_window, map_max_new_tokens, prompt_overhead\n",
        "if DEBUG_MODE: print(\"[Summary 4/6] Generating segments (token-aware; single segment ≤ safety limit) ...\")\n",
        "\n",
        "def count_tokens_text(text: str) -> int:\n",
        "    # Check if llm is initialized before using it\n",
        "    if 'llm' not in locals() or llm is None:\n",
        "         raise RuntimeError(\"LLM model is not loaded. Cannot count tokens.\")\n",
        "    return len(llm.tokenize(text.encode(\"utf-8\")))\n",
        "\n",
        "SYSTEM_INSTR = (\n",
        "  \"你是一個會議總結機器人。根據使用者提供的逐字稿（可能雜訊、重複、錯字），\"\n",
        "  \"請去除雜訊與重複、嚴守事實、不腦補。遇到不明確資訊以「待補充／未明確」標註。\"\n",
        "  \"輸出為 Markdown（繁體中文），不要輸出任何系統／思考標記。\"\n",
        ")\n",
        "\n",
        "# — Segment Summary Prompt: More concise request, avoid verbosity and system language - Uses 'topic_hint'\n",
        "MAP_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是逐字稿片段（非完整全文）：\n",
        "{chunk}\n",
        "\n",
        "請就此片段輸出「條列式重點摘要」（500–900 字，繁體中文），注意：\n",
        "- 只寫最終內容，不要寫解題想法、不要出現任何系統提示或中英括號標記。\n",
        "- 聚焦可驗證事實（時間、人物、任務、結論、未決事項、行動）。\n",
        "- 結構：可用小標題＋項目符號，語句務必短、準確、無贅詞。\n",
        "\"\"\")\n",
        "\n",
        "# — Summary Prompt: Maintain your three-section output structure - Uses 'topic_hint'\n",
        "REDUCE_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是所有片段的重點摘要彙整（仍可能有重疊）：\n",
        "{maps}\n",
        "\n",
        "請整合為一份會議筆記（Markdown，繁體）：\n",
        "1) **整體提要**（3–6 句，避免冗言）\n",
        "2) **章節要點（含時間脈絡）**：條列呈現，每點一行，可附粗略時間\n",
        "3) **可執行重點**：具體待辦（每條以動詞開頭）\n",
        "請只輸出最終筆記，不要出現系統或思考標記，不要加入未出現的新資訊。\n",
        "\"\"\")\n",
        "\n",
        "# Single segment token budget (reserve space for prompt and generation)\n",
        "prompt_overhead = 700\n",
        "chunk_target    = max(1024, min(3072, ctx_window - prompt_overhead - map_max_new_tokens))\n",
        "\n",
        "chunks: List[Tuple[float,float,str]] = []\n",
        "buf, t0, t1, cur = [], None, None, 0\n",
        "for (s, e, txt) in segments:\n",
        "    t = count_tokens_text(txt)\n",
        "    if not buf:\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "        continue\n",
        "    if cur + t <= chunk_target:\n",
        "        buf.append(txt); t1 = e; cur += t\n",
        "    else:\n",
        "        chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "if buf:\n",
        "    chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ Generated {len(chunks)} segments (target ~{chunk_target} tokens per segment)\")\n",
        "\n",
        "# ===== Common: Streaming Tools (No regex cleaning; use correct stop sequence) - Uses temperature, top_p, repeat_penalty, map_max_new_tokens, reduce_max_new_tokens\n",
        "def llm_stream(messages, max_tokens):\n",
        "    # Check if llm is initialized before using it\n",
        "    if 'llm' not in locals() or llm is None:\n",
        "         raise RuntimeError(\"LLM model is not loaded. Cannot stream generation.\")\n",
        "    # ChatML messages end with <|im_end|>; use stop to cut off, preventing the closing tag from being written to the file\n",
        "    gen = llm.create_chat_completion(\n",
        "        messages=messages,\n",
        "        temperature=float(temperature),\n",
        "        top_p=float(top_p),\n",
        "        repeat_penalty=float(repeat_penalty),\n",
        "        max_tokens=int(max_tokens),\n",
        "        stream=True,\n",
        "        stop=[\"<|im_end|>\"],  # Key: Prevent outputting the ending template\n",
        "    )\n",
        "    for ev in gen:\n",
        "        # Compatible with different fields\n",
        "        piece = \"\"\n",
        "        try:\n",
        "            piece = ev[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "        except Exception:\n",
        "            piece = ev[\"choices\"][0].get(\"text\", \"\")\n",
        "        if piece:\n",
        "            yield piece\n",
        "\n",
        "# ===== Summary 5/6) Segment Summary (map) - Uses map_max_new_tokens, ctx_window, prompt_overhead, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 5/6] Segment summarization (map) ...\")\n",
        "live = display(Markdown(\"\"), display_id=True)\n",
        "maps: List[str] = []\n",
        "\n",
        "for i, (s, e, body) in enumerate(chunks, 1):\n",
        "    pct = i / max(len(chunks),1) * 100\n",
        "    sys.stdout.write(f\"  - 處理分段 {i}/{len(chunks)}（~{pct:.1f}%）\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Shrink to safe budget before sending (prevent prompt+segment from exceeding window and causing model to terminate early)\n",
        "    budget_tokens = max(512, ctx_window - map_max_new_tokens - prompt_overhead)\n",
        "    def shrink_to_budget(text: str, budget_tokens: int) -> str:\n",
        "        cur = text\n",
        "        for _ in range(6):\n",
        "            if count_tokens_text(cur) <= budget_tokens:\n",
        "                return cur\n",
        "            keep = max(800, int(len(cur) * 0.85))\n",
        "            cur = cur[:keep]\n",
        "        return cur\n",
        "    body2 = shrink_to_budget(body, budget_tokens)\n",
        "\n",
        "    user_txt = MAP_USER_TMPL.format(topic=(topic_hint or \"（無）\"), chunk=body2)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n",
        "        {\"role\": \"user\",   \"content\": user_txt},\n",
        "    ]\n",
        "\n",
        "    part_buf = [] # Reset part_buf for each segment\n",
        "    for token in llm_stream(messages, map_max_new_tokens):\n",
        "        part_buf.append(token)\n",
        "        # Update live display and terminal character count periodically\n",
        "        if len(part_buf) % 24 == 0:\n",
        "            cur_txt = \"\".join(part_buf)\n",
        "            live.update(Markdown(cur_txt))\n",
        "            sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "    cur_txt = \"\".join(part_buf)\n",
        "    live.update(Markdown(cur_txt))\n",
        "    sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Include the model's final output directly, no regex cleaning\n",
        "    maps.append(cur_txt.strip())\n",
        "\n",
        "if DEBUG_MODE: print(\"→ Segment summarization complete\")\n",
        "\n",
        "# ===== Summary 6/6) Consolidate (reduce) & Only write .md (Summary) - Uses summary_output_dir, summary_srt_path_abs, reduce_max_new_tokens, ctx_window, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 6/6] Consolidating summary (reduce) ...\")\n",
        "maps_md = \"\\n\\n---\\n\\n\".join(f\"### 片段 {i+1} 要點\\n\\n{m}\" for i, m in enumerate(maps))\n",
        "\n",
        "# If combined text exceeds window, truncate proportionally first (without changing text within segments to avoid breaking meaning)\n",
        "def fit_reduce_payload(md_text: str, max_ctx_tokens: int) -> str:\n",
        "    for _ in range(8):\n",
        "        need = count_tokens_text(md_text)\n",
        "        if need + reduce_max_new_tokens + 400 <= max_ctx_tokens:\n",
        "            return md_text\n",
        "        md_text = md_text[: int(len(md_text) * 0.9)]\n",
        "    return md_text\n",
        "\n",
        "md_cur = fit_reduce_payload(maps_md, ctx_window)\n",
        "\n",
        "user_txt = REDUCE_USER_TMPL.format(topic=(topic_hint or \"（無）\"), maps=md_cur)\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_INSTR},\n",
        "            {\"role\":\"user\",\"content\":user_txt}]\n",
        "\n",
        "live2 = display(Markdown(\"\"), display_id=True)\n",
        "final_buf = []\n",
        "for token in llm_stream(messages, reduce_max_new_tokens):\n",
        "    final_buf.append(token)\n",
        "    if len(final_buf) % 24 == 0:\n",
        "        live2.update(Markdown(\"\".join(final_buf)))\n",
        "        sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "live2.update(Markdown(\"\".join(final_buf)))\n",
        "sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "\n",
        "final_text = \"\".join(final_buf).strip()\n",
        "\n",
        "# Determine and create the summary output directory\n",
        "summary_output_dir_abs = to_abs_mydrive(summary_output_dir)\n",
        "summary_output_dir_abs.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Determine the summary output file path using the stem of the input SRT\n",
        "out_md = summary_output_dir_abs / f\"{Path(summary_srt_path_abs).stem}_summary.md\"\n",
        "\n",
        "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_text)\n",
        "\n",
        "print(f\"→ 完成 ✅  {out_md}\")\n",
        "try:\n",
        "    del llm\n",
        "except Exception:\n",
        "    pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"（顯存已釋放，如需重跑可直接再次執行）\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "→ 當前工作目錄：/content/gdrive/MyDrive\n",
            "→ 來源檔：/content/gdrive/MyDrive/whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\n",
            "→ 輸出資料夾：/content/gdrive/MyDrive/whisper\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1748166938.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0mAUDIO_16K\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/tmp/audio_16k.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mDEBUG_MODE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[5/8] Extracting audio (ffmpeg → 16k/mono WAV) ...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m \u001b[0mffmpeg_extract_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAUDIO_16K\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdenoise_method\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"afftdn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1748166938.py\u001b[0m in \u001b[0;36mffmpeg_extract_wav\u001b[0;34m(in_path, out_wav, sr)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mffmpeg_extract_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_wav\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0mcmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"ffmpeg\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-y\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-i\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-vn\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-ac\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-ar\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"-f\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"wav\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_wav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPIPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTDOUT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mDEBUG_MODE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mPopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mstdout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstderr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommunicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTimeoutExpired\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/subprocess.py\u001b[0m in \u001b[0;36mcommunicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stdin_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                 \u001b[0mstdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1197\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstderr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "256d1895"
      },
      "source": [
        "**Reasoning**:\n",
        "The traceback indicates a `RuntimeError` because the faster-whisper model loading failed with an \"out of memory\" error on the GPU. This means the selected model size (`large-v3`) is too large for the available GPU memory (Tesla T4, which has ~15GB VRAM). While `large-v3` can sometimes fit on a T4 with specific compute types, it's often very tight or impossible depending on the exact environment state and other processes using memory. The most reliable way to resolve this is to select a smaller model size that is known to fit comfortably within the T4's memory limits. The `medium` model size is a good balance of accuracy and memory usage and is recommended in the user form parameters description for cases with limited VRAM. I will update the `model_size` parameter to \"medium\" in the user form parameters section (`[2/8]`) and regenerate the full code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dBCVT2eIuFt"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "# =========================================================\n",
        "# Whisper Automatic Subtitle Generation: GPU Transcription + CPU Denoising + OpenCC Post-processing (Traditional/Simplified Conversion)\n",
        "# And LLM Summarization (GPT-OSS-20B / llama.cpp / CUDA)\n",
        "# - Transcription: faster-whisper (CUDA, compute: int8_float16→float16→int8)\n",
        "# - Denoising: ffmpeg afftdn (CPU)\n",
        "# - Progress: Real-time printing of \"current sentence + video total length percentage\"\n",
        "# - Network source download and output: MyDrive/whisper; Files in Drive: Output to the same folder\n",
        "# - LLM Summary: llama.cpp + GPT-OSS-20B GGUF for summarizing transcription\n",
        "# - Prompts \"Delete runtime and restart\" if download is blocked or abnormal\n",
        "# =========================================================\n",
        "\n",
        "# Restrict multithreading (more stable)\n",
        "import os\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
        "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
        "\n",
        "# [1/8] Mount Google Drive\n",
        "from google.colab import drive\n",
        "try:\n",
        "    drive.mount(\"/content/gdrive\")\n",
        "except:\n",
        "    drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "\n",
        "# Consolidated Imports\n",
        "import sys, gc, shutil, datetime, subprocess as sp\n",
        "from pathlib import Path\n",
        "import re, math, time, importlib, textwrap\n",
        "from typing import List, Tuple\n",
        "from IPython.display import display, Markdown\n",
        "import soundfile as sf\n",
        "from faster_whisper import WhisperModel\n",
        "from opencc import OpenCC\n",
        "import srt as _srt # Import srt as _srt to avoid name conflict later with the module itself\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "ROOT = Path(\"/content/gdrive/MyDrive\")\n",
        "WHISPER_DIR = ROOT / \"whisper\"\n",
        "WHISPER_DIR.mkdir(exist_ok=True, parents=True)\n",
        "os.chdir(ROOT)\n",
        "print(f\"→ 當前工作目錄：{os.getcwd()}\")\n",
        "\n",
        "# [2/8] User Form Parameters (Unified)\n",
        "#@markdown # Whisper Transcription & LLM Summary Pipeline\n",
        "\n",
        "#@markdown ## Input & Transcription Settings\n",
        "#@markdown **Input Source:** Google Drive file (relative to MyDrive) or video URL (YouTube/HTTP).\n",
        "filename = \"whisper/jcz-mfkq-frc (2025-08-08 10_00 GMT+8).mp4\"  #@param {type:\"string\"}\n",
        "#@markdown **Download Option:** Check to save network source files to `MyDrive/whisper`.\n",
        "save_video_to_google_drive = True  #@param {type:\"boolean\"}\n",
        "#@markdown **Whisper Model Size:** Choose a model size. `large-v3` requires more GPU VRAM; `medium` is a good alternative if VRAM is limited.\n",
        "model_size = \"medium\"  #@param [\"tiny\", \"base\", \"small\", \"medium\", \"large-v2\", \"large-v3\"] # Changed model_size to \"medium\"\n",
        "#@markdown **Language:** Select the language for transcription. \"自動偵測\" (Auto-detect) is usually sufficient.\n",
        "language = \"自動偵測\"  #@param [\"自動偵測\", \"中文\", \"英文\"]\n",
        "#@markdown **Denoising:** Apply CPU-based denoising to the audio before transcription. `afftdn` is recommended.\n",
        "denoise_method = \"afftdn (建議)\"  #@param [\"afftdn (建議)\", \"none\"]\n",
        "#@markdown **Text Post-processing (OpenCC):** Convert the transcribed text (SRT/TXT output) between Simplified and Traditional Chinese variants.\n",
        "text_postprocess = \"臺灣繁體中文（預設）\"  #@param [\"臺灣繁體中文（預設）\",\"香港繁體中文\",\"大陸簡體中文\",\"關閉\"]\n",
        "#@markdown **YouTube Cookies (Optional):** Path to a Netscape-format cookies file (relative to MyDrive) for accessing age-restricted or member-only YouTube videos (e.g., `cookies/youtube.txt`).\n",
        "youtube_cookies_txt_path = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Summarization Settings\n",
        "#@markdown **SRT Input:** Path to the SRT file for summarization (relative to MyDrive or absolute). Leave empty to use the SRT generated by the transcription step above.\n",
        "summary_srt_path = \"\"  #@param {type:\"string\"}\n",
        "#@markdown **Topic Hint (Optional):** Provide a brief hint about the topic to guide the summarization process.\n",
        "topic_hint = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "#@markdown ## Output Paths\n",
        "#@markdown **Transcription Output Directory:** Directory where the generated SRT and TXT files will be saved (relative to MyDrive or absolute). Default is the input file's directory for local files, or `MyDrive/whisper` for network sources. This is determined automatically.\n",
        "# (Note: filename's directory is used if local, otherwise WHISPER_DIR. This parameter is more of an indicator of the default output base.)\n",
        "#@markdown **Summary Output Directory:** Directory where the final summary Markdown file will be saved (relative to MyDrive or absolute).\n",
        "summary_output_dir = \"/content/gdrive/MyDrive/whisper\"  #@param {type:\"string\"}\n",
        "\n",
        "\n",
        "language_code_map = {\"自動偵測\": None, \"中文\":\"zh\", \"英文\":\"en\"}\n",
        "language_code = language_code_map[language]\n",
        "\n",
        "# =========================================================\n",
        "# Developer Options\n",
        "# Advanced users can fine-tune parameters in this section.\n",
        "# Modify only if you understand the impact.\n",
        "# =========================================================\n",
        "DEBUG_MODE = False # Set to True for more detailed logging\n",
        "\n",
        "# --- Transcription Parameters ---\n",
        "TRANSCRIPTION_BEAM_SIZE_PRIMARY = 3\n",
        "TRANSCRIPTION_CHUNK_LENGTH_PRIMARY = 20\n",
        "TRANSCRIPTION_BEAM_SIZE_FALLBACK = 1 # Used if primary fails\n",
        "TRANSCRIPTION_CHUNK_LENGTH_FALLBACK = 15 # Used if primary fails\n",
        "\n",
        "# --- Denoising Parameters ---\n",
        "DENOISE_NOISE_FLOOR_DB = -25\n",
        "\n",
        "# --- Filtering Parameters ---\n",
        "FILTER_MIN_DURATION_SHORT = 1.5 # Minimum duration for short segments\n",
        "FILTER_AVG_LOGPROB_THRESHOLD = -1.0 # Avg log probability threshold for short segments\n",
        "FILTER_MIN_DURATION_SPEECH_PROB = 2.0 # Minimum duration for speech probability filtering\n",
        "FILTER_NO_SPEECH_PROB_THRESHOLD = 0.6 # No speech probability threshold\n",
        "\n",
        "# --- Summary Model Parameters ---\n",
        "REPO_ID   = \"unsloth/gpt-oss-20b-GGUF\"   # GGUF Model Repository\n",
        "GGUF_FILE = \"gpt-oss-20b-Q4_K_M.gguf\"    # Approx. 10.8GiB, T4 can run\n",
        "\n",
        "# --- Summary Inference Parameters (Increase available generation space to avoid truncation) ---\n",
        "ctx_window            = 8192\n",
        "map_max_new_tokens    = 512   # Segment output: original 256 -> 512 (approx. 350-450 chars)\n",
        "reduce_max_new_tokens = 1024  # Summary output: original 512 -> 1024 (approx. 700-900+ chars)\n",
        "temperature           = 0.2\n",
        "top_p                 = 0.9\n",
        "repeat_penalty        = 1.05\n",
        "# =========================================================\n",
        "# End of Developer Options\n",
        "# =========================================================\n",
        "\n",
        "\n",
        "# [3/8] Install Dependencies\n",
        "# Combine installation steps from both original cells\n",
        "if DEBUG_MODE: print(\"[Install] faster-whisper / yt-dlp / soundfile / opencc / srt / huggingface_hub / llama-cpp-python ...\")\n",
        "\n",
        "def pip_install(pkgs, extra_args=None, env=None):\n",
        "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\"]\n",
        "    if extra_args:\n",
        "        cmd += extra_args\n",
        "    cmd += pkgs\n",
        "    return sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True, env=env)\n",
        "\n",
        "# Install common dependencies first\n",
        "common_missing = []\n",
        "try: import srt # check srt module directly after import as _srt\n",
        "except ModuleNotFoundError: common_missing.append(\"srt>=3.5.3\")\n",
        "try: from huggingface_hub import snapshot_download # check huggingface_hub module directly\n",
        "except ModuleNotFoundError: common_missing.append(\"huggingface_hub>=0.23.0\")\n",
        "try: import soundfile # check soundfile\n",
        "except ModuleNotFoundError: common_missing.append(\"soundfile\")\n",
        "try: import opencc # check opencc\n",
        "except ModuleNotFoundError: common_missing.append(\"opencc-python-reimplemented\")\n",
        "\n",
        "if common_missing:\n",
        "    if DEBUG_MODE: print(\"→ Installing common missing packages:\", \", \".join(common_missing))\n",
        "    r = pip_install(common_missing)\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"基礎依賴安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "# Install faster-whisper and yt-dlp separately as they were in the first cell\n",
        "try: from faster_whisper import WhisperModel # check faster_whisper\n",
        "except ModuleNotFoundError:\n",
        "    if DEBUG_MODE: print(\"→ Installing missing package: faster-whisper yt-dlp\")\n",
        "    r = pip_install([\"faster-whisper\", \"yt-dlp\"])\n",
        "    if r.returncode != 0:\n",
        "        if DEBUG_MODE: print(r.stdout)\n",
        "        raise RuntimeError(\"faster-whisper / yt-dlp 安裝失敗，請重啟執行階段後重試。\")\n",
        "\n",
        "\n",
        "def suggest_runtime_reset():\n",
        "    print(\"\\n🧹 建議動作（Colab）\")\n",
        "    print(\"1) 依序：『執行階段 Runtime』 → 『刪除執行階段/還原出廠設定 Factory reset runtime』\")\n",
        "    print(\"2) 重新執行本 Notebook（從掛載雲端硬碟那格開始）\\n\", flush=True)\n",
        "\n",
        "def run_cmd(cmd:list, check=True):\n",
        "    if DEBUG_MODE: print(\"  $\", \" \".join(cmd))\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if check and p.returncode != 0:\n",
        "        raise RuntimeError(f\"命令失敗：{' '.join(cmd)}\")\n",
        "    return p\n",
        "\n",
        "def is_youtube_url(s:str)->bool:\n",
        "    return isinstance(s, str) and (\"youtu.be\" in s or \"youtube.com\" in s)\n",
        "def is_http_url(s:str)->bool:\n",
        "    return isinstance(s, str) and s.lower().startswith(\"http\")\n",
        "def to_abs_mydrive(p:str)->Path:\n",
        "    return (Path(p) if p.startswith(\"/\") else (ROOT / p)).resolve()\n",
        "def fmt_ts_srt(t:float)->str:\n",
        "    h = int(t//3600); m = int((t%3600)//60); s = t - h*3600 - m*60\n",
        "    return f\"{h:02d}:{m:02d}:{int(s):02d},{int(round((s-int(s))*1000)):03d}\"\n",
        "def verify_wav_ok(path: Path)->bool:\n",
        "    try:\n",
        "        info = sf.info(str(path))\n",
        "        return info.samplerate > 0 and info.channels in (1, 2)\n",
        "    except Exception:\n",
        "        return False\n",
        "\n",
        "# OpenCC converter setup\n",
        "def build_opencc_pipeline(choice:str):\n",
        "    if choice.startswith(\"臺灣\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2tw')]\n",
        "    if choice.startswith(\"香港\"):\n",
        "        return [OpenCC('s2t'), OpenCC('t2hk')]\n",
        "    if choice.startswith(\"大陸\"):\n",
        "        return [OpenCC('t2s')]\n",
        "    return []  # Disable\n",
        "\n",
        "def apply_opencc(text:str, pipeline)->str:\n",
        "    for cc in pipeline:\n",
        "        text = cc.convert(text)\n",
        "    return text\n",
        "\n",
        "def ytdl(yturl:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting YouTube video ...\")\n",
        "    # Use sp.run instead of subprocess.run directly\n",
        "    cmd = [\"yt-dlp\", \"-f\", \"mp4\", \"-o\", str(tmp / \"%(title)s.%(ext)s\")]\n",
        "    if youtube_cookies_txt_path.strip():\n",
        "        cookies_abs = to_abs_mydrive(youtube_cookies_txt_path.strip())\n",
        "        if cookies_abs.exists():\n",
        "            cmd += [\"--cookies\", str(cookies_abs)]\n",
        "        else:\n",
        "            if DEBUG_MODE: print(f\"⚠️ 找不到 cookies 檔：{cookies_abs}（改為不帶 cookies）\")\n",
        "    cmd.append(yturl)\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if DEBUG_MODE and p.stdout: sys.stdout.write(p.stdout)\n",
        "    if p.returncode != 0:\n",
        "        if \"Sign in to confirm\" in (p.stdout or \"\"):\n",
        "            print(\"\\n❗YouTube 要求登入/驗證，請提供 cookies 或先自行下載到雲端硬碟。\")\n",
        "        print(\"🔄 若多次失敗，請刪除執行階段並重啟後重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise RuntimeError(\"yt-dlp 下載失敗\")\n",
        "    files = list(tmp.glob(\"*\"))\n",
        "    if not files:\n",
        "        print(\"🔄 下載為空，建議刪除執行階段再重試。\")\n",
        "        suggest_runtime_reset()\n",
        "        raise FileNotFoundError(\"YouTube 下載失敗：/tmp/dl 為空\")\n",
        "    f = files[0]\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(f, WHISPER_DIR / f.name)\n",
        "    return f\n",
        "\n",
        "def http_dl(url:str)->Path:\n",
        "    tmp = Path(\"/tmp/dl\"); tmp.mkdir(parents=True, exist_ok=True)\n",
        "    for x in tmp.glob(\"*\"):\n",
        "        try: x.unlink()\n",
        "        except: shutil.rmtree(x, ignore_errors=True)\n",
        "    ts = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    out = tmp / f\"downloaded_{ts}.mp4\"\n",
        "    if DEBUG_MODE: print(\"[Download] Getting HTTP(S) video ...\")\n",
        "    run_cmd([\"curl\", \"-L\", \"-o\", str(out), url])\n",
        "    if save_video_to_google_drive:\n",
        "        shutil.copy2(out, WHISPER_DIR / out.name)\n",
        "    return out\n",
        "\n",
        "# Extract audio: ffmpeg -> 16k/mono WAV\n",
        "def ffmpeg_extract_wav(in_path:Path, out_wav:Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_path),\"-vn\",\"-ac\",\"1\",\"-ar\",str(sr),\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 轉 WAV 失敗\")\n",
        "\n",
        "# CPU Denoising: ffmpeg afftdn\n",
        "def ffmpeg_afftdn(in_wav: Path, out_wav: Path, noise_floor_db=DENOISE_NOISE_FLOOR_DB):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-af\",f\"afftdn=nf={noise_floor_db}\",\n",
        "           \"-ac\",\"1\",\"-ar\",\"16000\",\"-f\",\"wav\",str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg afftdn 失敗\")\n",
        "\n",
        "# Safeguard: Repack WAV header if format is strange\n",
        "def ffmpeg_repack_wav(in_wav: Path, out_wav: Path, sr=16000):\n",
        "    cmd = [\"ffmpeg\",\"-y\",\"-i\",str(in_wav),\"-acodec\",\"pcm_s16le\",\"-ac\",\"1\",\"-ar\",str(sr),str(out_wav)]\n",
        "    p = sp.run(cmd, stdout=sp.PIPE, stderr=sp.STDOUT, text=True)\n",
        "    if p.returncode != 0:\n",
        "        if DEBUG_MODE: print(p.stdout)\n",
        "        raise RuntimeError(\"ffmpeg 重包 WAV 失敗\")\n",
        "\n",
        "# [4/8] Parse Source (Transcription) - Uses 'filename' and 'save_video_to_google_drive'\n",
        "if DEBUG_MODE: print(\"[4/8] Parsing input source ...\")\n",
        "try:\n",
        "    if is_youtube_url(filename):\n",
        "        src_path = ytdl(filename); out_base_dir = WHISPER_DIR\n",
        "    elif is_http_url(filename):\n",
        "        src_path = http_dl(filename); out_base_dir = WHISPER_DIR\n",
        "    else:\n",
        "        src_path = to_abs_mydrive(filename)\n",
        "        if not src_path.exists(): raise FileNotFoundError(f\"找不到檔案：{src_path}\")\n",
        "        out_base_dir = src_path.parent\n",
        "except Exception as e:\n",
        "    print(f\"\\n⛔ 來源解析/下載失敗：{e}\")\n",
        "    print(\"🔄 請刪除執行階段並重新啟動後重跑。\"); suggest_runtime_reset(); raise\n",
        "\n",
        "print(f\"→ 來源檔：{src_path}\")\n",
        "print(f\"→ 輸出資料夾：{out_base_dir}\")\n",
        "\n",
        "# [5/8] Extract Audio & CPU Denoising (Transcription) - Uses 'denoise_method' and 'DENOISE_NOISE_FLOOR_DB'\n",
        "AUDIO_16K = Path(\"/tmp/audio_16k.wav\")\n",
        "if DEBUG_MODE: print(\"[5/8] Extracting audio (ffmpeg → 16k/mono WAV) ...\")\n",
        "ffmpeg_extract_wav(src_path, AUDIO_16K, sr=16000)\n",
        "\n",
        "if denoise_method.startswith(\"afftdn\"):\n",
        "    if DEBUG_MODE: print(\"[5.5/8] Denoising (ffmpeg afftdn, CPU) ...\")\n",
        "    DENOISED = Path(\"/tmp/audio_16k_denoised.wav\")\n",
        "    ffmpeg_afftdn(AUDIO_16K, DENOISED, noise_floor_db=DENOISE_NOISE_FLOOR_DB)\n",
        "    denoised_audio = DENOISED if verify_wav_ok(DENOISED) else AUDIO_16K\n",
        "else:\n",
        "    denoised_audio = AUDIO_16K\n",
        "\n",
        "if not verify_wav_ok(denoised_audio):\n",
        "    if DEBUG_MODE: print(\"  - 音訊格式異常；嘗試重包 WAV ...\")\n",
        "    FIXED = Path(\"/tmp/audio_16k_fixed.wav\")\n",
        "    ffmpeg_repack_wav(denoised_audio, FIXED, sr=16000)\n",
        "    denoised_audio = FIXED\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ 最終輸入音訊：{denoised_audio}\")\n",
        "\n",
        "# [6/8] Load faster-whisper (GPU enforced) - Uses 'model_size'\n",
        "if DEBUG_MODE: print(\"[6/8] Loading faster-whisper model (GPU) ...\")\n",
        "device = \"cuda\"  # Enforce GPU\n",
        "model = None; last_err = None\n",
        "for ctype in [\"int8_float16\", \"float16\", \"int8\"]:\n",
        "    try:\n",
        "        if DEBUG_MODE: print(f\"  - Trying compute_type={ctype}\")\n",
        "        model = WhisperModel(model_size, device=device, compute_type=ctype)\n",
        "        if DEBUG_MODE: print(\"  - Model loaded successfully\")\n",
        "        break\n",
        "    except Exception as e:\n",
        "        last_err = e\n",
        "        if DEBUG_MODE: print(f\"  - Load failed: {e}\")\n",
        "if model is None:\n",
        "    print(\"\\n⛔ GPU 模型載入失敗。請確認『變更執行階段類型』選了 GPU（T4/A100），或刪除執行階段後重試。\")\n",
        "    suggest_runtime_reset()\n",
        "    raise RuntimeError(f\"無法載入模型：{last_err}\")\n",
        "\n",
        "gc.collect()  # Clean up before transcription (safety)\n",
        "\n",
        "# [7/8] Transcribe (GPU; real-time progress per segment) - Uses 'language_code', 'TRANSCRIPTION_BEAM_SIZE_PRIMARY', 'TRANSCRIPTION_CHUNK_LENGTH_PRIMARY', 'TRANSCRIPTION_BEAM_SIZE_FALLBACK', 'TRANSCRIPTION_CHUNK_LENGTH_FALLBACK'\n",
        "if DEBUG_MODE: print(f\"[7/8] Starting transcription (GPU: beam={TRANSCRIPTION_BEAM_SIZE_PRIMARY} / chunk={TRANSCRIPTION_CHUNK_LENGTH_PRIMARY}s / no VAD) ...\")\n",
        "\n",
        "def transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY):\n",
        "    return model.transcribe(\n",
        "        str(denoised_audio),\n",
        "        task=\"transcribe\",\n",
        "        language=language_code,\n",
        "        temperature=0.0,\n",
        "        condition_on_previous_text=False,\n",
        "        compression_ratio_threshold=2.4,\n",
        "        log_prob_threshold=-1.0,\n",
        "        no_speech_threshold=0.6,\n",
        "        beam_size=_beam,\n",
        "        chunk_length=_chunk,\n",
        "        vad_filter=False,\n",
        "        word_timestamps=False\n",
        "    )\n",
        "\n",
        "try:\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_PRIMARY, _chunk=TRANSCRIPTION_CHUNK_LENGTH_PRIMARY)\n",
        "except Exception as e:\n",
        "    if DEBUG_MODE: print(f\"  - First transcription failed: {e}\\n    → Trying more conservative (beam={TRANSCRIPTION_BEAM_SIZE_FALLBACK}, chunk={TRANSCRIPTION_CHUNK_LENGTH_FALLBACK}) ...\")\n",
        "    seg_iter, info = transcribe_gpu(_beam=TRANSCRIPTION_BEAM_SIZE_FALLBACK, _chunk=TRANSCRIPTION_CHUNK_LENGTH_FALLBACK)\n",
        "\n",
        "# Display percentage based on total video duration\n",
        "duration = float(getattr(info, \"duration\", 0.0) or 0.0)\n",
        "if duration <= 0: duration = 1.0\n",
        "\n",
        "segments = []\n",
        "filtered = []\n",
        "\n",
        "if DEBUG_MODE:\n",
        "    print(f\"  - Detected language: {getattr(info,'language','未知')} (p={getattr(info,'language_probability',0):.2f})\")\n",
        "    print(f\"  - Audio length: {duration:.2f}s\")\n",
        "\n",
        "for s in seg_iter:\n",
        "    pct = int(min(100, round((s.end / duration) * 100)))\n",
        "    print(f\"[{pct:3d}%] {fmt_ts_srt(s.start)} → {fmt_ts_srt(s.end)}  {s.text.strip()}\", flush=True)\n",
        "    segments.append(s)\n",
        "\n",
        "    # Low confidence/high no-speech short segment filtering (no blacklist) - Uses FILTER_* parameters\n",
        "    keep = True\n",
        "    seg_dur = float(s.end - s.start)\n",
        "    if seg_dur < FILTER_MIN_DURATION_SHORT and getattr(s, \"avg_logprob\", None) is not None and s.avg_logprob < FILTER_AVG_LOGPROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if seg_dur < FILTER_MIN_DURATION_SPEECH_PROB and getattr(s, \"no_speech_prob\", None) is not None and s.no_speech_prob > FILTER_NO_SPEECH_PROB_THRESHOLD:\n",
        "        keep = False\n",
        "    if keep:\n",
        "        filtered.append(s)\n",
        "\n",
        "if DEBUG_MODE: print(f\"  - Number of segments: Before filtering {len(segments)} → After filtering {len(filtered)}\")\n",
        "\n",
        "# ---- OpenCC Normalization (for output text) ---- - Uses 'text_postprocess'\n",
        "pipeline = build_opencc_pipeline(text_postprocess)\n",
        "def norm(txt: str) -> str:\n",
        "    return apply_opencc(txt, pipeline) if pipeline else txt\n",
        "\n",
        "# [8/8] Output (text after OpenCC) - Uses 'out_base_dir' (derived from 'filename')\n",
        "print(\"[8/8] 輸出 SRT / TXT ...\")\n",
        "# Determine the output directory for transcription based on input type\n",
        "# If input is a network source, output to WHISPER_DIR\n",
        "# If input is a local file, output to the same directory as the input file\n",
        "if is_youtube_url(filename) or is_http_url(filename):\n",
        "    out_base_dir = WHISPER_DIR\n",
        "else:\n",
        "    src_path_abs = to_abs_mydrive(filename)\n",
        "    out_base_dir = src_path_abs.parent\n",
        "\n",
        "# Create the transcription output directory if it doesn't exist\n",
        "out_dir = out_base_dir\n",
        "out_dir.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Determine the stem from the original source file path\n",
        "stem = Path(src_path).stem\n",
        "SRT = out_dir / f\"{stem}.srt\"\n",
        "TXT = out_dir / f\"{stem}.txt\"\n",
        "\n",
        "with open(SRT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for i, s in enumerate(filtered, 1):\n",
        "        text_out = norm(s.text.strip())\n",
        "        f.write(f\"{i}\\n{fmt_ts_srt(s.start)} --> {fmt_ts_srt(s.end)}\\n{text_out}\\n\\n\")\n",
        "\n",
        "with open(TXT, \"w\", encoding=\"utf-8\") as f:\n",
        "    for s in filtered:\n",
        "        f.write(norm(s.text.strip()) + \"\\n\")  # Each segment on a new line\n",
        "\n",
        "print(f\"→ 完成！\\n  SRT: {SRT}\\n  TXT: {TXT}\")\n",
        "\n",
        "# Release model (release GPU memory)\n",
        "try: del model\n",
        "except: pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"→ Model released; can run again directly if needed.\")\n",
        "\n",
        "\n",
        "# ===== Summarization Logic Starts Here =====\n",
        "\n",
        "# Determine the SRT input path for summarization - Uses 'summary_srt_path' and 'SRT' from transcription\n",
        "if not summary_srt_path:\n",
        "    # If summary_srt_path is empty, use the SRT generated by the transcription step\n",
        "    summary_srt_path_abs = SRT\n",
        "    if DEBUG_MODE: print(f\"Using SRT from transcription step: {summary_srt_path_abs}\")\n",
        "else:\n",
        "    # If summary_srt_path is provided, convert it to an absolute path relative to MyDrive\n",
        "    summary_srt_path_abs = to_abs_mydrive(summary_srt_path)\n",
        "\n",
        "# Ensure the input SRT file for summarization exists\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "\n",
        "\n",
        "# ===== Summary 1/6) Check GPU and Install Dependencies (llama-cpp-python specific) =====\n",
        "# llama-cpp-python installation logic - Keep this separate as it has specific CUDA requirements\n",
        "# Moved this section to just before reading the SRT for summarization\n",
        "if DEBUG_MODE: print(\"[Summary 1/6] Checking GPU and installing llama-cpp-python ...\")\n",
        "\n",
        "def detect_cuda_tag():\n",
        "    try:\n",
        "        out = sp.check_output([\"nvidia-smi\"], text=True)\n",
        "        m = re.search(r\"CUDA Version:\\s*([\\d.]+)\", out)\n",
        "        if not m:\n",
        "            return \"cu124\"\n",
        "        major, minor = [int(x) for x in m.group(1).split(\".\")[:2]]\n",
        "        if major > 12 or (major == 12 and minor >= 5):\n",
        "            return \"cu125\"\n",
        "        return \"cu124\"\n",
        "    except Exception:\n",
        "        return \"cu124\"\n",
        "\n",
        "cuda_tag = detect_cuda_tag()\n",
        "if DEBUG_MODE: print(f\"GPU 0: Detected CUDA version tag {cuda_tag}\")\n",
        "\n",
        "def try_import_llama():\n",
        "    try:\n",
        "        from llama_cpp import Llama\n",
        "        return Llama\n",
        "    except ModuleNotFoundError:\n",
        "        return None\n",
        "\n",
        "Llama = try_import_llama()\n",
        "if Llama is None:\n",
        "    # Keep your existing installation strategy: extra-index -> fallback to source compilation on failure\n",
        "    candidates = [cuda_tag, \"cu125\", \"cu124\", \"cu122\", \"cu121\"]\n",
        "    ok = False\n",
        "    for tag in candidates:\n",
        "        idx = f\"https://abetlen.github.io/llama-cpp-python/whl/{tag}\"\n",
        "        if DEBUG_MODE: print(f\"→ Attempting to install llama-cpp-python ({tag}) ...\")\n",
        "        r = pip_install([\"llama-cpp-python\"], extra_args=[\"--extra-index-url\", idx])\n",
        "        if r.returncode == 0:\n",
        "            Llama = try_import_llama()\n",
        "            if Llama is not None:\n",
        "                ok = True\n",
        "                break\n",
        "        else:\n",
        "            if DEBUG_MODE: print(\"  ✗ Installation failed (summary):\", \"\\n\".join(r.stdout.splitlines()[-5:]))\n",
        "    if not ok:\n",
        "        if DEBUG_MODE: print(\"→ Pre-compiled wheels not available, switching to 'source compilation (CUDA=ON)' ... (takes longer)\")\n",
        "        try:\n",
        "            import ninja # noqa: F401 # Import ninja to check if installed\n",
        "        except ModuleNotFoundError:\n",
        "            if DEBUG_MODE: print(\"→ Installing missing package: ninja\")\n",
        "            r = pip_install([\"ninja\"])\n",
        "            if r.returncode != 0:\n",
        "                if DEBUG_MODE: print(r.stdout)\n",
        "                raise RuntimeError(\"安裝 ninja 失敗。請重啟後重試。\")\n",
        "        env = os.environ.copy()\n",
        "        env[\"CMAKE_ARGS\"] = \"-DGGML_CUDA=on -DLLAMA_CUBLAS=on\"\n",
        "        env[\"FORCE_CMAKE\"] = \"1\"\n",
        "        r = pip_install([\"llama-cpp-python\"], env=env)\n",
        "        if r.returncode != 0:\n",
        "            if DEBUG_MODE: print(r.stdout)\n",
        "            raise RuntimeError(\"無法安裝 GPU 版 llama-cpp-python。\")\n",
        "        Llama = try_import_llama()\n",
        "\n",
        "\n",
        "# ===== Summary 2/6) Read SRT (Summary) - Uses 'summary_srt_path_abs'\n",
        "if DEBUG_MODE: print(\"[Summary 2/6] Reading SRT ...\")\n",
        "assert summary_srt_path_abs.exists(), f\"SRT 檔不存在：{summary_srt_path_abs}\"\n",
        "with open(summary_srt_path_abs, \"r\", encoding=\"utf-8\") as f:\n",
        "    srt_text = f.read()\n",
        "subs = list(_srt.parse(srt_text)) # Use _srt as srt module was imported as _srt\n",
        "def td2s(td): return td.total_seconds()\n",
        "segments = []\n",
        "for it in subs:\n",
        "    txt = it.content.strip()\n",
        "    if not txt: continue\n",
        "    segments.append((td2s(it.start), td2s(it.end), txt))\n",
        "total_secs = (segments[-1][1] - segments[0][0]) if segments else 0\n",
        "if DEBUG_MODE: print(f\"→ Number of subtitle segments: {len(segments)}；Video length (est): {total_secs/60:.1f} minutes\")\n",
        "\n",
        "\n",
        "# ===== Summary 3/6) Download and Load GGUF Model (Summary) - Uses summary model parameters (REPO_ID, GGUF_FILE, ctx_window, etc.)\n",
        "# Moved this section to just after installing llama-cpp-python\n",
        "if DEBUG_MODE: print(\"[Summary 3/6] Loading GPT-OSS-20B (GGUF, CUDA) ...\")\n",
        "local_repo = snapshot_download(REPO_ID, allow_patterns=[GGUF_FILE])\n",
        "gguf_path = str(Path(local_repo)/GGUF_FILE)\n",
        "\n",
        "llm = Llama(\n",
        "    model_path=gguf_path,\n",
        "    n_ctx=ctx_window,\n",
        "    n_gpu_layers=-1,\n",
        "    seed=0,\n",
        "    logits_all=False,\n",
        "    verbose=True,          # Display the actual chat format used\n",
        "    chat_format=\"chatml\",  # Directly override the GGUF built-in Unsloth template to avoid outputting <|channel|> tags\n",
        ")\n",
        "if DEBUG_MODE: print(\"→ Model loaded successfully (GPU)\")\n",
        "\n",
        "\n",
        "# ===== Summary 4/6) Token-aware Segmentation (Summary) - Uses ctx_window, map_max_new_tokens, prompt_overhead\n",
        "if DEBUG_MODE: print(\"[Summary 4/6] Generating segments (token-aware; single segment ≤ safety limit) ...\")\n",
        "\n",
        "def count_tokens_text(text: str) -> int:\n",
        "    # Check if llm is initialized before using it\n",
        "    if 'llm' not in locals() or llm is None:\n",
        "         raise RuntimeError(\"LLM model is not loaded. Cannot count tokens.\")\n",
        "    return len(llm.tokenize(text.encode(\"utf-8\")))\n",
        "\n",
        "SYSTEM_INSTR = (\n",
        "  \"你是一個會議總結機器人。根據使用者提供的逐字稿（可能雜訊、重複、錯字），\"\n",
        "  \"請去除雜訊與重複、嚴守事實、不腦補。遇到不明確資訊以「待補充／未明確」標註。\"\n",
        "  \"輸出為 Markdown（繁體中文），不要輸出任何系統／思考標記。\"\n",
        ")\n",
        "\n",
        "# — Segment Summary Prompt: More concise request, avoid verbosity and system language - Uses 'topic_hint'\n",
        "MAP_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是逐字稿片段（非完整全文）：\n",
        "{chunk}\n",
        "\n",
        "請就此片段輸出「條列式重點摘要」（500–900 字，繁體中文），注意：\n",
        "- 只寫最終內容，不要寫解題想法、不要出現任何系統提示或中英括號標記。\n",
        "- 聚焦可驗證事實（時間、人物、任務、結論、未決事項、行動）。\n",
        "- 結構：可用小標題＋項目符號，語句務必短、準確、無贅詞。\n",
        "\"\"\")\n",
        "\n",
        "# — Summary Prompt: Maintain your three-section output structure - Uses 'topic_hint'\n",
        "REDUCE_USER_TMPL = textwrap.dedent(\"\"\"\\\n",
        "主題（可留空）：{topic}\n",
        "\n",
        "以下是所有片段的重點摘要彙整（仍可能有重疊）：\n",
        "{maps}\n",
        "\n",
        "請整合為一份會議筆記（Markdown，繁體）：\n",
        "1) **整體提要**（3–6 句，避免冗言）\n",
        "2) **章節要點（含時間脈絡）**：條列呈現，每點一行，可附粗略時間\n",
        "3) **可執行重點**：具體待辦（每條以動詞開頭）\n",
        "請只輸出最終筆記，不要出現系統或思考標記，不要加入未出現的新資訊。\n",
        "\"\"\")\n",
        "\n",
        "# Single segment token budget (reserve space for prompt and generation)\n",
        "prompt_overhead = 700\n",
        "chunk_target    = max(1024, min(3072, ctx_window - prompt_overhead - map_max_new_tokens))\n",
        "\n",
        "chunks: List[Tuple[float,float,str]] = []\n",
        "buf, t0, t1, cur = [], None, None, 0\n",
        "for (s, e, txt) in segments:\n",
        "    t = count_tokens_text(txt)\n",
        "    if not buf:\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "        continue\n",
        "    if cur + t <= chunk_target:\n",
        "        buf.append(txt); t1 = e; cur += t\n",
        "    else:\n",
        "        chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "        buf, t0, t1, cur = [txt], s, e, t\n",
        "if buf:\n",
        "    chunks.append((t0, t1, \"\\n\".join(buf)))\n",
        "\n",
        "if DEBUG_MODE: print(f\"→ Generated {len(chunks)} segments (target ~{chunk_target} tokens per segment)\")\n",
        "\n",
        "# ===== Common: Streaming Tools (No regex cleaning; use correct stop sequence) - Uses temperature, top_p, repeat_penalty, map_max_new_tokens, reduce_max_new_tokens\n",
        "def llm_stream(messages, max_tokens):\n",
        "    # Check if llm is initialized before using it\n",
        "    if 'llm' not in locals() or llm is None:\n",
        "         raise RuntimeError(\"LLM model is not loaded. Cannot stream generation.\")\n",
        "    # ChatML messages end with <|im_end|>; use stop to cut off, preventing the closing tag from being written to the file\n",
        "    gen = llm.create_chat_completion(\n",
        "        messages=messages,\n",
        "        temperature=float(temperature),\n",
        "        top_p=float(top_p),\n",
        "        repeat_penalty=float(repeat_penalty),\n",
        "        max_tokens=int(max_tokens),\n",
        "        stream=True,\n",
        "        stop=[\"<|im_end|>\"],  # Key: Prevent outputting the ending template\n",
        "    )\n",
        "    for ev in gen:\n",
        "        # Compatible with different fields\n",
        "        piece = \"\"\n",
        "        try:\n",
        "            piece = ev[\"choices\"][0][\"delta\"].get(\"content\", \"\")\n",
        "        except Exception:\n",
        "            piece = ev[\"choices\"][0].get(\"text\", \"\")\n",
        "        if piece:\n",
        "            yield piece\n",
        "\n",
        "# ===== Summary 5/6) Segment Summary (map) - Uses map_max_new_tokens, ctx_window, prompt_overhead, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 5/6] Segment summarization (map) ...\")\n",
        "live = display(Markdown(\"\"), display_id=True)\n",
        "maps: List[str] = []\n",
        "\n",
        "for i, (s, e, body) in enumerate(chunks, 1):\n",
        "    pct = i / max(len(chunks),1) * 100\n",
        "    sys.stdout.write(f\"  - 處理分段 {i}/{len(chunks)}（~{pct:.1f}%）\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Shrink to safe budget before sending (prevent prompt+segment from exceeding window and causing model to terminate early)\n",
        "    budget_tokens = max(512, ctx_window - map_max_new_tokens - prompt_overhead)\n",
        "    def shrink_to_budget(text: str, budget_tokens: int) -> str:\n",
        "        cur = text\n",
        "        for _ in range(6):\n",
        "            if count_tokens_text(cur) <= budget_tokens:\n",
        "                return cur\n",
        "            keep = max(800, int(len(cur) * 0.85))\n",
        "            cur = cur[:keep]\n",
        "        return cur\n",
        "    body2 = shrink_to_budget(body, budget_tokens)\n",
        "\n",
        "    user_txt = MAP_USER_TMPL.format(topic=(topic_hint or \"（無）\"), chunk=body2)\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_INSTR},\n",
        "        {\"role\": \"user\",   \"content\": user_txt},\n",
        "    ]\n",
        "\n",
        "    part_buf = [] # Reset part_buf for each segment\n",
        "    for token in llm_stream(messages, map_max_new_tokens):\n",
        "        part_buf.append(token)\n",
        "        # Update live display and terminal character count periodically\n",
        "        if len(part_buf) % 24 == 0:\n",
        "            cur_txt = \"\".join(part_buf)\n",
        "            live.update(Markdown(cur_txt))\n",
        "            sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "    cur_txt = \"\".join(part_buf)\n",
        "    live.update(Markdown(cur_txt))\n",
        "    sys.stdout.write(f\"    ↳ 分段 {i} 已產生字元：{len(cur_txt)}\\n\"); sys.stdout.flush()\n",
        "\n",
        "    # Include the model's final output directly, no regex cleaning\n",
        "    maps.append(cur_txt.strip())\n",
        "\n",
        "if DEBUG_MODE: print(\"→ Segment summarization complete\")\n",
        "\n",
        "# ===== Summary 6/6) Consolidate (reduce) & Only write .md (Summary) - Uses summary_output_dir, summary_srt_path_abs, reduce_max_new_tokens, ctx_window, topic_hint\n",
        "if DEBUG_MODE: print(\"[Summary 6/6] Consolidating summary (reduce) ...\")\n",
        "maps_md = \"\\n\\n---\\n\\n\".join(f\"### 片段 {i+1} 要點\\n\\n{m}\" for i, m in enumerate(maps))\n",
        "\n",
        "# If combined text exceeds window, truncate proportionally first (without changing text within segments to avoid breaking meaning)\n",
        "def fit_reduce_payload(md_text: str, max_ctx_tokens: int) -> str:\n",
        "    for _ in range(8):\n",
        "        need = count_tokens_text(md_text)\n",
        "        if need + reduce_max_new_tokens + 400 <= max_ctx_tokens:\n",
        "            return md_text\n",
        "        md_text = md_text[: int(len(md_text) * 0.9)]\n",
        "    return md_text\n",
        "\n",
        "md_cur = fit_reduce_payload(maps_md, ctx_window)\n",
        "\n",
        "user_txt = REDUCE_USER_TMPL.format(topic=(topic_hint or \"（無）\"), maps=md_cur)\n",
        "messages = [{\"role\":\"system\",\"content\":SYSTEM_INSTR},\n",
        "            {\"role\":\"user\",\"content\":user_txt}]\n",
        "\n",
        "live2 = display(Markdown(\"\"), display_id=True)\n",
        "final_buf = []\n",
        "for token in llm_stream(messages, reduce_max_new_tokens):\n",
        "    final_buf.append(token)\n",
        "    if len(final_buf) % 24 == 0:\n",
        "        live2.update(Markdown(\"\".join(final_buf)))\n",
        "        sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "live2.update(Markdown(\"\".join(final_buf)))\n",
        "sys.stdout.write(f\"    ↳ 彙整 已產生字元：{len(''.join(final_buf))}\\n\"); sys.stdout.flush()\n",
        "\n",
        "final_text = \"\".join(final_buf).strip()\n",
        "\n",
        "# Determine and create the summary output directory\n",
        "summary_output_dir_abs = to_abs_mydrive(summary_output_dir)\n",
        "summary_output_dir_abs.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Determine the summary output file path using the stem of the input SRT\n",
        "out_md = summary_output_dir_abs / f\"{Path(summary_srt_path_abs).stem}_summary.md\"\n",
        "\n",
        "with open(out_md, \"w\", encoding=\"utf-8\") as f:\n",
        "    f.write(final_text)\n",
        "\n",
        "print(f\"→ 完成 ✅  {out_md}\")\n",
        "try:\n",
        "    del llm\n",
        "except Exception:\n",
        "    pass\n",
        "gc.collect()\n",
        "if DEBUG_MODE: print(\"（顯存已釋放，如需重跑可直接再次執行）\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}